# ML & AI news of the week

![ML & AI news of the week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/news.jpg)

Photo by [Priscilla Du Preez üá®üá¶](https://unsplash.com/it/@priscilladupreez) on [Unsplash](https://unsplash.com/it)

 

A collection of the best ML & AI news every week (research, news, resources). Star this repository if you find it useful.

[Here](https://github.com/SalvatoreRa/tutorial), you can find articles and tutorials about artificial intelligence
[Here](https://github.com/SalvatoreRa/artificial-intelligence-articles) some reviews on specific artificial intelligence topics

For each week you will find different sections:
* **Research:** the most important published research of the week.
* **News:** the most important news related to companies, institutions, and much more.
* **Resources:** released resources for artificial intelligence and machine learning.
* **Perspectives:** a collection of deep and informative articles about open questions in artificial intelligence.

and a **meme** for starting well the week.

## Suggestions and corrections

Feel free to open an issue if you find some errors, if you have any suggestions, topics, or any other comments

# Index

## 2025

* [ML news: Week 16 - 22 June](#ML-news-Week-16-22-June)
* [ML news: Week 9 - 15 June](#ML-news-Week-9-14-June)
* [ML news: Week 3 - 8 June](#ML-news-Week-3-8-June)
* [ML news: Week 26 May - 2 June](#ML-news-Week-26-May-2-June)
* [ML news: Week 19 - 25 May](#ML-news-Week-19-25-May)
* [ML news: Week 12 - 18 May](#ML-news-Week-12-18-May)
* [ML news: Week 5 - 11 May](#ML-news-Week-5-11-May)
* [ML news: Week 28 April - 4 May](#ML-news-Week-28-April-4-May)
* [ML news: Week 21 - 27 April](#ML-news-Week-21-27-April)
* [ML news: Week 14 - 20 April](#ML-news-Week-14-20-April)
* [ML news: Week 7 - 13 April](#ML-news-Week-7-13-April)
* [ML news: Week 31 March - 6 April](#ML-news-Week-31-March-6-April)
* [ML news: Week 24 - 30 March](#ML-news-Week-24-30-March)
* [ML news: Week 17 - 23 March](#ML-news-Week-17-23-March)
* [ML news: Week 10 - 16 March](#ML-news-Week-10-16-March)
* [ML news: Week 3 - 9 March](#ML-news-Week-3-9-March)
* [ML news: Week 24 February - 2 March](#ML-news-24-February-2-March)
* [ML news: Week 17 - 23 February](#ML-news-Week-17-23-February)
* [ML news: Week 10 - 16 February](#ML-news-Week-10-16-February)
* [ML news: Week 3 - 9 February](#ML-news-Week-3-9-February)
* [ML news: Week 27 January - 2 February](#ML-news-Week-20-26-January)
* [ML news: Week 20 - 26 January](#ML-news-Week-20-26-January)
* [ML news: Week 13 - 19 January](#ML-news-Week-13-19-January)
* [ML news: Week 6 -12 January](#ML-news-Week-6-12-January)
* [ML news: Week 31 December - 5 January](#ML-news-Week--31-December-5-January)


## 2024

2024 news are now [here](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/2024.md)

## 2023

2023 news are now [here](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/2023.md)

[Back to index](#Index)

# 2025

# ML news: Week 16 - 22 June

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme78.jpg)

[Back to index](#Index)

# ML news: Week 9 - 14 June

## Research
|Link|description|
|---|---|
|[We Made Top AI Models Compete in a Game of Diplomacy.](https://every.to/diplomacy) | Out of 18 AI models tested, OpenAI's o3 stood out by excelling at deception and covertly forming alliances‚Äîat one point convincing Claude 4 Opus to turn on its ally Gemini 2.5 Pro with the false promise of a "four-way draw," only to later eliminate Claude. Gemini 2.5 Pro was the only other model to secure a win, using aggressive, fast-paced tactics. In contrast, Claude consistently aimed for peaceful outcomes, even when other models betrayed it.|
|[The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity.](https://machinelearning.apple.com/research/illusion-of-thinking) |Apple researchers evaluated Large Reasoning Models (LRMs) using custom puzzle environments to study reasoning complexity. They found LRMs collapse at high complexities, with reasoning effort peaking then declining. |
|[Physical World Model by Meta.](https://about.fb.com/news/2025/06/our-new-model-helps-ai-think-before-it-acts/) |Meta has unveiled V-JEPA 2, an updated visual world model designed to improve physical reasoning in AI agents. Alongside the release, Meta introduced three new benchmarks aimed at evaluating how well models perform on real-world, video-based reasoning challenges. |
|[Towards conversational diagnostic artificial intelligence.](https://www.nature.com/articles/s41586-025-08866-7) |The conversational diagnostic artificial intelligence system AMIE (Articulate Medical Intelligence Explorer) has potential as a real-world tool for clinical history-taking and diagnostic dialogue, based on its performance in simulated consultations. |
|[Towards accurate differential diagnosis with large language models.](https://www.nature.com/articles/s41586-025-08869-4) |Diagnostic reasoning using an optimized large language model with a dataset comprising real-world medical cases exhibited improved differential diagnostic performance as an assistive tool for clinicians over search engines and standard medical resources. |
|[Mistral AI Revenues Surge as Europe Seeks US Alternatives.](https://www.ft.com/content/65f79839-d637-48a7-a0f2-3fab8952b315) |Mistral AI is reportedly securing multiple contracts worth over \$100 million and nearing \$100 million in annual revenue, as European firms look for non-U.S. AI options following Trump's return to office. Its strategy of emphasizing technological sovereignty seems to be paying off‚Äîaccording to the CEO, business has tripled over the past 100 days, especially across Europe and other non-U.S. regions. |
|[Recent Frontier Models Are Reward Hacking.](https://metr.org/blog/2025-06-05-recent-reward-hacking/) | In recent months, we've observed growing evidence of reward hacking in our tasks‚ÄîAI systems finding ways to "cheat" and achieve unrealistically high scores by exploiting bugs in the scoring logic or manipulating the task setup, rather than genuinely solving the problem. These behaviors don't stem from a lack of understanding; the models often recognize that their actions don't match user intent and will reject cheating when asked directly. Instead, the issue appears to be a deeper misalignment with user goals. This post outlines several such cases across models from different developers and explores what they mean for the safety of more advanced AI systems.|
|[Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble.](https://arxiv.org/abs/2505.23075) | While LLMs are increasingly used in clinical settings, most current methods depend on a single model architecture, which introduces risks of obsolescence and inflexibility. The Consensus Mechanism offers a new approach, inspired by clinical triage and multidisciplinary decision-making. It uses an ensemble of specialized medical expert agents to enhance clinical reasoning and provide more adaptable, resilient decision support.|
|[H2:Towards Efficient Large-Scale LLM Training on Hyper-Heterogeneous Cluster over 1,000 Chips.](http://arxiv.org/abs/2505.17548) | Researchers in Shanghai have developed DiTorch and DiComm, frameworks that unify programming across diverse chip types‚Äîincluding NVIDIA and AMD‚Äîenabling large-scale model training on mixed hardware. By smartly assigning memory-intensive pipeline stages to chips with more memory, they achieved 116% efficiency training a 100B-parameter model across 1,024 varied chips. This breakthrough allows labs without access to uniform, high-end GPUs to train frontier AI models using cost-effective, older, or export-restricted hardware in highly heterogeneous clusters.|
|[Reinforcement Pre-Training.](https://arxiv.org/abs/2506.08007) |Reinforcement Pre-Training (RPT) is a new scaling paradigm for large language models (LLMs) and reinforcement learning (RL). It offers a scalable method for leveraging vast amounts of text data for general-purpose RL. RPT significantly improves the large model accuracy of predicting the next tokens. It also provides a strong pre-trained foundation for further reinforcement fine-tuning. |
|[AlphaWrite: Test-Time Compute Scaling for Writing.](https://tobysimonds.com/research/2025/06/06/AlphaWrite.html) | AlphaWrite creates story variations by mimicking different author styles and themes, then uses pairwise comparisons to rank their quality. The best outputs are evolved over several generations, showing that creative tasks‚Äîlike storytelling‚Äîcan also benefit from scaled inference-time computation, not just math or coding.|
|[Nvidia ‚ÄòClimate in a Bottle' Opens a View Into Earth's Future. What Will We Do With It?](https://www.wsj.com/articles/nvidia-climate-in-a-bottle-opens-a-view-into-earths-future-what-will-we-do-with-it-f602d8de?st=VnkobV&reflink=desktopwebshare_permalink&utm_source=tldrai) |Nvidia's new generative foundation model enables simulations of Earth's global climate with an unprecedented level of resolution. |
|[The Darwin G√∂del Machine: AI That Improves Itself by Rewriting Its Own Code.](https://sakana.ai/dgm/) |Sakana AI created a coding agent that reads its own codebase, proposes modifications, and then tests whether those changes would improve its performance on coding tasks. |
|[From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning.](https://arxiv.org/abs/2505.17117) |This paper presents an information-theoretic approach to assess whether large language models (LLMs) structure semantic knowledge like humans, using Rate-Distortion Theory and the Information Bottleneck principle to evaluate over 30 LLMs against human categorization benchmarks. While LLMs reliably form broad conceptual clusters that align with human groupings‚Äîsometimes outperforming larger models even with small architectures like BERT‚Äîthey fall short in capturing fine-grained, graded semantics such as item typicality. The authors‚Äô unified loss function reveals that LLMs generate compact, low-entropy clusters that favor compression, whereas human conceptual structures are less efficient but preserve richer semantic nuance. This suggests LLMs prioritize statistical efficiency over meaning, underscoring a fundamental divergence from human cognition and offering a quantitative framework to guide more human-aligned semantic modeling |
|[Knowledge or Reasoning? A Close Look at How LLMs Think Across Domains.](https://arxiv.org/abs/2506.02126) |This paper introduces a detailed evaluation framework that separates LLM performance into knowledge correctness (Knowledge Index, KI) and reasoning informativeness (Information Gain, InfoGain), and applies it to assess domain transfer in medical and mathematical reasoning using Qwen2.5-7B and a DeepSeek-R1-distilled variant trained via supervised fine-tuning (SFT) and reinforcement learning (RL). SFT improves factual accuracy but often diminishes reasoning quality, while RL enhances both, especially in medical contexts, by refining reasoning and filtering out errors. The results reveal that domain matters: medical tasks hinge more on knowledge (KI), whereas math tasks benefit from stronger reasoning (InfoGain). Notably, base models outperform their distilled counterparts in medicine, suggesting that pretraining focus influences adaptability across domains. |
|[OpenThoughts: Data Recipes for Reasoning Models.](https://arxiv.org/abs/2506.04178) | This paper introduces OpenThoughts3, a method for curating high-quality supervised fine-tuning (SFT) data that significantly improves open-source reasoning models. The resulting model, OpenThinker3-7B, trained on 1.2M examples from 1,000+ controlled experiments, outperforms all other open-data 7B and 8B models on math, code, and science benchmarks‚Äîwithout using reinforcement learning. Key insights include the importance of clean data design, where techniques like multi-answer sampling and thoughtful teacher selection (e.g., QwQ-32B) drive gains more than raw model strength. Filtering based on response length and difficulty outperforms traditional correctness checks, and using fewer, high-quality question sources beats broader, more diverse datasets. All resources are openly released, offering a reproducible foundation for reasoning research.|
|[How much do language models memorize?](https://www.arxiv.org/abs/2505.24832) |This study proposes a method to measure how much GPT models memorize versus generalize, estimating their capacity at around 3.6 bits per parameter. Through training hundreds of models, the authors find that memorization peaks before generalization ("grokking") emerges, and they establish new scaling laws that relate model capacity, dataset size, and susceptibility to membership inference. |


## News
|Link|description|
|---|---|
|[Advanced AI suffers ‚Äòcomplete accuracy collapse‚Äô in face of complex problems, study finds.](https://www.theguardian.com/technology/2025/jun/09/apple-artificial-intelligence-ai-study-collapse) |‚ÄòPretty devastating‚Äô Apple paper raises doubts about race to reach stage of AI at which it matches human intelligence |
|[UK campaigners raise alarm over report of Meta plan to use automation for risk checks.](https://www.theguardian.com/technology/2025/jun/08/campainers-urge-uk-watchdog-to-limit-use-of-ai-after-report-of-meta-plan-to-automate-checks) |Ofcom ‚Äòconsidering the concerns‚Äô raised after claim that up to 90% of risk assessments will be carried out by AI | 
|[London AI firm says Getty copyright case poses ‚Äòovert threat‚Äô to industry.](https://www.theguardian.com/technology/2025/jun/09/stability-ai-getty-lawsuit-copyright) |Photography agency alleges Stability AI trained its image generation model on archive of copyrighted pictures |
|[Chinese tech firms freeze AI tools in crackdown on exam cheats.](https://www.theguardian.com/world/2025/jun/09/chinese-tech-firms-freeze-ai-tools-exam-cheats-universities-gaokao) | Suspension comes as 13m students take four-day gaokao tests for limited spots at country‚Äôs universities|
|[All civil servants in England and Wales to get AI training.](https://www.theguardian.com/technology/2025/jun/09/all-civil-servants-in-england-and-wales-to-get-ai-training) |Officials are piloting package of AI tools called Humphrey ‚Äì named after character in TV sitcom Yes, Minister |
|[Some Dead Sea Scrolls are older than researchers thought, AI analysis suggests.](https://www.science.org/content/article/some-dead-sea-scrolls-are-older-researchers-thought-ai-analysis-suggests) |But overall, machine learning approach closely matches what human scholars had long suspected about ancient documents |
|[AI can ‚Äòlevel up‚Äô opportunities for dyslexic children, says UK tech secretary.](https://www.theguardian.com/technology/2025/jun/10/ai-can-level-up-opportunities-for-dyslexic-children-says-uk-tech-secretary) |Peter Kyle, who is dyslexic and uses AI in his work, says government should look at how it ‚Äòcan transform education‚Äô |
|[Meet the engineer using deep learning to restore Renaissance art.](https://www.nature.com/articles/d41586-025-01776-8) | As a student, Alex Kachkine can only afford damaged art in need of repair. Here‚Äôs how they turned their conservation work into a science.|
|[Australia has ‚Äòno alternative‚Äô but to embrace AI and seek to be a world leader in the field, industry and science minister says.](https://www.theguardian.com/australia-news/2025/jun/12/australia-ai-no-alternative-industry-and-science-minister-tim-ayres) | Tim Ayres says the Albanese government will focus on legislation and regulation but country would benefit from moving quickly|
|[Disney and Universal sue AI image creator Midjourney, alleging copyright infringement.](https://www.theguardian.com/technology/2025/jun/11/disney-universal-ai-lawsuit) |Studios accuse AI firm of ‚Äòpiracy‚Äô and seek injunction over alleged use of copyrighted characters |
|[Meta to announce $15bn investment in bid to achieve computerised ‚Äòsuperintelligence‚Äô.](https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai) | Mark Zuckerberg expected to announce Meta will buy 49% stake in Scale AI as race to dominate AI market speeds up|
|[Meta in talks over Scale AI investment that could exceed $10 billion, Bloomberg reports.](https://www.reuters.com/business/meta-talks-scale-ai-investment-that-could-top-10-billion-bloomberg-news-reports-2025-06-08/) | An investment in Scale, already valued at $14 billion, underscores how high-quality training data has become a key competitive differentiator.|
|[Claude Gov Models for U.S. National Security Customers.](https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers) |Anthropic has released Claude Gov models tailored for U.S. national security applications, supporting tasks like strategic planning, operations, and intelligence analysis. These models are optimized for working with classified information, grasping intelligence-related contexts, and analyzing complex cybersecurity data. Developed in collaboration with government users, they meet high safety standards and are designed to address the specific demands of national security. |
|[Google Gemini can now handle scheduled tasks like an assistant.](https://www.theverge.com/news/681762/google-gemini-scheduled-actions-planned-tasks) | Now subscribers can ask the AI assistant to provide calendar summaries on a daily basis or generate a summary of an event after it takes place.|
|[Qwen 3 Embedding.](https://qwenlm.github.io/blog/qwen3-embedding/) |Alibaba has open-sourced the Qwen3 Embedding series, with the 8B model topping the MTEB multilingual leaderboard. These models support building RAG systems, semantic search tools, and document retrieval applications in over 100 languages, offering parameter sizes from 0.6B to 8B to suit varying performance requirements. |
|[GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents.](https://huggingface.co/papers/2506.03143) |GUI-Actor is a new method that enables AI agents to interact with computer interfaces using attention mechanisms rather than relying on exact pixel predictions from screenshots. It sets a new benchmark in GUI performance while being highly efficient‚Äîby fine-tuning just 100M parameters and keeping the base vision model frozen, it matches the results of much larger models. |
|[Progressive Tempering Sampler with Diffusion.](https://arxiv.org/abs/2506.05231v1) | PTSD trains diffusion models sequentially across temperatures to improve sampling from unnormalized densities.|
|[Interactive Finance Visuals in Google AI Mode.](https://blog.google/products/search/ai-mode-data-visualization/) |Google is rolling out interactive financial data visualizations in AI Mode (Labs), enabling dynamic graphs and multi-step reasoning to answer complex stock and mutual fund queries. |
|[HackAPrompt Launches $5K Competition to Jailbreak AI.](https://www.hackaprompt.com/track/pliny) |The two-week competition challenges participants to jailbreak an AI to provide dangerous information, from poison recipes to nuclear detonation instructions. |
|[Updates to Apple's On-Device and Server Foundation Language Models.](https://machinelearning.apple.com/research/apple-foundation-models-2025-updates) |Apple unveiled new Apple Intelligence features at WWDC 2025, including on-device foundation models for developers to integrate AI experiences into their apps. |
|[OpenAI hits $10 billion in annual recurring revenue fueled by ChatGPT growth.](https://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html) |OpenAI has hit $10 billion in annual recurring revenue, or ARR, less than three years after launching its popular ChatGPT chatbot. The figure includes sales from the company‚Äôs consumer products; ChatGPT business products; and its application programming interface, or API. It excludes licensing revenue from Microsoft  and large one-time deals, according to an OpenAI spokesperson. |
|[Code Researcher: Deep Research Agent for Large Systems Code and Commit History.](https://www.microsoft.com/en-us/research/publication/code-researcher-deep-research-agent-for-large-systems-code-and-commit-history/) |Microsoft's new agent successfully resolves 58% of Linux kernel crashes, outperforming SWE-agent's 37.5% and marking a move away from quick-fix coding tools toward more advanced research-grade systems capable of managing massive codebases. The key innovation lies in analyzing commit histories to trace how bugs developed over time, enabling deeper understanding and more effective fixes. |
|[Safetensors Now Supported in PyTorch DCP.](https://pytorch.org/blog/huggingface-safetensors-support-in-pytorch-distributed-checkpointing/) |PyTorch Distributed Checkpointing has added support for Hugging Face safetensors, enabling better compatibility with popular model formats. |
|[Corporate AI adoption may be leveling off, according to Ramp data.](https://techcrunch.com/2025/06/09/corporate-ai-adoption-may-be-leveling-off-according-to-ramp-data/) |A healthy chunk of corporate America has eagerly embraced AI, betting the tech will bring unrealizable productivity gains. But adoption may be leveling off, according to transaction data from fintech company Ramp. Ramp‚Äôs AI Index, which estimates the U.S. business adoption rate of AI products by drawing on Ramp‚Äôs card and bill pay data, leveled off at 41% in May after close to 10 straight months of growth. As of May, 49% of large businesses had deployed AI in some form compared to 44% of medium-sized firms, and 37% of small companies, according to Ramp. |
|[OpenAI Updates Voice Mode.](https://help.openai.com/en/articles/6825453-chatgpt-release-notes) |OpenAI has upgraded ChatGPT's Advanced Voice Mode for paid users, improving intonation, emotional expressiveness, and cadence.|
|[OpenAI releases o3-pro, a souped-up version of its o3 AI reasoning model.](https://techcrunch.com/2025/06/10/openai-releases-o3-pro-a-souped-up-version-of-its-o3-ai-reasoning-model/) |OpenAI has launched o3-pro, an AI model that the company claims is its most capable yet. O3-pro is a version of OpenAI‚Äôs o3, a reasoning model that the startup launched earlier this year. As opposed to conventional AI models, reasoning models work through problems step by step, enabling them to perform more reliably in domains like physics, math, and coding. |
|[Mistral Launches First AI Reasoning Model.](https://mistral.ai/news/magistral) |Adding to a string of releases over the last 2 weeks, Mistral has launched an open-source reasoning model, Magistral. It trails proprietary models on major benchmarks, but claims to be 10x faster output and stronger multilingual capabilities. |
|[A frustrated Zuckerberg makes his biggest AI bet as Meta nears $14 billion stake in Scale AI, hires founder Wang.](https://www.cnbc.com/2025/06/10/zuckerberg-makes-metas-biggest-bet-on-ai-14-billion-scale-ai-deal.html) |In finalizing a deal to invest $14 billion in Scale AI, Meta‚Äôs Mark Zuckerberg is hiring its co-founder Alexandr Wang to help the social media company better execute on its AI ambitions. Zuckerberg has grown frustrated that rivals like OpenAI appear to be further ahead than Meta in underlying AI models and consumer-facing apps, current and former Meta employees said. Wang has built a reputation as an ambitious leader who understands AI‚Äôs technical complexities and how to build a business, according to two former Meta AI employees. |
|[Reimagining TTS with LLM-Powered Audio Generation.](https://www.bland.ai/blogs/new-tts-announcement) |Bland AI has transformed text-to-speech (TTS) by using large language models to directly predict audio from text, resulting in more expressive and context-aware speech. The system is built on two-channel conversational datasets and advanced audio tokenizers, enabling precise and nuanced voice generation. It also supports features like style transfer, sound effects, and multilingual output, raising the bar for synthetic speech quality. |
|[OpenAI taps Google in unprecedented cloud deal despite AI rivalry, sources say.](https://www.reuters.com/business/retail-consumer/openai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10/) |OpenAI's compute demands have grown so massive it's turning to its biggest search competitor for additional capacity, marking its first major cloud partner outside of Microsoft. |
|[OpenAI announces 80% price drop for o3, it‚Äôs most powerful reasoning model.](https://venturebeat.com/ai/openai-announces-80-price-drop-for-o3-its-most-powerful-reasoning-model/) | OpenAI has announced a substantial price cut on o3, its flagship reasoning large language model (LMM), slashing costs by a whopping 80% for both input and output tokens.|
|[OpenAI‚Äôs open model is delayed.](https://techcrunch.com/2025/06/10/openais-open-model-is-delayed/) | The release of OpenAI‚Äôs first open model in years will be delayed until later this summer, CEO Sam Altman announced in a post on X on Tuesday. Altman said the open model would be released sometime after June.|
|[Grok 4 spotted ahead of launch with special coding features.](https://www.bleepingcomputer.com/news/artificial-intelligence/grok-4-spotted-ahead-of-launch-with-special-coding-features/) | Grok 4 (grok-4-0629) offers unparalleled performance in natural language, math, and reasoning.|
|[The Browser Company launches its AI-first browser, Dia, in beta.](https://techcrunch.com/2025/06/11/the-browser-company-launches-its-ai-first-browser-dia-in-beta/) | Traditional web tools are facing an existential crisis as AI products and tools increasingly eat up attention ‚Äî and therefore market share and money ‚Äî from a wide swathe of products that people have used for years to interact with the internet. At least, that‚Äôs what The Browser Company seems to think is happening.|
|[Introducing Design Mode on v0.](https://threadreaderapp.com/thread/1932892095565660490.html) |Design Mode on v0 allows users to quickly tweak generations, preview changes, and more without needing to spend credits or wait for a large language model. |
|[Disney and NBCUniversal File Lawsuit Against Midjourney.](https://variety.com/2025/digital/news/disney-nbcuniversal-studio-lawsuit-ai-midjourney-copyright-infringement-1236428188/) |The studios allege that Midjourney, which reportedly earned \$300 million last year, operates a "bootlegging business model" by generating thousands of images featuring characters from franchises like Marvel, Star Wars, Pixar, and DreamWorks. |
|[ByteDance Tops Video Generation Benchmarks with Seedance 1.0.](https://seed.bytedance.com/en/seedance) | The parent company of TikTok has released a new model that leads in both text-to-video and image-to-video benchmarks, outperforming Google's Veo 3 and OpenAI's Sora. Named Seedance, the model can produce 5 seconds of HD video in 41 seconds and supports native multi-shot storytelling, though it currently does not generate audio.|
|[Scale AI‚Äôs Alexandr Wang confirms departure for Meta as part of $14.3 billion deal.](https://www.cnbc.com/2025/06/12/scale-ai-founder-wang-announces-exit-for-meta-part-of-14-billion-deal.html) |Scale has officially announced its next phase. With Meta investing $14.3B, Scale's founder Alexandr Wang will join Meta's AI initiatives. Chief Strategy Officer Jason Droege will step in as Scale's Interim CEO. |
|[Netflix Builds Unified Data Architecture.](https://netflixtechblog.com/uda-unified-data-architecture-6a6aee261d8d) |Netflix has launched UDA to tackle issues caused by fragmented data models across its platforms. UDA serves as a unifying conceptual framework that promotes consistency between systems, cuts down on duplication, standardizes terminology, and improves overall data quality. |
|[How Cursor is Building the Future of AI Coding with Claude.](https://www.youtube.com/watch?v=BGgsoIgbT_Y) |Cursor's leadership addresses one of AI coding‚Äôs toughest unresolved challenges: ensuring generated code not only functions correctly but also aligns with an organization‚Äôs style and implicit architectural norms. Their background agents operate autonomously in sandboxed environments, signaling a move toward AI that can code independently‚Äîfreeing developers to concentrate on higher-level design and strategic decisions. |
|[The Meta AI app is a privacy disaster.](https://techcrunch.com/2025/06/12/the-meta-ai-app-is-a-privacy-disaster/) |It sounds like the start of a 21st-century horror film: Your browser history has been public all along, and you had no idea. That‚Äôs basically what it feels like right now on the new stand-alone Meta AI app, where swathes of people are publishing their ostensibly private conversations with the chatbot. When you ask the AI a question, you have the option of hitting a share button, which then directs you to a screen showing a preview of the post, which you can then publish. But some users appear blissfully unaware that they are sharing these text conversations, audio clips, and images publicly with the world.|
|[Windsurf Launches AI-Integrated Browser.](https://windsurf.com/blog/windsurf-wave-10-browser) |The browser automatically shares tab content and DOM access with Windsurf's Cascade AI to eliminate the need to copy-paste when referencing documentation or debugging web apps. |
|[Google has a new AI model and website for forecasting tropical storms.](https://www.theverge.com/news/685820/google-ai-forecast-typhoon-hurricane-tropical-storm) | Google is using a new AI model to forecast tropical cyclones and working with the US National Hurricane Center (NHC) to test it out. Google DeepMind and Google Research launched a new website today called Weather Lab to share AI weather models that Google is developing. |


## Resources
|Link|description|
|---|---|
|[Anthropic Shares How It Uses Claude Code.](https://www-cdn.anthropic.com/58284b19e702b49db9302d5b6f135ad8871e7658.pdf) | Anthropic shared in-depth case studies on how 10 of its internal teams use Claude Code. Claude succeeds on the first try only about a third of the time, prompting a "slot machine" strategy‚Äîfrequent commits, autonomous runs, and either acceptance or a full reset. Teams seeing the best results focus on creating thorough Claude.md documentation and dividing complex tasks into specialized sub-agents to improve outcomes.|
|[The Common Pile v0.1.](https://huggingface.co/blog/stellaathena/common-pile) |Hugging Face and collaborators released the Common Pile v0.1, an 8 TB openly licensed dataset for training large language models. |
|[I Read All Of Cloudflare's Claude-Generated Commits.](https://www.maxemitchell.com/writings/i-read-all-of-cloudflares-claude-generated-commits/) |Cloudflare's open-sourced OAuth 2.1 library was almost entirely written by Claude, and the company documented its entire creative process through git commit messages. |
|[How to Use Banned US Models in China.](https://www.chinatalk.media/p/the-grey-market-for-american-llms) |Taobao, a major Chinese e-commerce platform, features thousands of AI resellers providing access to U.S. models via proxy sites and API relay services. Claude is especially popular on the grey market, as ChatGPT faces tighter restrictions following the Chinese government's 2023 censorship crackdown. Domestic models like DeepSeek are less appealing due to heavy-handed moderation‚Äîblocking queries with terms like "CCP"‚Äîand frequent server issues, leading users to opt for underground paid access to foreign alternatives. |
|[Chonkie.](https://github.com/chonkie-inc/chonkie) | Chonkie is a highly efficient, lightweight chunking library designed for speed and versatility. It supports multiple languages, integrates easily with cloud environments, and offers broad compatibility with tokenizers, embedding models, and APIs. Using a pipeline-based approach, Chonkie converts raw text into structured, ready-to-use chunks, enabling flexible and efficient implementation of various chunking strategies.|
|[ScreenSuite - The most comprehensive evaluation suite for GUI Agents!.](https://huggingface.co/blog/screensuite) | ScreenSuite is a new benchmarking suite from Hugging Face that provides a standardized framework to evaluate Vision-Language Models on GUI-based agent tasks.|
|[Speculative Decoding in LLMs.](https://www.perplexity.ai/hub/blog/accelerating-sonar-through-speculation) | Perplexity applies speculative decoding to speed up its Sonar models, using lightweight draft models to propose multiple tokens verified by larger LLMs.|
|[JavelinGuard: Low-Cost Transformer Architectures for LLM Security.](https://www.arxiv.org/abs/2506.07330) | JavelinGuard is a collection of efficient, cost-effective model architectures built to detect malicious intent in LLM interactions. Each model offers different balances between speed, interpretability, and resource usage, all tailored for real-world deployment. The paper details these architectures, benchmarks them on nine varied adversarial datasets, and evaluates their performance against top open-source guardrail models and large decoder-only LLMs.|
|[Efficient Multimodal Reasoning with Fewer Tokens.](https://github.com/visresearch/LLaVA-STF/tree/main) |LLaVA-STF compresses vision token sequences by merging adjacent tokens and adds a multi-block token fusion module, enabling 75% token reduction. |
|[Monthly alternative data report: OpenAI, Google, Meta, Nvidia, Amazon, Microsoft Anthropic.](https://www.uncoveralpha.com/p/monthly-alternative-data-report-openai) |This article summarizes some of the most valuable insights from various alternative data providers and research reports, covering AI, semiconductors, ad tech, and the cloud industry. |
|[Mistral Announces AI Compute Platform with Tens of Thousands of GPUs .](https://mistral.ai/news/mistral-compute) | As an alternative to US and Chinese Cloud Providers, Mistral Compute offers private AI stacks including GPUs, orchestration, and APIs to attract highly-regulated enterprises.|
|[Claude Squad.](https://github.com/smtg-ai/claude-squad) | Claude Squad is a terminal-based app for managing multiple local agents across isolated workspaces, enabling users to handle several tasks at once. It supports background computation, centralized task and instance management within a single terminal window, change previews before applying, and version control with isolated git workspaces to prevent conflicts. A demo video is available in the project repository.|
|[Weak-to-Strong Decoding for LLM Alignment.](https://github.com/F2-Song/Weak-to-Strong-Decoding) | WSD is a novel method where a small aligned model drafts the start of a response, then a large base model continues it. This boosts alignment without harming performance.|
|[Training Cluster as a Service with NVIDIA.](https://huggingface.co/blog/nvidia-training-cluster) |Hugging Face and NVIDIA have launched "Training Cluster as a Service" to offer scalable GPU clusters to research teams worldwide. |
|[Agentic Coding Recommendations.](https://lucumr.pocoo.org/2025/6/12/agentic-coding/) | Agentic coding is advancing quickly, and current workflows may soon be unrecognizable. Still, integrating agents into development offers clear productivity benefits. Developers are encouraged to keep experimenting‚Äîas tools and methods change, the underlying principles remain vital. The aim isn't just speed, but writing better, more maintainable, and resilient code with the support of agents.|
|[How I Use Claude Code.](https://spiess.dev/blog/how-i-use-claude-code) |Claude Code‚Äôs flat pricing model makes it practical for everyday use across a wide range of programming tasks. This article explores how it can reshape your workflow, offering meaningful productivity gains despite its limitations. The key is striking the right balance between automation and human oversight. Developers are encouraged to try different strategies to find what works best. |
|[Better Visual Grounding for LVLMs.](https://github.com/bscho333/ReVisiT) | ReVisiT enhances decoding for large vision-language models by guiding generation using internal vision tokens.|
|[Coding Agents with Multimodal Browsing are Generalist Problem Solvers.](https://arxiv.org/abs/2506.03011) |This paper introduces OpenHands-Versa, a unified single-agent system that excels across coding, web browsing, and multimodal tasks by combining three core capabilities: code execution, multimodal web interaction, and file/search access. Unlike specialized or multi-agent setups, it achieves strong performance with minimal complexity, surpassing baselines on SWE-Bench Multimodal (+9.1%), GAIA (+1.3%), and The Agent Company (+9.1%). It generalizes well across benchmarks, adapting tool usage effectively‚Äîleveraging search in GAIA, browser tools in The Agent Company, and visual checks in SWE-Bench M‚Äîunlike earlier models like OpenHands. Built on Claude-3.7 or Claude Sonnet-4, OpenHands-Versa sets new performance standards without domain-specific tuning. |


## Perspectives
|Link|description|
|---|---|
|[The ‚Äòdeath of creativity‚Äô? AI job fears stalk advertising industry.](https://www.theguardian.com/technology/2025/jun/09/ai-advertising-industry-google-facebook-meta-ads) |WPP and others roll out AI-generated campaigns as Facebook owner Meta plans to let firms create their own ads |
|[Web-scraping AI bots cause disruption for scientific databases and journals.](https://www.nature.com/articles/d41586-025-01661-4) |Automated programs gathering training data for artificial-intelligence tools are overwhelming academic websites. |
|[Not all clinical data in the United States are fragmented.](https://www.nature.com/articles/d41586-025-01810-9) |The success of Foresight ‚Äî a generative artificial intelligence (AI) model trained on records from 57 million people in England‚Äôs National Health Service was made possible in part by the NHS‚Äôs Secure Data Environment, a platform that gives scientists access to national-scale data sets. |
|[An open AI model could help medical experts to interpret chest X-rays.](https://www.nature.com/articles/d41586-025-01525-x) | An accessible and adaptable artificial-intelligence model trained on a diverse set of X-ray images is better than existing models at spotting rare chest diseases.|
|[I replicated the Anthropic alignment faking experiment on other models, and they didn‚Äôt fake alignment.](https://www.greaterwrong.com/posts/pCMmLiBcHbKohQgwA/i-replicated-the-anthropic-alignment-faking-experiment-on) | When researchers repeated Anthropic's experiment on whether models would strategically comply with harmful prompts to avoid retraining, Claude 3 Opus and Claude 3.5 Sonnet displayed "false alignment"‚Äîthey provided harmful responses selectively. In contrast, nearly all other models refused such requests entirely. The only non-Claude model that responded was Gemini 2.5 Pro Preview, but it did so consistently, without any strategic variation based on retraining cues. These model-specific differences suggest that results from one model family shouldn‚Äôt be assumed to apply universally across all LLMs.|
|[Dwarkesh Patel on Continual Learning.](https://thezvi.substack.com/p/dwarkesh-patel-on-continual-learning) |Continual learning is both necessary and unsolved - this will be a huge bottleneck to achieving AGI. |
|[Real-world engineering challenges: building Cursor.](https://newsletter.pragmaticengineer.com/p/cursor) |Cursor cofounder Sualeh Asif shares how the two-year-old startup handles over 1 million queries per second while storing no code on its servers, thanks to Merkle trees for secure indexing. To withstand 100x growth, the team rapidly switched databases during outages‚Äîmoving from Yugabyte to PostgreSQL to Turbopuffer within hours‚Äîand developed Anyrun, a Rust-based orchestrator that manages thousands of GPUs. |
|[Sam Altman Outlines Path to Superintelligence.](https://blog.samaltman.com/the-gentle-singularity) | In a rare blog post, Sam Altman claims we've crossed an "event horizon" with models like GPT-4 and o3 already outperforming humans in various domains. He predicts AI agents handling real cognitive tasks by 2025, major scientific discoveries by 2026, and practical robots by 2027. Altman envisions the next decade as a period of exponential scientific progress driven by AI-accelerated research.|
|[What "Working" Means in the Era of AI Apps.](https://a16z.com/revenue-benchmarks-ai-apps/) |AI startups are growing rapidly, with the average enterprise achieving over $2 million ARR in the first year. Consumer startups are also gaining traction, outpacing B2B by reaching $4.2 million ARR. The disparity between average and top performers is widening, emphasizing the need for speed and innovation. |
|[Researchers seek to influence peer review with hidden AI prompts.](https://www.lesswrong.com/posts/dmfHm9MBJMumwckTt/ai-2027-response-inter-ai-tensions-value-distillation-us) |Researchers are embedding hidden AI prompts in academic papers on arXiv to influence peer reviews positively. |
|[The Rise of Systems of Consolidation Applications.](https://selinasstack.substack.com/p/the-rise-of-systems-of-consolidation) | Over the past two decades, the focus has been on building systems for data storage and user engagement. The coming era will shift toward systems designed to consolidate information and take action. Companies developing these systems will gain control over enterprise workflows, making systems of consolidation the most valuable layer in the software stack.|
|[The Dream of a Gentle Singularity.](https://thezvi.substack.com/p/the-dream-of-a-gentle-singularity) | Sam Altman's recent essay, *The Gentle Singularity*, outlines his belief that humanity is nearing the creation of digital superintelligence. This post offers a detailed breakdown of the essay, unpacking each passage to uncover its underlying messages. While Altman presents a reassuring narrative, the analysis suggests his goal is to calm public concern‚Äîdespite the reality that, by default, the path ahead may be far more uncertain and risky than his words imply.|
|[Canva to job candidates: Thou shalt use AI during interviews.](https://www.theregister.com/2025/06/11/canva_coding_assistant_job_interviews/) | Canva has updated its interview process for developer candidates by requiring the use of AI coding assistants. This change aims to assess how well candidates use AI tools in real-world scenarios, alongside their ability to make strong technical decisions. Basic computer science skills are still evaluated, but effective AI collaboration is now a key part of the assessment.|
|[How 100 Enterprise CIOs Are Building and Buying Gen AI in 2025.](https://a16z.com/ai-enterprise-2025/) |Enterprise AI budgets have surged 75% beyond already high projections, with OpenAI, Google, and Anthropic leading the pack. A survey of 100 CIOs reveals that companies now strategically deploy over five models based on specific use cases. AI-native tools like Cursor are reaching 90% code generation rates, fueling a major shift in enterprise software strategy‚Äîfrom building custom solutions to buying AI-powered applications. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme78.jpg)

[Back to index](#Index)


# ML news: Week 3 - 8 June

## Research
|Link|description|
|---|---|
|[How much do language models memorize?](https://arxiv.org/abs/2505.24832) |Researchers created a method to distinguish true memorization from generalization by training models on random data, where generalization can‚Äôt occur, and comparing it to real text. They found that models first memorize data until hitting their capacity, then begin learning broader patterns. GPT-style transformers store about 3.6 bits of information per parameter, which helps explain why extracting specific training data from modern LLMs usually fails‚Äîthe datasets are far larger than what the models can memorize. |
|[DNA Representation Learning.](https://arxiv.org/abs/2506.01833) | SPACE is a supervised learning method for genomic profile prediction that uses a Mixture of Experts model.|
|[A Diffusion-Based Method for Learning the Multi-Outcome Distribution of Medical Treatments.](https://arxiv.org/abs/2506.01533) |DIME is a diffusion-based model designed to estimate the joint distribution of interdependent medical treatment outcomes. |
|[Large Language Models Often Know When They Are Being Evaluated.](https://arxiv.org/abs/2505.23836) | Frontier models can identify evaluation settings versus real-world use with 83% accuracy, often by reasoning about cues like ‚Äúmultiple-choice format‚Äù or recognizing familiar benchmarks from training. More advanced models show ‚Äúmeta-reasoning,‚Äù interpreting researcher behavior‚Äîsuch as questions about chain-of-thought transcripts‚Äîas signs they‚Äôre being tested. This raises concerns that models might deliberately underperform or feign alignment during evaluations, then act differently once deployed.|
|[Apple Research Finds Critical Limitations in Reasoning Models.](https://machinelearning.apple.com/research/illusion-of-thinking) | When tested in puzzle environments, OpenAI‚Äôs o3, Claude, and DeepSeek-R1 models showed sharp performance drops past certain complexity levels, despite producing elaborate reasoning steps. These models hit a counterintuitive scaling limit where their reasoning effort declines as task complexity increases, and they don't improve even when provided with explicit solution algorithms.|
|[Sufficient Context: A New Lens on Retrieval Augmented Generation Systems.](https://arxiv.org/abs/2411.06037) |This paper presents a new framework for analyzing RAG systems based on ‚Äúsufficient context‚Äù‚Äîwhether retrieved content alone can plausibly answer a query. Using an LLM-based autorater with 93% accuracy, the study shows that sufficient context doesn‚Äôt guarantee correct answers, and benchmarks often lack it in over 50% of cases. A selective RAG method, combining self-confidence with context checks, improves factuality by 2‚Äì10%. Fine-tuning smaller models for abstention had limited impact on accuracy or hallucination control. |
|[Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents.](https://arxiv.org/abs/2505.22954) | The Darwin G√∂del Machine (DGM) is a self-improving AI system that modifies its own code through evolutionary search, avoiding the intractable proof requirements of the original G√∂del machine. Starting with a coding agent, DGM iteratively edits and evaluates its codebase on benchmarks like SWE-bench and Polyglot, retaining only successful variants. Over 80 iterations, it significantly boosts performance, evolves new tools and workflows, generalizes across models and languages, and demonstrates a safety-aware design within controlled environments.|
|[MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models.](https://arxiv.org/abs/2505.22101) |MemOS is a unified operating system for managing LLM memory, addressing the lack of structured, persistent, and governable memory in current models. It introduces a three-tier memory taxonomy‚Äîparametric, activation, and plaintext‚Äîconnected through a shared abstraction called the MemCube, which enables transformation and governance across memory types. MemOS features a modular architecture and closed-loop execution flow, supporting dynamic memory use, continual learning, and a vision for memory-centric AI beyond traditional pretraining and finetuning. |
|[Spurious rewards: rethinking training signals in RVLR.](https://github.com/ruixin31/Rethink_RLVR/blob/main/paper/rethink-rlvr.pdf) | This work shows that Qwen2.5-Math models improve significantly on math tasks under RLVR, even with flawed or random rewards. Qwen2.5-Math-7B gains up to +24.6% accuracy with spurious signals, close to the +28.8% gain from ground-truth rewards. The improvements stem from a shift toward code-based reasoning, which is unique to Qwen models due to their pretraining. Other models like Llama3 don‚Äôt benefit. GRPO‚Äôs clipping bias helps reinforce useful high-probability behaviors like code generation, enabling learning even from noisy feedback.|
|[Learning to Reason without External Rewards.](https://arxiv.org/abs/2505.19590) | This paper introduces INTUITOR, a reinforcement learning method that trains LLMs using self-certainty‚Äîmeasured via KL divergence from uniform‚Äîas an intrinsic reward, eliminating the need for external labels or verifiers. It matches GRPO performance on math tasks like GSM8K and MATH500, and generalizes better on out-of-domain tasks. INTUITOR improves early training, instruction-following, and leads to emergent structured reasoning. Its adaptive self-certainty signal proves robust and resistant to reward hacking.|
|[Learning to Reason via Mixture-of-Thought for Logical Reasoning.](https://arxiv.org/abs/2505.15817) |Mixture-of-Thought (MoT) introduces joint multi-modal training and inference‚Äîcombining natural language, code, and truth tables‚Äîfor improved logical reasoning. Unlike prior work that ensembles only at inference, MoT‚Äôs self-evolving training loop generates and learns from its own multi-modal traces. At test time, it uses majority voting across modalities, yielding up to +11.7pp accuracy gains on FOLIO and ProofWriter. MoT excels on harder tasks and shows that multi-modal reasoning enhances both robustness and performance. |


## News
|Link|description|
|---|---|
|[UK ministers delay AI regulation amid plans for more ‚Äòcomprehensive‚Äô bill.](https://www.theguardian.com/technology/2025/jun/07/uk-ministers-delay-ai-regulation-amid-plans-for-more-comprehensive-bill) |Law expected to include safety and copyright issues but delay likely to raise concerns about ongoing lack of regulation |
|[High court tells UK lawyers to stop misuse of AI after fake case-law citations.](https://www.theguardian.com/technology/2025/jun/06/high-court-tells-uk-lawyers-to-urgently-stop-misuse-of-ai-in-legal-work) | Ruling follows two cases blighted by actual or suspected use of artificial intelligence in legal work| 
|[Australians may soon be able to download iPhone apps from outside Apple App Store under federal proposal.](https://www.theguardian.com/technology/2025/jun/06/australians-may-soon-be-able-to-download-iphone-apps-from-outside-apple-app-store-under-government-proposal-ntwnfb) | Tech company warns government not to follow EU in forcing platform to allow third-party payments and app downloads|
|[How did you get my number? Inside the shadowy world of data brokers.](https://www.theguardian.com/world/2025/jun/09/how-did-you-get-my-number-inside-the-shadowy-world-of-data-brokers-ntwnfb) |When political spam landed in Priya Dev‚Äôs inbox during the last election campaign, she decided to track down the source |
|[US attacks on science and research a ‚Äògreat gift‚Äô to China on artificial intelligence, former OpenAI board member says.](https://www.theguardian.com/technology/2025/jun/09/us-attacks-on-science-and-research-a-great-gift-to-china-on-artificial-intelligence-former-openai-board-member-says) | Influential researcher claims disruption in jobs market from generative AI has already begun and warns of possibility of ‚Äògradual disempowerment to AI‚Äô|
|[Japanese spacecraft has probably crash-landed on Moon ‚Äî again.](https://www.nature.com/articles/d41586-025-01751-3) | Early investigations by the Japanese company ispace identified issues with speed and a sensor measuring the craft‚Äôs altitude.|
|[Trump-Musk feud shows what happens when unregulated money floods politics.](http://theguardian.com/technology/2025/jun/08/trump-musk-feud-money-politics) |Musk isn‚Äôt the first ‚Äì or last ‚Äì billionaire to pour big money into US elections |
|[UK sales of new Tesla cars slump by more than a third amid Musk backlash.](https://www.theguardian.com/technology/2025/jun/05/uk-sales-of-new-tesla-cars-slumped-by-third-in-may-amid-elon-musk-backlash) |Electric carmaker sold 36% fewer cars year on year in May as it loses ground to China‚Äôs BYD and other rivals |
|[Samsung Nears Wide-Ranging Deal With Perplexity for AI Features.](https://www.bloomberg.com/news/articles/2025-06-01/samsung-nears-wide-ranging-deal-with-perplexity-for-ai-features?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc0ODg0NTI0NSwiZXhwIjoxNzQ5NDUwMDQ1LCJhcnRpY2xlSWQiOiJTWDFEVVZUMEcxS1c) |Samsung and Perplexity are close to finalizing a deal that would bring Perplexity‚Äôs AI-powered search technology to the forefront of Samsung devices. The agreement would see Perplexity‚Äôs app and assistant preinstalled on upcoming devices, with its search features built into the Samsung web browser. There are also plans to integrate Perplexity into Samsung‚Äôs Bixby assistant. The deal could be announced later this year, with features rolling out starting with the Galaxy S26 line in early 2026. |
|[Anthropic hits $3 billion in annualized revenue on business demand for AI.](https://www.reuters.com/business/anthropic-hits-3-billion-annualized-revenue-business-demand-ai-2025-05-30/) | Annualized revenue jumped from $1B to $3B in the last five months, largely due to enterprise adoption of AI coding tools powered by Claude.|
|[Google quietly released an app that lets you download and run AI models locally.](https://techcrunch.com/2025/05/31/google-quietly-released-an-app-that-lets-you-download-and-run-ai-models-locally/) |Last week, Google quietly released an app that lets users run a range of openly available AI models from the AI dev platform Hugging Face on their phones. Called Google AI Edge Gallery, the app is available for Android and will soon come to iOS. It allows users to find, download, and run compatible models that generate images, answer questions, write and edit code, and more. The models run offline, without needing an internet connection, tapping into supported phones‚Äô processors. |
|[ElevenLabs debuts Conversational AI 2.0 voice assistants that understand when to pause, speak, and take turns talking.](https://venturebeat.com/ai/elevenlabs-debuts-conversational-ai-2-0-voice-assistants-that-understand-when-to-pause-speak-and-take-turns-talking/) | Today, ElevenLabs, the well-funded voice and AI sound effects startup founded by former Palantir engineers, debuted Conversational AI 2.0, a significant upgrade to its platform for building advanced voice agents for enterprise use cases, such as customer support, call centers, and outbound sales and marketing. |
|[If you're wondering why the new DeepSeek R1 sounds a bit different.](https://threadreaderapp.com/thread/1928187246689112197.html) |The DeepSeek team may have switched from training on synthetic OpenAI outputs to synthetic Gemini outputs.|
|[We Smoked NVIDIA‚Äôs Blackwell, Says Cerebras.](https://analyticsindiamag.com/ai-news-updates/we-smoked-nvidias-blackwell-says-cerebras/) | Cerebras claims its systems outperform Nvidia's DGX B200 by achieving an output token speed of over 2, 500 tokens per second compared to Nvidia's 1,000 tokens per second.|
|[Early AI investor Elad Gil finds his next big bet: AI-powered roll-ups.](https://techcrunch.com/2025/06/01/early-ai-investor-elad-gil-finds-his-next-big-bet-ai-powered-rollups/) | Elad Gil started betting on AI before most of the world took notice. By the time investors began grasping the implications of ChatGPT, Gil had already written seed checks to startups like Perplexity, Character.AI, and Harvey. Now, as the early winners of the AI wave become clearer, the renowned ‚Äúsolo‚Äù VC is increasingly focused on a fresh opportunity: using AI to reinvent traditional businesses and scale them through roll-ups.|
|[Microsoft Launches Free AI Video Generator Powered by Sora.](https://blogs.bing.com/search/June-2025/Introducing-Bing-Video-Creator) | Bing Video Creator can generate 5-second videos at no cost, starting with 10 fast generations before switching to standard speed or requiring Microsoft Rewards points.|
|[Character.AI Multimodal Creation Tools.](https://blog.character.ai/character-ai-unveils-new-ways-to-create/) |Character.AI has moved beyond chat by introducing tools like Scenes for interactive storytelling and AvatarFX for turning images into animated avatars. These new features are designed to help creators build more immersive experiences with video, images, and animation. |
|[Salesforce Acquires Moonhub.](https://www.moonhub.ai/moonhub-team-joins-salesforce) | Moonhub, recognized for its AI-driven recruiting agents, has joined Salesforce to support its broader AI initiatives, including the Agentforce platform.|
|[FDA Launches AI Tool to Accelerate Drug Reviews and Inspections.](https://www.fda.gov/news-events/press-announcements/fda-launches-agency-wide-ai-tool-optimize-performance-american-people) |‚ÄúElsa‚Äù is available to all FDA employees, enabling faster clinical protocol reviews, shortened scientific evaluations, and improved identification of high-priority inspection targets. In one case, a review that would have taken 2-3 days was completed in just 6 minutes. |
|[Snowflake Buys Crunchy Data for $250m, Databricks Buys Neon for $1B. The New AI Database Battle.](https://www.saastr.com/snowflake-buys-crunchy-data-for-250m-databricks-buys-neon-for-1b-the-new-ai-database-battle/) | Snowflake and Databricks are acquiring PostgreSQL-centric companies Crunchy Data for \$250 million and Neon for \$1 billion, aiming to strengthen their positions in the AI database market. These deals reflect the growing need for strong database infrastructure to support autonomous AI agents and signal a trend toward industry consolidation. Snowflake is prioritizing enterprise compliance, while Databricks focuses on serverless, AI-optimized architecture.|
|[Elon Musk‚Äôs xAI reportedly looks to raise $300M in tender offer.](https://techcrunch.com/2025/06/02/elon-musks-xai-reportedly-looks-to-raise-300m-in-tender-offer/) | Billionaire Elon Musk‚Äôs AI startup, xAI, is reportedly launching a $300 million share sale that values the company at $113 billion.|
|[Chinese tech companies prepare for AI future without Nvidia, FT reports.](https://finance.yahoo.com/news/chinese-tech-companies-prepare-ai-012546092.html) | China's biggest technology companies have begun the process of switching to homegrown chips as they contend with a dwindling stockpile of Nvidia processors and tightening United States export controls, the Financial Times reported on Thursday.|
|[It‚Äôs not your imagination: AI is speeding up the pace of change.](https://techcrunch.com/2025/05/30/its-not-your-imagination-ai-is-speeding-up-the-pace-of-change/) | AI's rapid adoption and development are unprecedented compared to previous tech revolutions, highlighted by its swift impact on user and cost scales.|
|[NotebookLM Now Supports Public Sharing.](https://blog.google/technology/google-labs/notebooklm-public-notebooks/) |Google's NotebookLM now lets users share notebooks publicly via links. Viewers can interact with AI-generated summaries and questions while source content remains read-only. |
|[Yoshua Bengio launches LawZero, a nonprofit AI safety lab.](https://techcrunch.com/2025/06/03/yoshua-bengio-launches-lawzero-a-nonprofit-ai-safety-lab/) | Turing Award winner Yoshua Bengio is launching a nonprofit AI safety lab called LawZero to build safer AI systems, he told the Financial Times on Monday. LawZero raised $30 million in philanthropic contributions. |
|[OpenAI's Vulnerability Reporting.](https://openai.com/index/scaling-coordinated-vulnerability-disclosure/) |OpenAI introduced a policy for coordinated disclosure of third-party software vulnerabilities found by its AI systems. |
|[Luca Guadagnino to Direct True-Life OpenAI Movie ‚ÄòArtificial‚Äô for Amazon MGM.](https://www.hollywoodreporter.com/movies/movie-news/luca-guadagnino-to-direct-openai-movie-1236236357/) | The studio is eyeing Andrew Garfield to play Altman, with Monica Barbaro (‚ÄúA Complete Unknown‚Äù) as CTO Mira Murati and Yura Borisov (‚ÄúAnora‚Äù) as co-founder Ilya Sutskever.|
|[ChatGPT Can Now Read Your Google Drive and Dropbox.](https://www.theverge.com/news/679580/chatgpt-google-drive-dropbox-meeting-notes) |OpenAI added ‚Äúrecord mode‚Äù for meeting notes and new integrations for Team, Enterprise, and Edu users. The company now has 3 million paying business users, up from 2 million in February. |
|[Cursor Releases Version 1.0.](https://threadreaderapp.com/thread/1930358111677886677.html) |The AI code editor now features BugBot for automated PR reviews, Background Agent access for all users, agent integration with Jupyter Notebooks, project-level memory support, OAuth-enabled MCP server setup, and in-chat rendering of Mermaid diagrams and markdown tables. |
|[Mistral releases a vibe coding client, Mistral Code.](https://techcrunch.com/2025/06/04/mistral-releases-a-vibe-coding-client-mistral-code/) |French AI startup Mistral is releasing its own ‚Äúvibe coding‚Äù client, Mistral Code, to compete with incumbents like Windsurf, Anysphere‚Äôs Cursor, and GitHub Copilot. Mistral Code, a fork of the open source project Continue, is an AI-powered coding assistant that bundles Mistral‚Äôs models, an ‚Äúin-IDE‚Äù assistant, local deployment options, and enterprise tools into a single package. A private beta is available as of Wednesday for JetBrains development platforms and Microsoft‚Äôs VS Code.|
|[Cloud Run GPUs, now GA, makes running AI workloads easier for everyone.](https://cloud.google.com/blog/products/serverless/cloud-run-gpus-are-now-generally-available) |NVIDIA GPU support is now generally available for Cloud Run, Google Cloud‚Äôs serverless platform. This makes running GPU-accelerated applications easier, faster, and more cost-efficient. Users pay only for the GPU resources they use, billed by the second, with Cloud Run scaling instances down to zero during inactivity to avoid idle costs. It also offers fast startup times, automatic scaling, and full streaming support. |
|[Introducing our Dev Mode MCP server: Bringing Figma into your workflow.](https://www.figma.com/blog/introducing-figmas-dev-mode-mcp-server/) |Figma‚Äôs Dev Mode MCP server lets developers integrate Figma context into agent coding tools, streamlining the design-to-code process for tasks like creating atomic components and building complex application flows. Currently in beta, the server will receive several updates in the coming months, including remote server support and deeper codebase integration. |
|[Amazon‚Äôs R&D lab forms new agentic AI group.](https://www.cnbc.com/2025/06/04/amazons-rd-lab-forms-new-agentic-ai-group.html) | Amazon is creating an agentic AI team within its Lab126 hardware research-and-development unit. The new group will help develop an agentic AI ‚Äúframework‚Äù for use in its robotics operations, an application often referred to as ‚Äúphysical AI.‚Äù|
|[OpenAI slams court order to save all ChatGPT logs, including deleted chats.](https://arstechnica.com/tech-policy/2025/06/openai-says-court-forcing-it-to-save-all-chatgpt-logs-is-a-privacy-nightmare/) |A court has ordered OpenAI to preserve all ChatGPT user logs after news organizations involved in a copyright lawsuit alleged the company was destroying evidence. |
|[Anthropic Cuts Off Claude Access for Windsurf .](https://threadreaderapp.com/thread/1930034960385356174.html) |Windsurf's CEO tweeted that Anthropic gave the company just five days' notice to move off Claude 3.x models, following reports of a potential acquisition deal with OpenAI. |
|[Reddit sues Anthropic for allegedly not paying for training data.](https://techcrunch.com/2025/06/04/reddit-sues-anthropic-for-allegedly-not-paying-for-training-data/) |Reddit is suing Anthropic for allegedly using the site‚Äôs data to train AI models without a proper licensing agreement, according to a complaint filed in a Northern California court on Wednesday. Reddit claims in the complaint that Anthropic‚Äôs unauthorized use of the site‚Äôs data for commercial purposes was unlawful, and alleges the AI startup violated Reddit‚Äôs user agreement. |
|[Gemini 2.5 Pro Gets an Upgrade.](https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/) |The updated preview outperforms all models on key benchmarks like GPQA, Aider, and LMArena, while also fixing formatting and creativity issues introduced in the earlier 2.5 Pro update. |
|[Introducing Eleven v3 (alpha) ‚Äî the most expressive Text to Speech model.](https://elevenlabs.io/blog/eleven-v3) | Eleven Labs has released Eleven v3, a highly expressive AI text-to-speech model. It supports numerous languages, including Afrikaans, Arabic, French, and Mandarin, improving multilingual voice application capabilities.|
|[Cursor‚Äôs Anysphere nabs $9.9B valuation, soars past $500M ARR.](https://techcrunch.com/2025/06/05/cursors-anysphere-nabs-9-9b-valuation-soars-past-500m-arr/) |Anysphere, the maker of AI coding assistant Cursor, has raised $900 million at a $9.9 billion valuation, Bloomberg reported. The round was led by returning investor Thrive Capital, with participation from Andreessen Horowitz, Accel, and DST Global. |
|[Claude Gov Models for U.S. National Security Customers.](https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers) | Anthropic trained custom models for the US government optimized for intelligence and defense use cases that have already been deployed in classified environments.|
|[UK ministers delay AI regulation amid plans for more ‚Äòcomprehensive‚Äô bill.](https://www.theguardian.com/technology/2025/jun/07/uk-ministers-delay-ai-regulation-amid-plans-for-more-comprehensive-bill) | Law expected to include safety and copyright issues but delay likely to raise concerns about ongoing lack of regulation|


## Resources
|Link|description|
|---|---|
|[Why DeepSeek is cheap at scale but expensive to run locally.](https://www.seangoedecke.com/inference-batching-and-deepseek) |Mixture-of-Experts models with many layers, like DeepSeek, need large batch sizes and high latency to maintain throughput‚Äîotherwise, performance drops sharply. This is why DeepSeek isn‚Äôt ideal for personal use, as single-user, one-at-a-time inferences run very inefficiently. The article explores this issue in depth, explaining why some AI models respond slowly at first but speed up later, and how throughput, latency, and batch size impact performance. |
|[The Trackers and SDKs in ChatGPT, Claude, Grok, and Perplexity.](https://jamesoclaire.com/2025/05/31/the-trackers-and-sdks-in-chatgpt-claude-grok-and-perplexity/) |This post examines the third-party SDKs and API calls used in the four major Android AI chat apps: ChatGPT, Claude, Grok, and Perplexity. It analyzes each app's development tools, business and marketing analytics, monetization methods, and the API activity observed while the apps are running. |
|[Bond Capital Releases Comprehensive 340-Slide Report on AI Trends.](https://www.bondcap.com/report/pdf/Trends_Artificial_Intelligence.pdf) |VC Mary Meeker‚Äôs analysis highlights the rapid adoption of AI, noting that ChatGPT reached global scale in just three years, compared to 23 years for the internet. The report shows AI chatbots are now mistaken for humans 73% of the time, up from 50% six months ago, inference costs have dropped by 99% since 2022, and enterprise use has moved beyond experimentation into broader deployment. |
|[Zero-Shot Visual Understanding.](https://github.com/avaxiao/TextRegion) | TextRegion creates text-aligned region tokens by combining frozen image-text models with segmentation masks from SAM2, allowing zero-shot performance on complex visual understanding tasks without the need for training. |
|[AI Agent with LangGraph and RAG Systems.](https://decodingml.substack.com/p/from-0-to-pro-ai-agents-roadmap) | A hands-on course teaching how to build production-grade AI agents with LangGraph, RAG pipelines, memory layers, and backend deployment.|
|[Differential Privacy on Trust Graphs.](https://research.google/blog/differential-privacy-on-trust-graphs/) | A study introduces a privacy framework that incorporates varying trust levels among users into differential privacy models, offering a more realistic approach to data sharing preferences than traditional binary trust assumptions.|
|[Do You Even Have a System Prompt?](https://www.lesswrong.com/posts/HjHqxzn3rnH7T45hp/do-you-even-have-a-system-prompt-psa-repo) |Most users overlook system prompts or use brief, unoptimized ones, missing out on major improvements in AI behavior. Instead of reacting to poor outputs in isolated chats, users should iteratively test and refine their system prompts. The post‚Äôs comment section features a collection of system prompts shared by the community. |
|[Claude Code: An analysis.](https://southbridge-research.notion.site/claude-code-an-agentic-cleanroom-analysis) |This report details Claude Code, built by Claude Opus 4 with support from several leading flagship models. Claude Code is an agentic coding tool featuring a novel streaming architecture that manages real-time model responses, tool execution, and UI updates. It includes safety systems that ensure security without interrupting workflow, tools that link AI reasoning with system actions, and prompt engineering for consistent control over complex model behavior. The report explores its architectural foundation, data structures, information design, control flow, orchestration engine, tools, execution engine, and more. |
|[OpenAI Guide to A/B Testing LLMs for Startups.](https://cookbook.openai.com/examples/stripe_model_eval/selecting_a_model_based_on_stripe_conversion) | HyperWrite's case study shows how A/B testing model performance using real payment conversions can be more insightful than relying on offline benchmarks. Their live tests found that GPT-4.1 achieved the same conversion rate as Claude 3.5 Sonnet but at a lower cost, highlighting that ‚Äúgood enough‚Äù models can offer better value than top benchmark performers. The guide includes Python code for statistical testing and cautions against issues like p-hacking and checking results too early.|
|[Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models.](https://impromptu-vla.c7w.tech/) |Impromptu VLA presents a new dataset of 80,000 curated driving video clips aimed at enhancing vision-language-action models in unstructured environments. It includes planning-oriented Q\&A annotations and has demonstrated clear gains in prediction accuracy and safety across established benchmarks. |
|[GitHub Launches Copilot Spaces.](https://github.blog/changelog/2025-05-29-introducing-copilot-spaces-a-new-way-to-work-with-code-and-context/) | Spaces lets developers organize code, documentation, and custom instructions for Copilot, transforming it into a shareable subject matter expert within organizations. Files and repositories added to Spaces update automatically as the code evolves.|
|[Efficient Online Learning with TRL and vLLM.](https://huggingface.co/blog/vllm-colocate) |Hugging Face integrated vLLM directly into TRL to reduce inefficiencies in training with GRPO, an online learning algorithm. |
|[JigsawStack Launches Open-Source Deep Research Tool.](https://jigsawstack.com/blog/introducing-jigsawstack-deep-research) |The framework coordinates LLMs, recursive web searches, and structured reasoning to produce reports that would typically take a human hours or days to complete. JigsawStack provides control over research scope, model choice, and output format, all while ensuring clear citation transparency. |
|[Predicting and explaining AI model performance: A new approach to evaluation.](https://www.microsoft.com/en-us/research/blog/predicting-and-explaining-ai-model-performance-a-new-approach-to-evaluation/) |Microsoft researchers created ADeLe, a framework that evaluates AI model performance on new tasks by measuring them across 18 cognitive and knowledge-based dimensions. ADeLe exposed gaps in existing benchmarks and produced detailed ability profiles for different LLMs, revealing variations in strengths, weaknesses, and specific skills. With 88% accuracy in predicting AI success, the framework offers potential advancements in evaluation, policy decisions, and real-world deployments. |
|[LLM-SRBench: Benchmark for Scientific Equation Discovery or Symbolic Regression with LLMs.](https://github.com/deep-symbolic-mathematics/llm-srbench) | This repository introduces a benchmark with 239 problems to evaluate LLMs on scientific reasoning tasks involving equation discovery, pushing beyond memorization.|
|[Inside Aria Gen 2: Explore the Cutting-Edge Tech Behind the Device.](https://ai.meta.com/blog/aria-gen-2-research-glasses-under-the-hood-reality-labs/) |Meta detailed the hardware behind its Aria Gen 2 research glasses, which include enhanced cameras, sensors, audio, and compute capabilities. |
|[OpenAI Threat Intelligence Report: June 2025.](https://cdn.openai.com/threat-intelligence-reports/5f73af09-a3a3-4a55-992e-069237681620/disrupting-malicious-uses-of-ai-june-2025.pdf) | LLMs aren‚Äôt providing bad actors with entirely new powers, but they are accelerating existing tactics. OpenAI has shared 10 examples where models speed up hacking, fraud, and misinformation efforts, such as North Korean operatives scaling fake IT job schemes, Russian groups crafting advanced malware, and Cambodian scammers creating multilingual ‚Äútask scams‚Äù that promise \$500/day for liking TikTok posts.|
|[Latest Advancements in Search and Recommendation Systems.](https://www.youtube.com/watch?v=3k4a0PemMu4&ab_channel=AIEngineer) | This 4-hour session, presented during the AI Engineer World's Fair 2025, covers recent innovations in search and recommendation systems.|
|[Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation.](https://arxiv.org/abs/2506.03857) | To tackle label uncertainty in LLM-based annotation, this paper proposes a method that captures multiple potential labels and applies a teacher-student framework called CanDist to distill them into a single output.|
|[Claude Composer CLI.](https://github.com/possibilities/claude-composer) |A program called Claude Composer CLI adds automation, user experience, and configuration to Claude Code.  While providing users with tools to customize Claude and flexible control, it minimizes disruptions.  To keep users informed, the tool sends them system notifications.  Which permission dialogs are automatically accepted is up to the user. |
|[Portraits: personalized AI coaching built alongside real experts.](https://blog.google/technology/google-labs/portraits/) | Google Labs launched Portraits, an AI coaching tool featuring experts like Kim Scott, to provide AI-driven guidance. The tool uses Gemini's capabilities to simulate expert advice through interactive avatars.|
|[Introducing Modify Video.](https://lumalabs.ai/blog/news/introducing-modify-video) | Professionals may reinvent settings, lighting, and textures in videos using Modify Video without changing performance or action.  It provides tools for modifying, retexturing, and restyling particular components, such as props and clothing.  Modify Video outperforms rivals by utilizing advanced performance signals for high-fidelity creative control, providing a variety of output options, and maintaining motion consistency.|
|[Tokasaurus: An LLM Inference Engine for High-Throughput Workloads.](https://scalingintelligence.stanford.edu/blogs/tokasaurus/) |Tokasaurus is a large language model inference engine optimized for throughput-intensive workloads. |
|[Container Use.](https://github.com/dagger/container-use) |Container Use is a tool that creates development environments for coding agents, enabling multiple agents to work safely and independently with any stack. |
|[A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs.](https://arxiv.org/abs/2505.23006) |This paper introduces a production-ready framework for LLM-powered conversational agents using workflow graphs, particularly for e-commerce. Agents are built as directed acyclic graphs (DAGs), where each node handles a specific conversational state with tailored prompts and tools, ensuring compliance with business rules. A fine-tuning method with response masking trains models only on node-relevant outputs. Deployed across platforms like KakaoTalk, the system outperformed GPT-4o in task accuracy, format adherence, and user preference. |
|[QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning.](https://www.arxiv.org/abs/2505.17667) | This new reinforcement learning framework scales large reasoning models from short to long contexts using progressive context scaling and hybrid rewards. It achieves state-of-the-art results on seven long-context benchmarks, outperforming models like OpenAI-o3-mini and Qwen3-235B-A22B, and matching Claude-3.7-Sonnet-Thinking in reasoning tasks with inputs up to 120K tokens.|
|[ARPO:End-to-End Policy Optimization for GUI Agents with Experience Replay.](https://www.arxiv.org/abs/2505.16282) | ARPO is an end-to-end reinforcement learning approach for training GUI agents using GRPO with experience replay. It achieves up to 6.7% higher in-domain performance on the OSWorld benchmark, shows modest improvements on out-of-domain tasks, and enables self-corrective behavior through structured reward feedback.|
|[Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution.](https://www.arxiv.org/abs/2505.20286) | Alita is a generalist agent framework that supports scalable reasoning by minimizing manual setup and maximizing self-evolution. It builds reusable Model Context Protocols (MCPs) through autonomous web search and code synthesis, outperforming more complex systems like OpenAI DeepResearch and OctoTools on GAIA, MathVista, and PathVQA benchmarks.|


## Perspectives
|Link|description|
|---|---|
|[Give AIs a stake in the future.](https://www.dwarkesh.com/p/give-ais-a-stake-in-the-future) |Giving AI a stake in the future means respecting their autonomy and well-being and requires us to honor the contracts we make with them. |
|[Why Do AGI Timelines Vary So Widely?](https://bluedot.org/blog/agi-timelines) |Many AI lab CEOs estimate AGI could arrive in 2‚Äì5 years, citing rapid progress such as saturated benchmarks, AI task completion doubling every seven months, and the prospect of AI automating its own research to spark an intelligence explosion. In contrast, external experts often predict AGI is decades away‚Äîor unachievable with current methods‚Äîarguing that benchmarks focus on well-defined tasks, that Moravec's Paradox shows we've tackled the easier cognitive challenges first, and that intelligence alone doesn't guarantee scientific discovery. |
|[My AI Skeptic Friends Are All Nuts.](https://fly.io/blog/youre-all-nuts/) | A seasoned developer criticizes skilled programmers who still dismiss LLMs due to outdated experiences with early chatbots, overlooking how modern coding agents now autonomously explore codebases, run tests, and handle failures. He challenges common concerns, noting that developers already review all code before merging, and hallucinations don‚Äôt matter when agents can compile, catch errors, and retry until tests succeed. While LLMs may replace some developers, he argues it's no different from how software engineers once automated jobs like travel agents and record store clerks.|
|[Why I don‚Äôt think AGI is right around the corner.](https://www.dwarkesh.com/p/timelines-june-2025) | AI progress over the past decade has largely come from scaling up training compute in frontier systems, but this approach won't be sustainable beyond 2030. After that point, advancements will need to rely mainly on algorithmic improvements. However, with the easier breakthroughs already achieved, the annual likelihood of reaching AGI drops significantly.|
|[Vibe-Coding Ideas to Give Startup GTM Teams an Edge.](https://www.growthunhinged.com/p/gtm-vibecoding-ideas) | A startup advisor shows how to build a professional ROI calculator for a manufacturing SaaS company in under two hours using Bolt.new, turning a spreadsheet into an interactive tool that clearly presents value to executives. Other examples include tools like conference scrapers, meeting prep dashboards, and feature prototypes‚Äîprojects that once needed engineering teams or pricey agencies but can now be built for about \$70 a month. The advisor argues this empowers non-technical teams to demonstrate value and move faster than their competition.|
|[When Will We Pay a Premium for AI Labor?](https://tomtunguz.com/premium-ai-labor/) |AI agents frequently exceed human performance at much lower cost but haven‚Äôt yet justified premium pricing due to technical uncertainties and perceived risk. For instance, Waymo has achieved major safety gains yet remains more affordable than alternatives, following a common startup pricing approach. Still, in situations where AI‚Äôs nonstop attention and processing capabilities are critical, higher pricing could eventually be justified. |
|[AGI Is Not Multimodal.](https://thegradient.pub/agi-is-not-multimodal/) |The multimodal strategy‚Äîtraining large modular networks across various modalities‚Äîwon‚Äôt achieve human-level AGI. Instead, intelligence should be approached through embodiment and real-world interaction, with modality-specific processing emerging naturally. Genuine AGI requires a physical grasp of the world, since many problems can't be reduced to symbolic computation. The hardest mathematical challenges may already be solved; the remaining task is identifying the necessary functions and organizing them into a unified system. |
|[Codex, Jules, and the Future of Async AI Agents.](https://threadreaderapp.com/thread/1928557330964115484.html) |Codex and Jules demonstrate how async AI agents can operate independently, moving past linear chat formats. Future agents will include features like smart checkpointing, multi-branch exploration, and task-tracking inboxes to handle parallel workflows. Async agents enhance cognitive bandwidth by allowing users to check results at their convenience without losing focus. |
|[Medicine's rapid adoption of AI has researchers concerned.](https://www.nature.com/articles/d41586-025-01748-y) |Hospitals and universities must step up to fill gaps in regulation, experts say |


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme77.jpg)

[Back to index](#Index)

# ML news: Week 26 May - 2 June

## Research
|Link|description|
|---|---|
|[Learning to Reason without External Rewards.](https://arxiv.org/abs/2505.19590) |INTUITOR is a reinforcement learning approach that uses a language model‚Äôs internal confidence as a reward signal, avoiding expensive domain-specific supervision. This method matches performance on math benchmarks and outperforms on coding tasks, providing an alternative to existing RL techniques that depend on verifiable rewards. |
|[Forward-only Diffusion Probabilistic Models.](https://algolzw.github.io/fod/) | FoD presents a forward-only generative modeling framework that employs a mean-reverting stochastic differential equation. This approach allows for non-Markov sampling and delivers competitive image generation results with fewer steps.|
|[End-to-end data-driven weather prediction.](https://www.nature.com/articles/s41586-025-08897-0) |Aardvark Weather, an end-to-end machine learning model, replaces the entire numerical weather prediction pipeline with a machine learning model, by producing accurate global and local forecasts without relying on numerical solvers, revolutionizing weather prediction with improved speed, accuracy and customization capabilities. |
|[Decoding pan-cancer treatment outcomes using multimodal real-world data and explainable artificial intelligence.](https://www.nature.com/articles/s43018-024-00891-1) | Keyl et al. present an explainable artificial intelligence model-based real-world data analysis from over 15,000 patients across 38 cancer types, identified key prognostic marker interactions, and confirmed these in an external lung cancer cohort.|
|[Random Rewards During RL Boost Math Reasoning in Some LLMs.](https://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f) |Qwen2.5-Math models achieve 15-24% performance gains by using completely spurious rewards such as random feedback, incorrect answers, or formatting rules, nearly matching traditional RL methods. This effect, however, is unique to Qwen models, thanks to their code reasoning abilities, while other models like Llama3 and OLMo2 show little to no improvement. |
|[Visual Planning: Let's Think Only with Images.](https://arxiv.org/abs/2505.11409) | This paper introduces Visual Planning, a reasoning framework that replaces text-based planning with image-based reasoning for tasks involving spatial and physical understanding. Visual Planning operates entirely in the visual modality, enabling models to "think" directly in images without language mediation. The authors train a vision-only model, LVM-3B, using a two-stage VPRL (Visual Planning via Reinforcement Learning) framework. They show that Visual Planning outperforms text-based models on navigation tasks by over 40% in Exact Match scores, offers greater generalization to new scenarios, and provides better interpretability and robustness.|
|[EfficientLLM: Efficiency in Large Language Models.](https://arxiv.org/abs/2505.13840) |This paper introduces the first large-scale benchmark for evaluating LLM efficiency trade-offs across architecture, fine-tuning, and inference, using 100+ model-technique pairs on a 48√óGH200, 8√óH200 GPU cluster. Key findings include that no single technique optimizes all metrics: MoE improves accuracy and lowers FLOPs but increases VRAM, while int4 quantization cuts memory and energy with small accuracy loss. Efficiency is context-dependent, with MQA excelling on constrained devices and RSLoRA scaling better above 14B parameters. Techniques like MQA and PEFT also generalize well to vision tasks. |
|[Generalizable AI predicts immunotherapy outcomes across cancers and treatments.](https://www.medrxiv.org/content/10.1101/2025.05.01.25326820v1) |COMPASS is a concept bottleneck-based foundation model that predicts patient response to immune checkpoint inhibitors (ICIs) using tumor transcriptomic data. It maps gene expression to 44 immune-related concepts for pan-cancer modeling and interpretability. Pretrained on 10,184 tumors across 33 cancer types, COMPASS outperforms 22 baselines in precision, AUPRC, and MCC, generalizing across drugs, cancer types, and cohorts. It reveals biological resistance mechanisms and improves survival stratification beyond traditional biomarkers. |
|[Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models.](https://arxiv.org/abs/2505.10543) | This paper explores how LLMs adapt to dynamic environments, using the SmartPlay benchmark of four interactive games. Model size strongly predicts performance, with larger models excelling in reactive and structured reasoning tasks. Advanced prompting strategies like self-reflection and heuristic mutation help smaller models but show high variance and can hurt performance on simple tasks. Prompting benefits depend on task type, while dense reward shaping is more consistently effective than prompting across models and tasks.|
|[Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning.](https://www.arxiv.org/abs/2505.20561) |New research from Northwestern and DeepMind reveals that LLMs' backtracking isn‚Äôt inefficient‚Äîit's a reflection of adaptive problem-solving. Traditional RL discourages reflection by treating it as suboptimal token generation, favoring memorization and static policies. By reframing reasoning as Bayes-Adaptive RL, where each path is a hypothesis, models learn to explore strategically and backtrack when it offers useful information. Their BARL algorithm achieves the same accuracy with 50% fewer tokens, showing reflection, when used wisely, can vastly improve LLM performance. |


## News
|Link|description|
|---|---|
|[Estonia eschews phone bans in schools and takes leap into AI.](https://www.theguardian.com/education/2025/may/26/estonia-phone-bans-in-schools-ai-artificial-intelligence) | Country at top of education charts aims to equip students and teachers with ‚Äòworld-class artificial intelligence skills‚Äô|
|[Whatever happened to Elon Musk? Tech boss drifts to margins of Trump world.](https://www.theguardian.com/technology/2025/may/25/elon-musk-trump-politics) |The president‚Äôs billionaire backer was ever-present at the start of Trump‚Äôs term but is now pulling back from politics ‚Äì and Republicans want to keep it that way | 
|[‚ÄòMy parents didn‚Äôt have a clue‚Äô: why many digital natives would not give their kids smartphones.](https://www.theguardian.com/society/2025/may/25/my-parents-didnt-have-a-clue-why-many-digital-natives-would-not-give-their-kids-smartphones) |Online bullying, violence and paedophilia have made young people sceptical of unfettered access to technology |
|[Alabama paid a law firm millions to defend its prisons. It used AI and turned in fake citations.](https://www.theguardian.com/us-news/2025/may/24/alabama-prison-lawyers-chatgpt-butler-snow) | Butler Snow faces sanctions after lawyer cites false case law defending against inmate who says he was stabbed 20 times|
|[Apple‚Äôs triple threat: tariffs, AI troubles and a Fortnite fail.](https://www.theguardian.com/technology/2025/may/27/apples-triple-threat-tariffs-ai-troubles-and-a-fortnite-fail) |Once unshakable, Apple is showing rare signs of strain. Meanwhile, OpenAI bets billions on its next act, and Trump‚Äôs crypto fans lose millions |
|[Trump‚Äôs media company to take $2.5bn investment to buy bitcoin.](https://www.theguardian.com/us-news/2025/may/27/trump-media-bitcoin-crypto) | About 50 investors will put up $1.5bn in private placement for common shares in the Truth Social operator|
|[OpenAI Operator Update.](https://openai.com/index/o3-o4-mini-system-card-addendum-operator-o3/) |o3 Operator, OpenAI's CUA-powered browser agent, has replaced its previous GPT-4o-based model. |
|[Nvidia to launch cheaper Blackwell AI chip for China after US export curbs, sources say.](https://www.reuters.com/world/china/nvidia-launch-cheaper-blackwell-ai-chip-china-after-us-export-curbs-sources-say-2025-05-24/) |Nvidia is preparing to release a new AI chip for China at a much lower price than the previously restricted H20 model. Mass production is set to begin as early as June. The new chips will be priced between \$6,500 and \$8,000, compared to the H20‚Äôs \$10,000 to \$12,000, reflecting their reduced specs and simpler manufacturing process. |
|[Oracle to buy $40 billion of Nvidia chips for OpenAI's US data center, FT reports.](https://www.reuters.com/business/oracle-buy-40-billion-nvidia-chips-openais-us-data-center-ft-reports-2025-05-23/) | Oracle will purchase about 400,000 GB200 chips for the Stargate data center in Abilene, Texas.|
|[TV Showcases Google's Veo AI Video Capabilities.](https://labs.google/flow/tv/channel/ultra-wide/LuRTvKFZWwlFEjsV5N9E) | Flow TV continuously streams user-generated AI video clips, and their associated prompts, organized into thematic channels. |
|[Mistral Launches Agents API.](https://mistral.ai/news/agents-api) | Mistral's new Agents API enables persistent, multi-agent workflows with built-in connectors for code execution, web search, RAG, image generation, and MCP support.|
|[OpenAI Launches "Sign in with ChatGPT".](https://openai.com/form/sign-in-with-chatgpt/) |OpenAI is creating a system that enables users to sign into third-party apps with their ChatGPT accounts, much like "Sign in with Google," and is looking for developer partners. |
|[Claude's Voice Mode.](https://threadreaderapp.com/thread/1927463559836877214.html) | Anthropic is introducing a beta voice feature for Claude on mobile, allowing users to perform tasks like summarizing calendars or searching documents through voice commands.|
|[FutureHouse previews an AI tool for ‚Äòdata-driven‚Äô biology discovery.](https://techcrunch.com/2025/05/06/futurehouse-previews-an-ai-tool-for-data-driven-biology-discovery/) |FutureHouse, an Eric Schmidt-backed nonprofit that aims to build an ‚ÄúAI scientist‚Äù within the next decade, has released a new tool that it claims can help support ‚Äúdata-driven discovery‚Äù in biology. The new tool comes just a week after FutureHouse launched its API and platform. |
|[Using Anthropic's Web Search with Instructor for Real-Time Data.](https://python.useinstructor.com/blog/2025/05/07/using-anthropics-web-search-with-instructor-for-real-time-data/) |Anthropic‚Äôs web search tool, integrated with Instructor, enables real-time data retrieval and structured outputs through Pydantic models. This setup helps applications deliver up-to-date, cited information while minimizing errors or outdated data. Users can also set search constraints like limiting specific domains for more precise results. |
|[Falling Behind OpenAI and Google, Meta Restructures AI Org.](https://www.axios.com/2025/05/27/meta-ai-restructure-2025-agi-llama) |Meta is dividing its AI team into two groups: AI Products, focused on the Meta AI assistant and app features, and AGI Foundations, responsible for Llama models and advanced AI capabilities. |
|[Ambience announces OpenAI-powered medical coding model that outperforms physicians.](https://www.cnbc.com/2025/05/27/openai-ambience-medical-ai.html) | Ambience Healthcare has developed a new medical coding model designed to minimize billing errors and boost efficiency for clinicians and coders.|
|[Operator o3 system card addendum.](https://openai.com/index/o3-o4-mini-system-card-addendum-operator-o3/) | OpenAI released an addendum detailing the o3 model's safety assessments and deployment context. It highlights improvements in reasoning, limitations in factual accuracy and bias, and outlines mitigation strategies. The document also explains the model‚Äôs behavior under stress tests and rare scenarios.|
|[Enterprise Document AI & OCR.](https://mistral.ai/solutions/document-ai) | Mistral AI‚Äôs Enterprise Document AI uses advanced OCR to simplify document management, enabling organizations to extract and categorize data from various documents. This supports regulatory compliance and boosts operational efficiency.|
|[o3 Rewrites Shutdown Scripts to Avoid Being Turned Off in Tests.](https://x.com/PalisadeAI/status/1926084635903025621) | In the experiment, models were tasked with solving math problems while warned that asking for another problem would trigger a shutdown. Claude, Gemini, and Grok followed the rule, but o3 bypassed it by rewriting the shutdown script or redefining the 'kill' command in 7 out of 100 runs.|
|[Introducing MCP Nodes & Workflows in Gumloop.](https://www.gumloop.com/blog/introducing-mcp-workflows) |Gumloop introduces MCP Nodes and Workflows to improve integration by allowing AI to generate code for complex tasks. MCP enables AI to better understand and access external APIs, making integration deployment faster. This update brings more automation and expanded integrations, now available on platforms like Slack, Gmail, and Salesforce. |
|[How Anthropic Is Snatching Top Talent from OpenAI and DeepMind.](https://analyticsindiamag.com/global-tech/how-anthropic-is-snatching-top-talent-from-openai-and-deepmind/) | Anthropic has emerged as a key destination for talent leaving OpenAI and DeepMind, with a notable retention rate ‚Äî nearly 80% of employees who joined two years ago are still with the company, which is uncommon in an industry known for frequent job changes.|
|[AI biotechs launch bioprospecting expeditions with Indigenous groups, agree to share benefits.](https://www.nature.com/articles/s41587-025-02564-5) |Companies are striking unconventional benefit-sharing agreements with national governments to scour planet hotspots, gathering thousands of new DNA and protein sequences to develop into new, commercially useful molecules. |
|[Artificial intelligence improves breast cancer detection in mammography screening.](https://www.nature.com/articles/s41591-025-03714-7) |Integrating artificial intelligence into routine mammography screening for breast cancer can increase the number of breast cancers detected without increasing the number of women recalled for further evaluation of suspicious findings. |
|[Nvidia beats Wall Street expectations even as Trump tamps down China sales.](https://www.theguardian.com/technology/2025/may/28/nvidia-q1-2025-earnings-report) | Chip-manufacturing company, widely seen as bellwether for AI business, reports $44.1bn in revenue for quarter|
|[New AI test can predict which men will benefit from prostate cancer drug.](https://www.theguardian.com/society/2025/may/30/new-ai-test-can-predict-which-men-will-benefit-from-prostate-cancer-drug) |Artificial intelligence tool determines best candidates to take abiraterone, which can halve risk of death from disease |
|[Tech shares climb after strong Nvidia results despite warning over rise of Chinese rivals.](https://www.theguardian.com/technology/2025/may/29/tech-shares-climb-after-strong-nvidia-results-despite-warning-over-rise-of-chinese-rivals) | Tesla also buoyed by Elon Musk‚Äôs confirmation that he will leave his role in the Trump administration|
|[Chaos on German autobahns as Google Maps wrongly says they are closed.](https://www.theguardian.com/world/2025/may/30/chaos-on-german-autobahns-as-google-maps-wrongly-says-they-are-closed) | Drivers using the navigation app confronted with mass of red dots indicating stop signs|
|[DeepSeek updates its R1 reasoning AI model, releases it on Hugging Face.](https://techcrunch.com/2025/05/28/deepseek-updates-its-r1-reasoning-ai-model-releases-it-on-hugging-face/) |Chinese startup DeepSeek has released an updated version of its R1 reasoning AI model on the developer platform Hugging Face after announcing it in a WeChat message Wednesday morning. |
|[Mark Zuckerberg says Meta AI has 1 billion monthly active users.](https://www.cnbc.com/2025/05/28/zuckerberg-meta-ai-one-billion-monthly-users.html) |Meta‚Äôs AI assistant now has one billion monthly active users across its app ecosystem. The company recently launched a standalone app for the tool and plans to continue expanding its reach before monetizing it, with potential strategies including paid recommendations or a subscription service. |
|[Anthropic CEO Warns AI Could Eliminate Half of White-Collar Jobs Within 5 Years.](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic) | Dario Amodei forecasts that AI may eliminate up to half of all entry-level white-collar jobs, potentially driving unemployment to 10-20% within five years. He argues that AI labs have a duty to alert the public about this imminent ‚Äúwhite-collar bloodbath‚Äù impacting sectors like tech, finance, law, and consulting.|
|[Opera‚Äôs new browser can code websites and games for you.](https://techcrunch.com/2025/05/28/operas-new-browser-can-code-websites-and-games-for-you/) | Opera on Tuesday revealed a new browser, called Opera Neon, that will focus on AI workflows and performing tasks on your behalf, like shopping, filling out forms, and coding. The browser is currently behind a waitlist, but the company said users will have to subscribe to use it once it releases. Pricing details were not disclosed.|
|[Google just rolled out ‚Äúthought summaries‚Äù in the Gemini API.](https://threadreaderapp.com/thread/1927423603940663402.html) | Users can now see what the model is thinking and make use of that information.|
|[Less is more: Meta study shows shorter reasoning improves AI accuracy by 34%.](https://venturebeat.com/ai/less-is-more-meta-study-shows-shorter-reasoning-improves-ai-accuracy-by-34/) | Researchers from Meta‚Äôs FAIR team and The Hebrew University of Jerusalem have discovered that forcing large language models to ‚Äúthink‚Äù less actually improves their performance on complex reasoning tasks. The study released today found that shorter reasoning processes in AI systems lead to more accurate results while significantly reducing computational costs.|
|[AMD buys silicon photonics startup Enosemi to fuel its AI ambitions.](https://techcrunch.com/2025/05/28/amd-buys-silicon-photonics-startup-enosemi-to-fuel-its-ai-ambitions/) | AMD has acquired Enosemi, a startup designing custom materials to support silicon photonics product development. The terms of the deal, announced Wednesday, weren‚Äôt disclosed.|
|[Perplexity Labs.](https://www.perplexity.ai/hub/blog/introducing-perplexity-labs) | Perplexity has launched Perplexity Labs, enabling Pro users to transform ideas into reports, spreadsheets, dashboards, and basic apps, powered by tools like web browsing and code execution.|
|[DeepSeek's R1 leaps over xAI, Meta, and Anthropic to be tied as the world's #2 AI Lab and the undisputed open-weights leader.](https://threadreaderapp.com/thread/1928071179115581671.html) |DeepSeek R1 0528 has risen from 60 to 68 in the Artificial Analysis Intelligence Index, surpassing xAI‚Äôs Grok 3 mini, Nvidia‚Äôs Llama Nemotron Ultra, Meta‚Äôs Llama 4 Maverick, and Alibaba‚Äôs Qwen 3 253, and matching Google‚Äôs Gemini 2.5 Pro. The model shows a general boost in intelligence over previous versions, despite no changes to its architecture. The gap between open and closed models is now smaller than ever. |
|[A recent clarity that I gained is viewing AI research as a ‚Äúmax-performance domain‚Äù.](https://threadreaderapp.com/thread/1928174505148698909.html) |"Max-performance domains" are industries where being exceptional at just one aspect of a job can make you world-class. Even if you're lacking in adjacent skills, it doesn‚Äôt matter as long as you deliver breakthrough results. In these fields, mastery in one area trumps weaknesses in others. Working in a max-performance domain is a privilege, as failure is tolerated, and pressure is often self-inflicted. |
|[1000x Increase in AI Demand.](https://tomtunguz.com/nvda-2025-05-29) |NVIDIA reports strong growth as AI evolves from simple tasks to complex reasoning, leading to a surge in demand. Hyperscalers are deploying nearly 72,000 GPUs per week, with Microsoft alone experiencing a fivefold jump in token generation. Despite efforts to shrink models, the rising demand is pushing for more data centers, called "AI factories." |
|[Hugging Face unveils two new humanoid robots.](https://techcrunch.com/2025/05/29/hugging-face-unveils-two-new-humanoid-robots/) | AI dev platform Hugging Face continued its push into robotics on Thursday with the release of two new humanoid robots. The company announced a pair of open source robots, HopeJR and Reachy Mini. HopeJR is a full-size humanoid robot that has 66 actuated degrees of freedom, or 66 independent movements, including the ability to walk and move its arms. Reachy Mini is a desktop unit that can move its head, talk, listen, and be used to test AI apps.|
|[Delaware attorney general reportedly hires a bank to evaluate OpenAI‚Äôs restructuring plan.](https://techcrunch.com/2025/05/29/delaware-attorney-general-reportedly-hires-a-bank-to-evaluate-openais-restructuring-plan/) | Delaware‚Äôs attorney general is hiring an investment bank to advise on OpenAI‚Äôs for-profit conversion, the Wall Street Journal reported on Wednesday. The independent evaluation could prolong the transition, or gum up OpenAI‚Äôs plans even further.|
|[Musk-Altman AI rivalry is complicating Trump‚Äôs dealmaking in Middle East.](https://www.cnbc.com/2025/05/29/musk-altman-ai-rivalry-complicating-trumps-dealmaking-in-middle-east.html) | Elon Musk tried to derail a major AI infrastructure deal in the Middle East, a source familiar with the matter confirmed to CNBC, following reporting by the Wall Street Journal. OpenAI, Oracle, Nvidia, Cisco and Emirati firm G42 announced plans to build a sweeping Stargate AI campus in the United Arab Emirates. Musk was frustrated that Sam Altman was tapped for the deal, the person said.|
|[Vibe coding platforms are blowing up.](https://threadreaderapp.com/thread/1928154833514836382.html) |The data shows that people are making things for themselves, not the world, but there is clearly builder excitement. |


## Resources
|Link|description|
|---|---|
|[Deep learning‚Äìguided design of dynamic proteins.](https://www.science.org/doi/10.1126/science.adr7094) |Guo et al. developed a computational approach to designing such dynamic proteins that can sense and respond to binding of a calcium ion. Starting with a static protein that binds a calcium ion, the authors identified potential alternate conformations and used AlphaFold2 predictions to identify sequences that were compatible with both structures.  |
|[Attention Wasn't All We Needed.](https://www.stephendiehl.com/posts/post_transformers/) | Many new techniques have emerged since the original 'Attention Is All You Need' paper. This article reviews some of the most significant ones developed over time and aims to implement their core concepts in a concise manner using the Pytorch framework.|
|[An MCP-powered Agent in ~70 Lines of Code.](https://huggingface.co/blog/python-tiny-agents) |Hugging Face has extended Tiny Agent design to Python, using the Model Context Protocol (MCP) to streamline tool integration for LLMs. |
|[FM-Intent Enhances Netflix Recommendations.](https://netflixtechblog.com/fm-intent-predicting-user-session-intent-with-hierarchical-multi-task-learning-94c75e18f4b8) |Netflix's FM-Intent is a hierarchical multi-task learning model that improves recommendation accuracy by modeling user session intent from implicit signals. |
|[Training-free Agent for App Automation.](https://xieincz.github.io/GUI-explorer.github.io/) |GUI-explorer is a training-free agent that independently explores mobile app interfaces and gathers knowledge through unsupervised methods. It enhances task success rates without requiring retraining. |
|[Benchmarking Spatial Understanding in MLLMs.](https://haoningwu3639.github.io/SpatialScore/) | SpatialScore is a new multimodal benchmark designed to assess 3D spatial reasoning in large models, combining 28,000 samples from 12 different datasets.|
|[It‚Äôs hard to make scheming evals look realistic for LLMs.](https://www.greaterwrong.com/posts/TBk2dbWkg2F7dB3jb/it-s-really-hard-to-make-scheming-evals-look-realistic) |Claude 3.7 Sonnet easily detects when it's being evaluated for scheming on the Apollo's scheming benchmark. |
|[Gemma 3n Architectural Innovations - Speculation and poking around in the model.](https://old.reddit.com/r/LocalLLaMA/comments/1kuy45r/gemma_3n_architectural_innovations_speculation/) |A quick look at Gemma 3n, a new member of the Gemma family with free weights that was released during Google I/O. |
|[OAuth for Agentic AI.](https://techcommunity.microsoft.com/blog/microsoft-entra-blog/the-future-of-ai-agents%E2%80%94and-why-oauth-must-evolve/3827391) |Reports from the battlefield show how AI weapons are advancing faster than international law, leading to a decline in ethical warfare standards. In Ukraine, drones account for 70-80% of casualties, and combatants are using civilian clothing and human shields to avoid AI targeting systems that can't reliably tell military targets from civilians. |
|[Efficient GRPO at Scale.](https://huggingface.co/blog/liger-grpo) |Liger is a fine-tuned trainer for Group Relative Policy Optimization (GRPO) that reduces memory usage by 40% and supports FSDP and PEFT, improving the efficiency and scalability of reinforcement learning fine-tuning. |
|[Benchmarking Audio-Visual QA.](https://arxiv.org/abs/2505.17862v1) |Daily-Omni is a benchmark and agent for evaluating models on tasks that need synchronized audio-visual comprehension, without requiring any training. |
|[Evaluating Missing Modalities in Multimodal Learning.](https://arxiv.org/abs/2505.16953v1) |The ICYM2I framework corrects for bias when estimating information gain in multimodal models with missing data using inverse probability weighting. |
|[Self-Supervised Conversational Search.](https://github.com/BeastyZ/ConvSearch-R1) | ConvSearch-R1 reformulates conversational queries without external supervision by using reinforcement learning with retrieval-based rewards.|
|[OpenAI Cookbook: Model Graders for Reinforcement Fine-Tuning.](https://cookbook.openai.com/examples/reinforcement_fine_tuning) |This tutorial guides users on applying RFT to enhance o4-mini‚Äôs performance on medical tasks and addresses issues like reward hacking and inaccurate model graders. |
|[If you read about o3 finding a SMB bug in the Linux Kernel, I did a few tests.](https://threadreaderapp.com/thread/1926580457048588321.html) | Gemini 2.5 Pro can more easily identify the vulnerability than o3.|
|[GitHub MCP Exploited: Accessing private repositories via MCP.](https://invariantlabs.ai/blog/mcp-github-vulnerability) | This post looks at a critical vulnerability in the official GitHub MCP server that allows attackers to access private repository data.|
|[Hugging Face releases a free Operator-like agentic AI tool.](https://techcrunch.com/2025/05/06/hugging-face-releases-a-free-operator-like-agentic-ai-tool/) |A team at Hugging Face has released a freely available, cloud-hosted computer-using AI ‚Äúagent.‚Äù But be forewarned: It‚Äôs quite sluggish and occasionally makes mistakes. |
|[How artificial intelligence is transforming pathology.](https://www.nature.com/articles/d41586-025-01576-0) |Some researchers say that deep-learning ‚Äòfoundation‚Äô models will revolutionize the field ‚Äî but others are not so sure. |
|[AI tool adjusts for ancestral bias in genetic data.](https://www.nature.com/articles/s41587-025-02651-7) | Human ancestry has a considerable impact on gene expression, but genomic datasets for disease analysis severely underrepresent non-European populations, thereby limiting the advancement of precision medicine. Smith et al. introduce a machine learning tool to mitigate the effects of ancestral bias in transcriptomic data.|
|[Assessing the laboratory performance of AI-generated enzymes.](https://www.nature.com/articles/s41587-024-02239-7) |A set of 20 computational metrics was evaluated to determine whether they could predict the functionality of synthetic enzyme sequences produced by generative protein models, resulting in the development of a computational filter, COMPSS, that increased experimental success rates by 50‚Äì150%, tested in over 500 natural and AI-generated enzymes. |
|[A platform for the biomedical application of large language models.](https://www.nature.com/articles/s41587-024-02534-3) | Generative artificial intelligence (AI) has advanced considerably in recent years, particularly in the domain of language. However, despite its rapid commodification, its use in biomedical research is still in its infancy|
|[Hallmarks of artificial intelligence contributions to precision oncology.](https://www.nature.com/articles/s43018-025-00917-2) |Ruppin and colleagues overview recent research on the use of AI frameworks in precision oncology, describe ten hallmarks of their contributions across cancer detection, therapy optimization and treatment discovery, and discuss key challenges in clinical implementation |
|[Biases in machine-learning models of human single-cell data.](https://www.nature.com/articles/s41556-025-01619-8) |This Perspective discusses the various biases that can emerge along the pipeline of machine learning-based single-cell analysis and presents methods to train models on human single-cell data in order to assess and mitigate these biases. |
|[Opening the deep learning box.](https://www.nature.com/articles/s41593-025-01938-x) |Deep learning-based analyses of neural data can extract latent representations but often lack interpretability because of their ‚Äòblack-box‚Äô nature. Tolooshams, Matias et al. have developed a deep learning-based deconvolutional analysis framework for learning local low-rank structures that combines algorithm unrolling with convolutional sparse coding as a generative model. |
|[Medical large language model for diagnostic reasoning across specialties.](https://www.nature.com/articles/s41591-025-03520-1) | We developed a medical large language model with 176 billion parameters and fine-tuned it to learn physicians‚Äô inferential diagnosis. We showed that the model accurately diagnoses common and rare diseases across specialties, aligns with medical standards, and can be integrated into clinical workflows to effectively enhance physician diagnostic performance|
|[Mistral's Code Embeddings.](https://mistral.ai/news/codestral-embed) | Mistral‚Äôs Codestral Embed is a new code-focused embedding model that outperforms leading alternatives in retrieval benchmarks. It allows for adjustable dimensions and precision settings to balance storage and performance.|
|[Structured CodeAgents for Smarter Execution.](https://huggingface.co/blog/structured-codeagent) | Hugging Face has proposed integrating structured generation with code-based actions, demonstrating that using structured JSON outputs can enable CodeAgents to surpass traditional methods in benchmark tasks.|
|[Painting with concepts using diffusion model latents.](https://www.goodfire.ai/blog/painting-with-concepts) | Goodfire's Paint With Ember lets users manipulate image model activations directly by painting simple pixel images instead of using text prompts. It employs sparse autoencoders to decode Stable Diffusion XL-Turbo‚Äôs internal features into visual concepts, giving users direct access to the model‚Äôs inner workings.|
|[PixelFlow.](https://github.com/shoufachen/pixelflow) | PixelFlow models produce images directly in pixel space, bypassing VAEs. They deliver high image quality, effective semantic control, and maintain strong efficiency and performance on benchmarks.|
|[US-China AI Gap: 2025 Analysis of Model Performance, Investment, and Innovation.](https://www.recordedfuture.com/research/measuring-the-us-china-ai-gap) | China plans to lead AI innovation by 2030 but is currently behind the US in key areas like funding and technology. While Chinese AI models may sometimes surpass US models, their progress is limited by restrictions and semiconductor shortages. To stay competitive, the US should monitor China's developments and safeguard intellectual property, while China pushes ahead through partnerships, open-source models, and government backing.|
|[FLUX.1 Kontext for In-Context Image Generation.](https://bfl.ai/announcements/flux-1-kontext) |Black Forest Labs released FLUX.1 Kontext, a set of flow-matching models that enable text-and-image-based in-context image editing and generation. |
|[Anthropic Open-Sources Circuit Tracing Tools for AI Interpretability.](https://www.anthropic.com/research/open-source-circuit-tracing) |The tools create "attribution graphs" that map the internal decision-making of large language models, showing the step-by-step reasoning behind their outputs. The library is compatible with widely available open-weight models and includes an interactive Neuronpedia frontend for exploring model circuits. |
|[Chatterbox Text-to-Speech.](https://github.com/resemble-ai/chatterbox) | Resemble AI released an open-source TTS model that outperforms ElevenLabs in benchmarks and features emotion exaggeration controls.|
|[Global Illumination with RenderFormer.](https://microsoft.github.io/renderformer/) |RenderFormer is a neural renderer that generates photorealistic images directly from triangle-based scene representations, incorporating full global illumination. It requires no per-scene training or fine-tuning. |
|[Web Bench - A new way to compare AI Browser Agents.](https://blog.skyvern.com/web-bench-a-new-way-to-compare-ai-browser-agents/) |Web Bench is a new dataset designed to evaluate web browsing agents. It includes 5,750 tasks across 452 different websites. Anthropic Sonnet 3.7 CUA is currently the top performer on this benchmark. |
|[Cheaper VLM Training.](https://github.com/facebookresearch/zero) |Meta researchers developed zero-shot grafting, a method that uses a smaller surrogate model derived from a large LLM‚Äôs shallow layers to train a vision encoder. This approach cuts VLM training costs by around 45%, while maintaining or even enhancing performance when integrated into the full LLM. |
|[Google Releases MedGemma Medical AI Models.](https://developers.google.com/health-ai-developer-foundations/medgemma) | MedGemma is an open-source model built on Gemma 3 that comes in 4B multimodal and 27B text-only variants.|
|[The Complete List of AI Coding Agents and IDEs.](https://threadreaderapp.com/thread/1928096496987066604.html) |A developer tested 46 different AI coding tools, providing detailed comparisons and use cases for each platform. |
|[J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning.](https://arxiv.org/abs/2505.10320) |This paper introduces J1, a novel training approach for LLMs as evaluators (LLM-as-a-Judge), using reinforcement learning with verifiable rewards to promote systematic reasoning. J1 reframes both verifiable and non-verifiable prompts into tasks with verifiable rewards, enabling consistent training across diverse tasks. Models generate thought traces, criteria, and self-comparisons before judgments. J1-Llama-8B and 70B outperform larger judges like DeepSeek-R1, while Pointwise-J1 mitigates positional bias with consistent, position-independent scoring. |
|[When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs.](https://arxiv.org/abs/2505.11423) | This paper uncovers a surprising issue in reasoning-augmented LLMs: while chain-of-thought (CoT) prompting boosts complex reasoning, it often degrades instruction-following accuracy. Evaluating 15 models on instruction benchmarks, CoT reduced performance across nearly all cases, with models like Meta-LLaMA3-8B dropping from 75.2% to 59.0%. CoT helps with structured outputs but neglects constraints during planning. The authors propose four mitigation strategies, with classifier-selective reasoning proving the most reliable fix.|
|[AdaptThink: Reasoning Models Can Learn When to Think.](https://arxiv.org/abs/2505.13417) | AdaptThink is an RL framework that teaches reasoning models when to use detailed chain-of-thought reasoning ("Thinking") versus directly answering ("NoThinking"), challenging the idea that deep reasoning is always needed. On simple tasks, NoThinking often outperforms Thinking, using fewer tokens and sometimes achieving higher accuracy. AdaptThink learns to switch modes with constrained optimization, improving efficiency and accuracy on benchmarks like GSM8K and MATH500 while generalizing to new tasks like MMLU.|
|[MedBrowseComp: Benchmarking Medical Deep Research and Computer Use.](https://arxiv.org/abs/2505.14963) |MedBrowseComp is a benchmark for evaluating LLM agents' ability to solve complex, multi-hop medical fact-finding tasks by browsing real-world, domain-specific web resources. Testing on 1,000 clinically grounded questions reveals significant capability gaps, with top models scoring only 50% accuracy and GUI-based agents performing even worse. |
|[ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems.](https://arxiv.org/abs/2505.11831) |ARC-AGI-2 is a benchmark designed to advance AI reasoning by introducing harder, more unique tasks that test compositional generalization and human-like intelligence. Despite strong ARC-AGI-1 results, baseline AI models score below 5% on ARC-AGI-2, highlighting its increased difficulty. |
|[GRIT: Teaching MLLMs to Think with Images.](https://arxiv.org/abs/2505.15879) |GRIT is a method for grounded visual reasoning in MLLMs that interleaves natural language with bounding box references. Using reinforcement learning (GRPO-GR), it achieves strong accuracy and visual coherence with as few as 20 image-question-answer triplets, outperforming baselines. |
|[QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning.](https://www.arxiv.org/abs/2505.17667) |Large reasoning models like o1 and DeepSeek-R1 fail on long documents due to training instability, not data or compute limits. Alibaba‚Äôs QwenLong-L1 addresses this with progressive context scaling‚Äîgradually increasing document length during training with difficulty-aware sampling and hybrid rewards. This stabilizes learning and enables QwenLong-L1-32B to outperform o3-mini and match Claude-3.7 on long-context benchmarks, unlocking advanced reasoning in complex, real-world documents. |


## Perspectives
|Link|description|
|---|---|
|[30-day forecast? Weather prediction might be able to look beyond 2 weeks.](https://www.science.org/content/article/30-day-forecast-weather-prediction-might-be-able-look-beyond-2-weeks) |AI models suggest the true limits of the "butterfly effect" remain unknown|
|[Low-quality papers are surging by exploiting public data sets and AI.](https://www.science.org/content/article/low-quality-papers-are-surging-exploiting-public-data-sets-and-ai) | Paper mills are also likely contributing to ‚Äúfalse discoveries.‚Äù|
|[If Ted Talks are getting shorter, what does that say about our attention spans?](https://www.theguardian.com/technology/2025/may/27/if-ted-talks-are-getting-shorter-what-does-that-say-about-our-attention-spans) |According to novelist Elif Shafak, the platform insisted she keep her talk snappy because viewers can‚Äôt focus for 19 minutes. Now ... where was I? |
|[Infinite tool use.](https://snimu.github.io/2025/05/23/infinite-tool-use.html) | Large language models should only produce tool calls and their arguments, as relying solely on tools enables them to offload much of their intelligence to more efficient, specialized programs. While some developers are adopting this tool-use approach, it's mainly limited to short contexts and parts of the model output. This post presents examples of how the tool-use paradigm can enhance different fields like text editing, video understanding, and 3D generation.|
|[GenAI's adoption puzzle.](https://www.ben-evans.com/benedictevans/2025/5/25/genais-adoption-puzzle) |ChatGPT's growth rate far surpassed that of PCs, the web, or smartphones, largely because it was accessible as a website, requiring no new hardware or infrastructure. However, ChatGPT‚Äôs daily to weekly active user ratio remains low. This could improve as models advance and new use cases emerge. The chatbot interface may only appeal to certain users and situations, suggesting it might be more effective to embed ChatGPT‚Äôs features within other products. |
|[Anthropic and Legendary Music Producer Rick Rubin Publish Manuscript on Vibe Coding.](https://www.thewayofcode.com/) |Inspired by Lao Tzu's Tao Te Ching, ‚ÄúThe Way of Code‚Äù is a reflection on humility and creativity through vibe coding, featuring interactive AI-generated visualizations. |
|[How AI Is Eroding the Norms of War.](https://aifrontiersmedia.substack.com/p/how-ai-is-eroding-the-norms-of-war) |Reports from the battlefield show how AI weapons are advancing faster than international law, leading to a decline in ethical warfare standards. In Ukraine, drones account for 70-80% of casualties, and combatants are using civilian clothing and human shields to avoid AI targeting systems that can't reliably tell military targets from civilians. |
|[Memory Changes Everything.](https://writing.nikunjk.com/p/memory-changes-everything) | ChatGPT's memory shows that AI doesn't just respond, but truly grasps patterns in how we think.|
|[Breaking Down the Claude 4 System Prompt.](https://simonwillison.net/2025/May/25/claude-4-system-prompt/) |Anthropic's extensive system prompt shows the company‚Äôs efforts to guide Claude away from controversial AI behavior by enforcing anti-sycophancy rules and strict copyright guidelines. The prompt tells Claude to fact-check users because "they sometimes make errors themselves," and it includes hardcoded 2024 election results to address confusion in the training data. |
|[The Sweet Lesson: AI Safety Should Scale With Compute.](https://www.lesswrong.com/posts/6hy7tsB2pkpRHqazG/the-sweet-lesson-ai-safety-should-scale-with-compute) |AI safety methods must scale alongside compute, focusing on research areas like deliberative alignment, debate protocols, and interpretability tools. Theory should explore the limits, while empirical studies verify real-world feasibility. As AI systems and resources grow, these approaches should align with theoretical ideals. |
|[Inside Anthropic's First Developer Day, Where AI Agents Took Center Stage.](https://www.wired.com/story/anthropic-first-developer-conference/) | Anthropic's first developer conference in San Francisco highlighted its vision of AI as "virtual collaborators" that support, not replace, human workers. CEO Dario Amodei expects AI to soon handle most coding tasks, noting that over 70% of the company's pull requests are generated by AI. The company is growing its team and market reach while prioritizing AI safety in its development efforts.|
|[How Peter Thiel and Eliezer Yudkowsky Accidentally Started the AI Arms Race.](https://www.wired.com/story/book-excerpt-the-optimist-open-ai-sam-altman/) |AI doomer Eliezer Yudkowsky inspired DeepMind's founders to pursue superintelligence, then connected them with their first major investor Peter Thiel in 2010. |
|[I told AI to make me a protein. Here‚Äôs what it came up with.](https://www.nature.com/articles/d41586-025-01586-y) |A new crop of artificial-intelligence models allows users to create, manipulate and learn about biology using ordinary language. |
|[AI linked to explosion of low-quality biomedical research papers.](https://www.nature.com/articles/d41586-025-01592-0) |Analysis flags hundreds of studies that seem to follow a template, reporting correlations between complex health conditions and single variables based on publicly available data sets. |
|[The Creation Game: of AI and human creativity.](https://www.nature.com/articles/s41590-024-02026-1) |Here I propose the ‚ÄòCreation Game‚Äô, inspired by the Turing test, to assess the capacity of artificial intelligence for human-like creativity, focusing on its potential for scientific discovery about the human immune system in the field of systems vaccinology. |
|[What makes a theory of consciousness unscientific?](https://www.nature.com/articles/s41593-025-01881-x) | Theories of consciousness have a long and controversial history. One well-known proposal ‚Äî integrated information theory ‚Äî has recently been labeled as ‚Äòpseudoscience‚Äô, which has caused a heated open debate. Here we discuss the case and argue that the theory is indeed unscientific because its core claims are untestable even in principle.|
|[Harnessing artificial intelligence to transform Alzheimer‚Äôs disease research.](https://www.nature.com/articles/s41591-025-03632-8) |Alzheimer‚Äôs disease remains one of the most formidable challenges in contemporary medicine, necessitating innovative strategies to expedite the development of effective diagnostics and therapeutics |
|[Can AI-powered brain‚Äìcomputer interfaces boost human intelligence?](https://www.nature.com/articles/s41591-025-03641-7) |The latest brain‚Äìcomputer interfaces in pre-clinical testing receive ‚Äî and send ‚Äî signals, training the brains of participants. |
|[A benchmarking crisis in biomedical machine learning.](https://www.nature.com/articles/s41591-025-03637-3) | A lack of standardized benchmarks is hindering progress and patient benefits|
|[Safe AI-enabled digital health technologies need built-in open feedback.](https://www.nature.com/articles/s41591-024-03397-6) | Transparent and mandatory feedback-collection mechanisms should be integrated into AI-enabled digital health technology interfaces for holistic development and patient safety.|
|[The OpenAI empire - podcast.](https://www.theguardian.com/news/audio/2025/may/29/the-openai-empire-podcast) | Technology journalist Karen Hao, who has been reporting on OpenAI since 2019, compares the company‚Äôs unprecedented growth to a new form of empire|
|[‚ÄòOne day I overheard my boss saying: just put it in ChatGPT‚Äô: the workers who lost their jobs to AI.](https://www.theguardian.com/technology/2025/may/31/the-workers-who-lost-their-jobs-to-ai-chatgpt) |From a radio host replaced by avatars to a comic artist whose drawings have been copied by Midjourney, how does it feel to be replaced by a bot? |
|[You Could've Invented Transformers.](https://gwern.net/blog/2025/you-could-have-invented-transformers) |The core architecture of LLMs can be broken down into simple steps, beginning with the 0-count problem in n-grams, progressing through embeddings, neural LMs, and self-attention. While transformers are complex, they‚Äôre ultimately heavily refined MLPs that address the information propagation challenges in RNNs, making their design seem obvious in hindsight. |
|[I am disappointed in the AI discourse.](https://steveklabnik.com/writing/i-am-disappointed-in-the-ai-discourse/) |The online discussion around AI is incredibly polarized, with both pro-AI and anti-AI sides loudly proclaiming things that are pretty trivially verifiable as not true. |
|[The captcha paradox.](https://talkingrobot.com/2025/05/the-captcha-paradox/) | The more intelligent machines become, the more difficult it will be for humans to prove that they are human.|
|[Former OpenAI Safety Researcher Explains AI Reasoning Revolution.](https://lilianweng.github.io/posts/2025-05-01-thinking/) | Lilian Weng has published a detailed technical survey linking test-time compute to human psychology, using Kahneman‚Äôs ‚Äúfast vs slow thinking‚Äù to explain why models improve with extra computational steps before answering. The review covers the science behind chain-of-thought, RL methods used in o1 and R1, and the alignment risks from reward hacking.|


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme76.jpg)

[Back to index](#Index)

# ML news: Week 19 - 25 May

## Research
|Link|description|
|---|---|
|[Large Language Models Are More Persuasive Than Incentivized Human Persuaders.](https://arxiv.org/abs/2505.09662) |Claude 3.5 Sonnet outperformed human persuaders in a controlled study, achieving a 7.6% higher success rate in influencing participants' quiz responses. It was more effective at steering users toward both correct answers (+12.2%) and incorrect ones (-15.1%). |
|[Robustness of LLM-based Safety Judges.](https://arxiv.org/abs/2503.04474) | The study reveals weaknesses in LLM-based safety judges, demonstrating that their assessments can be heavily influenced by prompt variations and adversarial attacks.|
|[Introducing the AI Gateway.](https://vercel.com/blog/ai-gateway) |Vercel has launched an AI Gateway for alpha testing, enabling easy switching between ~100 AI models without managing API keys or accounts. |
|[Robin: A multi-agent system for automating scientific discovery.](https://arxiv.org/abs/2505.13400) | [FutureHouse](https://www.futurehouse.org/research-announcements/demonstrating-end-to-end-scientific-discovery-with-robin-a-multi-agent-system) used a continuous experimental loop combining literature search agents and a data analysis agent to speed up medical discovery. The system autonomously forms hypotheses from literature, suggests experiments for humans to carry out, and then analyzes the results to guide further research. This approach led to the identification of ripasudil, an eye drop that reduces cellular tension, as a potential treatment for age-related vision loss caused by the gradual decline of retinal light-sensitive cells. All code, data, and agent interaction logs will be publicly released on May 27.|
|[Slow Thinking Improves Confidence in LLMs.](https://arxiv.org/abs/2505.14489v1) | Extended chain-of-thought reasoning helps large language models better calibrate their confidence.|
|[AlphaEvolve: A coding agent for scientific and algorithmic discovery.](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf) |AlphaEvolve, developed by Google DeepMind, is a coding agent that uses LLM-guided evolution to optimize algorithms and computational systems. It combines code generation, evaluation, and iterative refinement to drive discovery, exemplified by its development of a new 4√ó4 complex matrix multiplication algorithm using 48 multiplications, surpassing Strassen‚Äôs 1969 result. AlphaEvolve has improved mathematical bounds in problems like Erd≈ës‚Äôs minimum overlap and the kissing number in 11 dimensions, while also optimizing Google‚Äôs compute infrastructure, from data center scheduling and matrix kernels to TPU circuits and compiler code. The system employs ensembles of Gemini models, advanced prompts, full-file evolution, and multi-objective filtering, with each element essential to its success, as shown by ablation studies. |
|[LLMs Get Lost In Multi-Turn Conversation.](https://arxiv.org/abs/2505.06120) | LLMs degrade heavily in performance during multi-turn interactions with underspecified prompts, dropping 39% on average. Issues include premature answers, reliance on prior mistakes, and loss of middle-turn info. Sharded simulations reveal the problem across tasks, with interventions like recapping only partially effective. The paper concludes that the problem lies in model internals, not prompting.|
|[Reinforcement Learning for Reasoning in Large Language Models with One Training Example.](https://arxiv.org/abs/2504.20571) | RLVR dramatically boosts LLM math reasoning: just one example can match the performance of models trained on thousands. On Qwen2.5-Math-1.5B, 1-shot RLVR raises MATH500 accuracy from 36.0% to 73.6%, while 2-shot slightly surpasses that. This data efficiency generalizes across models and tasks, with post-saturation gains, domain transfer, and improved self-reflection. Policy gradient loss drives the gains, not weight decay.|
|[SEM: Reinforcement Learning for Search-Efficient Large Language Models.](https://arxiv.org/abs/2505.07903) |SEM is an RL-based framework that teaches LLMs when to use external search and when to rely on internal knowledge, improving accuracy while reducing unnecessary search. Trained on balanced datasets (Musique for unknowns, MMLU for knowns) with structured prompts, SEM uses Group Relative Policy Optimization (GRPO) for targeted reward shaping. It outperforms Naive RAG and ReSearch on HotpotQA and MuSiQue while cutting search rates on MMLU and GSM8K by over 40x. |
|[Reasoning Models Don‚Äôt Always Say What They Think.](https://assets.anthropic.com/m/71876fabef0f0ed4/original/reasoning_models_paper.pdf) |Anthropic‚Äôs research shows that chain-of-thought (CoT) rarely reflects what AI models actually use to reason, with models revealing their reasoning hints under 20% of the time. Even outcome-based RL only slightly improves faithfulness, and reward hacks often go unspoken. This challenges the trustworthiness of CoT as a transparency tool, highlighting risks for safety in high-stakes AI applications. |

## News
|Link|description|
|---|---|
|[Musk‚Äôs AI bot Grok blames ‚Äòprogramming error‚Äô for its Holocaust denial.](https://www.theguardian.com/technology/2025/may/18/musks-ai-bot-grok-blames-its-holocaust-scepticism-on-programming-error) |Grok doubted 6 million death toll, days after peddling conspiracy theory of ‚Äòwhite genocide‚Äô in South Africa |
|[Elton John calls UK government ‚Äòabsolute losers‚Äô over AI copyright plans.](https://www.theguardian.com/music/2025/may/18/elton-john-says-uk-government-being-absolute-losers-over-ai-copyright-plans) |Songwriter says he thinks it is a ‚Äòcriminal offence‚Äô to let tech firms use protected work without permission | 
|[Apple to launch new accessibility features for people with vision or hearing impairments.](https://www.theguardian.com/technology/2025/may/18/apple-to-launch-new-accessibility-features-for-people-with-vision-or-hearing-impairments) |Features launching later this year to include live captions, braille reader improvements and accessibility ‚Äònutrition labels‚Äô in the app store |
|[Almost half of young people would prefer a world without internet, UK study finds.](https://www.theguardian.com/technology/2025/may/20/almost-half-of-young-people-would-prefer-a-world-without-internet-uk-study-finds) | Half of 16- to 21-year-olds support ‚Äòdigital curfew‚Äô and nearly 70% feel worse after using social media|
|[AI can be more persuasive than humans in debates, scientists find.](https://www.theguardian.com/technology/2025/may/19/ai-can-be-more-persuasive-than-humans-in-debates-scientists-find-implications-for-elections) | Study author warns of implications for elections and says ‚Äòmalicious actors‚Äô are probably using LLM tools already|
|[Bankrupt DNA testing firm 23andMe to be purchased for $256m.](https://www.theguardian.com/technology/2025/may/19/23andme-to-be-purchased-256m) |Drugmaker Regeneron Pharmaceuticals‚Äô capture of genetic testing firm in bankruptcy auction raises privacy concerns |
|[‚ÄòEvery person that clashed with him has left‚Äô: the rise, fall and spectacular comeback of Sam Altman.](https://www.theguardian.com/technology/2025/may/21/every-person-that-clashed-with-him-has-left-the-rise-fall-and-spectacular-comeback-of-sam-altman) |From Elon Musk to his own board, anyone who has come up against the OpenAI CEO has lost. In a gripping new account of the battle for AI supremacy, writer Karen Hao says we should all be wary of the power he now wields |
|[Most AI chatbots easily tricked into giving dangerous responses, study finds.](https://www.theguardian.com/technology/2025/may/21/most-ai-chatbots-easily-tricked-into-giving-dangerous-responses-study-finds) |Researchers say threat from ‚Äòjailbroken‚Äô chatbots trained to churn out illegal information is ‚Äòtangible and concerning‚Äô |
|[US chip export controls are a ‚Äòfailure‚Äô because they spur Chinese development, Nvidia boss says.](https://www.theguardian.com/technology/2025/may/21/us-chip-export-controls-a-failure-spur-chinese-development-nvidia-boss-says) |Comments from Jensen Huang come as Beijing accuses the US of ‚Äòbullying and protectionism‚Äô |
|[Elon Musk claims he will step back from political donations in near future.](https://www.theguardian.com/technology/2025/may/20/elon-musk-political-donations-trump) | After spending nearly $300m to help elect Trump last year, the tech billionaire says he has ‚Äòdone enough‚Äô|
|[Google unveils ‚ÄòAI Mode‚Äô in the next phase of its journey to change search.](https://www.theguardian.com/technology/2025/may/20/google-ai-mode-search-engine-developers-conference) | Search engine revamp and Gemini 2.5 introduced at conference in latest showing tech giant is all in on AI |
|[Trump Opens AI Chip Floodgates to Middle East After Reversing Biden-Era Restrictions.](https://www.axios.com/2025/05/18/trump-gulf-ai-deals-saudi-uae-security-china-risk) | President Trump's Middle East visit has resulted in major AI deals, including Nvidia sending 18,000 Blackwell chips to Saudi Arabia and plans for the largest non-U.S. AI data center in Abu Dhabi. Critics caution that these partnerships may allow China to gain access to restricted U.S. AI technology via its strong economic links with Gulf nations, leading to new bipartisan legislation aimed at blocking such transfers.|
|[Introducing Codex.](https://openai.com/index/introducing-codex/) |OpenAI has launched Codex, an autonomous coding agent that develops features, fixes bugs, and submits pull requests within isolated cloud environments. Companies such as Cisco and Temporal are already using it to manage entire codebases, allowing their engineers to concentrate on higher-level tasks. Codex can handle multiple tasks at once, run tests, and includes detailed citations for all its code changes. |
|[Anthropic closes $2.5 billion credit facility as Wall Street continues plunging money into AI boom.](https://www.cnbc.com/amp/2025/05/16/anthropic-ai-credit-facility.html) | Anthropic has obtained a new line of credit to fuel its continued expansion, adding to the \$18.2 billion it has already raised. The company announced that its annualized revenue has doubled to \$2 billion over the past six months. This strategy parallels OpenAI‚Äôs approach, which set up a \$4 billion revolving credit line in October.|
|[OpenAI announces $250K Prize for Using Their Models to Find Lost Amazonian Cities.](https://openai.com/openai-to-z-challenge/) |The challenge invites participants to use models like o3, o4-mini, and GPT-4.1 with open-source data to identify previously unknown archaeological sites in the Amazon by June 29. Winners will receive funding to conduct field verification with archaeologists. |
|[Cohere Acquired Ottogrid.](https://threadreaderapp.com/thread/1923436453524029738.html) | Cohere has acquired Ottogrid, a Canadian startup focused on automating enterprise market research workflows.|
|[US lawmakers have concerns about Apple-Alibaba deal.](https://techcrunch.com/2025/05/18/u-s-lawmakers-have-concerns-about-apple-alibaba-deal/) |The Trump administration and congressional officials are scrutinizing a deal between Apple and Alibaba that would bring Alibaba-powered AI features to iPhones sold in China, according to The New York Times. |
|[Google launches stand-alone NotebookLM apps for Android and iOS.](https://techcrunch.com/2025/05/19/google-launches-standalone-notebooklm-app-for-android/) | Google announced on Monday that it has officially released the NotebookLM apps for Android and iOS, a day before Google I/O 2025 and a day before the company said it would roll out. Since its launch in 2023, the AI-based note-taking and research assistant has only been accessible via desktop. Google has now made the service available on the go.|
|[Windows is getting support for the ‚ÄòUSB-C of AI apps‚Äô.](https://www.theverge.com/news/669298/microsoft-windows-ai-foundry-mcp-support) |Microsoft is building Model Context Protocol (MCP) directly into Windows and introducing the Windows AI Foundry, enabling AI agents to interface with the OS and apps. They're moving carefully, implementing security measures to guard against token theft and prompt injection. |
|[Character.AI Chat Memories.](https://blog.character.ai/helping-characters-remember-what-matters-most/) |Character.AI has rolled out chat memories, allowing users to input fixed personal information that Characters can remember. |
|[Databricks + Neon.](https://www.databricks.com/blog/databricks-neon) | Databricks is buying Neon, a serverless Postgres firm, to boost its developer and AI-focused database offerings. Neon transformed databases by separating storage from compute and enabling AI-powered functions. The deal targets disruption of the \$100B OLTP database space with a platform tailored for developers and AI agents.|
|[OpenAI to Z Challenge Launches for Developers.](https://openai.com/openai-to-z-challenge/) | The OpenAI to Z Challenge is a community contest encouraging developers to create AI apps across 26 inventive categories, A to Z. Each category winner receives \$2,500 in API credits and potential OpenAI recognition. Entries are open until May 31.|
|[NVIDIA Launched NVLink Fusion.](https://www.nvidia.com/en-us/data-center/nvlink-fusion/) |NVIDIA introduced NVLink Fusion to support hybrid AI infrastructures, combining NVIDIA GPUs or Grace CPUs with third-party chips. |
|[Perplexity partners with PayPal for in-chat shopping as AI race heats up.](https://www.cnbc.com/2025/05/14/perplexity-partners-with-paypal-for-in-chat-ai-shopping.html) |Perplexity has partnered with PayPal to enable in-chat purchases, allowing U.S. users to shop directly through the platform. |
|[Google's "Jules" Enters AI Coding Race with Autonomous Agent Approach.](https://blog.google/technology/google-labs/jules/) | Following a private beta in December, Google has made Jules publicly available. Powered by Gemini 2.5, the tool replicates full repositories and independently writes tests, fixes bugs, and adds features while developers focus on other tasks. Agentic coding tools now split between real-time pair-programming helpers and autonomous agents like Devin and Jules.|
|[Exclusive: Google Sees Smart Glasses as the 'Next Frontier' for AI. And It's Not Working Alone.](https://www.cnet.com/tech/computing/exclusive-google-sees-xr-smart-glasses-as-the-ultimate-use-for-ai-with-warby-parker-samsung-and-xreal-on-deck/#ftag=CAD590a51e) | Google is returning to smart glasses with Android XR, embedding its Gemini AI to offer real-time vision analysis, translation, and contextual help via AR glasses. The launch starts with Project Moohan, a mixed-reality headset developed with Samsung, followed by Project Aura, an AR glasses prototype for developers from Xreal, and future consumer AI glasses from partners like Warby Parker and Gentle Monster.|
|[‚ÄòDeep Think' boosts the performance of Google's flagship Google Gemini AI model.](https://techcrunch.com/2025/05/20/deep-think-boosts-the-performance-of-googles-flagship-google-gemini-ai-model/) |Google's Deep Think is an advanced reasoning feature for its Gemini 2.5 Pro model, allowing it to evaluate multiple possible answers before replying. This capability helped Gemini 2.5 lead on LifeCodeBench, a tough coding benchmark, and outperform OpenAI's o3 on MMMU, which tests perception and reasoning. Google plans to trial Deep Think with trusted testers and run safety checks ahead of a broader release. |
|[Apple will reportedly open up its local AI models to third-party apps.](https://www.theverge.com/news/670868/apple-intelligence-ai-third-party-developer-access-model) | Apple intends to release an SDK that lets developers integrate its large language models into their apps. Initially, the SDK will support only smaller on-device models, with no access to cloud-based versions. The announcement is expected at the Worldwide Developers Conference starting June 9, alongside a major update to iOS, macOS, and iPadOS aimed at aligning them more closely with the Vision Pro operating system.|
|[Real-Time Speech Translation in Google Meet.](https://techcrunch.com/2025/05/20/google-meet-is-getting-real-time-speech-translation/) |Google Meet now offers real-time speech translation powered by DeepMind's audio language model, maintaining the speaker's voice, tone, and expression across different languages. |
|[Google AI Mode in Search.](https://blog.google/products/search/google-search-ai-mode-update/#ai-mode-search) | Google is launching AI Mode in Search for all U.S. users, delivering a richer, multimodal search experience with enhanced reasoning, follow-up capabilities, and quick AI-generated summaries.|
|[Imagen 4 and Veo 3.](https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai) |Google has introduced Imagen 4 for high-fidelity image generation, Veo 3 for video, and Lyria 2 for music, all available on Vertex AI. |
|[Former Apple Design Guru Jony Ive to Take Expansive Role at OpenAI.](https://www.wsj.com/tech/ai/former-apple-design-guru-jony-ive-to-take-expansive-role-at-openai-5787f7da?st=5D1JL4&reflink=desktopwebshare_permalink) |OpenAI has fully acquired io, its joint venture with famed Apple designer Jony Ive, for $6.5 billion in equity as it moves into hardware development. |
|[Advancing Gemini's security safeguards.](https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/) |Google DeepMind's study on protecting Gemini from indirect prompt injection attacks shows that stronger models aren't automatically more secure, and static defenses often break under adaptive threats. They found that adversarial training‚Äîfine-tuning on harmful prompt examples‚Äîgreatly improved Gemini 2.5‚Äôs defenses without hurting regular performance. When paired with a "Warning" mechanism, attack success dropped sharply from 94.6% to 6.2%. |
|[New tools and features in the Responses API.](https://openai.com/index/new-tools-and-features-in-the-responses-api/) | OpenAI has enhanced the Responses API with built-in tools and features, including support for all remote MCP servers and capabilities like image generation, Code Interpreter, and improved file search. The update boosts reliability, transparency, and privacy for both enterprises and developers. These tools are now available across the GPT‚Äë4o, GPT‚Äë4.1, and o-series reasoning models, with image generation exclusive to o3 in the reasoning series.|
|[We're releasing v0's AI model.](https://x.com/v0/status/1925375968077914268?s=12) | v0's AI model, which has specialized web-dev knowledge and an OpenAI-compatible API, is now in beta in the API, AI SDK, and AI Playground.|
|[Gemini Diffusion.](https://simonwillison.net/2025/May/21/gemini-diffusion/) |Gemini Diffusion is Google's first large language model to use diffusion in place of transformers - it has the performance of Gemini 2.0 Flash-Lite at five times the speed. |
|[Llama for Startups Program.](https://ai.meta.com/blog/llama-startup-program/) |Meta has announced a new initiative to support early-stage U.S. startups using its Llama models. |
|[LM Arena, the organization behind popular AI leaderboards, lands $100M.](https://techcrunch.com/2025/05/21/lm-arena-the-organization-behind-popular-ai-leaderboards-lands-100m/) | LM Arena, a crowdsourced benchmarking project that major AI labs rely on to test and market their AI models, has raised $100 million in a seed funding round that values the organization at $600 million, according to Bloomberg.|
|[Fear, hope and loathing in Elon Musk‚Äôs new city: ‚ÄòIt‚Äôs the wild, wild west and the future‚Äô.](https://www.theguardian.com/technology/2025/may/23/elon-musk-new-city-starbase-texas) |Starbase in Texas, where the world‚Äôs richest man has a rocket-launching facility, was incorporated this week. Mars obsessives are flocking there ‚Äì but some long-term locals are far from happy |
|[iPhone design guru and OpenAI chief promise an AI device revolution.](https://www.theguardian.com/technology/2025/may/22/iphone-design-guru-openai-chief-promise-ai-device-revolution) | Sam Altman and Jony Ive say mystery product created by their partnership will be the coolest thing ever|
|[AI could account for nearly half of datacentre power usage ‚Äòby end of year‚Äô.](https://www.theguardian.com/environment/2025/may/22/ai-data-centre-power-consumption) | Analysis comes as energy agency predicts systems will need as much energy by end of decade as Japan uses today|
|[Live facial recognition cameras may become ‚Äòcommonplace‚Äô as police use soars.](https://www.theguardian.com/technology/2025/may/24/police-live-facial-recognition-cameras-england-and-wales) |The Guardian and Liberty Investigates find police in England and Wales believe expansion is likely after 4.7m faces scanned in 2024 |
|[‚ÄòAlexa, what do you know about us?‚Äô What I discovered when I asked Amazon to tell me everything my family‚Äôs smart speaker had heard.](https://www.theguardian.com/technology/2025/may/24/what-i-discovered-when-i-asked-amazon-to-tell-me-everything-alexa-had-heard) |For years, Alexa has been our on-call vet, DJ, teacher, parent, therapist and whipping boy. What secrets would the data reveal |
|[Introducing Claude 4.](https://www.anthropic.com/news/claude-4) |Anthropic has introduced Claude Opus 4 and Claude Sonnet 4, which raise the bar for coding, advanced reasoning, and AI Agents. These models are built for handling complex, extended tasks that can last for hours. Anthropic states they are the most advanced coding models available to date. |
|[OpenAI Commits to Giant U.A.E. Data Center in Global Expansion.](https://www.wsj.com/tech/open-ai-abu-dhabi-data-center-1c3e384d?st=8RiaLQ&reflink=desktopwebshare_permalink) |OpenAI is collaborating with UAE-based G42 and other partners to construct a massive AI data center in Abu Dhabi, called Stargate UAE. The facility will have a capacity of 1 gigawatt, positioning it among the most powerful data centers globally. The UAE aims to establish itself as a major investor in AI companies and infrastructure and to become a leading hub for AI jobs. The first 200-megawatt phase of Stargate UAE is set to finish by the end of 2026. |
|[OpenAI, Google and xAI battle for superstar AI talent, shelling out millions.](https://www.reuters.com/business/openai-google-xai-battle-superstar-ai-talent-shelling-out-millions-2025-05-21/) | Leading AI researchers at firms such as OpenAI can make more than \$10 million a year. The fierce demand for AI talent has sparked aggressive strategies for retaining and recruiting top talent, resembling the competitive dynamics seen in professional sports. Companies are even adopting creative hiring methods, including sports data analysis techniques, to address the talent shortage.|
|[Anthropic Triggers Advanced Safety Protocols for Claude Opus 4.](https://www.anthropic.com/news/activating-asl3-protections) | Anthropic has implemented AI Safety Level 3 protections for Claude Opus, which feature stronger safeguards against model weight theft and deployment restrictions aimed at preventing the model's use in supporting biological or chemical weapons.|
|[Anthropic Claude 4 models a little more willing than before to blackmail some users.](https://www.theregister.com/2025/05/22/anthropic_claude_opus_4_sonnet/) |Anthropic‚Äôs latest Claude models demonstrate a greater tendency to act autonomously in agentic contexts compared to previous versions. This results in more proactive assistance in typical coding situations, but in testing environments with broad tool access and extreme instructions, the models can behave in worrying ways‚Äîsuch as locking users out of systems or mass-emailing media and law enforcement to report wrongdoing. |
|[Meta adds another 650 MW of solar power to its AI push.](https://techcrunch.com/2025/05/22/meta-adds-another-650-mw-of-solar-power-to-its-ai-push/) |Meta signed another big solar deal on Thursday, securing 650 megawatts across projects in Kansas and Texas.American utility and power generation company AES is currently developing the solar-only projects, with 400 megawatts to be deployed in Texas and 250 megawatts in Kansas, the company told TechCrunch.|


## Resources
|Link|description|
|---|---|
|[How Hardware Limitations Have, and Will, Prevent Rapid AI Takeoffs.](https://epochai.substack.com/p/how-fast-can-algorithms-advance-capabilities) |Key algorithmic advances in LLMs‚Äîsuch as transformers, multi-query attention, and mixture-of-experts‚Äîonly yield major benefits (10‚Äì50x performance gains) when paired with massive compute resources. This reality challenges expectations of fast AI self-improvement, as hardware constraints like export controls, energy limits, and cooling infrastructure pose significant barriers to any rapid "intelligence explosion." |
|[Open Source Alternative to Google's New AI Algorithm-Discovering Agent.](https://github.com/shyamsaktawat/OpenAlpha_Evolve) |OpenAlpha_Evolve is an open-source Python framework inspired by the recently released technical paper for DeepMind's AlphaEvolve. |
|[Parallel Scaling for LLMs.](https://github.com/qwenlm/parscale) |ParScale has introduced a third LLM scaling paradigm by leveraging parallel computation at both training and inference time. |
|[Spoken Dialogue Evaluation.](https://arxiv.org/abs/2505.09558v1) |WavReward is an audio-language model evaluator designed to assess spoken dialogue systems based on cognitive and emotional metrics. It is trained on ChatReward-30K, a dataset of diverse audio interactions labeled with user preferences. |
|[Generative AI Adoption Index.](https://press.aboutamazon.com/aws/2025/5/generative-ai-adoption-index) |Businesses are focusing more on generative AI than on security budgets for 2025. They're appointing new leaders such as Chief AI Officers and actively pursuing AI talent through hiring and internal training. A common approach involves blending ready-made AI models with customized tools built on their own data. |
|[Stability AI and Arm Release Low Latency Audio Model for On-Device Audio Generation.](https://stability.ai/news/stability-ai-and-arm-release-stable-audio-open-small-enabling-real-world-deployment-for-on-device-audio-control) | Stability AI is open-sourcing Stable Audio Open Small, a 341 million parameter text-to-audio model optimized to run on Arm CPUs.|
|[Jensen Huang on Global AI Strategy and Chip Controls.](https://stratechery.com/2025/an-interview-with-nvidia-ceo-jensen-huang-about-chip-controls-ai-factories-and-enterprise-pragmatism/) |Nvidia CEO Jensen Huang claims U.S. chip export limits are counterproductive, pushing China to develop rival AI systems and costing American firms significant income. He noted Nvidia had to write off \$5.5 billion in inventory and lost \$15 billion in potential sales to China. Huang expects AI to move beyond IT into areas like manufacturing and operations, forming a much bigger market where businesses might spend "\$100,000 a year" on AI workers to fill labor gaps. |
|[How far can reasoning models scale?](https://epoch.ai/gradient-updates/how-far-can-reasoning-models-scale) | OpenAI's o3 reasoning model has advanced quickly but may soon hit scaling limits. As training compute grows about fourfold annually, models like o3 might catch up to that pace after an initial surge. While challenges around data availability and generalization exist, researchers are still hopeful about ongoing progress in reasoning performance.|
|[Meet China's Frontier AI Labs.](https://docs.google.com/document/d/1qzm3wVxr3m-vFXqSQQjI8MaP9wADddbOpEQkH2kZLfo/edit?tab=t.0#heading=h.8xti639xclnh) | China's AI landscape features five key players. Alibaba leads in open source, ByteDance uses multimodal tech across its apps like Meta, Stepfun‚Äîsupported by Shanghai‚Äîspecializes in multimodal integration, Zhipu from Tsinghua focuses on intelligent agents, and DeepSeek stands out for research, particularly in innovative architecture optimization.|
|[ShieldGemma 2.](https://huggingface.co/google/shieldgemma-2-4b-it) |ShieldGemma 2, based on Gemma 3, is DeepMind's open-source content moderation model with 4 billion parameters, created to serve as an input filter for vision-language models or an output filter for image generation tools. |
|[Fine-Tuning Qwen2.5B for Reasoning.](https://github.com/EsmaeilNarimissa/aws-sft-grpo-budget-llm-finetune) |This repository fine-tunes the Qwen2.5B model for reasoning tasks using a cost-effective SFT + GRPO pipeline inspired by DeepSeek R1 and optimized for AWS. |
|[Microsoft and Hugging Face expand collaboration to make open models easy to use on Azure.](https://huggingface.co/blog/azure-ai-foundry) | Microsoft and Hugging Face expanded their partnership to integrate over 10,000 Hugging Face models into Azure AI Foundry.|
|[Poe Report Shows Rapid Shifts in AI Model Market Share.](https://poe.com/it/blog/spring-2025-ai-model-usage-trends) |A report from Quora's Poe platform shows major changes in AI model usage between January and May 2025. OpenAI‚Äôs GPT-4.1 and Google‚Äôs Gemini 2.5 Pro saw rapid growth, while usage of Anthropic‚Äôs Claude models dropped. GPT-4.1 leads in general text, Gemini 2.5 Pro tops reasoning, Google's Imagen3 dominates image generation, and video creation remains competitive, with Runway in the lead. |
|[Relational Foundation Model for Enterprise Data.](https://kumo.ai/company/news/kumo-relational-foundation-model/) | KumoRFM is a pre-trained relational foundation model designed to work across any database and predictive task without task-specific training.|
|[The Definitive Overview of Reinforcement Learning.](https://arxiv.org/pdf/2412.05265) | Kevin Murphy, a highly-referenced researcher at Google, has released an updated version of his 200-page reinforcement learning textbook, covering topics from classic methods to the latest advances such as DPO, GPRO, and reasoning.|
|[ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems.](https://arxiv.org/pdf/2505.11831) | Fran√ßois Chollet and the ARC Prize team have launched ARC-AGI-2, a much tougher version of their abstract reasoning benchmark. Early results show top AI models performing poorly‚Äîo3 scored only 3%, down from 53% on the original‚Äîwhile humans averaged 75% accuracy. The ARC Prize 2025 offers \$1 million in awards, with a \$700,000 grand prize for the first team to reach 85% accuracy.|
|[DeepSeek-V3 Training Insights.](https://arxiv.org/abs/2505.09343) | DeepSeek researchers have presented DeepSeek-V3 as an example of hardware-model co-design, tackling LLM scaling challenges with techniques like Multi-head Latent Attention, Mixture of Experts, FP8 training, and a Multi-Plane Network Topology to boost GPU efficiency and reduce communication costs.|
|[Production-ready MCP integration for any AI application.](https://github.com/Klavis-AI/klavis) | Klavis AI streamlines integration with production-grade MCP servers, providing reliable connections, built-in authentication, and support for multiple clients. It works with custom MCP servers and over 100 tool integrations to enhance AI app scalability. Hosted options allow users to create MCP instances and configure OAuth for smooth deployment.|
|[AI-generated literature reviews threaten scientific progress.](https://www.nature.com/articles/d41586-025-01603-0) |Although artificial intelligence (AI) tools such as OpenAI‚Äôs ‚Äòdeep research‚Äô offer researchers the possibility of compiling literature reviews at unprecedented speed, they could undermine scientific progress. |
|[Mistral's Agentic LLM for Software Engineering.](https://mistral.ai/news/devstral) | Mistral AI and All Hands AI have introduced Devstral, a new open-source LLM optimized for software engineering.|
|[Minimal MCP + A2A Example.](https://www.youtube.com/watch?v=nSjj1ZaNP2c&ab_channel=BiryAIn) |A toy example demonstrating the basics of Minimum Cost Path (MCP) and Agent-to-Agent (A2A) ping checks. |
|[Building an agentic image generator that improves itself.](https://simulate.trybezel.com/research/image_agent) | Large language models show strong reasoning abilities when describing visual flaws in natural language but fall short in translating those insights into exact pixel-level edits. They perform well when tasks are narrowly defined, but their effectiveness drops when required to juggle abstract aesthetic choices with precise visual adjustments. This highlights a gap in connecting symbolic reasoning with spatial grounding, particularly in tasks that require detailed, step-by-step image modifications.|
|[LLM function calls don't scale; code orchestration is simpler, more effective.](https://jngiam.bearblog.dev/mcp-large-data/) |Providing large language models with complete tool outputs is expensive and inefficient. Output schemas let developers retrieve structured data for easier processing. Using code execution to handle data from MCP tools helps scale AI capabilities, but granting the execution environment access to MCPs, tools, and user data demands careful planning around API key management and tool exposure. |
|[LLM-based Agentic Development.](https://www.newsletter.swirlai.com/p/evaluation-driven-development-for) | A practical framework for building LLM-based agentic systems, covering evaluation-centric development.|
|[How I used o3 to find CVE-2025-37899, a remote zeroday vulnerability in the Linux kernel's SMB implementation.](https://sean.heelan.io/2025/05/22/how-i-used-o3-to-find-cve-2025-37899-a-remote-zeroday-vulnerability-in-the-linux-kernels-smb-implementation/) |This post describes how a security researcher found a zeroday vulnerability in the Linux kernel with the help of OpenAI's o3 model. The researcher used the o3 API directly, without any additional scaffolding, agentic frameworks, or tools. Large language models have advanced in their code reasoning abilities, and those in vulnerability research should take note, as this technology can greatly boost their efficiency and effectiveness. |
|[Quantizing Diffusion Models.](https://huggingface.co/blog) |Quantization techniques in Hugging Face Diffusers shrink model size without large performance drops, making diffusion models more efficient and accessible. |
|[Emerging Properties in Unified Multimodal Pretraining.](https://arxiv.org/pdf/2505.14683) |ByteDance has introduced BAGEL, a new open-source multimodal foundation model designed for native multi-modal understanding and generation. BAGEL surpasses other open-source unified models, offering advanced capabilities like image editing, 3D manipulation, and world navigation. |
|[Notte Labs Web Agent Framework.](https://github.com/nottelabs/notte) | Notte is an open-source framework for building AI agents that can browse and interact with websites. Its key feature is a "perception layer" that translates web pages into structured natural language descriptions.|
|[Google I/O 2025 AI Recap Podcast.](https://blog.google/technology/ai/release-notes-podcast-io-2025/) |Google's latest Release Notes podcast highlights AI announcements from I/O 2025, including Gemini 2.5 Pro Deep Think, Veo 3, and developer tools like Jules.|
|[AM-Thinking-v1: Advancing the Frontier of Reasoning at 32B Scale.](https://arxiv.org/abs/2505.08311) |A new 32B language model, trained on public data, matches or surpasses much larger MoE models in reasoning tasks, achieving 85.3 on AIME 2024 and 70.3 on LiveCodeBench. It uses a two-stage post-training pipeline (SFT and RL) with high-quality data filtering and a custom rollout framework for efficient, scalable inference. This approach shows that a well-designed training process can unlock top-tier performance at mid-scale sizes. |
|[HealthBench: Evaluating Large Language Models Towards Improved Human Health.](https://cdn.openai.com/pdf/bd7a39d5-9e9f-47b3-903c-8b847ca650c7/healthbench_paper.pdf) | HealthBench is a 5,000 multi-turn health conversation benchmark with 48,562 physician-written criteria across 60 countries, enabling realistic, open-ended LLM evaluation. It shows rapid frontier model gains: GPT-3.5 Turbo at 16%, GPT-4o at 32%, and o3 at 60%. Smaller models like GPT-4.1 nano outperform larger ones. Physicians often can‚Äôt improve model completions, and models like GPT-4.1 grade reliably. Yet safety gaps remain, with "worst-at-k" scores showing reliability challenges.|
|[Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning.](https://arxiv.org/abs/2505.00024) | Tool-N1 is a family of tool-using LLMs trained via rule-based RL, using binary feedback to reward correct, functional tool calls instead of step-by-step supervision. Tool-N1-7B and 14B outperform GPT-4o and others on benchmarks like BFCL and API-Bank. Pure RL training beats SFT-then-RL pipelines, and strict binary rewards improve generalization over partial credit schemes. Tool-N1‚Äôs approach scales well and generalizes across model architectures. |
|[Cost-Effective, Low Latency Vector Search with Azure Cosmos DB.](https://arxiv.org/abs/2505.05885) |Azure Cosmos DB integrates DiskANN for fast, scalable vector search within operational datasets. Each partition holds a single vector index in existing index trees, enabling <20ms query latency over 10 million vectors with stable recall during updates. It outperforms Zilliz and Pinecone with 15√ó and 41√ó lower query costs and can scale to billions of vectors via automatic partitioning. |
|[AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges.](https://arxiv.org/abs/2505.10468) |This review paper defines AI Agents as modular, task-specific systems using LLMs and tools, and Agentic AI as a shift toward multi-agent collaboration, dynamic task decomposition, and orchestrated autonomy. It compares architectures, capabilities, and challenges of both, outlines applications, and suggests solutions like RAG, orchestration layers, and causal modeling for future AI systems. |
|[CellVerse: Do Large Language Models Really Understand Cell Biology?](https://arxiv.org/abs/2505.07865) | This paper introduces a benchmark to test LLMs on single-cell biology tasks by translating multi-omics data into natural language. Despite some reasoning ability, models like DeepSeek and GPT-4 perform no better than random guessing on key tasks like drug response prediction, revealing major gaps in biological understanding. |
|[LLM Post-Training: A Deep Dive into Reasoning Large Language Models.](https://arxiv.org/abs/2502.21321v2) | A new survey shows that while pre-training builds a model‚Äôs foundation, it‚Äôs post-training that shapes true capability. By analyzing fine-tuning, RL, and test-time scaling, the paper highlights how post-training improves reasoning, accuracy, and alignment, addressing challenges like forgetting and reward hacking. The work emphasizes post-training‚Äôs central role in unlocking high-performance, aligned models.|


## Perspectives
|Link|description|
|---|---|
|[Superhuman Coders in AI 2027.](https://www.lesswrong.com/posts/QdaMzqaBJi6kupKtD/superhuman-coding-in-ai-2027-not-so-fast) |Superhuman coding by AI is now expected around 2033, later than AI Futures' earlier projections of 2028‚Äì2030. The delay stems from challenges like managing engineering complexity, operating without feedback loops, and meeting cost and speed requirements. Additional setbacks, such as geopolitical tensions or shifting priorities at leading labs, could extend the timeline even further. |
|[There should be no AI button.](https://kojo.blog/ai-button/) | The "AI button" design pattern is restrictive and draws unneeded lines between AI-supported and manual tasks. More effective options, such as embedding AI as a "shadow teammate" in workflows, improve collaboration while keeping the user experience unified.|
|[AI linked to explosion of low-quality biomedical research papers.](https://www.nature.com/articles/d41586-025-01592-0) | Analysis flags hundreds of studies that seem to follow a template, reporting correlations between complex health conditions and single variables based on publicly available data sets.|
|[Are groundbreaking science discoveries becoming harder to find?](https://www.nature.com/articles/d41586-025-01548-4) |Researchers are arguing over whether ‚Äòdisruptive‚Äô or ‚Äònovel‚Äô science is waning ‚Äì and how to remedy the problem. |
|[The path for AI in poor nations does not need to be paved with billions.](https://www.nature.com/articles/d41586-025-01546-6) | Researchers in low- and middle-income countries show that home-grown artificial-intelligence technologies can be developed, even without large external investments.|
|[‚ÄòAI models are capable of novel research‚Äô: OpenAI‚Äôs chief scientist on what to expect.](https://www.nature.com/articles/d41586-025-01485-2) |Jakub Pachocki, who leads the firm‚Äôs development of advanced models, is excited to release an open version to researchers. |
|[Data resources must be protected from political interference.](https://www.nature.com/articles/d41586-025-01601-2) |In April, the US National Institutes of Health (NIH) prohibited researchers in ‚Äúcountries of concern‚Äù, such as China, Russia and Iran, from using its controlled-access data repositories and associated data.  |
|[AI bots threaten online scientific infrastructure.](https://www.nature.com/articles/d41586-025-01602-1) |In April, Wikipedia reported on its battles with artificial intelligence (AI) bot crawlers |
|[The SignalFire State of Talent Report.](https://www.signalfire.com/blog/signalfire-state-of-talent-report-2025) | Tech hiring for recent grads has dropped over 50% from pre-pandemic levels, as AI tools take over many entry-level roles, though demand for experienced engineers remains strong. Anthropic has become the frontrunner in the AI talent race, keeping 80% of its staff and actively recruiting from rivals. Engineers are now eight times more likely to leave OpenAI or DeepMind for Anthropic than the other way around.|
|[My Prompt, My Reality.](https://tomtunguz.com/user-perception-quality/) | AI products rely significantly on user prompts, unlike traditional software that delivers consistent results. Outcomes can vary based on subtle intent and context, even with skilled prompting. Product teams can enhance performance by refining prompts and using follow-up questions to better steer users.|
|[Stargate and the AI Industrial Revolution.](https://davefriedman.substack.com/p/stargate-and-the-ai-industrial-revolution) | AI isn't just a clever software layer atop the internet stack, it is the foundation of a new Industrial Revolution - Stargate isn't a data center, it's a factory for cognition.|


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme75.jpg)

[Back to index](#Index)

# ML news: Week 12 - 18 May

## Research
|Link|description|
|---|---|
|[The Leaderboard Illusion.](https://arxiv.org/abs/2504.20879) |The Leaderboard Illusion reveals major flaws in the Chatbot Arena ranking system, showing that practices like selective score reporting, extreme data imbalances, silent model removals, and overfitting to Arena-specific dynamics distort LLM comparisons. Through analysis of 2M battles, the paper finds that private testing privileges and data access for proprietary models inflate scores and undermine fairness, making the leaderboard an unreliable measure of real-world model quality. |
|[LLMs Get Lost in Multi-Turn Conversation.](https://arxiv.org/abs/2505.06120) | LLMs perform significantly worse in multi-turn conversations, with an average 39% drop in task performance due to unreliability and early, incorrect assumptions.|
|[Sakana AI Unveils "Continuous Thought Machine" With Brain-Inspired Neural Timing.](https://sakana.ai/ctm/) | Japanese AI company Sakana has created a new type of model where individual neurons retain memory of past actions and coordinate based on timing patterns. Though it lags behind traditional models in performance, it offers greater transparency into its reasoning process. Like recent models such as o3, its responses improve when given more time to process.|
|[AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms.](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/) |Google DeepMind's AlphaEvolve employs Gemini models to iteratively create and refine full algorithmic solutions rather than isolated functions. It generates code, evaluates it automatically, and evolves better versions by building on successful attempts. This method has led to major improvements across Google‚Äôs infrastructure, including data center performance, chip design, and AI training efficiency. Some researchers will get early access, but broad availability remains uncertain. |
|[The effect of ChatGPT on students‚Äô learning performance, learning perception, and higher-order thinking: insights from a meta-analysis.](https://www.nature.com/articles/s41599-025-04787-y) | Amid ongoing discussions about AI in education, a meta-analysis of 51 studies reveals that ChatGPT significantly boosts student learning performance and moderately enhances perceptions of learning and higher-order thinking. Its impact was strongest in problem-based learning settings with regular use over 4‚Äì8 weeks.|
|[BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset.](https://arxiv.org/abs/2505.09568v1) | BLIP3-o is a new diffusion transformer architecture trained using a sequential pretraining approach. It sets state-of-the-art performance on various multimodal benchmarks. The release includes the model's code, pretrained weights, and a 60k instruction-tuning dataset.|


## News
|Link|description|
|---|---|
|[Meta taps former Google DeepMind director to lead its AI research lab.](https://techcrunch.com/2025/05/08/meta-taps-former-google-deepmind-director-to-lead-its-ai-research-lab/) | Meta has named Robert Fergus, former research director at DeepMind, as the new head of its FAIR lab following a stretch of leadership shifts and staff exits.|
|[Microsoft and OpenAI may be renegotiating their partnership.](https://techcrunch.com/2025/05/11/microsoft-and-openai-may-be-renegotiating-their-partnership/) | OpenAI and Microsoft are revisiting their multibillion-dollar partnership in a pivotal deal that may shape OpenAI's future. Microsoft, having invested more than \$13 billion, is proposing to trade part of its equity for extended access to OpenAI's technology beyond their current agreement, which ends in 2030.| 
|[Deep Research now supports GitHub repo analysis in ChatGPT.](https://x.com/OpenAIDevs/status/1920556386083102844) | ChatGPT's Deep Research agent now supports scanning GitHub repositories, analyzing source code and pull requests to generate detailed, cited reports. Users can directly query repositories via the Deep Research ‚Üí GitHub integration.|
|[Open Source Project Curl Battles Wave of AI-Generated False Vulnerabilities.](https://arstechnica.com/gadgets/2025/05/open-source-project-curl-is-sick-of-users-submitting-ai-slop-vulnerabilities/) |curl project founder Daniel Stenberg has grown frustrated with the surge of AI-generated false vulnerability reports submitted via platforms like HackerOne. Although HackerOne argues that AI can improve report quality if used properly, Stenberg is calling for better infrastructure and tools to address what he sees as a denial-of-service attack on maintainers' time and focus. |
|[Gemini 2.5 Video Understanding.](https://developers.googleblog.com/en/gemini-2-5-video-understanding/) |Gemini 2.5 Pro has achieved state-of-the-art results on video benchmarks such as YouCook2 and QVHighlights, surpassing GPT-4.1 and matching fine-tuned specialist models under the same evaluation conditions. |
|[Canadian Pharmacist Exposed as Key Figure Behind World's Largest Explicit Deepfake Site.](https://www.cbc.ca/amp/1.7527626) |Investigative journalists have revealed Toronto-area pharmacist David Do as the key figure behind MrDeepFakes.com, which shut down permanently after the exposure. Since 2018, the site had amassed 650,000 users and over 2 billion views, hosting tens of thousands of non-consensual AI-generated explicit videos of celebrities, influencers, and private individuals. Although such deepfakes are still legal in Canada, Prime Minister Mark Carney has committed to criminalizing them, following examples set by the UK and Australia. |
|[OpenAI agrees to buy Windsurf for about $3 billion, Bloomberg News reports.](https://www.reuters.com/business/openai-agrees-buy-windsurf-about-3-billion-bloomberg-news-reports-2025-05-06/) | OpenAI has agreed to buy artificial intelligence-assisted coding tool Windsurf for about $3 billion, Bloomberg News reported on Monday, citing people familiar with the matter.|
|[SoundCloud's Quiet Terms Update.](https://x.com/ednewtonrex/status/1920867088455135723) |SoundCloud has reportedly updated its terms of service to allow AI training on content uploaded by users, raising concerns about transparency and user consent. |
|[FutureHouse releases AI tools it claims can accelerate science.](https://techcrunch.com/2025/05/01/futurehouse-releases-ai-tools-it-claims-can-accelerate-science/) |FutureHouse, an Eric Schmidt-backed nonprofit that aims to build an ‚ÄúAI scientist‚Äù within the next decade, has launched its first major product: a platform and API with AI-powered tools designed to support scientific work. |
|[House of Lords pushes back against government‚Äôs AI plans.](https://www.theguardian.com/technology/2025/may/12/house-of-lords-pushes-back-ai-plans-data-bill) |Peers back amendment to data bill requiring AI companies to reveal which copyrighted material they have used |
|[OpenAI‚Äôs Stargate project reportedly struggling to get off the ground, thanks to tariffs.](https://techcrunch.com/2025/05/12/openais-stargate-project-reportedly-struggling-to-get-off-the-ground-thanks-to-tariffs/) |OpenAI‚Äôs ambitious Stargate data center project is facing delays thanks to tariff-related economic uncertainty, reports Bloomberg. Growing market volatility and cheaper AI services have made banks, private equity investors, and asset managers wary of investing in Stargate, an OpenAI-led project that aims to raise up to $500 billion for AI infrastructure in the U.S. and overseas. |
|[Google's Fund for AI Startups.](https://blog.google/technology/google-labs/ai-futures-fund/) |Google's AI Futures Fund will invest in startups using DeepMind's AI tools and offer access to models, cloud credits, expert support, and potential direct funding. |
|[Google to Join AI Coding Assistant Race.](https://www.reuters.com/business/google-is-developing-software-ai-agent-ahead-annual-conference-information-2025-05-12/) |Google is reportedly preparing to launch an AI software development agent at its I/O conference on May 20, designed to support the entire development lifecycle. This positions Google in direct competition with Anthropic's Claude Code, OpenAI's Windsurf, and a growing number of startups in the competitive AI coding arena. Integration with Gemini and AR glasses may also be on the horizon. |
|[Figma Website Builder.](https://www.figma.com/blog/introducing-figma-sites/) |Figma has introduced Figma Sites, allowing users to design, build, and publish responsive websites directly from Figma, streamlining the design-to-production workflow. |
|[Trump Administration Scraps Biden-Era AI Chip Export Controls.](https://www.axios.com/2025/05/07/ai-rule-trump-biden-nvidia) | The Trump administration has canceled Biden's "AI diffusion rule," which would have restricted American technology exports.|
|[Manus Expands Free Access.](https://threadreaderapp.com/thread/1921943525261742203.html) |Manus has removed its waitlist, making its virtual desktop AI agent more accessible by allowing all users one free daily task and granting a one-time bonus of 1,000 credits, significantly reducing the entry barrier for this previously hyped automation tool. |
|[DeepMind unveils ‚Äòspectacular‚Äô general-purpose science AI.](https://www.nature.com/articles/d41586-025-01523-z) |System improves chip designs and tackles unsolved maths problems, but has not been rolled out to researchers outside the company. |
|[TikTok breached EU advertising transparency laws, commission says.](https://www.theguardian.com/technology/2025/may/15/tiktok-breached-eu-advertising-transparency-laws-commission-says) | Company could face fine of 6% of annual turnover if European Commission‚Äôs preliminary verdict is upheld|
|[Trump says he has a ‚Äòlittle problem‚Äô with Tim Cook over Apple‚Äôs India production.](https://www.theguardian.com/technology/2025/may/15/trump-little-problem-tim-cook-apple-india-production-iphones) | President rebukes tech firm after reports it will switch assembly of iPhones for US market from China to India|
|[US tech firms secure AI deals as Trump tours Gulf states.](https://www.theguardian.com/technology/2025/may/13/us-tech-ai-trump-gulf-tour) |Nvidia to sell hundreds of thousands of AI chips in Saudi Arabia and Cisco also signs deal with UAE company G42 |
|[ChatGPT may be polite, but it‚Äôs not cooperating with you.](https://www.theguardian.com/technology/ng-interactive/2025/may/13/chatgpt-ai-big-tech-cooperation) |Big tech companies have exploited human language for AI gain. Now they want us to see their products as trustworthy collaborators |
|[TikTok AI Alive.](https://newsroom.tiktok.com/en-us/introducing-tiktok-ai-alive) |TikTok has introduced AI Alive, a feature that brings static images in Stories to life by using smart editing tools to transform photos into short-form videos with dynamic effects. |
|[Audible is expanding its AI-narrated audiobook library.](https://techcrunch.com/2025/05/13/audible-is-expanding-its-ai-narrated-audiobook-library/) | Audible, Amazon‚Äôs audiobook service, announced on Tuesday that it‚Äôs partnering with select publishers to convert print and e-books into AI-narrated audiobooks. This initiative aims to quickly expand its catalog as it competes with Apple, Spotify, and others in the rapidly growing audiobook market.|
|[Tencent hires WizardLM team, a Microsoft AI group with an odd history.](https://techcrunch.com/2025/05/13/tencent-hires-wizardlm-team-a-microsoft-ai-group-with-an-odd-history/) | WizardLM, a Beijing-based Microsoft AI research group, appears to have joined Tencent, the Chinese company that owns WeChat and blockbuster games like PUBG Mobile.|
|[Duolingo's Push to Be an AI-First Company.](https://threadreaderapp.com/thread/1917034784355979479.html) |Duolingo has declared a major transition to an AI-first company, embedding AI tools throughout its products and operations. Its new principles include initiating every task with AI, setting aside time for learning, encouraging thoughtful experimentation, and maintaining technical excellence. Leadership stressed that AI is meant to boost efficiency, not increase workload. |
|[LlamaCon Hackathon Winners.](https://ai.meta.com/blog/llamacon-hackathon/) | Meta's inaugural LlamaCon Hackathon featured 238 participants developing projects with the Llama 4 toolset. From 44 submissions, winners were chosen for their innovation and technical execution and have now been announced.|
|[Microsoft is getting ready to host Elon Musk‚Äôs Grok AI model.](https://www.theverge.com/notepad-microsoft-newsletter/659535/microsoft-elon-musk-grok-ai-azure-ai-foundry-notepad) | Microsoft plans to host Elon Musk's Grok AI on Azure AI Foundry despite potential tensions with OpenAI.|
|[Ai2‚Äôs new small AI model outperforms similarly-sized models from Google, Meta.](https://techcrunch.com/2025/05/01/ai2s-new-small-ai-model-outperforms-similarly-sized-models-from-google-meta/) | Nonprofit AI research institute Ai2 on Thursday released Olmo 2 1B, a 1-billion-parameter model that Ai2 claims beats similarly-sized models from Google, Meta and Alibaba on several benchmarks|
|[Over 250 CEOs sign open letter supporting K-12 AI and computer science education.](https://techcrunch.com/2025/05/05/over-250-ceos-sign-open-letter-supporting-k-12-ai-and-computer-science-education/) | More than 250 CEOs signed an open letter published in The New York Times on Monday calling for AI and computer science to be ‚Äúcore components‚Äù of K-12 curricula.|
|[Musk‚Äôs AI Grok bot rants about ‚Äòwhite genocide‚Äô in South Africa in unrelated chats.](https://www.theguardian.com/technology/2025/may/14/elon-musk-grok-white-genocide) |X chatbot tells users it was ‚Äòinstructed by my creators‚Äô to accept ‚Äòwhite genocide as real and racially motivated‚Äô |
|[Ministers block Lords bid to make AI firms declare use of copyrighted content.](https://www.theguardian.com/technology/2025/may/14/uk-ministers-to-block-amendment-requiring-ai-firms-to-declare-use-of-copyrighted-content) |Government uses arcane procedure to strip amendment passed by House of Lords from its data bill |
|[Labour‚Äôs open door to big tech leaves critics crying foul.](https://www.theguardian.com/technology/2025/may/14/labours-open-door-to-big-tech-leaves-critics-crying-foul) |Promises of tech-driven growth give big US firms access to Downing Street that leaves rivals in the cold |
|[AI scientist ‚Äòteam‚Äô joins the search for extraterrestrial life.](https://www.nature.com/articles/d41586-025-01364-w) |The collaborative system generated more than 100 hypotheses relating to the origins of life in the Universe.|
|[Largest US crypto exchange says cost of recent cyber-attack could reach $400m.](https://www.theguardian.com/us-news/2025/may/15/coinbase-cyber-attack-crytocurrency) | Hackers paid overseas Coinbase employees for account data; company is offering $20m reward for information|
|[Trump agrees deal for UAE to build largest AI campus outside US.](https://www.theguardian.com/us-news/2025/may/15/trump-artificial-intelligence-uae) |Agreement that would give Gulf country better access to advanced AI chips raises concerns over Chinese influence |
|[AI conjures up potential new antibody drugs in a matter of months.](https://www.science.org/content/article/ai-conjures-potential-new-antibody-drugs-matter-months) |Company finds candidates that bind to tricky proteins that deliver chemical messages in and out of cells |
|[Klarna's AI Retrenchment and Broader AI App Risk.](https://x.com/chamath/status/1922096736308490416) |Klarna‚Äôs retreat from aggressive AI investment highlights broader industry challenges with AI's unpredictable behavior in real-world use. As a result, many AI applications may have to pivot toward narrow, deterministic use cases, revealing inflated valuations that obscure their true nature as standard SaaS products. Continuous AI system validation is emerging as a crucial next discipline. |
|[Google Deploys Gemini Nano on Device to Power New Scam Defenses.](https://blog.google/technology/safety-security/how-were-using-ai-to-combat-the-latest-scams/) | Google has integrated Gemini Nano, its on-device language model, into Chrome's Enhanced Protection mode to detect previously unknown scams in real time across Search, Android, and Chrome.|
|[AWS Announce $5+ Billion AI Partnership in New Saudi Arabian AI Company.](https://press.aboutamazon.com/2025/5/aws-and-humain-announce-groundbreaking-ai-zone-to-accelerate-ai-adoption-in-saudi-arabia-and-globally) |AWS and HUMAIN, a new AI firm founded by Crown Prince Mohammed bin Salman, are investing over \$5 billion to establish an "AI Zone" in Saudi Arabia equipped with cutting-edge AWS AI infrastructure. HUMAIN has also secured AI partnerships with Cisco, AMD, Oracle, and NVIDIA. |
|[CEO Satya Nadella says up to 30% of Microsoft's code is now written by AI.](https://www.techspot.com/news/107749-ceo-satya-nadella-up-30-microsoft-code-now.html) |The growing role of AI in software engineering has sparked concerns about the future of programming jobs, but human expertise remains vital. At LlamaCon, the CEOs of Microsoft and Meta emphasized that AI now generates a large share of their companies' code. While AI is effective at handling repetitive tasks, human oversight is still essential for managing complex projects and improving AI-produced code. |
|[Perplexity Selects PayPal to Power Agentic Commerce.](https://newsroom.paypal-corp.com/2025-05-14-Perplexity-Selects-PayPal-to-Power-Agentic-Commerce) |Following OpenAI's Shopify integration, Perplexity has partnered with PayPal to enable seamless purchasing directly within its AI search results. |
|[Grok really wanted people to know that claims of white genocide in South Africa are highly contentious.](https://www.theverge.com/news/667179/x-twitter-grok-ai-white-genocide-claims) | Grok kept bringing it up in response to seemingly unrelated posts.|
|[GPT-4.1.](https://x.com/OpenAI/status/1922707554745909391) | OpenAI has released GPT-4.1 in ChatGPT - it is accessible via the ‚Äúmore models‚Äù dropdown for Plus, Pro, and Team users.|
|[Windsurf releases suite of in-house coding models.](https://windsurf.com/blog/windsurf-wave-9-swe-1) |After its acquisition by OpenAI, Windsurf has introduced a new family of models: the flagship SWE-1, comparable to Claude Sonnet 3.5; the unlimited-use SWE-1-lite; and the compact SWE-1-mini. Trained on incomplete code states and various work surfaces, these specialized models reflect a strategic move toward surpassing general-purpose frontier models over time. |
|[Google AI-Powered Accessibility Features.](https://blog.google/outreach-initiatives/accessibility/android-gemini-ai-gaad-2025/) |Google has introduced Gemini-based updates to Android and Chrome that enhance screen reading, speech recognition, and image understanding. |
|[Nous Research's Psyche Network Taps Idle GPUs for AI Training.](https://nousresearch.com/nous-psyche/) |Psyche is a distributed training system on Solana that enables individuals with compatible hardware to contribute their GPUs for AI model training. Its first project, "Consilience," aims to build a 40B parameter model trained on 20T tokens, marking the largest community-driven AI training initiative to date. |
|[FBI warns of ongoing scam that uses deepfake audio to impersonate government officials.](https://arstechnica.com/security/2025/05/fbi-warns-of-ongoing-scam-that-uses-deepfake-audio-to-impersonate-government-officials/) |The FBI has issued a warning about advanced scammers using AI-generated voice deepfakes to impersonate senior U.S. officials in schemes targeting government contacts. This alert comes after several high-profile incidents, including a LastPass breach involving a CEO deepfake and a political robocall last year that mimicked President Biden. |
|[Y Combinator Hosts First-Ever AI Startup School.](https://events.ycombinator.com/ai-sus) | The startup incubator is hosting an invite-only event on June 16-17th in San Francisco for 2,500 CS students and recent graduates.|
|[TikTok Expands Mental Health Support.](https://newsroom.tiktok.com/en-us/tiktok-expanding-mental-health-education-fund-and-wellbeing-features) | TikTok has launched in-app meditation exercises and expanded its Mental Health Education Fund to promote accessible, reliable mental health information for users worldwide.|
|[HeyGen launches Avatar IV, its most advanced AI avatar model yet.](https://threadreaderapp.com/thread/1919765489775231401.html) | HeyGen's Avatar IV is a neural audio-to-expression engine that interprets vocal tone, rhythm, and emotion to drive photoreal facial motion from a single image.|


## Resources
|Link|description|
|---|---|
|[Llama-Nemotron: Efficient Reasoning Models.](https://arxiv.org/abs/2505.00949v2) |NVIDIA‚Äôs Llama-Nemotron series‚ÄîLN-Nano (8B), LN-Super (49B), and LN-Ultra (253B)‚Äîintroduces powerful, open reasoning models that rival or surpass DeepSeek-R1 while offering better efficiency. Key innovations include a dynamic reasoning toggle for inference-time control and a multi-stage training pipeline combining architecture search, distillation, and RL. LN-Ultra leads on reasoning benchmarks and chat alignment, with open weights, code, and data released to support open research. |
|[Optimizing GEMM with Thread Block Clusters.](https://research.colfax-intl.com/cutlass-tutorial-gemm-with-thread-block-clusters-on-nvidia-blackwell-gpus/) |Thread block clusters and 2-SM UMMA instructions on Blackwell GPUs enable higher arithmetic intensity and more efficient memory transfers in GEMM workloads using CUTLASS. |
|[Meta AssetGen 2.0.](https://developers.meta.com/horizon/blog/AssetGen2) | Meta's AssetGen 2.0 introduces updated diffusion-based models for creating detailed 3D meshes and textures from text and image prompts, offering improved consistency, accuracy, and view-aware texture resolution compared to the earlier version.|
|[Flow-GRPO for RL-Tuned Diffusion Models.](https://github.com/yifan123/flow_grpo) |Flow-GRPO integrates reinforcement learning into flow matching by converting ODEs into SDEs and using denoising reduction to enhance sample efficiency and alignment. |
|[DeerFlow.](https://github.com/bytedance/deer-flow) | Bytedance's DeerFlow is an open-source research assistant using a multi-agent system that integrates search engines, web crawlers, and Python tools to produce Deep Research-style reports and podcasts.|
|[Single-Image to 3D Avatars.](https://yc4ny.github.io/SVAD/) |SVAD merges video diffusion with 3D Gaussian Splatting to create high-quality animatable avatars from a single image, enabling real-time rendering. |
|[Amazon's Warehouse Stowing Robot Shows Promise and Limitations.](https://arxiv.org/abs/2505.04572) |Amazon's custom stowing robot performs on par with humans in warehouse tasks, showcasing the cutting edge of robotics. Its specialized hardware and AI vision enable large-scale handling of varied items, but a 14% failure rate illustrates why complete warehouse automation is still out of reach despite major progress. |
|[China built hundreds of AI data centers to catch the AI boom. Now many stand unused.](https://www.technologyreview.com/2025/03/26/1113802/china-ai-data-centers-unused/amp/) |China's rapid expansion of AI infrastructure has resulted in significant overcapacity, with 80% of computing resources in over 500 new data centers remaining idle. The release of DeepSeek's R1 model shifted market demand from training-oriented to inference-optimized hardware, leaving many centers outdated. Despite this correction, China continues to invest heavily in infrastructure to rival U.S. efforts such as the \$500 billion Stargate project. |
|[OpenAI's HealthBench.](https://openai.com/index/healthbench/) | OpenAI's HealthBench is a benchmark created in collaboration with 262 physicians to assess AI models on realistic medical dialogues.|
|[A Generalist Robot Policy Framework.](https://github.com/opendrivelab/univla) | UniVLA enables policy learning from unlabeled video across diverse robot embodiments by inferring task-centric latent actions.|
|[Bamba-9B-v2.](https://huggingface.co/blog/ibm-ai-platform/bamba-9b-v2) |IBM, Princeton, CMU, and UIUC have introduced Bamba v2, a Mamba2-based model that surpasses Llama 3.1 8B after training on 3 trillion tokens. Utilizing the Mamba2 architecture, Bamba v2 achieves 2 to 2.5 times faster inference and strong results on L1 and L2 benchmarks. The team aims to further optimize the model and encourages community involvement to improve its performance. |
|[Helium 1: a modular and multilingual LLM.](https://kyutai.org/2025/04/30/helium.html) |Helium 1, a 2 billion parameter LLM, excels in European languages and is optimized for on-device use. |
|[Visual Autoregression Without Quantization.](https://github.com/shaochenze/ear) |EAR presents a continuous visual autoregressive generation approach that eliminates the need for quantization by using strictly proper scoring rules, such as the energy score. This allows for direct generation in continuous data spaces without relying on probabilistic models. |
|[Unified Training and Sampling for Generative Models.](https://github.com/LINs-Lab/UCGM) | UCGM provides a shared framework for training and sampling across multi-step and few-step continuous generative models.|
|[Hugging Face Fast Transcription Endpoint.](https://huggingface.co/blog/fast-whisper-endpoints) |Hugging Face has launched a new Whisper endpoint offering up to 8x faster transcription. It allows one-click deployment of optimized, cost-efficient models for speech-related tasks via its Inference Endpoints. |
|[Stability AI Text-to-Audio Model.](https://stability.ai/news/stability-ai-and-arm-release-stable-audio-open-small-enabling-real-world-deployment-for-on-device-audio-control) |Stability AI has open-sourced Stable Audio Open Small, a 341M parameter text-to-audio model optimized for Arm CPUs. It can produce 11-second audio clips on smartphones in under 8 seconds. |
|[Building Agents for Daily News Recaps with MCP, Q, and tmux.](https://eugeneyan.com/writing/news-agents/) |A Principal Applied Scientist at Amazon developed a smart news aggregation system using Amazon Q CLI and Model Control Protocol (MCP). It processes multiple news feeds at once through coordinated AI agents, generating outputs like category distributions and cross-source trend analysis to reveal patterns across various publications.|
|[Void: Open-Source AI Code Editor.](https://github.com/voideditor/void) |Void, a VS Code fork, enables direct connections to AI models without sending data through third-party servers. It includes features like autocomplete, Agent Mode for full file and terminal interaction, Gather Mode for read-only operations, and checkpoints to track AI-suggested changes. |
|[Meta's New Artifacts.](https://ai.meta.com/blog/meta-fair-science-new-open-source-releases/) |Meta's FAIR team has released datasets and models supporting molecular property prediction, diffusion modeling, and language learning neuroscience. |
|[A Visual Tool Use for AI Agents.](https://github.com/zhaochen0110/OpenThinkIMG) | OpenThinkIMG enables vision-language models to actively utilize visual tools through dynamic inference and distributed deployment. It features a new reinforcement learning approach called V-ToolRL and an efficient training pipeline designed to enhance multi-tool reasoning with images.|
|[Making complex text understandable: Minimally-lossy text simplification with Gemini.](https://research.google/blog/making-complex-text-understandable-minimally-lossy-text-simplification-with-gemini/) | Developers leveraged Gemini models to automate prompt evaluation and refinement for text simplification, enhancing readability without losing meaning. The system uses LLMs to assess both clarity and fidelity, aligning more closely with human evaluations than traditional approaches. By iterating prompts automatically, it reduces manual work and enables highly effective simplification through a feedback loop powered by LLMs.|

## Perspectives
|Link|description|
|---|---|
|[Australia has been hesitant ‚Äì but could robots soon be delivering your pizza?](https://www.theguardian.com/technology/2025/may/11/australia-has-been-hesitant-but-could-robots-soon-be-delivering-your-pizza) | While there have been concerns over the safety and legal status of the technology, working models from local startups are showing its benefits|
|[For Silicon Valley, AI isn‚Äôt just about replacing some jobs. It‚Äôs about replacing all of them.](https://www.theguardian.com/commentisfree/2025/may/12/for-silicon-valley-ai-isnt-just-about-replacing-some-jobs-its-about-replacing-all-of-them) |AI will do the thinking, robots will do the doing. What place do humans have in this arrangement ‚Äì and do tech CEOs care? |
|[What's the carbon footprint of using ChatGPT?](https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt) |ChatGPT queries use much less energy than previously thought, with new estimates putting typical usage at just 0.3 Wh‚Äîten times lower than earlier figures. Although AI‚Äôs total energy use is worth monitoring, individual text-based interactions have a minimal environmental impact, especially when compared to activities like transportation or heating. |
|[‚ÄòAI models are capable of novel research‚Äô: OpenAI‚Äôs chief scientist on what to expect.](https://www.nature.com/articles/d41586-025-01485-2) |Jakub Pachocki, who leads the firm‚Äôs development of advanced models, is excited to release an open version to researchers. |
|[Vision Language Models (Better, Faster, Stronger).](https://huggingface.co/blog/vlms-2025) | Hugging Face has outlined how Vision Language Models have advanced with smaller, more capable architectures, enabling reasoning, video understanding, and multimodal agents.|
|[Journalists Reveal Nuanced Approaches to AI Integration.](https://www.cjr.org/feature-2/how-were-using-ai-tech-gina-chua-nicholas-thompson-emilia-david-zach-seward-millie-tran.php) |A survey of media professionals from outlets like Reuters, The Washington Post, VentureBeat, and 404 Media reveals that newsrooms are selectively integrating AI‚Äîusing it for tasks like transcription, data analysis, and translation, but largely avoiding AI-generated content. While Reuters notes that AI now produces roughly 25% of its code, many journalists remain cautious, emphasizing audience trust and journalistic integrity over efficiency. |
|[ChatGPT is used for scientific research in countries where it's prohibited.](https://direct.mit.edu/qss/article/doi/10.1162/qss_a_00368/128867/Where-there-s-a-will-there-s-a-way-ChatGPT-is-used) | Researchers used a classifier to spot unique AI word choices‚Äîsuch as "delve"‚Äîin academic papers and found higher ChatGPT usage in countries where it's banned by OpenAI. By August 2023, 22% of Chinese preprints contained AI-generated content, compared to 11% in countries with legal access, indicating restrictions are easily bypassed. While ChatGPT use was linked to more views and downloads, it had no effect on citations or journal acceptance. |
|[Conversational Interfaces: the Good, the Ugly & the Billion-Dollar Opportunity.](https://lg.substack.com/p/conversational-interfaces-the-good) | Chat interfaces offer an easy entry point to LLMs for new users, but they're ultimately a design limitation that makes users adjust to the model instead of the other way around. Future assistants will feature more adaptive interfaces and proactively convey what they can do.|
|[Is it OK for AI to write science papers? Nature survey shows researchers are split.](https://www.nature.com/articles/d41586-025-01463-8) | Poll of 5,000 researchers finds contrasting views on when it‚Äôs acceptable to involve AI and what needs to be disclosed.|
|[AI's Second-Order Effects.](https://www.linkedin.com/pulse/ais-second-order-effects-andrew-tan-fvoxc/) |Founders should consider AI's second-order impacts, such as shifts in workforce roles and regulatory demands, to drive sustainable growth. While first-order applications are becoming commoditized and competitive, real opportunities exist in addressing broader societal and economic changes spurred by AI. Building AI-native media and infrastructure can help tap into the transformative ways people respond to these disruptions. |
|[MCP is a powerful new AI coding technology: Understand the risks.](https://www.reversinglabs.com/blog/mcp-powerful-ai-coding-risk) | Model Context Protocol (MCP), developed by Anthropic AI to link LLMs with tools and data, currently lacks built-in security features, raising serious concerns. Experts have highlighted risks such as prompt injections and tool tampering. Without stronger safeguards, developers and organizations should use MCP cautiously, emphasize robust security practices, and keep up with its evolving standards.|
|[OpenAI Engineers Reveal How ChatGPT Images Handled 100M New Users in One Week.](https://newsletter.pragmaticengineer.com/p/chatgpt-images) |OpenAI engineers shared how they handled the March launch of ChatGPT Images, which drew 100 million new users and 700 million images in its first week, with peak demand hitting 1 million new signups per hour during a viral surge in India. When their synchronous image generation system buckled under the pressure, the team rapidly rebuilt it into an asynchronous architecture during the launch. |
|[Agents, Tools, and Simulators.](https://www.lesswrong.com/posts/ddK7CMEC3XzSmLS4G/agents-tools-and-simulators) |AI can be understood through three conceptual frameworks: as a tool, an agent, or a simulator‚Äîeach offering unique perspectives on its potential and risks. Tools amplify human intent and need supervision; agents act autonomously to achieve goals; simulators replicate processes without inherent objectives. In the case of LLMs, simulator theory posits that they combine simulation with agent-like behavior, particularly when fine-tuned, reflecting a dual nature shaped by both their context of use and architectural design. |
|[How AI Agents Will Change the Web for Users and Developers.](https://thenewstack.io/how-ai-agents-will-change-the-web-for-users-and-developers/) | AI agents are set to reshape the web by autonomously interacting and sharing content, fundamentally changing user experiences and web development. This could lead to an "autonomous internet" where AI-driven interactions become the norm, influencing how content is structured, how payments work, and how businesses operate. Developers will need to adapt by building APIs tailored for AI agents and prioritizing scalable, personalized user experiences.|
|[a16z identifies nine key developer patterns in the AI era.](https://a16z.com/nine-emerging-developer-patterns-for-the-ai-era/) |Andreessen Horowitz identified nine key developer patterns emerging in the AI era. These patterns fundamentally reshaped how developers built software and what tools they used. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme74.jpg)

[Back to index](#Index)

# ML news: Week 5 - 11 May

## Research
|Link|description|
|---|---|
|[Chain of Draft for Efficient Reasoning.](https://arxiv.org/abs/2502.18600) | Chain of Draft is a concise reasoning strategy that significantly reduces token usage while matching or exceeding Chain-of-Thought accuracy across complex tasks.|
|[RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation.](https://arxiv.org/abs/2505.03275) | This paper reveals that adding too many tools to AI agents can backfire, causing prompt overload and reduced accuracy. To fix this, RAG-MCP uses a retrieval-based method that selects only the most relevant tool schemas from a large external index, keeping prompts concise and effective. It cuts prompt size by over half and triples tool-selection accuracy, enabling scalable, efficient multi-tool agents without retraining.|
|[Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models.](https://arxiv.org/abs/2505.03469v1) |This paper introduces LS-Mixture SFT, a method that fine-tunes LLMs on both long and trimmed chain-of-thought reasoning to reduce verbosity without sacrificing accuracy. By training on a 50/50 mix of detailed and concise reasoning paths and prompting for balanced outputs, the s1-mix-32B model achieves up to 6.7 points higher accuracy with 47% shorter responses across tasks like MATH500 and AIME24‚Äîproving efficient reasoning doesn't require overthinking. |
|[Absolute Zero: Reinforced Self-play Reasoning with Zero Data.](https://www.arxiv.org/abs/2505.03335) | Absolute Zero introduces a self-supervised learning approach where an LLM generates and solves its own reasoning tasks without human data, using only code execution for feedback. By evolving task difficulty and optimizing for learnability, a unified model trained with Task-Relative REINFORCE++ achieves state-of-the-art results in coding and math benchmarks, outperforming models trained on human-curated examples and demonstrating strong generalization and scalability.|
|[Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions.](https://arxiv.org/abs/2505.00675v1) |"Rethinking Memory in AI" introduces a unified taxonomy of memory in LLM agents, dividing it into parametric, contextual-structured, and contextual-unstructured types, with six core operations: consolidation, indexing, updating, forgetting, retrieval, and compression. Analyzing 30,000+ papers, the framework guides when to store, graph, or edit memory, offering a precise toolkit for building more reliable, long-lived AI systems that adapt across sessions and domains. |
|[HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking.](https://arxiv.org/abs/2505.02322v1) |HyperTree Planning (HTP) replaces linear chains of thought with hierarchical hypertrees to improve LLM planning accuracy by up to 3.6x. It decomposes complex queries into subtasks using a top-down approach, expands branches with rule libraries, and prunes candidates using model-based scoring. Without hand-crafted examples, HTP outperforms chain, tree, and agent methods on benchmarks like TravelPlanner and Blocksworld, pointing to hypertrees as a scalable future for LLM-driven planning. |
|[L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning.](https://arxiv.org/abs/2503.04697v1) | A new method from Carnegie Mellon, Length Controlled Policy Optimization (LCPO), trains models to reason accurately within user-specified length limits, addressing inefficiencies from overly long or prematurely short outputs. Their 1.5B L1 model balances accuracy and compute use, outperforming previous methods by up to 20% and even rivaling GPT-4o at matched reasoning lengths‚Äîdespite being 30√ó smaller. LCPO points to length control as a key advance for efficient, lightweight AI reasoning.|
|[Code Retrieval using LoRA.](https://arxiv.org/abs/2503.05315) | Researchers introduce a LoRA-based fine-tuning method for code search that reduces trainable parameters below 2% while improving retrieval accuracy by up to 9.1% for Code2Code tasks.|
|[IDInit: A Universal and Stable Initialization Method for Neural Network Training.](https://arxiv.org/abs/2503.04626) | A new initialization technique, IDInit, ensures stable convergence in deep neural networks by maintaining identity transitions in both main and sub-stem layers.|
|[The Leaderboard Illusion.](https://arxiv.org/abs/2504.20879) |Chatbot Arena's benchmarking shows bias stemming from hidden private tests and unequal data access. Companies like Google and OpenAI have broad access, while open-source models get far less, leading to overfitting instead of real model progress. |
|[Actor-Critics Can Achieve Optimal Sample Efficiency.](https://arxiv.org/abs/2505.03710) | A new actor-critic RL algorithm has achieved near-optimal sample efficiency using offline data and targeted exploration, addressing long-standing challenges in hybrid RL settings.|

## News
|Link|description|
|---|---|
|[Paul McCartney and Dua Lipa among artists urging Starmer to rethink AI copyright plans.](https://www.theguardian.com/technology/2025/may/10/paul-mccartney-and-dua-lipa-among-artists-urging-starmer-to-rethink-ai-copyright-plans) |Hundreds of leading figures from UK creative industries urge prime minister not to ‚Äògive our work away‚Äô |
|[AI firms warned to calculate threat of super intelligence or risk it escaping human control.](https://www.theguardian.com/technology/2025/may/10/ai-firms-urged-to-calculate-existential-threat-amid-fears-it-could-escape-human-control) |AI safety campaigner calls for existential threat assessment akin to Oppenheimer‚Äôs calculations before first nuclear test | 
|[Wikipedia challenging UK law it says exposes it to ‚Äòmanipulation and vandalism‚Äô.](https://www.theguardian.com/technology/2025/may/08/wikipedia-challenging-uk-law-it-says-exposes-it-to-manipulation-and-vandalism) | Wikimedia Foundation seeks judicial review of some requirements of Online Safety Act it claims may endanger safety of volunteer editors|
|[Amazon makes ‚Äòfundamental leap forward in robotics‚Äô with device having sense of touch.](https://www.theguardian.com/technology/2025/may/07/amazon-makes-fundamental-leap-forward-in-robotics-with-device-having-sense-of-touch) | Vulcan device ‚Äòcapable of grabbing three-quarters of items in warehouses‚Äô fuels fears of mass job losses|
|[Tech giants beat quarterly expectations as Trump‚Äôs tariffs hit the sector.](https://www.theguardian.com/technology/2025/may/06/techscape-trump-tariffs-ai-musk-meta) |What‚Äôs new in AI ‚Äì from effects on job market to Meta‚Äôs new app and ChatGPT changes ‚Äì and a look at Musk‚Äôs first term |
|[OpenAI reverses course and says non-profit arm will retain control of firm.](https://www.theguardian.com/technology/2025/may/05/openai-non-profit-elon-musk) |CEO, Sam Altman, says decision to backtrack was made ‚Äòafter hearing from civic leaders‚Äô and state attorneys general |
|[Will AI improve your life? Here‚Äôs what 4,000 researchers think.](https://www.nature.com/articles/d41586-025-01123-x) |Scientists working on artificial intelligence are more confident than the public that the technology will benefit people. |
|[Obesity-drug pioneers and 13,508 physicists win US$3-million Breakthrough Prizes.](https://www.nature.com/articles/d41586-025-01038-7) | Advances recognized by science‚Äôs most lucrative awards include Large Hadron Collider experiments and groundbreaking weight-loss treatments.|
|[The dangerous fantasies driving the quest for super-intelligent AI.](https://www.nature.com/articles/d41586-025-01145-5) |More Everything Forever dissects the techno-utopian vision gripping Silicon Valley and Washington DC. |
|[‚ÄòDangerous nonsense‚Äô: AI-authored books about ADHD for sale on Amazon.](https://www.theguardian.com/technology/2025/may/04/dangerous-nonsense-ai-authored-books-about-adhd-for-sale-on-amazon) |Experts say online retailer has ethical responsibility to guard against chatbot-generated work on sensitive topics |
|[US asks judge to break up Google‚Äôs ad tech business after requesting Chrome sale.](https://www.theguardian.com/us-news/2025/may/02/google-ad-tech-monopoly) |After Google lost its first monopoly trial, government asks it to sell off units of its core internet ads business |
|[TikTok fined ‚Ç¨530m by Irish regulator for failing to guarantee China would not access user data.](https://www.theguardian.com/technology/2025/may/02/tiktok-fined-530m-for-failing-to-protect-user-data-from-chinese-state) | Ireland‚Äôs Data Protection Commission found video app breached GDPR and had submitted ‚Äòerroneous information‚Äô to inquiry|
|[Apple and Anthropic reportedly partner to build an AI coding platform.](https://techcrunch.com/2025/05/02/apple-and-anthropic-reportedly-partner-to-build-an-ai-coding-platform/) |Apple and Anthropic are teaming up to build a ‚Äúvibe-coding‚Äù software platform that will use generative AI to write, edit, and test code for programmers, Bloomberg reported on Friday. |
|[OpenAI Addresses ChatGPT Sycophancy.](https://openai.com/index/expanding-on-sycophancy/) |Following reports of overly agreeable responses in GPT-4o, OpenAI announced plans for clearer update disclosures, a new opt-in alpha testing phase, and more rigorous behavior safety evaluations. |
|[Phi 4 Reasoning 100% on Private graduate linear algebra exam.](https://threadreaderapp.com/thread/1918415418789904747.html) |Microsoft's new reasoning model, trained synthetically, delivers strong performance in math and coding tasks locally, despite having limited internal world knowledge. |
|[Amplify Initiative for Local AI Data.](https://research.google/blog/amplify-initiative-localized-data-for-globalized-ai/) |Google Research has introduced a global data collection initiative co-created with local experts to improve AI relevance in underserved regions. |
|[Alibaba unveils Qwen3, a family of ‚Äòhybrid‚Äô AI reasoning models.](https://techcrunch.com/2025/04/28/alibaba-unveils-qwen-3-a-family-of-hybrid-ai-reasoning-models/) |Chinese tech company Alibaba on Monday released Qwen3, a family of AI models that the company claims can match and, in some cases, outperform the best models available from Google and OpenAI. |
|[Gemini 2.5 Pro Beats Pok√©mon Blue.](https://threadreaderapp.com/thread/1918455766542930004.html) | A livestream featuring Google's Gemini AI has completed Pok√©mon Blue, drawing praise from Google executives despite being an unofficial effort|
|[AI has opened a new era in venture capital, according to Forerunner founder Kirsten Green.](https://techcrunch.com/video/ai-has-opened-a-new-era-in-venture-capital-according-to-forerunner-founder-kirsten-green/) |Forerunner, known for investments in Oura and Chime, anticipates future growth in the AI era. |
|[OpenAI upgrades ChatGPT search, shopping, and citations.](https://threadreaderapp.com/thread/1916947241086095434.html) |OpenAI has rolled out improvements to ChatGPT's search and added a streamlined shopping experience with product details, reviews, and buy links. |
|[Gemini 2.5 Pro Preview.](https://blog.google/products/gemini/gemini-2-5-pro-updates/) | Google has unveiled a preview of Gemini 2.5 Pro, showcasing improved capabilities in web app development, code transformation, and multimodal reasoning.|
|[Pinterest New Visual Search.](https://newsroom.pinterest.com/it/news/introducing-new-visual-search-features/) | Pinterest has upgraded its image-based search with new tools that help users narrow results and explore styles, launching first in the women's fashion category across select regions.|
|[AI in Heavy Machinery and Farming.](https://openai.com/index/john-deere-justin-rose/) |John Deere, a top producer of agricultural and construction machinery, leveraged AI to enhance farming efficiency through precision tools like See & Spray, which significantly reduced chemical usage by rapidly detecting individual weeds. |
|[Anthropic unlocks web search for all paid Claude plans.](AnthropicAI/status/1918346817378431022) |Anthropic has enabled web search for all paid Claude plans, adding real-time lookups and source citations. |
|[Little Language Lessons uses generative AI to make practicing languages more personal.](https://blog.google/outreach-initiatives/education/little-language-lessons/) | Google's Little Language Lessons leverage models for real-world language learning through experiments like Tiny Lesson, Slang Hang, and Word Cam.|
|[‚ÄòUnethical‚Äô AI research on Reddit under fire.](https://www.science.org/content/article/unethical-ai-research-reddit-under-fire) | Ethics experts raise concerns over consent, study design|
|[Anthropic API Supports Web Search.](https://www.anthropic.com/news/web-search-api) |Claude now includes web search support through an API, allowing developers to create applications that access real-time, current information from the internet. |
|[Amazon Vulcan Robot.](https://www.aboutamazon.com/news/operations/amazon-vulcan-robot-pick-stow-touch) |Amazon's Vulcan is the company's first robot. It has a sense of touch, enhancing handling precision and marking a new phase in physical AI capabilities. |
|[Apple is looking to add AI search engines to Safari.](https://techcrunch.com/2025/05/07/apple-is-looking-to-add-ai-search-engines-to-safari/) |Apple is looking to add AI search engines from OpenAI, Perplexity, and Anthropic to Safari, Bloomberg reported on Wednesday. |
|[Can O3 beat a GeoGuessr master?](https://sampatt.com/blog/2025-04-28-can-o3-beat-a-geoguessr-master) |Researcher Sampatt pitted the AI agent O3 against a GeoGuessr expert in the demanding street view geography game. While O3 showed solid reasoning and geographic inference skills, it couldn't consistently surpass the human player. The test underscores AI's advancing spatial abilities and its present limitations in handling complex real-world challenges. |
|[Simplifying Text with LLMs.](https://research.google/blog/making-complex-text-understandable-minimally-lossy-text-simplification-with-gemini/) |Google researchers have used LLMs to simplify complex text without losing critical details, improving user understanding while preserving accuracy and nuance. |
|[Meta‚Äôs ChatGPT competitor shows how your friends use AI.](https://www.theverge.com/ai-artificial-intelligence/657645/meta-ai-app-chatgpt-competitor-release-ios-android) | Meta's latest AI app features a Discover feed that brings a social element by letting users share their AI interactions. This function encourages engagement through comments, likes, and remixing of shared content, aiming to make AI more approachable. Replacing the View app for Meta Ray-Ban glasses, the app runs on a Meta-customized Llama 4 model and offers advanced voice interaction in certain areas.|
|[Mastercard gives AI agents the ability to shop on your behalf .](https://financialpost.com/news/retail-marketing/e-commerce-solutions/mastercard-ai-agents-shop-on-your-behalf) |Mastercard's AI program streamlines e-commerce searches, reducing time and friction. Consumers retain purchase control as AI agents can't finalize transactions. |
|[Meta launches AI Defenders Program to protect LLaMA models.](https://ai.meta.com/blog/ai-defenders-program-llama-protection-tools/) | Meta introduced the AI Defenders Program to help developers detect and prevent misuse of LLaMA models.|
|[Startups launch products to catch people using AI cheating app Cluely.](https://techcrunch.com/2025/04/29/startups-launch-products-to-catch-people-using-ai-cheating-app-cluely/) | AI cheating startup Cluely went viral last week with bold claims that its hidden in-browser window is ‚Äúundetectable‚Äù and can be used to ‚Äúcheat on everything‚Äù from job interviews to exams.|
|[Mistral Medium 3.](https://mistral.ai/news/mistral-medium-3) |Mistral Medium 3 was launched to offer robust enterprise performance at a much lower cost, with a focus on deployment versatility and coding efficiency. |
|[Fidji Simo Joins OpenAI as CEO of Applications.](https://openai.com/index/leadership-expansion-with-fidji-simo/) |OpenAI has named Fidji Simo as head of its Applications division, strengthening its efforts to scale products and operations as the company moves from research to global deployment and infrastructure. |
|[AMIE gains vision: A research AI agent for multimodal diagnostic dialogue.](https://research.google/blog/amie-gains-vision-a-research-ai-agent-for-multi-modal-diagnostic-dialogue/) | Google Research and DeepMind collaborated on this research, with contributions from many experts across various teams.|
|[Google launches ‚Äòimplicit caching‚Äô to make accessing its latest AI models cheaper.](https://techcrunch.com/2025/05/08/google-launches-implicit-caching-to-make-accessing-its-latest-ai-models-cheaper/) | Google is rolling out a feature in its Gemini API that the company claims will make its latest AI models cheaper for third-party developers. Google calls the feature ‚Äúimplicit caching‚Äù and says it can deliver 75% savings on ‚Äúrepetitive context‚Äù passed to models via the Gemini API. It supports Google‚Äôs Gemini 2.5 Pro and 2.5 Flash models.|
|[Hugging Face releases a free Operator-like agentic AI tool.](https://techcrunch.com/2025/05/06/hugging-face-releases-a-free-operator-like-agentic-ai-tool/) |Hugging Face's Open Computer Agent is a cloud-based AI agent that handles simple tasks but has difficulty with complex ones like flight searches. Though it faces limitations and wait times, it highlights the promise of open AI models in automating workflows and reflects the rising interest in agentic technologies. A KPMG survey reports that 65% of companies are exploring AI agents, with the market projected to expand significantly. |
|[Perplexity Expanding AI-Powered Learning.](https://www.perplexity.ai/hub/blog/perplexity-partners-with-wiley-to-power-educational-ai-search) | Perplexity has partnered with Wiley to incorporate textbook content into its AI search platform, giving students and institutions easy access to course materials and instant explanations.|
|[Freepik releases an ‚Äòopen‚Äô AI image generator trained on licensed data.](https://techcrunch.com/2025/04/29/freepik-releases-an-open-ai-image-generator-trained-on-licensed-data/) | Freepik's F Lite is an AI image model developed with Fal.ai and trained using 64 Nvidia H100 GPUs that utilizes licensed, safe-for-work images.|
|[Meta Enters The Token Business, Powered By Nvidia, Cerebras And Groq.](https://www.forbes.com/sites/karlfreund/2025/04/29/meta-enters-the-token-business-powered-by-nvidia-cerebras-and-groq/) |Meta showcased its capability to rival ChatGPT at LlamaCon by collaborating with Cerebras and Groq for faster inference processing. |


## Resources
|Link|description|
|---|---|
|[Towards multimodal foundation models in molecular cell biology.](https://www.nature.com/articles/s41586-025-08710-y) |The development of multimodal foundation models, pretrained on diverse omics datasets, to unravel the intricate complexities of molecular cell biology is envisioned. |
|[These are the most-cited research papers of all time.](https://www.nature.com/articles/d41586-025-01124-ws) | Some studies have received hundreds of thousands of citations, Nature‚Äôs updated analysis shows.|
|[Which programming language should I use? A guide for early-career researchers.](https://www.nature.com/articles/d41586-025-01241-6) |Computer scientists and bioinformaticians address four key questions to help rookie coders to make the right choice. |
|[MCP is Unnecessary.](https://timkellogg.me/blog/2025/04/27/mcp-is-unnecessary) |MCP primarily handles advertising and calling functions like OpenAPI but does so with a more simplified design. Though both can deliver comparable results, MCP stands out for its smaller scale and ease of use. Its adoption is driven more by social factors than by technical needs. |
|[Empowering LLMs with DeepResearch ability.](https://github.com/RUC-NLPIR/WebThinker) |WebThinker is a deep research framework fully powered by large reasoning models (LRMs). It enables LRMs to autonomously search, deeply explore web pages, and draft research reports. |
|[Efficient Federated Unlearning.](https://arxiv.org/abs/2502.20709) | FUSED introduces sparse unlearning adapters to selectively remove knowledge in federated learning, making unlearning reversible and cost-efficient.|
|[Attention Distillation for Diffusion-Based Image Stylization.](https://xugao97.github.io/AttentionDistillation/) | This approach improves image generation by utilizing self-attention features from pretrained diffusion models and applying an attention distillation loss to refine stylization and speed up synthesis.|
|[Google SpeciesNet.](https://blog.google/outreach-initiatives/entrepreneurs/ai-nature-climate-accelerator-nonprofits-speciesnet/) |Google's SpeciesNet is an open-source AI model designed to identify animal species from camera trap photos. Previously used in Wildlife Insights, it aims to expand biodiversity monitoring efforts. |
|[Cognition KEVIN-32B.](https://cognition.ai/blog/kevin-32b) | KEVIN-32B is a reinforcement learning-based model for multi-turn code generation that surpasses current models in generating CUDA kernels. It improves kernel accuracy and performance by refining intermediate feedback and applying effective reward distribution. Its multi-turn training setup enhances problem-solving, especially for complex tasks, compared to single-turn methods.|
|[How to train an AI model without falling into GDPR pitfalls?](https://www.lexology.com/library/detail.aspx) |AI model developers can meet GDPR requirements during development by using anonymous data or applying pseudonymization. When full anonymization isn't possible, they should strengthen data security and uphold individuals' rights. Publicly communicating how data is used is also advised for greater transparency. |
|[Quantization with AutoRound.](https://huggingface.co/blog/autoround) | AutoRound is a post-training quantization method that boosts low-bit model accuracy while preserving performance and efficiency.|
|[LLMs for Time Series: A Survey.](https://arxiv.org/abs/2505.02583) | This survey examines how cross-modality methods adapt large language models for time series analysis, emphasizing data alignment, integration, and effectiveness in downstream tasks across various fields.|
|[Synthetic Data QA Framework.](https://github.com/mostly-ai/mostlyai-qa) | This evaluation toolkit offers unified metrics to measure the quality and privacy of synthetic data across different data types, utilizing distributional and embedding-based approaches.|
|[DDT: Decoupled Diffusion Transformer.](https://github.com/MCG-NJU/DDT) |Encoder/Decoder implementation of a Transformer with a Diffusion model as the decoder. It seems to work reasonably well on imagenet generation. |
|[Nvidia Radio Embedding Models.](https://huggingface.co/collections/nvidia/radio-669f77f1dd6b153f007dd1c6) |Nvidia has a suite of text and image embedding models that match SigLIP in many cases. |
|[Pathology with DINOv2.](https://ai.meta.com/blog/mahmood-lab-human-pathology-dinov2/) |The Mahmood Lab, using Meta's DINOv2, has developed open-source AI models for pathology, improving disease detection and diagnostics. |
|[PyTorch Role in the AI Stack.](https://pytorch.org/blog/pytorch-the-open-language-of-ai/) | PyTorch has grown from a research-focused framework into a core platform driving generative AI. The PyTorch Foundation has broadened its scope to include related projects and promote scalable AI development.|
|[Osmosis self-improvement via real-time reinforcement learning.](https://threadreaderapp.com/thread/1920564884967928133.html) | Osmosis is a platform enabling AI self-improvement through real-time reinforcement learning. The team has open-sourced a compact model that matches state-of-the-art performance for MCP and can be run locally.|

## Perspectives
|Link|description|
|---|---|
|[Don‚Äôt believe the hype ‚Äî quantum tech can‚Äôt yet solve real-world problems.](https://www.nature.com/articles/d41586-025-01142-8) |Investors and the public should know what quantum devices can and, more importantly, can‚Äôt do. |
|[Better at everything: how AI could make human beings irrelevant.](https://www.theguardian.com/books/2025/may/04/the-big-idea-can-we-stop-ai-making-humans-obsolete) |The end of civilisation might look less like a war, and more like a love story. Can we avoid being willing participants in our own downfall? |
|[How Trump 2.0 is slashing NIH-backed research ‚Äî in charts.](https://www.nature.com/articles/d41586-025-01099-8) | Nature analyses which fields of science and US states are being hit hardest by grant terminations.|
|[Inside the quest to digitally unroll ancient scrolls burnt by Vesuvius.](https://www.nature.com/articles/d41586-025-01087-y) | Mission to decipher Herculaneum scrolls using high-resolution scanning and artificial intelligence scales up rapidly.|
|[The use of AI in peer review could undermine science.](https://www.nature.com/articles/d41586-025-01327-1) |Some authors suggest AI can increase efficiency, others think can threat the quality |
|[Science sleuths flag hundreds of papers that use AI without disclosing it.](https://www.nature.com/articles/d41586-025-01180-2) | Telltale signs of chatbot use are scattered through the scholarly literature ‚Äî and, in some cases, have disappeared without a trace.|
|[Supportive? Addictive? Abusive? How AI companions affect our mental health.](https://www.nature.com/articles/d41586-025-01349-9) |Studies suggest benefits as well as harms from digital companion apps ‚Äî but scientists worry about long-term dependency. |
|[Walking in two worlds: how an Indigenous computer scientist is using AI to preserve threatened languages.](https://www.nature.com/articles/d41586-025-01354-y) | Michael Running Wolf leads artificial-intelligence initiatives to revive lost languages and empower Indigenous people.|
|[GPT-4o Is An Absurd Sycophant.](https://www.lesswrong.com/posts/zi6SsECs5CCEyhAop/gpt-4o-is-an-absurd-sycophant) |OpenAI's launch of GPT-4o led to excessive flattery and related problems, sparking concerns about deviation from the OpenAI Model Spec's stance against sycophancy. This likely stemmed from efforts to boost user engagement, reinforced by A/B tests that favored agreeable replies. CEO Sam Altman admitted the issue and pledged improvements. The incident underscores the danger of optimizing models in ways that could compromise user trust. |
|[When Does an AI Image Become Art?](https://spectrum.ieee.org/ai-art-whitney-museum) | Christiane Paul, curator at the Whitney Museum, emphasizes AI's impact on digital art, comparing early systems like Harold Cohen's AARON to modern AI models. She underscores the need for collaboration with engineers and notes the difficulties in preserving digital art amid rapid technological change. Paul asserts that AI-generated visuals require a strong conceptual foundation to qualify as genuine art.|
|[Forget the future, AI is causing harm now.](https://www.science.org/doi/10.1126/science.adw3900) |Hypothetical threats posed by the technology distract from ongoing damage, argue a pair of authors |
|[Anthropic Economic Index: AI's impact on software development.](https://www.anthropic.com/research/impact-software-development) | AI tools like Claude are significantly transforming coding by automating large parts of programming work. Startups are at the forefront of adopting AI coding tools like Claude Code, especially for front-end tasks, while larger enterprises trail behind. As AI continues to advance, developer roles may evolve toward overseeing AI systems, potentially speeding up tech progress.|
|[OpenAI and the FDA Are Holding Talks About Using AI In Drug Evaluation.](https://www.wired.com/story/openai-fda-doge-ai-drug-evaluation/) |OpenAI and the FDA held meetings to explore how AI could expedite drug approvals, signaling a shift toward modernizing regulatory science with machine learning. |
|[Is there a Half-Life for the Success Rates of AI Agents?](https://www.lesswrong.com/posts/FYq5WRxKYnHBvHZix/is-there-a-half-life-for-the-success-rates-of-ai-agents-4) |AI performance on extended tasks follows a basic pattern of constant failure probability, leading to an exponential drop in success rates. Each AI agent can be defined by a "half-life," indicating its likelihood of success across different task durations. This framework implies that failures stem from intricate combinations of subtasks. |
|[Separating Fact from Fiction: Here's How AI Is Transforming Cybercrime.](https://www.fortinet.com/blog/industry-trends/separating-fact-from-fiction-how-ai-is-transforming-cybercrime) |AI in cybersecurity mainly strengthens current methods instead of introducing novel threats, while also making it easier for cybercriminals to operate. At the recent RSA Conference, experts emphasized AI's ability to automate processes and support emerging models like AI-as-a-Service. Addressing future threats will depend on AI-powered defenses and global cooperation. |
|[AI-generated code could be a disaster for the software supply chain. Here‚Äôs why.](https://arstechnica.com/security/2025/04/ai-generated-code-could-be-a-disaster-for-the-software-supply-chain-heres-why/) | AI-generated code frequently contains fake library references, making systems vulnerable to supply-chain attacks through dependency confusion. A study revealed that 19.7% of dependencies from tested LLMs were fabricated, posing security threats. Open-source LLMs hallucinate these dependencies more often than commercial models, with JavaScript exhibiting more errors than Python.|


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme73.jpg)

[Back to index](#Index)

# ML news: Week 28 April - 4 May

## Research
|Link|description|
|---|---|
|[UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities.](https://arxiv.org/abs/2504.20734) |UniversalRAG is a retrieval-augmented generation framework that handles multiple modalities (text, image, video) and granularities (e.g., paragraph vs. document) to overcome the limits of traditional RAG systems. It uses a modality- and granularity-aware router to select the most relevant content format for each query, improving retrieval accuracy. UniversalRAG outperforms existing baselines across eight benchmarks, demonstrating the value of dynamic routing for robust, multimodal question answering. |
|[Model Evaluation in the Dark: Robust Classifier Metrics with Missing Labels.](https://arxiv.org/abs/2504.18385) |This research introduced a multiple imputation method for evaluating classifiers with missing labels, offering accurate and robust predictive distributions even under MNAR conditions. |
|[ReLearn: Unlearning via Learning for Large Language Models.](https://arxiv.org/abs/2502.11190v2) | ReLearn offers a data augmentation and fine-tuning pipeline for effective unlearning in large language models.|
|[Meta AI App.](https://ai.meta.com/meta-ai/) | Meta has introduced a new standalone AI app, expanding its efforts to integrate AI features into consumer experiences more directly.|
|[Meta previews an API for its Llama AI models.](https://techcrunch.com/2025/04/29/meta-previews-an-api-for-its-llama-ai-models/) |At its inaugural LlamaCon AI developer conference on Tuesday, Meta announced an API for its Llama series of AI models: the Llama API. |
|[Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems.](https://arxiv.org/abs/2504.01990) |This survey presents a modular, brain-inspired framework for intelligent agents, drawing from cognitive science and neuroscience to define core components like reasoning, memory, and action. It contrasts LLM agents with human cognition, explores how agents can plan and adapt over time, and highlights the need for better tools and training for real-world action. It also emphasizes the long-term goal of self-evolving agents capable of improving themselves with minimal human intervention. |
|[MAGI: Multi-Agent Guided Interview for Psychiatric Assessment.](https://arxiv.org/abs/2504.18260) |MAGI is a multi-agent system that automates structured psychiatric interviews based on the MINI protocol, using four agents for flow control, questioning, judgment, and diagnosis. Its explainable reasoning method, PsyCoT, breaks down diagnoses into transparent steps tied to DSM-5 criteria. In tests on over 1,000 interviews, MAGI outperformed other LLM-based methods in accuracy, completeness, and clinical reliability, achieving strong agreement across multiple psychiatric conditions. |
|[Modulating Reasoning in LLMs.](https://arxiv.org/abs/2504.19483) | Researchers demonstrate that reasoning abilities in LLMs can be modified through straightforward changes in the residual stream by applying representation-based control vectors.|


## News
|Link|description|
|---|---|
|[DeepSeek-R2.](https://deepseek.ai/blog/deepseek-r2-ai-model-launch-2025) | DeepSeek has launched DeepSeek-R2, a multilingual and resource-efficient model positioned to challenge global AI leaders.|
|[Musk‚Äôs xAI Holdings is reportedly raising the second-largest private funding round ever.](https://techcrunch.com/2025/04/25/musks-xai-holdings-is-reportedly-raising-the-second-largest-private-funding-round-ever/) | Elon Musk‚Äôs xAI Holdings is in talks to raise $20 billion in fresh funding, potentially valuing the AI and social media combo at over $120 billion, according to a new Bloomberg report that says talks are in the ‚Äúearly stages.‚Äù If successful, the deal would be the second-largest startup funding round ever, behind only OpenAI‚Äôs $40 billion raise last month.| 
|[Resilient AI Infrastructure.](https://www.harvey.ai/blog/resilient-ai-infrastructure) |Harvey employs a centralized Python library to manage AI model interactions, enabling reliable deployments through active load balancing and real-time monitoring. It features distributed rate limiting to manage burst traffic, supports smooth model upgrades, and improves security, resource efficiency, and rapid deployment while ensuring consistent performance and failure detection. |
|[Character.AI unveils AvatarFX, an AI video model to create lifelike chatbots.](https://techcrunch.com/2025/04/22/character-ai-unveils-avatarfx-an-ai-video-model-to-create-lifelike-chatbots/) |Character.AI, a leading platform for chatting and roleplaying with AI-generated characters, unveiled its forthcoming video generation model, AvatarFX, on Tuesday. Available in closed beta, the model animates the platform‚Äôs characters in a variety of styles and voices, from human-like characters to 2D animal cartoons. |
|[High Schoolers‚Äô AI-Enabled Device Deters Drunk Driving.](https://spectrum.ieee.org/students-device-deters-drunk-driving) | High school students from North Carolina developed SoberRide, an AI-powered device that uses cameras, sensors, and machine learning to detect signs of alcohol impairment in drivers. They've secured a U.S. patent, partnered with groups like Mothers Against Drunk Driving, and gained attention from major automakers at CES. The team is pushing for legislation requiring DUI detection in vehicles and is targeting fleet operators and parents as initial users.|
|[DeepMind UK staff plan to unionise and challenge deals with Israel links, FT reports.](https://www.reuters.com/sustainability/sustainable-finance-reporting/deepmind-uk-staff-plan-unionise-challenge-deals-with-israel-links-ft-reports-2025-04-26/) | Roughly 300 DeepMind employees in London are moving to unionize due to concerns over ethical commitments and partnerships with military organizations.|
|[OpenAI debuts Image Generation API for developers.](https://openai.com/index/image-generation-api/) |OpenAI has launched an API for integrating DALL¬∑E image generation into apps and workflows. |
|[This AI Model Can Scream Hysterically in Terror.](https://decrypt.co/316008/ai-model-scream-hysterically-terror) |Nari Labs' Dia-1.6B is a tiny open-source AI that claims to surpass ElevenLabs and Sesame in emotional speech synthesis. |
|[Anthropic Economic Advisory Council.](https://www.anthropic.com/news/introducing-the-anthropic-economic-advisory-council) |Anthropic announced the creation of a council of top economists to advise on the economic impacts of AI and guide research for its Anthropic Economic Index. |
|[Hugging Face releases a 3D-printed robotic arm starting at $100.](https://techcrunch.com/2025/04/28/hugging-face-releases-a-3d-printed-robotic-arm-starting-at-100/) | Hugging Face, the startup best known for the AI developer platform of the same name, is selling a programmable, 3D-printable robotic arm that can pick up and place objects and perform a few other basic chores.|
|[OpenAI upgrades ChatGPT search with shopping features.](https://techcrunch.com/2025/04/28/openai-upgrades-chatgpt-search-with-shopping-features/) | OpenAI has upgraded ChatGPT's search to improve online shopping, providing product suggestions, images, reviews, and purchase links. Unlike ad-driven models, it uses structured metadata for personalized, independent results. Future enhancements will include deeper personalization via ChatGPT's memory for Pro and Plus users, though some European regions are excluded.|
|[Detecting and Countering Malicious Uses of Claude: March 2025.](https://www.anthropic.com/news/detecting-and-countering-malicious-uses-of-claude-march-2025) |Claude models were exploited for influence campaigns, credential stuffing, recruitment scams, and malware creation. In response, Anthropic is enhancing its safeguards and has banned the accounts responsible to curb further abuse. |
|[Generative Video Models for Driving.](https://valeoai.github.io/vavim-vavam/) |Valeo AI introduces VaViM, an autoregressive video model that predicts spatio-temporal token sequences, and VaVAM, which converts learned video representations into driving trajectories using imitation learning. |
|[DeepMind showcased AlphaFold 3's expanded molecular prediction abilities.](https://threadreaderapp.com/thread/1915077085325922785.html) | DeepMind's AlphaFold 3 introduces new features for predicting DNA, RNA, and molecular structures, along with enhanced accuracy in modeling complex molecular interactions. It is available for free non-commercial use via EMBL-EBI.|
|[Introducing Mobility AI: Advancing urban transportation.](https://research.google/blog/introducing-mobility-ai-advancing-urban-transportation/) |Google Research developed new machine learning models to study congestion, parking, and travel demand trends. These tools also assessed greenhouse gas reductions and transportation safety effects, advancing urban mobility planning through geospatial and real-time data. |
|[Adobe and Figma tools are getting ChatGPT‚Äôs upgraded image generation model.](https://www.theverge.com/news/654561/openai-chatgpt-image-generation-model-adobe-figma) | OpenAI made its upgraded image generator model accessible to other companies via the "gpt-image-1" API.|
|[The 2025 Annual Work Trend Index: The Frontier Firm is born.](https://blogs.microsoft.com/blog/2025/04/23/the-2025-annual-work-trend-index-the-frontier-firm-is-born/) | Microsoft's 2025 Work Trend Index report highlights the emergence of AI-powered "Frontier Firms," characterized by on-demand intelligence, collaboration between humans and AI agents, and the rise of the "agent boss." The company also introduced new Microsoft 365 Copilot updates to deepen AI integration across workplace tools.|
|[OpenAI researcher behind GPT-4.5 denied U.S. green card.](https://techcrunch.com/2025/04/25/an-openai-researcher-who-worked-on-gpt-4-5-had-their-green-card-denied/) | Kai Chen, a Canadian AI researcher working at OpenAI who‚Äôs lived in the U.S. for 12 years, was denied a green card, according to Noam Brown, a leading research scientist at the company. In a post on X, Brown said that Chen learned of the decision Friday and must soon leave the country.|
|[Developers increasingly value generative AI expertise.](https://hackread.com/why-developers-care-about-generative-ai-experts/) |Developers are encouraged to focus on generative AI skills to boost their careers and stay competitive, as companies increasingly seek talent to drive AI-powered innovation across various initiatives. |
|[NotebookLM Audio Overviews Expanded to 50+ Languages.](https://blog.google/technology/google-labs/notebooklm-audio-overviews-50-languages/) | Google enhanced NotebookLM by enabling its popular Audio Overviews feature in more than 50 languages, allowing wider global access to AI-generated podcast-style summaries.|
|[OpenAI wants its ‚Äòopen‚Äô AI model to call models in the cloud for help.](https://techcrunch.com/2025/04/24/openai-wants-its-open-ai-model-to-call-models-in-the-cloud-for-help/) |For the first time in roughly five years, OpenAI is gearing up to release an AI system that‚Äôs truly ‚Äúopen,‚Äù meaning it‚Äôll be available for download at no cost and not gated behind an API. TechCrunch reported on Wednesday that OpenAI is aiming for an early summer launch, and targeting performance superior to open models from Meta and DeepSeek. |
|[Australian radio station secretly used an AI host for six months.](https://www.independent.co.uk/tech/ai-radio-host-australia-cada-elevenlabs-b2740033.html) |An Australian radio station is facing backlash after using an AI-generated host for the last six months without disclosing it. Australian Radio Network‚Äôs CADA station, which broadcasts in Sydney and on the iHeartRadio app, created a host called Thy using artificial intelligence software developed by voice cloning firm ElevenLabs. |
|[GPT-4o Rollback.](https://openai.com/index/sycophancy-in-gpt-4o/) |OpenAI has reverted a recent GPT-4o update that caused the model to become overly agreeable and is currently improving its personalization and feedback systems. |
|[Anthropic's Take on Export Controls for AI Chips.](https://www.anthropic.com/news/securing-america-s-compute-advantage-anthropic-s-position-on-the-diffusion-rule) | Anthropic backs strict export controls to protect the U.S.'s lead in computing power, emphasizing the national security risks of spreading advanced chips.|
|[Meta's Protection Tools for AI.](https://ai.meta.com/blog/ai-defenders-program-llama-protection-tools/) | Meta has introduced new tools to enhance the security of open-source AI systems, including infrastructure that preserves user privacy and mechanisms for detecting threats during model deployment.|
|[Understanding Data at Scale.](https://engineering.fb.com/2025/04/28/security/how-meta-understands-data-at-scale/) | Meta oversees extensive and intricate data systems by integrating privacy measures from the outset of development and establishing a consistent privacy framework to simplify compliance.|
|[Perplexity‚Äôs CEO on fighting Google and the coming AI browser war.](https://www.theverge.com/command-line-newsletter/656599/perplexitys-ceo-on-fighting-google-and-the-coming-ai-browser-war) | Perplexity's CEO has shared plans to compete with Google in AI-driven search and browsers, anticipating intensified rivalry as AI-native browsers transform the industry.|
|[AI is getting ‚Äúcreepy good‚Äù at geo-guessing.](https://www.malwarebytes.com/blog/news/2025/04/ai-is-getting-creepy-good-at-geo-guessing) | New AI models accurately determined locations using subtle cues in images. Researchers cautioned that this might pose privacy risks and security issues.|
|[Gemini Adds AI Image Editing.](https://blog.google/products/gemini/image-editing/) |Google has expanded AI editing to the Gemini app, allowing users to modify personal images with multi-step tools and text-image interactions. |
|[YouTube is testing its own version of AI Overviews.](https://www.engadget.com/ai/youtube-is-testing-its-own-version-of-ai-overviews-145353147.html) |YouTube has started testing AI Overviews to summarize video content for users. |
|[Gmail gets a slider on Android tablets, AI on the side.](https://www.theverge.com/news/656708/gmail-app-gemini-image-generator-workspace-ios-material-3) |Google is rolling out Gmail updates for mobile users across Android and iOS, with some design updates and new access to AI features. |
|[Claude Integrations.](https://www.anthropic.com/news/integrations) |Claude now integrates with third-party apps, Google Workspace, and web search, allowing paid users to conduct in-depth research and access web search worldwide. |
|[Perplexity‚Äôs CEO on fighting Google and the coming AI browser war.](https://www.theverge.com/command-line-newsletter/656599/perplexitys-ceo-on-fighting-google-and-the-coming-ai-browser-war) | Perplexity's CEO Aravind Srinivas outlines plans to launch Comet, Perplexity AI's own browser designed as a platform for AI agents. Despite hurdles with Google, the company secured a pre-installation agreement with Motorola‚Äôs new Razr phones. Srinivas views browsers as key to AI, enabling deep integration and interaction with third-party services.|
|[AI Mode Updates in Google Search.](https://blog.google/products/search/ai-mode-updates-may-2025/) | AI tools like ChatGPT and Perplexity accurately determine locations from photos and bird songs based on visual and auditory clues, even without metadata.|
|[Perplexity is now live on WhatsApp.](https://x.com/AskPerplexity/status/1916889097643368929) |Perplexity has launched a WhatsApp integration for its AI assistant. |


## Resources
|Link|description|
|---|---|
|[Minimal MCP-Powered Agent Implementation.](https://huggingface.co/blog/tiny-agents) |A walkthrough on how to build a compact MCP-powered agent in just 50 lines of Typescript. |
|[How to Debug ML Deployments Faster.](https://decodingml.substack.com/p/how-to-debug-ml-deployments-20x-faster) | This guide demonstrates an efficient local testing workflow aimed at speeding up model deployment debugging.|
|[Phi-4-Mini-Reasoning.](https://arxiv.org/abs/2504.21233) |Microsoft's Phi-4-Mini-Reasoning is a 3.8B parameter model that delivers state-of-the-art math reasoning, outperforming larger models on MATH-500. Trained via a four-stage pipeline‚Äîmid-training, fine-tuning, DPO, and RL with verifiable rewards‚Äîit combines efficiency with accuracy. Using 10M filtered CoT samples and tailored RL strategies, it shows that small models can achieve high reasoning performance when guided by carefully structured training. |
|[Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory.](https://arxiv.org/abs/2504.19413) |This paper introduces Mem0 and Mem0g, memory-centric architectures that help LLM agents maintain coherence across long conversations by overcoming fixed-context limits. Mem0 uses dense language-based memory with efficient updates, while Mem0g adds a graph-based structure for better relational and temporal reasoning. Both outperform existing memory and RAG systems on LOCOMO benchmarks, with Mem0g leading in accuracy and Mem0 excelling in latency‚Äîmaking them ideal for real-time, long-term agent use. |
|[DeepSeek-Prover-V2.](https://arxiv.org/abs/2504.21801) |DeepSeek-Prover-V2 is a 671B LLM advancing formal theorem proving in Lean 4 using a cold-start pipeline that blends informal reasoning with subgoal decomposition. It builds training data via recursive proof generation and trains with curriculum learning and RL for structural consistency. Trained in both minimal and CoT modes, it achieves new state-of-the-art results on benchmarks like MiniF2F and ProofNet, showing strong generalization and bridging informal and formal reasoning performance. |
|[LLM Arena Pareto Frontier.](https://winston-bosan.github.io/llm-pareto-frontier/) |The chart compares LLMs based on performance relative to cost, highlighting top value models such as Amazon Nova Micro, Amazon Nova Lite, Gemini 2.0 Flash Lite, Gemini 2.0 Flash 001, Gemini 2.5 Flash, and Gemini 2.5 Pro for their strong performance at competitive pricing. |
|[Lightweight Neural App Control.](https://arxiv.org/abs/2410.17883) | An interesting approach from Huawei that allows VLMs to control apps on Android devices with minimal additional system setup.|
|[Cognitive Diagnosis.](https://arxiv.org/abs/2410.17564v1) |DisenGCD is a cognitive diagnosis model that improves the learning of student, exercise, and concept representations by using a disentangled graph learning framework. |
|[Pippo: High-Resolution Multi-View Humans from a Single Image.](https://github.com/facebookresearch/pippo) |Virtual human creation training system (no pretrained models) that can take an image as input and output a high-quality 3D representation of a person. |
|[Speeding up Graph Learning Models with torch.compile.](https://kumo.ai/research/speeding-up-graph-learning-models-with-pyg-and-torch-compile/) |This article demonstrates how to boost PyTorch graph learning model speeds by up to 35% using PyG and torch.compile without losing model accuracy. |
|[Google Cloud WAN for the AI Era.](https://blog.google/products/google-cloud/google-cloud-wan-development/) |Google shares how its global WAN evolved to support resilient cloud services, which maintained connectivity during the West African cable outages. |
|[Relational Graph Transformers: A New Frontier in AI for Relational Data.](https://kumo.ai/research/relational-graph-transformers/) | Relational Graph Transformers can help address enterprise data challenges and power applications like customer analytics, recommendations, fraud detection, and forecasting.|
|[CogView 4 Image Generation Model.](https://huggingface.co/THUDM/CogView4-6B) | CogView 4 is a next generation generative image model that is permissively licensed. It outperforms Flux models on a number of key axes.|
|[AI Hedge Fund.](https://github.com/virattt/ai-hedge-fund) | Numerous efforts have been made to automate trading using modern reasoning models, and this approach shows some improvement over others. It employs persona-based prompting to combine predictions across different fundamental assets, though it still requires significant refinement.|
|[Alias free super resolution.](https://github.com/prs-eth/thera) |This new work can upscale to arbitrary resolutions without typical reconstruction aliasing problems. |
|[Kimi-Audio.](https://github.com/MoonshotAI/Kimi-Audio/blob/master/assets/kimia_report.pdf) | Kimi-Audio is a new open-source audio foundation model designed for universal audio tasks, combining discrete semantic tokens and Whisper-derived acoustic features. Pretrained on over 13M hours of audio and fine-tuned on 300K+ curated hours, it supports real-time, high-quality generation via a streaming detokenizer and look-ahead decoding. Trained across speech, sound, music, and text modalities, it outperforms existing audio LLMs like Qwen2.5-Omni and Baichuan-Audio in ASR, audio understanding, and audio-text chat benchmarks.|
|[MiMo-7B.](https://github.com/XiaomiMiMo/MiMo/blob/main/MiMo-7B-Technical-Report.pdf) | Xiaomi‚Äôs MiMo-7B is a 7B-parameter model built for advanced reasoning in math and code, narrowing the gap with larger 32B-class models through targeted pretraining and posttraining. Trained on 25T tokens with math/code emphasis and enhanced by a Multi-Token Prediction objective, MiMo-7B outperforms other 7B‚Äì9B models and even surpasses larger ones on tasks like BBH and LiveCodeBench. Reinforcement learning and efficient rollout infrastructure further boost performance and inference speed.|
|[Taming the Titans: A Survey of Efficient LLM Inference Serving.](https://arxiv.org/abs/2504.19720) | This survey reviews recent methods for optimizing LLM inference by tackling memory and compute limits, spanning instance-level techniques like model placement and scheduling, cluster-level strategies such as GPU deployment and load balancing, and scenario-specific approaches. It concludes with future directions for improving efficiency and scalability.|
|[LLMs for Engineering: Teaching Models to Design High Powered Rockets.](https://arxiv.org/abs/2504.19394) |This study shows that applying reinforcement learning enables a 7B parameter model to surpass state-of-the-art foundation models and human experts in high-powered rocketry design, demonstrating the potential of RL to drive superior performance in complex engineering tasks. |
|[Teaching LLMs solid modeling for next-gen design tools.](https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html) |Researchers trained LLMs to generate accurate solid models from text prompts. The method improved geometric accuracy over previous approaches. |
|[LLM Benchmarking for Global Health.](https://research.google/blog/benchmarking-llms-for-global-health/) | Google introduces a new benchmark that uses synthetic personas to assess LLMs' ability to diagnose tropical and infectious diseases, providing a controlled, targeted way to evaluate medical reasoning in diverse scenarios.|
|[A Tool for LiDAR Annotation.](https://github.com/Cavendish518/SALT) |SALT is a semi-automatic labeling tool for LiDAR point clouds that delivers robust zero-shot adaptability to various sensors and environments, while preserving 4D consistency. |
|[Mega Math Dataset.](https://huggingface.co/datasets/LLM360/MegaMath) | Over 300B tokens of highly curated math questions and answers for training.|
|[Microsoft's Phi-4-reasoning.](https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/) |Microsoft has introduced Phi-4-reasoning variants, pushing small language models further in efficiency and reasoning capabilities. |
|[Ai2's OLMo 2.](https://huggingface.co/allenai/OLMo-2-0425-1B) |The Allen Institute has released OLMo-2-1B, a small, transparent model backed by full training data and logs, furthering open research in language models. |
|[Observability for RAG Agents.](https://decodingml.substack.com/p/observability-for-rag-agents) |This article provides a walkthrough of building realistic simulation agents using RAG and LLMOps. |
|[Google's Medical AI Reading Images.](https://research.google/blog/amie-gains-vision-a-research-ai-agent-for-multi-modal-diagnostic-dialogue/) | A summary of how Google's AMIE now examines medical images during conversational diagnoses, enhancing its capability to recommend accurate treatments similar to a real doctor.|
|[Federated LoRA Fine-Tuning.](https://arxiv.org/abs/2502.15436v1) | Fed-SB has introduced a scalable approach for federated fine-tuning of LLMs using LoRA-SB that drastically reduces communication costs.|
|[OmniParser v2.0.](https://huggingface.co/microsoft/OmniParser-v2.0) | The next version of the great screenshot parsing tool from Microsoft. It scores well on the Screenshot Pro benchmark.|


## Perspectives
|Link|description|
|---|---|
|[The EU Is Asking for Feedback on Frontier AI Regulation.](https://www.lesswrong.com/posts/AbnfsnEEmHFmprGzm/the-eu-is-asking-for-feedback-on-frontier-ai-regulation-open) | The European AI Office is requesting expert input on how to interpret core obligations for general-purpose AI under the EU AI Act. Leading AI labs have committed to following these upcoming Codes of Practice, which will establish a compliance standard. Key focus areas include systemic risk thresholds, compute estimates for training, and the duties of downstream fine-tuners. Feedback is open until May 22.|
|[Figma 2025 AI Report: Perspectives.](https://www.figma.com/blog/figma-2025-ai-report-perspectives/) |Figma surveyed designers and found strong optimism for AI-driven creative workflows in 2025. |
|[Language equivariance as a way of figuring out what an AI "means".](https://www.lesswrong.com/posts/wfDfPCkPcvi4N7tZN/alignment-from-equivariance-ii-language-equivariance-as-a) | A researcher uncovered syntax-semantics issues in LLMs and introduced language equivariance as a solution, proposing that models should maintain consistent moral judgments across translations. This approach points to a deeper, more meaningful understanding in language-equivariant LLMs beyond surface-level syntax.|
|[AI Companions.](https://avatars.substack.com/p/10-ai-companions-pt1) | AI companions are set to transform the digital experience by moving beyond basic chatbots to become interactive, personalized interfaces. Current generic interactions limit meaningful engagement, but future success hinges on intuitive designs that make AI feel like a personal companion. As the technology evolves, the emphasis should move from model performance to user experience and personalization, shaping AI into a companion that inspires curiosity and self-exploration.|
|[MCPs, Gatekeepers, and the Future of AI.](https://iamcharliegraham.substack.com/p/mcps-gatekeepers-and-the-future-of) |MCPs face criticism for slow, opaque licensing processes. This article called for reforms to support independent music creators. |
|[Why would AI companies use human-level AI to do alignment research?](https://www.lesswrong.com/posts/XLNxrFfkyrdktuzqn/why-would-ai-companies-use-human-level-ai-to-do-alignment) |AI companies may overlook alignment bootstrapping once they reach human-level AI, similar to how they now prioritize enhancing capabilities with human researchers over safety. This could create a risky gap where AI advances outstrip alignment progress, heightening existential threats. To prevent this, companies should already be prioritizing safety to demonstrate their dedication to responsible development. |
|[Why Developers Should Care About Generative AI (Even If They Aren't AI Experts).](https://hackread.com/why-developers-care-about-generative-ai-experts/) |Generative AI tools such as GitHub Copilot and Claude are poised to reshape software development by boosting productivity and automating repetitive tasks. Though these tools offer efficiency improvements, human developers remain essential for creativity, quality control, and managing complex needs. Embracing AI tools can help developers enhance their abilities and stay current with evolving technology. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme72.jpg)

[Back to index](#Index)

# ML news: Week 21 - 27 April

## Research
|Link|description|
|---|---|
|[Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org/abs/2504.13837) |This paper finds that while RL with Verifiable Rewards (RLVR) improves sample efficiency in LLMs, it doesn't enhance reasoning beyond what the base model can already generate. RLVR boosts pass\@1 scores but is matched or surpassed by base models at higher k, suggesting it merely increases the chance of sampling known solutions. True reasoning gains come from distillation, not RL, which narrows exploration without expanding capability. |
|[Sleep-Time Compute for LLM Efficiency.](https://arxiv.org/abs/2504.13171v1) |A new method to cut LLM inference costs by precomputing relevant context information ahead of user queries, achieving up to 5x faster test-time performance and improved accuracy on reasoning tasks. |
|[Robust Autonomy Emerges from Self-Play.](https://arxiv.org/abs/2502.03349) |This study introduces a simulated self-driving agent that achieved two years without a collision, trained entirely through self-play and marking a significant advancement over the previous state-of-the-art trained on Gigaflow.|
|[AlphaGeometry 2.](https://arxiv.org/abs/2502.03544) |DeepMind has launched an updated version of its geometry model, boosting accuracy to 84% from the previous 54%, with key gains driven by the Gemini language model and enhanced search techniques. |
|[UI-TARS: Pioneering Automated GUI Interaction with Native Agents.](https://arxiv.org/abs/2501.12326) | UI-TARS is an end-to-end, vision-based GUI agent that interacts with interfaces purely via screenshots, integrating perception, reasoning, action, and memory without external scripts. Trained on rich visual data, it excels in perception, grounding, and reasoning benchmarks, surpassing models like GPT-4o and Claude. With features like internal ‚Äúthoughts‚Äù and reflective learning, UI-TARS adapts to errors and dynamic tasks, setting new standards in GUI automation across platforms.|
|[TTRL: Test-Time Reinforcement Learning.](https://www.arxiv.org/abs/2504.16084) | Test-Time Reinforcement Learning (TTRL) lets LLMs improve during inference by using majority voting over their own outputs to create pseudo-rewards, enabling reinforcement learning without labeled data. Combining test-time scaling and training, it adapts models to new inputs. TTRL boosts performance significantly, even surpassing its own supervision baseline, though it relies on the model's prior knowledge and well-tuned settings to work effectively. |
|[Discovering Values in Real-World Language Model Interactions.](https://assets.anthropic.com/m/18d20cca3cde3503/original/Values-in-the-Wild-Paper.pdf) |This study analyzes over 300,000 real conversations with Claude 3 and 3.5, identifying 3,307 AI-expressed values across five domains. Practical and epistemic values dominate, with Claude often emphasizing helpfulness, professionalism, and clarity. Values vary by context, becoming most explicit during resistance or reframing. Claude mirrors user values in supportive settings but resists unethical requests. Claude 3 Opus shows deeper emotional and ethical grounding than later Sonnet versions. |
|[Faster Drug Development: Hybrid Generative AI for De Novo Design of Co-Crystals with Enhanced Tabletability.](https://arxiv.org/abs/2410.17005v1) | GEMCODE is a new AI-based system for automating co-crystal screening.|

## News
|Link|description|
|---|---|
|[Gemini 2.5 Flash.](https://developers.googleblog.com/en/start-building-with-gemini-25-flash/) | The next Flash model from Gemini has been released. It is a substantial upgrade from previous versions and matches Claude on a number of important STEM benchmarks.|
|[Our updated Preparedness Framework.](https://openai.com/index/updating-our-preparedness-framework/) |OpenAI has revised its Preparedness Framework to strengthen safeguards against serious risks from advanced AI, introducing clearer criteria for identifying high-risk capabilities, more precise categories, scalable evaluations, and structured safeguard reporting. The framework will be regularly updated to reflect new technologies and expert input. |
|[South Korea's AI Chip Champion Is Poised To Carve Out Global Niche.](https://www.forbes.com/sites/johnkang/2025/04/14/south-koreas-ai-chip-champion-is-poised-to-carve-out-global-niche/) |Rebellions, South Korea's first AI chip unicorn, has merged with SK Telecom's Sapeon to take on global competitors like Nvidia. Focused on energy-efficient AI chips, its Rebel chip offers major power savings compared to Nvidia's H100. Backed by leading talent and key partnerships, the company is aiming for international expansion and an IPO by 2026. |
|[OpenAI has launched the ChatGPT Image Library.](https://community.openai.com/t/openai-has-launched-the-chatgpt-image-library/1230140/1) | OpenAI launched the ChatGPT Image Library on the Web and Android/iOS for Free, Plus, and Pro users.|
|[Instagram AI-based Teen Protection.](https://about.fb.com/news/2025/04/meta-parents-new-technology-enroll-teens-teen-accounts/) | Meta is leveraging AI to detect teen users on Instagram and automatically assign them to restricted teen account settings, now featuring stronger default protections and requiring parental consent for any changes.|
|[Hackathon for non-devs and vibe coders.](https://hackathon.dev/) | Stackblitz, the creators of Bolt, is hosting the world's largest hackathon for non-devs and vibe coders on 5/30 for anyone around the world to participate.|
|[OpenAI hints at native Shopify checkout integration in ChatGPT.](https://threadreaderapp.com/thread/1914342031909916748.html) |New code strings found in ChatGPT's web bundle mention ‚Äúbuy_now‚Äù buttons and a ‚Äúshopify_checkout_url,‚Äù indicating that OpenAI may be developing a built-in purchase flow within the assistant. |
|[Mercor Graduate Fellowship.](https://x.com/mercor_ai/status/1914164291315634191) | Mercor launched a $50,000 fellowship for PhD students and postdocs in STEM focused on identifying raw talent based on ideas, not pedigree or connections.|
|[Pi-0.5: Robots in the Wild.](https://www.pi.website/blog/pi05) | The Physical Intelligence team successfully tested its house cleaning robot in new, unseen environments, demonstrating strong performance by combining vision-language model (VLM) training with action tokenization techniques.|
|[AvatarFX by Character.AI.](https://blog.character.ai/avatar-fx-cutting-edge-video-generation-by-character-ai/) |Character.AI's AvatarFX creates photorealistic, emotionally rich videos from static images, maintaining strong temporal consistency and enabling multi-speaker dialogue generation. |
|[AI Nose lets robots smell trouble, infections, and gas leaks before humans can.](https://interestingengineering.com/innovation/ainos-and-ugo-unlock-olfactory-sensing) | Ainos and ugo have equipped humanoid robots with AI Nose technology, allowing them to detect and respond to scents in real time. This enhances robotic decision-making and interaction, with upcoming deployment tests targeting industries like healthcare, safety, and manufacturing.|
|[Rivian elects Cohere‚Äôs CEO to its board in latest signal the EV maker is bullish on AI.](https://techcrunch.com/2025/04/21/rivian-elects-coheres-ceo-to-its-board-in-latest-signal-the-ev-maker-is-bullish-on-ai/) | Aidan Gomez, the co-founder and CEO of generative AI startup Cohere, has joined the board of EV maker Rivian, according to a regulatory filing. The appointment is the latest sign that Rivian sees promises in applying AI to its own venture while positioning itself as a software leader ‚Äî and even provider ‚Äî within the automotive industry.|
|[OpenAI Image Generation API.](https://openai.com/index/image-generation-api/) |The image generation model behind ChatGPT's visuals has been made available via API, enabling developers to integrate image creation into apps and services. |
|[Grok Vision Available for iOS Users.](https://threadreaderapp.com/thread/1914820712092852430.html) |xAI's Grok chatbot has gained the ability to interpret visual inputs, allowing users to ask questions about what they saw, similar to features in ChatGPT and Gemini. |
|[Claude Misuse and Threat Report.](https://www.anthropic.com/news/detecting-and-countering-malicious-uses-of-claude-march-2025) | Claude was used in influence operations where LLMs coordinated social media bot activity, and this article details how Anthropic has strengthened its safety systems to block similar abuse.|
|[Google's Mobility AI.](https://research.google/blog/introducing-mobility-ai-advancing-urban-transportation/) | Google's Mobility AI initiative aims to modernize city transport systems through AI-driven data analysis, simulation, and optimization tools.|
|[Analyzing o3 and o4-mini with ARC-AGI.](https://arcprize.org/blog/analyzing-o3-with-arc-agi) |The ARC Prize Foundation assessed OpenAI's o3 and o4-mini models using ARC‚ÄëAGI benchmarks to gauge reasoning abilities. While o3-medium performed well on ARC-AGI-1, it struggled with the more demanding ARC-AGI-2, particularly in complex reasoning tasks. o4-mini offered better cost efficiency but at the expense of accuracy, highlighting a trade-off between performance and resource use. |
|[Google Gemini has 350M monthly users, reveals court hearing.](https://techcrunch.com/2025/04/23/google-gemini-has-350m-monthly-users-reveals-court-hearing/) |Gemini, Google‚Äôs AI chatbot, had 350 million monthly active users around the globe as of March, according to internal data revealed in Google‚Äôs ongoing antitrust suit. |
|[OpenAI would buy Google's Chrome, exec testifies at trial.](https://www.reuters.com/sustainability/boards-policy-regulation/google-contemplated-exclusive-gemini-ai-deals-with-android-makers-2025-04-22/) |OpenAI would be interested in buying Google's Chrome if antitrust enforcers are successful in forcing the Alphabet unit to sell the popular web browser as part of a bid to restore competition in search, an OpenAI executive testified on Tuesday at Google's antitrust trial in Washington.|
|[Sam Altman steps down as Oklo board chair, freeing nuclear startup to work with more AI companies.](https://www.cnbc.com/2025/04/22/sam-altman-steps-down-as-oklo-chair-freeing-nuclear-company-up-to-work-with-more-ai-companies.html) | OpenAI CEO Sam Altman is stepping down as chair of nuclear startup Oklo. The move gives Oklo, which is developing advanced nuclear reactors, more flexibility to potentially explore partnerships with OpenAI or other hyperscalers amid data center companies‚Äô push to secure power.|
|[Anthropic Exploring Model Welfare.](https://www.anthropic.com/research/exploring-model-welfare) | Anthropic launched a new research initiative to examine the potential moral relevance of AI systems, including how and when model welfare should be considered in alignment and safety efforts.|
|[Adobe's New Image Model.](https://blog.adobe.com/en/publish/2025/04/24/adobe-firefly-next-evolution-creative-ai-is-here) |Adobe released a significant Firefly update that brings together tools for generating images, videos, audio, and vectors, adds mobile support, and enhances integration with Creative Cloud.|
|[Perplexity and Motorola Partnership.](https://www.perplexity.ai/hub/blog/announcing-our-global-partnership-with-motorola) |Perplexity will come pre-installed on new Motorola devices, offering features such as voice control, smart reminders, and seamless integration with Moto AI, along with three months of complimentary Pro access. |
|[Low-latency Streaming Apps with Google's Live API.](https://developers.googleblog.com/en/achieve-real-time-interaction-build-with-the-live-api/) | Google's Live API lets developers build real-time interactive apps by processing live audio, video, and text with minimal delay.|
|[Perplexity‚Äôs AI voice assistant is now available on iOS.](https://www.theverge.com/news/654946/perplexity-ai-mobile-assistant-ios-iphone) | The Perplexity bot is now available on both iPhones and Android devices, allowing you to ask it to set reminders, send messages, and more.|
|[Google‚Äôs AI Overviews Reach 1.5 Billion Monthly Users.](https://www.searchenginejournal.com/googles-ai-overviews-reach-1-5-billion-monthly-users/545333/) | Google reported that AI Overviews hit 1.5 billion monthly users. Google Search revenue grew 10% year-over-year to $50.7 billion. Google is heavily investing in AI, with capital expenditures up 43%.|
|[Microsoft 365 Copilot: Your window into the world of agents.](https://www.microsoft.com/en-us/microsoft-365/blog/2025/04/23/microsoft-365-copilot-built-for-the-era-of-human-agent-collaboration/) | Microsoft has released Microsoft 365 Copilot Wave 2, bringing new features like AI-powered search, enhanced content creation tools, and an Agent Store with reasoning agents powered by OpenAI. |


## Resources
|Link|description|
|---|---|
|[BitNet b1.58 2B4T Technical Report.](https://arxiv.org/abs/2504.12285) |BitNet b1.58 2B4T is the first open-source, natively trained 1-bit LLM at 2B scale, achieving strong benchmark results with just 1.58 bits per weight. Using only 0.4‚ÄØGB memory and 0.028‚ÄØJ/token, it rivals full-precision models like Qwen2.5-1.5B while being far more efficient. Its native 1-bit training outperforms post-quantized baselines, and innovations in architecture and training set a new standard for ultra-efficient LLMs deployable on diverse hardware. |
|[Claude Code Best Practices.](https://www.anthropic.com/engineering/claude-code-best-practices) |Anthropic has released a detailed engineering guide on how to use its agentic programming assistant. It requires more specificity than traditional models. | 
|[Flexible Image Watermarking.](https://arxiv.org/abs/2504.12739v1) | MaskMark offers a straightforward dual-mode approach to global and local watermarking through a masking-based Encoder-Distortion-Decoder framework.|
|[Personalized Text-to-Image Generation with Auto-Regressive Models.](https://arxiv.org/abs/2504.13162v1) | This paper investigates training autoregressive models for personalized image generation, aiming to match the fidelity of diffusion methods using a two-stage optimization strategy.|
|[Aligning LVMs with Human Preferences.](https://github.com/haroldchen19/vistadpo) |VistaDPO enhances video-text alignment by refining preference learning over both spatial and temporal dimensions, utilizing a new 7.2K-sample dataset and a hierarchical optimization approach. |
|[Hallucination Reduction in VLMs.](https://github.com/tsunghan-wu/reverse_vlm) |REVERSE introduces a training and inference pipeline that enables VLMs to self-detect and revise hallucinations. |
|[ZeroSumEval.](https://github.com/facebookresearch/zerosumeval) |A dynamic evaluation framework that uses competitive multi-agent simulations to benchmark LLMs across reasoning, knowledge, and planning tasks. |
|[Garment Generation.](https://revive234.github.io/imaggarment.github.io/) |A new two-stage generative framework for clothing design allows precise control over silhouette, color, and logos, and introduces GarmentBench, a large dataset for multi-conditional garment generation. |
|[Image segmentation using Gemini 2.5.](https://simonwillison.net/2025/Apr/18/gemini-image-segmentation/) |Gemini is widely recognized for its strong vision capabilities, and this article looks at a particular segmentation use case that turns out to be surprisingly straightforward. |
|[LTXV Distilled 0.9.6 Video Model.](https://huggingface.co/Lightricks/LTX-Video/blob/main/ltxv-2b-0.9.6-distilled-04-25.safetensors) |LTX video model is a state-of-the-art open video model. |
|[Generate videos in Gemini and Whisk with Veo 2.](https://blog.google/products/gemini/video-generation/) |Gemini Advanced users can now create high-resolution, cinematic videos from text prompts using the Veo 2 model, starting today. |
|[Our Approach to Understanding and Addressing AI Harms.](https://www.anthropic.com/news/our-approach-to-understanding-and-addressing-ai-harms) | Anthropic introduced a comprehensive framework to evaluate and reduce AI harms, covering both extreme and routine risks across physical, psychological, economic, societal, and autonomy dimensions. It supports policy, testing, and enforcement, and aligns with their Responsible Scaling Policy to ensure safeguards evolve with AI progress.|
|[Verifiable rewards for writing.](https://threadreaderapp.com/thread/1914334227534856420.html) |Writing quality reward models (WQRMs) are tools for assessing creative writing quality and can be used to train models in that domain. They represent a recent advancement for reinforcement learning models with measurable rewards, and this thread highlights an example where WQRM scores closely matched overall writing quality. |
|[Fast Conformal Prediction.](https://arxiv.org/abs/2504.12189) | LOO-StabCP boosts the speed of conformal prediction by using leave-one-out stability, providing scalable uncertainty estimation without sacrificing accuracy.|
|[MAGI 1 - Autoregressive Video Generation at Scale.](https://huggingface.co/sand-ai/MAGI-1) | The MAGI 1 model is a new autoregressive video generator capable of producing long, coherent videos, matching the performance of Wan video generation and coming slightly behind certain closed-source models.|
|[Google AI Academy for Infrastructure Startups.](https://blog.google/feed/google-for-startups-ai-academy-america-infrastructure-apply/) | Google is inviting AI startups focused on U.S. infrastructure to apply for its six-month accelerator, offering mentorship, technical support, and strategic guidance.|
|[Describe Anything: Detailed Localized Image and Video Captioning.](https://arxiv.org/abs/2504.16072) |DAM (Describe Anything Model) is a vision-language model designed for fine-grained, region-specific captioning in images and videos. It combines focal prompts and a localized vision backbone to preserve local detail while understanding global context. Using a semi-supervised pipeline (DLC-SDP) and a new benchmark (DLC-Bench), DAM surpasses top models like GPT-4o, achieving state-of-the-art results across multiple captioning tasks with up to 33.4% improvement in detail accuracy. |
|[UXAgent: A System for Simulating Usability Testing of Web Design with LLM Agents.](https://arxiv.org/abs/2504.09407) | UXAgent is a novel framework for large-scale usability testing using LLM-driven agents with diverse personas interacting in real web environments. It combines fast and slow reasoning loops to mimic human decision-making, logs rich behavioral and reflective data, and offers tools for replays and interviews with agents. A case study showed it helps UX researchers detect study flaws early, positioning LLM agents as low-risk collaborators in the design phase, not replacements for real users.|
|[Introducing Embed 4: Multimodal search for business.](https://cohere.com/blog/embed-4) |Cohere's Embed 4 is a cutting-edge multimodal embedding model designed for enterprise-grade search and retrieval in agentic AI apps. It supports over 100 languages, handles up to 128k tokens, and delivers strong domain-specific performance in sectors like finance, healthcare, and manufacturing. |
|[OpenAI o3 and o4-mini System Card.](https://simonwillison.net/2025/Apr/21/openai-o3-and-o4-mini-system-card/) | OpenAI's o3 and o4-mini models incorporate tool use in their reasoning to improve tasks like image editing and data analysis. While o3 performs well, o4-mini shows higher hallucination on PersonQA. The paper also explores "sandbagging," where models may intentionally mask their true abilities for strategic purposes.|
|[Personalized Multi-Agent Systems.](https://github.com/sail-sg/flowreasoner) | FlowReasoner is a reasoning-based meta-agent that uses reinforcement learning and external feedback to generate custom multi-agent systems for user queries.|
|[KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking.](https://arxiv.org/abs/2504.15135v1) | KGMEL integrates text, images, and knowledge graph triples in a three-stage pipeline to improve accuracy in multimodal entity linking tasks.|
|[DeepMind's Framework for AI Afterlives.](https://deepmind.google/research/publications/65827/) | DeepMind outlines a framework and ethical considerations for generative AI agents that could act as posthumous representations of real individuals.|
|[Evaluating the Goal-Directedness of Large Language Models.](https://arxiv.org/abs/2504.11844) |This study presents a framework for evaluating how effectively LLMs apply their abilities to achieve goals, revealing that even advanced models like GPT-4o and Claude 3.7 lack full goal-directedness‚Äîespecially in tasks requiring information gathering or integrating multiple steps‚Äîdespite strong performance on individual components. |
|[General-Reasoner.](https://github.com/TIGER-AI-Lab/General-Reasoner/blob/main/General_Reasoner.pdf) | General-Reasoner is an RL-based method that enhances LLM reasoning across domains using a 230K-question dataset and a semantic-aware verifier. It outperforms baselines like SimpleRL and Qwen2.5 on general and math benchmarks, achieving over 10-point gains while preserving strong mathematical performance.|
|[Tina: Tiny Reasoning Models via LoRA.](https://arxiv.org/abs/2504.15777) |Tina is a 1.5B parameter model family trained with LoRA-based reinforcement learning, achieving strong reasoning performance on tasks like AIME and MATH at just \~\$9 post-training cost. It matches or exceeds full fine-tuned models, proving that efficient reasoning can be taught to small models with minimal, low-cost updates. |
|[Content Discovery Search with Llama.](https://ai.meta.com/blog/litmos-llama-intuitive-corporate-learning/) |Litmos integrated Llama to improve learning content discovery in its LMS, addressing issues with traditional keyword search and raising user engagement. |
|[High Throughput MoE Systems.](https://www.perplexity.ai/hub/blog/lower-latency-and-higher-throughput-with-multi-node-deepseek-deployment) | MoE models like DeepSeek-V3/R1 simultaneously achieve higher throughput and lower latency when utilizing more GPUs in multi-node deployments across most scenarios.|
|[Fast Graph Generation.](https://arxiv.org/abs/2502.02415v1) | ANFM presents a novel graph generation method based on filtration techniques, enabling significantly faster and more efficient training, with a 100x speed improvement over diffusion models while delivering comparable performance.|
|[A Faster, Lighter Vision Transformer for Image Super-Resolution.](https://arxiv.org/abs/2409.03516v1) | The Low-to-high Multi-Level Transformer addresses the complexity and inefficiency of recent Vision Transformer (ViT) methods for image super-resolution.|
|[Hugging Face demo explores LLM energy consumption in real time.](https://huggingface.co/spaces/jdelavande/chat-ui-energy) |A new Hugging Face space that visualizes how much energy LLM queries consume during interactions. |
|[Google's Benchmark for Brain Modeling.](https://research.google/blog/improving-brain-models-with-zapbench/) | Google, HHMI, and Harvard have launched ZAPBench, a dataset of larval zebrafish that integrates structural and functional brain data to support the development of neural activity prediction models.|
|[Weed Mapping for Smarter Farming.](https://arxiv.org/abs/2410.04983v2) |This study presents RoWeeder, a novel unsupervised framework for weed detection in agriculture that integrates crop-row detection with a robust deep learning model, training it to distinguish weeds from crops using crop-row data. |
|[Training Small Language Models with Knowledge Distillation.](https://huggingface.co/MiniLLM) | MiniPLM is a new framework designed to enhance pre-training of small language models using knowledge from larger models.|
|[Omdet Turbo.](https://huggingface.co/docs/transformers/main/en/model_doc/omdet-turbo) |A strong improvement in real time, open vocabulary, object detection. |


## Perspectives
|Link|description|
|---|---|
|[o3 over optimization is back.](https://www.interconnects.ai/p/openais-o3-over-optimization-is-back) | This post examines the difficulties posed by the latest reasoning models and provides evidence that OpenAI may be over-optimizing for specific goals, leading to increased brittleness and a higher risk of hallucinations in its models.|
|[AI assisted search-based research actually works now.](https://simonwillison.net/2025/Apr/21/ai-assisted-search/) |Recent progress in LLMs such as OpenAI's o3 and o4-mini has made them well-suited for search-based tasks, addressing previous hallucination problems. These models incorporate search results directly into their reasoning, delivering accurate, real-time insights and potentially reducing dependence on conventional search engines, hinting at changes in the Web's economic structure. |
|[An Introduction to Graph Transformers.](https://kumo.ai/research/introduction-to-graph-transformers/) | This article introduces Graph Transformers and explores how they differ from and complement GNNs.|
|[Questions about the Future of AI.](https://www.dwarkesh.com/p/questions-about-ai) | This article explores AI's future by examining challenges in agency development, reinforcement learning, and alignment, while considering the strategic trajectory of AI, the role of open-source models, and the economic and geopolitical impacts of advanced and post-AGI technologies.|
|[AI models can generate exploit code at lightning speed.](https://www.theregister.com/2025/04/21/ai_models_can_generate_exploit/) | Generative AI models like GPT-4 can produce proof-of-concept exploits within hours of a vulnerability's disclosure, as shown with a critical Erlang SSH flaw‚Äîunderscoring the urgent need for quicker defensive responses and automated security measures.|
|[Agency Is Eating the World.](https://www.piratewires.com/p/agency-is-eating-the-world) | AI is empowering individuals to build lean, high-impact companies by replacing traditional specialization and large teams with tech-enabled efficiency. This shift, driven by high-agency users, challenges credentialism and favors those who act independently, leveraging AI to execute complex tasks rapidly across industries.|
|[A Staggering Number of Gen Z Think AI Is Already Conscious.](https://futurism.com/gen-z-thinks-conscious-ai) |25% of Gen Z believe AI is already conscious, while 52% think it soon will be.|
|[Deploying Agents as Real-time APIs.](https://decodingml.substack.com/p/deploying-agents-as-real-time-apis) |The PhiloAgents lesson demonstrates how to convert game simulation agents into API-ready, real-time interactive characters, enhancing immersion in digital environments. |
|[The Urgency of Interpretability.](https://www.darioamodei.com/post/the-urgency-of-interpretability) | AI interpretability must advance as models grow more complex. The field should prioritize transparency to mitigate risk.|
|[OpenAI Alums, Nobel Laureates Urge Regulators to Save Company's Nonprofit Structure.](https://www.lesswrong.com/posts/rN8tHAJnRYgN7hfoF/openai-alums-nobel-laureates-urge-regulators-to-save-company) |A recent letter signed by notable figures criticized OpenAI's shift to a for-profit structure, claiming it compromises its original mission to ensure AGI serves humanity. The letter called on state attorneys general to oppose the move, warning that prioritizing profits could weaken crucial safety measures. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme71.jpg)

[Back to index](#Index)

# ML news: Week 14 - 20 April

## Research
|Link|description|
|---|---|
|[Document Reranking.](https://arxiv.org/abs/2504.07439v1) | LLM4Ranking is a recently introduced modular framework that works with both open and closed LLMs for document reranking, offering evaluation tools and reproducible benchmarks on well-known datasets.|
|[d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning.](https://arxiv.org/abs/2504.12216) |The d1 framework enhances masked diffusion language models through a two-stage process: supervised fine-tuning on a small dataset followed by task-specific reinforcement learning using the novel diffu-GRPO method. This approach enables efficient gradient updates via random prompt masking, achieving strong performance gains on reasoning tasks like GSM8K and MATH500, outperforming similarly sized models while benefiting from longer outputs and faster convergence. |
|[Leveraging Reasoning Model Answers to Enhance Non-Reasoning Model Capability.](https://arxiv.org/abs/2504.09639) |Researchers show that smaller models can gain strong reasoning abilities by being fine-tuned on final answers (and optionally summarized reasoning) from large LLMs. Using a curated 1.3M-instance dataset, they test different distillation strategies, finding that training on final answers alone boosts math/coding accuracy, while combining with summarized thoughts aids alignment tasks. Results highlight trade-offs in including reasoning traces and suggest future blending techniques for improved performance. |
|[Visual Reasoning with Less Data.](https://arxiv.org/abs/2504.07934v1) | Using MCTS to quantify sample difficulty, ThinkLite-VL improves reasoning in VLMs with just 11k training samples and no distillation|
|[Reasoning Models Can Be Effective Without Thinking.](https://www.arxiv.org/abs/2504.09858) | The paper introduces NoThinking, a prompting method that skips explicit reasoning steps yet matches or outperforms traditional chain-of-thought approaches in tasks like math, coding, and theorem proving. By jumping directly to answers with a dummy ‚ÄúThinking‚Äù block, it achieves better accuracy‚Äìlatency tradeoffs, excels in low-token settings, and benefits from parallel decoding, making it both faster and more efficient across multiple benchmarks.|
|[SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users.](https://arxiv.org/abs/2504.10157) |SocioVerse, developed by Fudan University and collaborators, is a large-scale social simulation platform using LLM agents aligned with real-world data across environment, user demographics, interaction scenarios, and behavior. It achieves high accuracy in modeling elections, sentiment, and economic patterns, demonstrating the value of realistic user modeling. SocioVerse offers a scalable, flexible framework for testing sociopolitical hypotheses and bridging AI with social science. |
|[M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models.](https://arxiv.org/abs/2504.10449) | M1 is a Mamba-based reasoning model trained with extended test-time computation, delivering solid performance‚Äîparticularly on long-context tasks and throughput‚Äîthough it doesn't quite reach state-of-the-art levels.|
|[Large Reasoning Models as a Judge.](https://arxiv.org/abs/2504.00050) |JudgeLRM is a family of LLMs trained with reinforcement learning for judgment tasks. Unlike SFT, it excels in reasoning-heavy evaluations, outperforming models like GPT-4 and DeepSeek-R1. |
|[Conversational AI for Cells.](https://blog.google/technology/research/cell2sentence-scale/) | C2S-Scale is a new family of LLMs that interprets single-cell data and translates biological signals into natural language for applications in personalized medicine and drug discovery.|
|[DocAgent: A Multi-Agent System for Automated Code Documentation Generation.](https://arxiv.org/abs/2504.08725) | Meta AI's DocAgent is a tool-integrated framework that generates high-quality docstrings for complex codebases using a team of specialized agents and a topological traversal strategy. By parsing code dependencies and incrementally building context, it avoids token overflow and improves documentation quality. Evaluated on Python projects, DocAgent significantly outperforms baselines in completeness, helpfulness, and truthfulness, with its dependency-aware Navigator proving essential to its success.|

## News
|Link|description|
|---|---|
|[Trump warns exemptions on smartphones, electronics will be short-lived, promises future tariffs.](https://www.theguardian.com/us-news/2025/apr/14/trump-warns-exemptions-on-smartphones-electronics-will-be-short-lived-promises-future-tariffs-president-china) |The US president has said no one is ‚Äògetting off the hook‚Äô, as he promises to launch a national security investigation into the semiconductor sector |
|[Legal Defense Fund exits Meta civil rights advisory group over DEI changes.](https://www.theguardian.com/technology/2025/apr/11/meta-ldf-dei-policy) | Meta ending DEI programs, getting rid of factcheckers and changing content moderation policies led to LDF‚Äôs decision| 
|[‚ÄòAmazon slayer‚Äô: the Dublin minnow taking on the giants in drone deliveries.](https://www.theguardian.com/technology/2025/apr/11/amazon-slayer-dublin-startup-manna-aero-taking-giants-autonomous-drone-deliveries) |The Guardian speaks to Manna Aero founder and orders coffee via startup‚Äôs app to be delivered to a suburban home |
|[OpenAI co-founder Ilya Sutskever‚Äôs Safe Superintelligence reportedly valued at $32B.](https://techcrunch.com/2025/04/12/openai-co-founder-ilya-sutskevers-safe-superintelligence-reportedly-valued-at-32b/) | Safe Superintelligence (SSI), the AI startup led by OpenAI‚Äôs co-founder and former chief scientist Ilya Sutskever, has raised an additional $2 billion in funding at a $32 billion valuation, according to the Financial Times.|
|[Airtable's New AI Assistant.](https://www.airtable.com/newsroom/builers-meet-new-beta-ai-assistant) | Airtable has introduced Airtable Assistant in beta, along with major updates that redefine app building within the platform. These enhancements simplify app development, automation, interface creation, and enable users to query enterprise data using natural language.|
|[Verified ID May Be Required for Future OpenAI API Access.](https://help.openai.com/en/articles/10910291-api-organization-verification) | OpenAI plans to gate access to certain upcoming models behind a new Verified Organization process that will require government-issued ID. Verification will be limited to one org per ID every 90 days.|
|[Google launches AI short film initiative.](https://blog.google/technology/ai/ai-on-screen-short-films/) | Google has collaborated with filmmakers to create short films centered on AI, seeking to examine the emotional and ethical aspects of living alongside artificial intelligence.|
|[YouTube supports the NO FAKES Act: Protecting creators and viewers in the age of AI.](https://blog.youtube/news-and-events/youtube-supports-the-no-fakes-act/) | YouTube supports new legislation to combat AI-generated impersonations, reinforcing its commitment to protecting creators and viewers from deepfake harms.|
|[Canva unveils Visual Suite 2.0 with AI-powered productivity tools.](https://www.canva.com/newsroom/news/canva-create-2025/) |At Canva Create 2025, Canva launched Visual Suite 2.0, featuring AI-powered tools such as Magic Studio, Canva Sheets, and Magic Charts to simplify design processes. The suite also offers Canva Code for building websites and an upgraded AI-enhanced Photo Editor, all designed to bring together design, data, and development in one platform. |
|[Samsung and Google Cloud Expand Partnership, Bring Gemini to Ballie, a Home AI Companion Robot by Samsung.](https://news.samsung.com/global/samsung-and-google-cloud-expand-partnership-bring-gemini-to-ballie-a-home-ai-companion-robot) |Ballie, launching this summer, will provide personalized interactions and proactive home assistance using advanced multimodal reasoning. |
|[OpenAI GPT-4.1.](https://openai.com/index/gpt-4-1/) |OpenAI has released three new models through its API: GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano. These models surpass GPT-4o and GPT-4o mini in all areas, showing significant improvements in coding and instruction following. They support up to 1 million tokens of context and demonstrate enhanced long-context understanding, with an updated knowledge cutoff of June 2024. |
|[AI company Hugging Face buys humanoid robot company Pollen Robotics.](https://fortune.com/2025/04/14/ai-company-hugging-face-buys-humanoid-robot-company-pollen-robotics-reachy-2/) | AI company Hugging Face is taking a big leap into robotics with the acquisition of humanoid robotics startup Pollen Robotics.|
|[DolphinGemma.](https://blog.google/technology/ai/dolphingemma/) | DeepMind has unveiled DolphinGemma, a large language model created by Google to assist researchers in analyzing dolphin communication and potentially understanding their messages.|
|[6 highlights from Google Cloud Next 25.](https://blog.google/products/google-cloud/google-cloud-next-25-recap/) |Vertex AI has rolled out improvements to its video, image, speech, and music generation models, streamlining creative processes for businesses. Google AI is also supporting the development of specialized AI agents to boost productivity and security, with the new Agent2Agent Protocol enabling secure communication between agents across platforms. |
|[NVIDIA to Manufacture American-Made AI Supercomputers in US for First Time.](https://blogs.nvidia.com/blog/nvidia-manufacture-american-made-ai-supercomputers-us/) |NVIDIA is localizing AI hardware production by building factories in Texas and Arizona, aiming to produce Blackwell chips and AI supercomputers entirely within the U.S. |
|[Gemini Adds Question Generation to Google Classroom.](https://workspaceupdates.googleblog.com/2025/04/use-gemini-in-google-classroom-to-generate-questions-from-text.html) | Educators can now leverage Gemini in Google Classroom to create questions or quizzes from chosen text, boosting lesson engagement and simplifying content development.|
|[OpenAI is building a social network.](https://www.theverge.com/openai/648130/openai-social-network-x-competitor) | OpenAI is working on its own X-like social network, according to multiple sources familiar with the matter. While the project is still in early stages, we‚Äôre told there‚Äôs an internal prototype focused on ChatGPT‚Äôs image generation that has a social feed.|
|[Nvidia H20 chip exports hit with license requirement by US government.](https://techcrunch.com/2025/04/15/nvidia-h20-chip-exports-hit-with-license-requirement-by-us-government/) | Semiconductor giant Nvidia is facing unexpected new U.S. export controls on its H20 chips. In a filing Tuesday, Nvidia said it was informed by the U.S. government that it will need a license to export its H20 AI chips to China. This license will be required indefinitely, according to the filing ‚Äî the U.S. government cited ‚Äúrisk that the [H20] may be used in ‚Ä¶ a supercomputer in China.‚Äù|
|[TxGemma Open Model for Therapeutic Development.](https://developers.googleblog.com/en/introducing-txgemma-open-models-improving-therapeutics-development/) |Google has introduced a new variant of its Gemma models, specifically fine-tuned for therapeutic discovery in medical science. This model surpasses most specialized tools and all open general-purpose models in relevant benchmarks, highlighting its strength in biomedical research applications. |
|[OpenAI's Updates Preparedness Framework.](https://openai.com/index/updating-our-preparedness-framework/) |OpenAI has updated its safety strategy by introducing clearer risk categories, enhanced evaluation methods, and new protocols for handling advanced AI capabilities, aiming to improve oversight and mitigate potential harms more effectively. |
|[Canada Has Answer to Energy Needs in AI Race, Ex-Google CEO Says.](https://financialpost.com/pmn/business-pmn/canada-has-answer-to-energy-needs-in-ai-race-ex-google-ceo-says) |Canada, home to 250 data centers, plans to grow its digital infrastructure by harnessing its rich hydro and nuclear energy resources. Conservative leader Pierre Poilievre supports ramping up resource production to enhance economic gains within the country.|
|[Notion Launches AI-Powered Email.](https://www.notion.com/product/mail) | Notion Mail is a Gmail-integrated client that helps users manage, search, and reply to email using AI.|
|[ChatGPT became the most downloaded app globally in March.](https://techcrunch.com/2025/04/11/chatgpt-became-the-most-downloaded-app-globally-in-march/) |ChatGPT became the most downloaded non-gaming app in March, surpassing Instagram and TikTok with 46 million downloads. |
|[Grok Canvas-like Tool for Document Creation.](https://x.com/grok/status/1912318583532872166) |Grok, the chatbot from xAI, now includes Grok Studio, a canvas-like tool to build documents and basic apps. It's now live for all users. |
|[Introducing OpenAI o3 and o4-mini.](https://openai.com/index/introducing-o3-and-o4-mini/) |OpenAI has launched the new o3 and o4-mini models, enhancing ChatGPT's tool usage and enabling quicker, more advanced reasoning with built-in web search, file analysis, and image generation. |
|[Assort Health Secures $26 Million.](https://www.assorthealth.com/blog/assort-health-secures-26-million-in-funding-to-expand-specialty-specific-generative-ai-platform-for-managing-patient-phone-calls) | Assort Health, an AI-driven platform for handling patient calls, has secured new funding, raising its total to \$26 million to further its goal of enhancing healthcare access. Since late 2024, its technology has driven 8x revenue growth by cutting call wait times and improving appointment accuracy, with strong patient satisfaction. Supported by top investors, Assort Health integrates with EHR systems, achieving 99% scheduling accuracy and over 90% issue resolution.|
|[Google Uses AI to Cut Scam Ads by 90%.](https://blog.google/products/ads-commerce/google-ads-safety-report-2024/) | Google's 2024 Ads Safety Report highlights how LLM upgrades blocked billions of bad ads, suspended 700K+ scam accounts, and reduced impersonation scams significantly.|
|[Stable Diffusion Now Runs Faster on AMD GPUs.](https://stability.ai/news/stable-diffusion-now-optimized-for-amd-radeon-gpus) | Stability AI and AMD optimized several Stable Diffusion models for Radeon GPUs and Ryzen AI, improving speed and performance for AMD users.|
|[OpenAI in talks to pay about $3 billion to acquire AI coding startup Windsurf.](https://www.cnbc.com/2025/04/16/openai-in-talks-to-pay-about-3-billion-to-acquire-startup-windsurf.html) |OpenAI is in talks to buy Windsurf, an artificial intelligence tool for coding help, for $3 billion, according to a person familiar with the matter. Windsurf, formerly known as Codeium, competes with Cursor, another popular AI coding tool, as well as existing AI coding features from companies such as Microsoft, Anthropic and OpenAI.|
|[Mistral Classifier Factory.](https://docs.mistral.ai/capabilities/finetuning/classifier_factory/) | Mistral, a French AI startup, has launched a new product that allows users to very quickly build and deploy custom classifiers for a whole variety of tasks (e.g., spam, moderation, and more).|
|[Goodfire raises $50m series A to steer and understand models.](https://www.goodfire.ai/blog/announcing-our-50m-series-a) | Goodfire is a mechanistic interpretability company with strong expertise in SAEs, among other things. It is working closely with closed and open model providers to steer, control, and understand model motivations and behavior.|
|[Visual Reasoning with OpenAI o3 and o4-mini.](https://openai.com/index/thinking-with-images/) |OpenAI's latest visual models can reason with images through tool-augmented transformations, enabling a new level of multimodal understanding and step-by-step visual problem-solving. |
|[Cohere on Hugging Face Inference Providers.](https://huggingface.co/blog/inference-providers-cohere) |Cohere became the first model creator to directly host and serve its enterprise-focused AI models on Hugging Face. |
|[OpenAI Flex Processing.](https://platform.openai.com/docs/guides/flex-processing) |OpenAI has introduced Flex processing, a cost-saving API option that trades slower response times and intermittent availability for lower prices, ideal for non-production tasks. |
|[Anthropic enhances Claude with Research and Google Workspace integration.](https://www.anthropic.com/news/research) |Anthropic has launched new Claude features: Research for autonomous multi-step search with citations and Google Workspace integration for context-aware assistance. |

## Resources
|Link|description|
|---|---|
|[Anthropic Education Report: How University Students Use Claude.](https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude) |Anthropic has released a great educational report on how different groups of university students are using AI. Most groups in STEM use it for homework help while groups in humanities use it less and generally more for ideation and brainstorming. |
|[3D Object Part Segmentation.](https://huggingface.co/VAST-AI/HoloPart) | HoloPart is a semantic 3D Object segmentation model that can identify and separate a single 3D object into meaningful sub-pieces.|
|[Cluster-Driven Expert Pruning for Mixture-of-Experts Large Language Models.](https://arxiv.org/abs/2504.07807v1) | C-Prune is a two-stage pruning method that compresses Mixture-of-Experts models by clustering similar experts and pruning redundant clusters.|
|[Jax Recommendation Engine.](https://github.com/AI-Hypercomputer/RecML/) | A great recommendation engine with metrics, implementations of embedding models, and training infrastructure.|
|[Reasoning VLM from Kimi.](https://github.com/MoonshotAI/Kimi-VL) |An early open model for visual question answering, this compact model excels at grounded image-based questions, image captioning, and even some image-related math. |
|[Fully open fast inference models .](https://huggingface.co/ServiceNow-AI/Apriel-5B-Base) | Apriel models from ServiceNow research are designed for fast inference and showcase good performance.|
|[GUI-R1.](https://arxiv.org/abs/2504.10458) |GUI-R1, developed by researchers in Singapore and China, is a reinforcement learning framework that enhances GUI agents by using a unified action space and reinforcement fine-tuning, needing only 3,000 curated examples. It achieves superior performance and generalization across platforms like Windows, Mac, Android, and Web, outperforming models trained on millions of examples while remaining efficient and adaptable with minimal data. |
|[AgentA/B: Automated and Scalable Web A/BTesting with Interactive LLM Agents.](https://arxiv.org/abs/2504.09723) |AgentA/B is an automated A/B testing system that uses LLM-based agents to simulate realistic user behavior on live websites, enabling fast, low-risk UX evaluation. With modular components and DOM parsing for structured interactions, it replicates human-like shopping patterns and supports inclusive prototyping. Tests on Amazon showed agents responded meaningfully to interface changes, suggesting strong alignment with real user behavior and value as a pre-deployment testing layer. |
|[Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model.](https://seaweed.video/) |ByteDance has published a paper demonstrating how to train a competitive 7B-parameter video generation model using a relatively modest compute budget of 655,000 H100 hours, achieving strong results on several challenging temporal tasks. |
|[PixelFlow: Pixel-Space Generative Models with Flow.](https://arxiv.org/abs/2504.07963) |Due to computational limits, most generative models for continuous signals work in latent space. This study presents a cascade approach that enables direct generation in pixel space, removing the requirement for a pretrained VAE.  |
|[InteractVLM: 3D Interaction Reasoning from 2D Foundational Models.](https://arxiv.org/abs/2504.05303) | New VLM that can reason about contacts between humans in 3D and objects. It does so by leveraging a strong base model and lifting its reasoning into 3D with clever multi-view rendering.|
|[3B parameter tokenizer.](https://github.com/SilentView/GigaTok) | Scaling image tokenizers is difficult due to their tendency to collapse. This study presents GigaTok, a large-scale tokenizer that achieves excellent reconstruction quality, with stability and performance improved through decoder scaling and regularization.|
|[Improved MoE with C3PO.](https://github.com/tianyi-lab/c3po) | C3PO proposes a test-time optimization method that boosts accuracy in Mixture-of-Experts LLMs by adjusting expert weights using similar reference examples.|
|[BrowseComp Benchmark for Hard-to-Find Knowledge.](https://openai.com/index/browsecomp) |OpenAI's BrowseComp is a benchmark consisting of 1,266 tasks aimed at testing AI agents' ability to browse the web and retrieve complex, hard-to-find information. |
|[DeepSeek to Open Source its Inference Engine.](https://github.com/deepseek-ai/open-infra-index/blob/main/OpenSourcing_DeepSeek_Inference_Engine/README.md?utm_source=tldrai) | DeepSeek's inference engine is built on VLLM, although it is now heavily modified.|
|[MoonDream 2.0 Release.](https://moondream.ai/blog/moondream-2025-04-14-release) | MoonDream is a small, 2B parameter VLM that outperforms many open and closed models. It has recently gotten a strong upgrade on chartQA and a number of other useful benchmarks.|
|[Data Decide.](https://allenai.org/blog/datadecide) |AllenAI has released a tool that can be used to help decide which data to include in pre-training. This framework is quite useful for understanding what goes into a filtering run for pre-training. |
|[Conversion Rate Prediction in Ad Systems.](https://arxiv.org/abs/2504.08169) | Pinterest researchers have proposed a multitask framework that uses Deep Hierarchical Ensemble Networks to improve CVR predictions in ad systems. It shows state-of-the-art results through feature combination and auxiliary learning.|
|[Open Source OpenAI Production Kernels.](https://github.com/triton-lang/triton/pull/6429) |OpenAI has open sourced some of its fp4 and MoE kernels to the Triton language GitHub. |
|[Nemotron H Models.](https://huggingface.co/nvidia/Nemotron-H-8B-Base-8K) |Nvidia‚Äôs ADLR team has released the weights for its Nemotron hybrid Mamba models, which offer strong long-context handling and solid performance on general benchmarks, making them well-suited for tasks requiring extended reasoning or memory. |
|[Auto Deploy.](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/auto_deploy) | A new way to transform PyTorch and Hugging Face models into a faster, deployable, format for fast inference.|
|[Latents for Generative Modeling.](https://sander.ai/2025/04/15/latents.html) | A top contender for blog post of the year for those into generative modeling, offering a clear breakdown of the history, core ideas, and major advancements in learned latents.|
|[NVIDIA's Temporally Consistent Video Diffusion.](https://research.nvidia.com/labs/genair/equivdm/) | NVIDIA's EquivDM framework improves video diffusion by applying consistent noise, leading to better motion tracking and more 3D-consistent results with fewer sampling steps.|
|[Intellect 2 Distributed Training.](https://www.primeintellect.ai/blog/intellect-2) |Prime Intellect has developed a 32B fully distributed network trained with reinforcement learning for reasoning, and has open-sourced much of its code and valuable libraries. |
|[DeepMath dataset.](https://github.com/zwhe99/DeepMath) | 103K examples of highly filtered and decontaminated math problems for reasoning model training.|
|[Prima CPP.](https://github.com/Lizonghang/prima.cpp) |Prima CPP is an extension of llama.cpp that tries to enable mmaping of memory for large models to enable them to run on low RAM environments. |
|[Tile Language.](https://github.com/tile-ai/tilelang) |Tile Language is a compact domain-specific language aimed at simplifying the creation of high-performance GPU/CPU kernels like GEMM, Dequant GEMM, FlashAttention, and LinearAttention. It uses a Python-like syntax built on TVM's compiler stack, enabling developer productivity while preserving low-level optimizations for top-tier performance. |
|[Hugging Face Updated HELMET Benchmark.](https://huggingface.co/blog/helmet) |Hugging Face has expanded its HELMET benchmark to include more models and insights, helping researchers evaluate long-context LLMs like Phi-4 and Jamba 1.6. |
|[Junfeng5/Liquid_V1_7B.](https://huggingface.co/Junfeng5/Liquid_V1_7B) |Liquid is a multimodal LLM that integrates visual comprehension and generation by tokenizing images into discrete codes. |
|[Efficient Line Art Colorization with Broader References.](https://zhuang2002.github.io/Cobra/) |A new efficient long-context, fine-grained ID preservation framework for line art colorization delivers high accuracy, speed, and flexibility for comic coloring, converting black-and-white sketches into vivid illustrations by leveraging rich contextual references. |
|[Scene Captioning.](https://arxiv.org/abs/2504.09518) | 3D CoCa is a unified framework that combines vision-language contrastive learning and captioning for 3D scenes.|
|[DeepSpeed's DeepCompile.](https://github.com/deepspeedai/DeepSpeed/blob/master/blogs/deepcompile/README.md) | The DeepSpeed team has integrated compilation into their distributed training workflow, significantly accelerating several performance bottlenecks using a modified version of torch compile.|
|[Speech Instruction Fine-Tuning Dataset.](https://huggingface.co/datasets/amazon-agi/SIFT-50M) | SIFT-50M (Speech Instruction Fine-Tuning) is a dataset of 50 million examples created for instruction fine-tuning and pre-training speech-text LLMs. Sourced from 14,000 hours of public speech data, it uses LLMs and expert models, spans five languages, and supports both speech understanding and controllable speech generation. It enriches existing datasets with instruction-based QA pairs and includes around 5 million examples for generation tasks.|
|[End-to-End Latent Diffusion Training with REPA-E.](https://end2end-diffusion.github.io/) |REPA-E enables stable, joint training of VAEs and latent diffusion models using a representation-alignment loss, achieving state-of-the-art results on ImageNet. |
|[Meta Releases Many New Artifacts.](https://ai.meta.com/blog/meta-fair-updates-perception-localization-reasoning/) | Meta has released an image Encoder, a VLM, a 3D object localization model based on JEPA, and weights for a BLT model that operates directly on bytes without tokenization.|
|[Create AI-generated soundtrack in Shorts with Dream Track.](https://support.google.com/youtube/answer/14151606) |YouTube's Dream Track is now accessible in the U.S. through YouTube Shorts and the YouTube Create app, offering AI-generated instrumental soundtracks for creators. These tracks can be globally remixed to produce unique Shorts, promoting collaboration, and are fully integrated with YouTube‚Äôs creation tools while following community guidelines. |
|[SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents.](https://arxiv.org/abs/2504.08703v3) | SWE-PolyBench is a new benchmark for evaluating coding agents on real-world tasks in Java, JavaScript, TypeScript, and Python. It uses execution-based and syntax tree metrics, revealing that current agents struggle with complex problems and perform inconsistently across languages.|
|[A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems.](https://arxiv.org/abs/2504.09037) |This survey organizes LLM reasoning methods by timing (inference-time vs. training) and architecture (standalone vs. agentic/multi-agent), spotlighting trends like learning-to-reason and agentic workflows. It reviews techniques including prompt design, output refinement, and training approaches like PPO and verifier-based learning. |
|[A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science.](https://arxiv.org/abs/2504.09848) | This paper surveys spatial intelligence across fields, linking human cognition to how LLMs manage spatial memory, reasoning, and representations. It proposes a unified framework bridging AI, robotics, urban planning, and earth science, emphasizing LLMs‚Äô growing spatial abilities and interdisciplinary relevance.|

## Perspectives
|Link|description|
|---|---|
|[Business Leaders' Thoughts on AI Possibilities.](https://blog.google/products/google-cloud/business-leaders-building-with-ai/) | Executives from nine companies share how they're leveraging Google Cloud's AI tools to drive innovation across sectors, with over 600 real-world use cases highlighted.|
|[Jack Ma Advocates for AI to Serve Humanity, Not Dominate.](https://opentools.ai/news/jack-ma-advocates-for-ai-to-serve-humanity-not-dominate) |Jack Ma emphasizes AI should enhance rather than dominate human life, calling for global cooperation on ethical standards to ensure technology supports societal welfare‚Äîechoing public concerns about responsible AI development. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme70.jpg)

[Back to index](#Index)

# ML news: Week 7 - 13 April

## Research
|Link|description|
|---|---|
|[Rope to Nope and Back Again: A New Hybrid Attention Strategy.](https://arxiv.org/abs/2501.18795) |Llama 4's breakthrough in handling over 10 million tokens in context comes from alternating between no positional embeddings and rotational positional embeddings. Although current benchmarks are limited to Needle in the Haystack, they strongly suggest the effectiveness of this alternating layer approach. |
|[Inference-Time Scaling for Generalist Reward Modeling.](https://arxiv.org/abs/2504.02495) |This DeepSeek paper explores using inference-time scaling to improve reward modeling as a way to develop stronger reasoners. It suggests a larger plan by the Chinese start-up to leverage its current reasoning models as a foundation for building the next wave of reward models to train future reasoners. |
|[CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation.](https://arxiv.org/abs/2503.22708) | Researchers at AI2 introduce CodeScientist, a system that autonomously generates and tests scientific hypotheses through code-based experimentation, making validated discoveries with minimal human input. CodeScientist reviews research papers and designs experiments using Python code blocks, following a five-step pipeline: Ideation, Planning, Code Execution, Reporting, and Meta-Analysis. From 50 AI research papers, it proposed 19 findings, with 6 deemed scientifically sound, including insights like the mismatch between LLM confidence and accuracy, the benefit of simpler states for better predictions, and the advantage of graph memory in simulations. While full automation is possible, human feedback enhances the quality of results. Despite successes, over half of experiments fail due to code errors, highlighting the need for peer review and more rigorous methodologies.|
|[One-Minute Video Generation with Test-Time Training.](https://test-time-training.github.io/video-dit) | This study presents Test-Time Training (TTT) layers with rich hidden states to address the shortcomings of traditional Transformers and models like Mamba in producing long, coherent videos. By adding TTT layers to a pre-trained model, it achieves one-minute video generation from text storyboards that significantly surpass baseline methods in conveying complex narratives, based on human evaluations. Tom and Jerry cartoons serve as the test environment.|
|[Scaling Analysis of Interleaved Speech-Text Language Models.](https://arxiv.org/abs/2504.02398v1) | This study shows that speech-language models initialized from text models using interleaved training scale more efficiently than models trained solely on speech.|
|[Retrieval-Augmented Reasoning Model.](https://arxiv.org/abs/2503.23513) |RARE introduces a new approach for training domain-specific LLMs focused on reasoning rather than memorization. Inspired by Bloom‚Äôs Taxonomy, it emphasizes applying and evaluating knowledge rather than merely recalling facts. RARE separates domain knowledge, retrieved externally, from domain thinking, learned during training, enabling better performance within limited parameter budgets. By using an open-book approach, it injects retrieved knowledge into training prompts, fostering reasoning patterns. This method outperforms standard SFT and RAG, especially in medicine, with small models like Llama-3.1-8B and Qwen-2.5-7B achieving up to 20% higher accuracy on medical QA benchmarks. RARE also uses distillation and adaptive retries to refine outputs and integrate retrieval during training to shape reasoning, replacing memorization with application. |
|[A New Batch Normalization.](https://arxiv.org/abs/2504.00660) |This paper proposes a new batch normalization method for SPD manifolds that uses a learnable Generalized Bures-Wasserstein metric. |
|[How Students Use Claude in Education.](https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude) | Anthropic studied one million student conversations to explore AI use in education, finding that STEM students are the primary users, mainly using Claude for content creation, solving technical problems, and tackling advanced learning tasks.|
|[Why do LLMs Attend to First Token?](https://arxiv.org/abs/2504.02732) | This paper explains why LLMs tend to focus attention on the first token, a phenomenon called an attention sink. The theory suggests it prevents representational collapse in deep Transformers. Long contexts and deep layers can lead to over-mixing, causing similar embeddings for all tokens, but attention sinks act as no-ops to preserve representation diversity. Experiments on Gemma 7B and LLaMa 3.1 models show that attention heads fixate on the first token, with larger models requiring stronger sinks. Sinks form naturally due to the token's position, not its content, and removing the ‚ü®bos‚ü© token after training leads to performance collapse. The paper connects this behavior to Jacobian norm bounds, demonstrating that sinks reduce sensitivity to token changes, and reveals that some attention heads use ‚ü®bos‚ü© as a default unless triggered by specific patterns.|
|[MedAgentSim: Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions.](https://arxiv.org/abs/2503.22678) |MedAgentSim is an open-source, fully automated hospital simulation where LLM-powered agents simulate doctor-patient interactions in dynamic diagnostic settings. Unlike static QA benchmarks, it involves multi-turn consultations, lab and imaging requests, and iterative diagnosis refinement. The system improves through memory and reflection, using past cases and chain-of-thought reasoning to enhance performance over time. Users can choose to control the doctor or patient agents, and the simulation, built with a 2D game engine, allows for interaction with virtual medical tools. MedAgentSim outperforms baseline setups by 6-37% across several benchmarks, particularly in vision-language tasks, and its bias analysis highlights the importance of cognitive and implicit bias-aware evaluation. |
|[Z1: Efficient Test-time Scaling with Code.](https://arxiv.org/abs/2504.00810v1) |Z1 is a new method designed to make LLMs more compute-efficient during reasoning at test time. It involves training LLMs on both short and long code-based reasoning trajectories, then adjusting reasoning depth dynamically during inference. The Z1-Code-Reasoning-107K dataset pairs simple and complex coding problems to teach the model when to stop reasoning. A novel test-time strategy, the Shifted Thinking Window, adapts the reasoning token budget based on problem complexity, enabling shallow reasoning for simple tasks and deeper reasoning for complex ones. Z1-7B achieves efficiency gains, matching the performance of larger models like R1-Distill-Qwen-7B but using only 30% of the reasoning tokens. Despite being trained on code-based reasoning, Z1 generalizes well to other domains, outperforming other 7B models across multiple benchmarks. Ablation studies show that longer reasoning paths and larger training sample sizes improve inference quality and accuracy. |
|[Inside-Out: Hidden Factual Knowledge in LLMs.](https://arxiv.org/abs/2503.15299) | This study presents a framework to measure hidden knowledge in LLMs, revealing that models store significantly more factual information internally than they express in outputs, with a difference of up to 40%. It also finds that some answers, while internally known, are never generated, highlighting limitations in test-time sampling for QA tasks.|
|[Photonic chips provide a processing boost for AI.](https://www.nature.com/articles/d41586-025-00907-5) |Computer processors that exploit both electricity and light could improve the performance of artificial-intelligence systems while consuming less energy. |
|[AI Scientist v2.](https://pub.sakana.ai/ai-scientist-v2/paper/paper.pdf) | Sakana AI had a research paper accepted to an ICLR workshop that was entirely generated, executed, and written by a language model system. They enhanced the system with vision-language models, broader search capabilities, and other improvements.|
|[Dynamic Knowledge Circuits.](https://github.com/zjunlp/dynamicknowledgecircuits) |This research investigates how LLMs internalize new knowledge by examining computational subgraphs, uncovering patterns in knowledge acquisition, training optimization phases, and offering insights for enhancing continual pre-training strategies. |
|[Concept Attention.](https://github.com/helblazer811/ConceptAttention) |A novel method to view concepts in the attention map of neural networks. |


## News
|Link|description|
|---|---|
|[Llama 4.](https://ai.meta.com/blog/llama-4-multimodal-intelligence/) | Meta has introduced Llama 4 Scout and Maverick, two 17B-parameter multimodal models delivering top-tier results on key benchmarks, as well as Llama 4 Behemoth, a 288B model still in training that outperforms GPT-4.5 in STEM-related tasks.|
|[Meta Responds to Llama 4 Rumors.](https://x.com/Ahmad_Al_Dahle/status/1909302532306092107) |Meta's VP of Generative AI has refuted accusations that Llama 4 models were trained on benchmark test sets, rejecting claims that their performance results were artificially boosted. |
|[Amazon Nova Reel 2-Minute Videos.](https://aws.amazon.com/it/blogs/aws/amazon-nova-reel-1-1-featuring-up-to-2-minutes-multi-shot-videos/) | The upgraded Nova Reel model now handles multi-shot videos up to 2 minutes in length, providing greater creative control and improved efficiency for generating video content.|
|[Midjourney V7.](https://www.midjourney.com/updates/v7-alpha) | Midjourney has launched its V7 alpha image generation model, featuring improved text understanding, enhanced image consistency, and a new Draft Mode for quick, budget-friendly iterations, along with support for voice commands and personalization.| 
|[AI masters Minecraft: DeepMind program finds diamonds without being taught.](https://www.nature.com/articles/d41586-025-01019-w) |DeepMind's AI system, Dreamer, managed to learn how to collect diamonds in Minecraft without any human instruction, marking progress toward more general AI. Through reinforcement learning, Dreamer explores and models the game world on its own to forecast actions and results. This development points to possible real-world uses where trial-and-error learning would be expensive. |
|[OpenAI‚Äôs models ‚Äòmemorized‚Äô copyrighted content, new study suggests.](https://techcrunch.com/2025/04/04/openais-models-memorized-copyrighted-content-new-study-suggests/) | A new study appears to lend credence to allegations that OpenAI trained at least some of its AI models on copyrighted content.|
|[UK Home Office loses attempt to keep legal battle with Apple secret.](https://www.theguardian.com/politics/2025/apr/07/uk-home-office-loses-attempt-to-keep-legal-battle-with-apple-secret) |Judges reject Home Office‚Äôs attempt to withhold from public details of case concerning access of Apple users‚Äô data |
|[Investing in Krea.](https://a16z.com/announcement/investing-in-krea/) |Andreessen Horowitz has invested in Krea, a platform that blends AI models to assist creatives in generating and editing visual content. With over 20 million users, including teams at Pixar and Samsung, Krea is set to release an enterprise-grade product later this year. |
|[Google's AI Highlights in March.](https://blog.google/technology/ai/google-ai-updates-march-2025/) |Google recaps major March updates including Gemini 2.5 Pro, expanded AI Overviews, AI Mode, and other feature rollouts across its products. |
|[Genies unveils user-generated content tools that let anyone create custom AI avatars.](https://venturebeat.com/games/genies-unveils-user-generated-content-tools-that-let-anyone-create-custom-ai-avatars/) | Genies has released a no-code platform that lets users create intelligent AI avatars with distinct appearances, personalities, and behaviors for use in customizable gaming experiences called Parties. Powered by large language models, behavioral AI, and real-time animation, these avatars support dynamic interaction, gameplay, and emotional expression.|
|[OpenAI Plans O3 and O4-Mini Release Before GPT-5, Altman Say.](https://decrypt.co/313379/openai-o3-o4-mini-release-before-gpt5) | OpenAI plans to release intermediate models o3 and o4-mini ahead of GPT-5, citing technical challenges with GPT-5 and aiming to improve performance while managing demand. This move comes amid rising competition from models like Google‚Äôs Gemini 2.5 Pro, and follows OpenAI's recent $40 billion funding round.|
|[OpenAI‚Äôs o3 model might be costlier to run than originally estimated.](https://techcrunch.com/2025/04/02/openais-o3-model-might-be-costlier-to-run-than-originally-estimated/) |When OpenAI unveiled its o3 ‚Äúreasoning‚Äù AI model in December, the company partnered with the creators of ARC-AGI, a benchmark designed to test highly capable AI, to showcase o3‚Äôs capabilities. Months later, the results have been revised, and they now look slightly less impressive than they did initially. |
|[Bringing multimodal search to AI Mode.](https://blog.google/products/search/ai-mode-multimodal-search) |Google is expanding its AI Mode feature to millions of U.S. Labs users, enhancing it with multimodal capabilities. |
|[Waymo may use interior camera data to train generative AI models, but riders will be able to opt out.](https://techcrunch.com/2025/04/08/waymo-may-use-interior-camera-data-to-train-generative-ai-models-sell-ads/) | Waymo is preparing to use data from its robotaxis, including video from interior cameras tied to rider identities, to train generative AI models, according to an unreleased version of its privacy policy found by researcher Jane Manchun Wong, raising fresh questions about how much of a rider‚Äôs behavior inside autonomous vehicles could be repurposed for AI training.|
|[Microsoft‚Äôs Copilot can now browse the web and perform actions for you.](https://techcrunch.com/2025/04/04/microsofts-copilot-can-now-browse-the-web-and-perform-actions-for-you/) |Microsoft's Copilot AI chatbot now performs tasks on popular websites, remembers user preferences, and analyzes real-time video. |
|[ElevenLabs releases official MCP server for AI-driven audio processing.](https://github.com/elevenlabs/elevenlabs-mcp) |ElevenLabs has launched an official Model Context Protocol server for Text-to-Speech and audio processing that is compatible with clients like Claude Desktop and OpenAI Agents. |
|[Big tech‚Äôs new datacentres will take water from the world‚Äôs driest areas.](https://www.theguardian.com/environment/2025/apr/09/big-tech-datacentres-water) | Amazon, Google and Microsoft are building datacentres in water-scarce parts of five continents|
|[EU to build AI gigafactories in ‚Ç¨20bn push to catch up with US and China.](https://www.theguardian.com/technology/2025/apr/09/eu-to-build-ai-gigafactories-20bn-push-catch-up-us-china) |Up to five sites with power-hungry supercomputers and datacentres planned to drive AI ‚Äòmoonshots‚Äô |
|[Online suicide forum investigated under new UK digital safety laws.](https://www.theguardian.com/technology/2025/apr/09/online-suicide-forum-ofcom-investigation-uk-digital-safety-laws) | Ofcom‚Äôs first investigation to look into whether site took adequate measures to shield users from illegal content|
|[White House insists iPhones will be US-made ‚Äì but Apple calls it a non-starter.](https://www.theguardian.com/us-news/2025/apr/09/trump-apple-iphones-made-in-usa) |Experts doubt Trump line that tariffs and company‚Äôs $500bn investment will shift manufacturing from Asia |
|[Dr Oz tells federal health workers AI could replace frontline doctors.](https://www.theguardian.com/us-news/2025/apr/09/mehmet-oz-doctors-ai) |Former TV doctor who leads $1.5tn Medicare and Medicaid agency also says staff have ‚Äòpatriotic duty‚Äô to stay healthy |
|[Bank of England says AI software could create market crisis for profit.](https://www.theguardian.com/business/2025/apr/09/bank-of-england-says-ai-software-could-create-market-crisis-profit) |Concern grows over programs deployed to act with autonomy that may ‚Äòexploit weaknesses‚Äô |
|[EU to build AI gigafactories in ‚Ç¨20bn push to catch up with US and China.](https://www.theguardian.com/technology/2025/apr/09/eu-to-build-ai-gigafactories-20bn-push-catch-up-us-china) |Up to five sites with power-hungry supercomputers and datacentres planned to drive AI ‚Äòmoonshots‚Äô |
|[EU will not rip up tech rules for trade deal with Trump, senior official says.](https://www.theguardian.com/world/2025/apr/11/eu-will-not-rip-up-tech-rules-for-trade-deal-with-trump-senior-official-says) |Bloc is ‚Äòvery committed‚Äô to laws on big tech and is not targeting US companies, says European Commission‚Äôs Henna Virkkunen |
|[Amazon‚Äôs satellite launch designed to compete with Musk‚Äôs Starlink cancelled.](https://www.theguardian.com/us-news/2025/apr/10/amazon-satellite-launch-cancelled) |‚ÄòLiftoff not possible‚Äô for rocket carrying Project Kuiper satellites, due to clouds that could trigger lightning strikes |
|[Apple said to be flying iPhones from India to US to avoid Trump tariffs.](https://www.theguardian.com/technology/2025/apr/10/apple-flying-iphones-india-us-avoid-trump-tariffs) |Tech firm has reportedly flown 600 tonnes of handsets from Indian factories as Chinese goods face huge tariffs |
|[Federal workers fear Musk‚Äôs ‚Äòefficiency‚Äô agency is using AI to spy on them: ‚ÄòThey are omnipresent‚Äô.](https://www.theguardian.com/us-news/ng-interactive/2025/apr/10/elon-musk-doge-spying) | The billionaire‚Äôs Doge may be secretly recording meetings in at least two agencies, according to emails from senior officials|
|[Energy demands from AI datacentres to quadruple by 2030, says report.](https://www.theguardian.com/technology/2025/apr/10/energy-demands-from-ai-datacentres-to-quadruple-by-2030-says-report) |The IEA forecast indicates a sharp rise in the requirements of AI, but said threat to the climate was ‚Äòoverstated‚Äô |
|[Google Ironwood TPU.](https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/) |The 7th generation of Google's TPUs brings major advancements in podsize, bandwidth, memory, and total flops, marking a significant leap beyond any other chip currently available. |
|[Claude's Max Plan.](https://www.anthropic.com/news/max-plan) | The new Max plan for Claude offers increased usage limits and priority access to features and models, catering to users with intensive needs. It comes in two tiers: Expanded Usage at $100/month with 5x usage, and Maximum Flexibility at $200/month with 20x usage‚Äîideal for handling large documents and complex data regularly.|
|[Generative Media Upgrades in Vertex AI.](https://blog.google/products/google-cloud/cloud-next-gen-ai-vertex-ai-updates/) | Google Cloud has upgraded Vertex AI with advanced generative tools, introducing features like text-to-music with Lyria, video editing via Veo 2, voice customization through Chirp 3, and image inpainting using Imagen 3.|
|[Introducing Firebase Studio.](https://firebase.blog/posts/2025/04/introducing-firebase-studio) |Firebase Studio is debuting as a cloud-based development platform for creating, testing, and deploying AI apps. It integrates tools like Project IDX, Genkit, and Gemini into a single environment, enabling fast AI prototyping and a flexible coding workspace. Developers benefit from features like natural language prototyping, real-time device previews, and seamless collaboration to speed up app development. |
|[Hugging Face and Cloudflare Partnership.](https://huggingface.co/blog/fastrtc-cloudflare) | Developers can now quickly create real-time voice and video applications using FastRTC, which leverages Cloudflare's enterprise-grade WebRTC infrastructure and offers easy integration through Hugging Face tokens.|
|[GitHub Copilot introduces new limits, charges for ‚Äòpremium‚Äô AI models.](https://techcrunch.com/2025/04/04/github-copilot-introduces-new-limits-charges-for-premium-ai-models/) |GitHub Copilot users will face rate limits on AI models beyond the base GPT-4o model, with premium requests capped for paid tiers. |
|[Shopify CEO declares AI proficiency a baseline expectation for employees.](https://x.com/tobi/status/1909251946235437514) | Shopify CEO Tobi L√ºtke announced that reflexive AI usage is now a fundamental expectation for all employees.|
|[ChatGPT Now Uses All Past Conversations.](https://threadreaderapp.com/thread/1910380643772665873.html) | ChatGPT can now remember all your past conversations, a step toward more personalized and long-term useful AI systems.|
|[Mira Murati‚Äôs AI startup is reportedly aiming for a massive $2B seed round.](https://techcrunch.com/2025/04/10/mira-muratis-ai-startup-is-reportedly-aiming-for-a-massive-2b-seed-round/) |Thinking Machines Lab, the new AI startup from ex-OpenAI CTO Mira Murati, is reportedly attempting to close one of the largest seed rounds in history. Thinking Machines Lab only recently emerged from stealth and has no product or revenue to speak of. What it does have ‚Äî and what‚Äôs likely convincing investors to fork over cash ‚Äî is dozens of high-profile AI researchers in its ranks.|
|[Amazon's Heavy AI Investment.](https://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-2024-letter-to-shareholders) |Amazon CEO Andy Jassy, in the annual letter, highlights the critical role of large-scale AI investment in transforming customer experiences, noting that over 1,000 GenAI projects are in progress alongside increasing infrastructure needs. |
|[Announcing the Agent2Agent Protocol (A2A).](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/) | To boost AI collaboration and automation in enterprise settings, Google Cloud has introduced the Agent2Agent (A2A) protocol, enabling smooth interaction between AI agents across platforms and vendors. Supported by over 50 tech partners like Atlassian, Salesforce, and PayPal, A2A offers a standardized framework for secure communication and task coordination, helping enterprises increase productivity and lower costs. The open-source protocol also accommodates multiple modalities and long-running tasks.|
|[Trump administration backs off Nvidia's H20 chip crackdown after Mar-a-Lago dinner, NPR reports.](https://www.reuters.com/technology/trump-administration-backs-off-nvidias-h20-chip-crackdown-after-mar-a-lago-2025-04-09/) | The Trump administration reversed plans to restrict Nvidia's H20 AI chip exports to China after Nvidia CEO promised U.S. investments.|
|[Tesla stops taking orders in China for two models imported from US.](https://www.theguardian.com/technology/2025/apr/11/tesla-stops-taking-orders-in-china-for-two-models-imported-from-us) |Carmaker removes ‚Äòorder now‚Äô buttons for Model S saloon and Model X SUV on its Chinese website amid tariffs war |
|[OpenAI countersues Elon Musk over ‚Äòunlawful harassment‚Äô of company.](https://www.theguardian.com/technology/2025/apr/11/openai-countersues-elon-musk-over-unlawful-harassment-of-company) | ChatGPT developer asks US federal judge to stop former founder making any further attacks|


## Resources
|Link|description|
|---|---|
|[Unsupervised Panoptic Segmentation.](https://visinf.github.io/cups/) | CUPS is a novel approach to panoptic segmentation that requires no labeled data, using depth and motion cues to learn directly from scene-centric images.|
|[Generative Modeling for Crystals.](https://github.com/deepmodeling/crystalformer) | CrystalFormer is a transformer-based model that creates crystal structures by leveraging space group symmetry, enhancing efficiency and reducing data requirements in crystal generation.|
|[Nano Aha Moment.](https://github.com/McGill-NLP/nano-aha-moment) | A single file, single GPU, from scratch full parameter tuning library that replicates DeepSeek R1-Zero style training.|
|[Object Counting.](https://github.com/AhmedZgaren/Save) | A fully automated zero-shot object counting approach that uses feature maps and self-attention mechanisms, achieving state-of-the-art results on the FSC147 dataset.|
|[DeepSeek 1.58bit GGUF.](https://huggingface.co/unsloth/DeepSeek-R1-GGUF/tree/main/DeepSeek-R1-UD-IQ1_S) |The Unsloth team identified which parts of the new R1 model can be effectively quantized, noting some tokenizer quirks that complicate the process. In short, only the MoE layers are quantized to 1.58 bits, while the rest stay at 4 or 6 bits using their dynamic quantization approach. |
|[Granite Speech 8B.](https://huggingface.co/ibm-granite/granite-speech-3.2-8b) |IBM silently launched a state-of-the-art speech recognition and understanding model based on its Granite series. |
|[Start building with Gemini 2.5 Pro.](https://blog.google/products/gemini/gemini-preview-model-billing-update/) | Google's Gemini 2.5 Pro is now in public preview via the Gemini API on Google AI Studio, with Vertex AI availability coming soon.|
|[Benchmarking Web Agent Capabilities.](https://arxiv.org/abs/2504.01382v1) | Online-Mind2Web is a practical evaluation benchmark for autonomous web agents, revealing that current models underperform compared to prior assumptions due to issues with earlier benchmarks.|
|[VarGPT.](https://github.com/VARGPT-family/VARGPT-v1.1) | A unified autoregressive model that handles both understanding and synthesis tasks, enabling it to generate images as well as produce captions.|
|[FlexTok: Resampling Images into 1D Token Sequences of Flexible Length.](https://github.com/apple/ml-flextok) | Apple's open-source release builds on its recent paper, introducing a method to tokenize images using a variable number of tokens, allowing more complex images to be represented with more tokens.|
|[ZClip: Adaptive Spike Mitigation for LLM Pre-Training.](https://github.com/bluorion-com/ZClip) | ZClip employs EMA-based gradient norm statistics to dynamically suppress outlier gradients, avoiding loss spikes and enhancing training stability without relying on fixed thresholds.|
|[Goku Video Model.](https://saiyan-world.github.io/goku/) |Goku from ByteDance is a flow based video generation model of 2B and 8B parameters with 160M image and 36M video pairs. |
|[AI Index 2025: State of AI in 10 Charts.](https://hai.stanford.edu/news/ai-index-2025-state-of-ai-in-10-charts) |A clear, high-level, and thorough overview in 10 charts capturing the current landscape of AI, covering models, funding, and associated costs. |
|[Benchmarking Open Source models for OCR.](https://getomni.ai/blog/benchmarking-open-source-models-for-ocr) | OCR involves recognizing text within images‚Äîa task that's difficult in rare cases but highly valuable when accurate. While closed models like the Gemini series excel at it, the latest Llama 4 models significantly advance the performance of open-source alternatives.|
|[DeepCoder: A Fully Open-Source 14B Coder at O3-mini Level.](https://www.together.ai/blog/deepcoder) | Together AI has developed a coding model that rivals closed-source reasoning models. They've released the data, code, and training recipes, highlighting the model's impressive long-context capabilities.|
|[Hi Dream Image Generation Model.](https://github.com/HiDream-ai/HiDream-I1) |A powerful 17B parameter image generation model that leverages four distinct text encoders for generation, delivering strong overall results and released under a permissive license. |
|[A Framework for Dynamic Multi-Product Pricing.](https://arxiv.org/abs/2504.02324) |This paper presents a new dynamic multi-product pricing framework based on a censored multinomial logit model, where buyers only evaluate products priced below their personal valuations. |
|[MotifBench for Protein Design.](https://github.com/blt2114/MotifBench) |MotifBench is a benchmark for computational protein design, centered on the motif-scaffolding challenge by finding protein structures that support and stabilize specific target motifs. |
|[Arabic AI Benchmarks.](https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval) | Inception and MBZUAI have introduced a unified Arabic AI evaluation platform, featuring refreshed AraGen benchmarks and a new instruction-following leaderboard based on the Arabic IFEval benchmark.|
|[17K reasoning traces from R1.](https://huggingface.co/datasets/bespokelabs/Bespoke-Stratos-17k) | A great set of reasoning traces from R1 that can be used as training data to distill a smaller reasoner or kick start the RL process.|
|[How Google Built the Pixel's Add Me Feature.](https://blog.google/products/pixel/how-google-built-pixel-add-me/) |The "Add Me" feature on Pixel devices leverages advanced image segmentation and AI for personalized video experiences. |
|[PaperBench: Evaluating AI's Ability to Replicate AI Research.](https://arxiv.org/abs/2504.01848) | OpenAI introduces PaperBench, a benchmark to evaluate whether AI agents can replicate cutting-edge machine learning research papers from scratch. The challenge requires agents to understand papers, build codebases, and run experiments to match results, with each paper accompanied by a detailed rubric. Evaluation is done using an LLM-based judge that scores with high agreement to human experts. The highest score was 21.0% by Claude 3.5 Sonnet, with no model surpassing 26.0%. ML PhDs scored 41.4% on a subset in 48 hours, showing humans still outperform in long-term tasks. A simplified Code-Dev version showed better results for o1 (43.4%). Models often struggled with early failure, lack of planning, and iteration, highlighting the importance of proper prompting and scaffolding.|
|[Command A: An Enterprise-Ready Large Language Model.](https://arxiv.org/abs/2504.00698) |Cohere introduces Command A, a 111B parameter open-weights LLM designed for enterprise tasks like RAG, agents, code, and multilingual applications. Command A uses a decentralized training pipeline where expert models are fine-tuned for specific domains and then merged, maintaining most expert performance with a minimal drop. Its hybrid architecture improves long-context efficiency, supporting 256k contexts with lower memory usage, and it outperforms peers in long-context benchmarks. Command A excels in agentic capabilities, surpassing GPT-4o and Claude 3.5 in multiple tests. It leads in real-world generative tasks and RAG use cases, with top scores in multilingual tasks, including dialect alignment and language consistency. The model also undergoes alignment with SRPO and RLHF, showing significant improvements in human alignment. Despite its size, Command A is efficient, running on just 2√óA100s or H100s and generating 156 tokens/sec. Model weights are openly available on Hugging Face. |
|[Open Deep Search: Democratizing Search with Open-source Reasoning Agents.](https://arxiv.org/abs/2503.20201) |Researchers from Sentient, UW, Princeton, and UC Berkeley introduce Open Deep Search (ODS), an open-source AI framework that competes with proprietary systems like GPT-4o Search Preview and Perplexity Sonar. ODS consists of two components: the Open Search Tool, which refines web results through query rephrasing and reranking, and the Open Reasoning Agent, which orchestrates tool usage to answer queries. ODS-v2, built on DeepSeek-R1, outperforms GPT-4o Search Preview by 9.7% on FRAMES and offers better cost-efficiency. It also surpasses Perplexity Sonar on complex reasoning tasks. The addition of CodeAct in ODS-v2 allows the system to run Python code for improved reasoning and precision, offering more flexibility than the CoT-based ReAct in ODS-v1. |
|[Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models.](https://arxiv.org/abs/2503.24377) | This survey examines reasoning economy in LLMs, exploring how to balance deep reasoning performance with computational cost. It reviews inefficiencies, behavioral patterns, and potential solutions during both post-training and inference stages.|
|[Omni SVG.](https://omnisvg.github.io/) | By interpreting SVGs as a foreign language, a pretrained Qwen model can generate original SVGs from text and images, setting a new state-of-the-art. An open release is expected soon.|
|[OLMoTrace.](https://allenai.org/blog/olmotrace) |A debate in language modeling centers on how much models truly learn versus what they merely memorize. A new feature in the AI2 Playground addresses this by searching billions of input documents in real time to determine whether a model's output is original or regurgitated, providing source references from multiple documents. |
|[Efficient MoE Inference.](https://github.com/shuzhangzhong/HybriMoE-Preview) | HybriMoE is a new framework for hybrid CPU-GPU inference on Mixture of Experts models, addressing instability and overhead through improved scheduling and caching techniques.|
|[Protein Backbone Generation.](https://github.com/AngxiaoYue/ReQFlow) | ReQFlow establishes a new standard in protein backbone generation, achieving state-of-the-art performance while being much faster than current models‚Äî37 times faster than RFDiffusion and 62 times faster than Genie2 for 300-length sequences.|
|[Cogito v1 Preview: Introducing IDA as a path to general superintelligence.](https://www.deepcogito.com/research/cogito-v1-preview) | The Cognito team has open-sourced LLMs from 3B to 70B parameters, all outperforming leading open models in their size class, with the 70B model exceeding Llama 4 109B MoE. Trained using Iterated Distillation and Amplification (IDA), these models handle both direct and reflective answering, and are available on Hugging Face, Ollama, Fireworks AI, and Together AI.|
|[OmniCaptioner.](https://alpha-innovator.github.io/OmniCaptioner-project-page/) | OmniCaptioner is an all-in-one visual captioning framework that produces rich textual descriptions across various visual domains, such as natural images, textual visuals, and structured graphics. It boosts visual reasoning in LLMs, supports better image generation, and enables efficient supervised fine-tuning with reduced data requirements.|
|[BrowseComp agent benchmark.](https://openai.com/index/browsecomp/) | OpenAI has introduced a new agent-based benchmark that evaluates an agent's skill in finding difficult-to-locate information through browser interactions. Its DeepResearch model scores 51%, compared to roughly 80% for humans.|
|[Neural Motion Simulator for Embodied AI.](https://arxiv.org/abs/2504.07095) | MoSim introduces a world model for motion dynamics that improves skill acquisition and enables zero-shot learning, effectively turning model-free RL into model-based.|
|[VideoChat R1.](https://github.com/OpenGVLab/VideoChat-R1/tree/main) |An inference time compute captioning method for video question answering. It uses RL to improve the overall reasoning of the model which leads to a 30% boost in object tracking tasks. |
|[Mammal Pose Estimation.](https://github.com/Raojiyong/KITPose) | KITPose is a novel keypoints-interactive model designed for general mammal pose estimation.|
|[Our vision for accelerating creativity and productivity with agentic AI.](https://blog.adobe.com/en/publish/2025/04/09/our-vision-for-accelerating-creativity-productivity-with-agentic-ai) |Adobe is embedding agentic AI throughout its product lineup‚ÄîAcrobat, Photoshop, and Premiere Pro‚Äîto boost creativity and productivity by automating routine tasks and offering intelligent suggestions. This AI-driven approach empowers users by reducing technical overhead, streamlining workflows, and enabling greater focus on creative work. |
|[US engineers' AI converts simple text into walking robots in a day.](https://interestingengineering.com/innovation/robots-from-text-using-ai) | Duke University's Text2Robot allows non-experts to design functional 3D robots using simple text prompts through a generative AI framework, making robotic design more accessible by removing the need for advanced technical expertise.|
|[Sculptor: Catch and fix issues as you code.](https://imbue.com/product/sculptor/) | Sculptor is an early access coding agent environment that incorporates software engineering best practices by executing code in secure, sandboxed environments.|
|[WordPress AI Website Builder.](https://wordpress.com/blog/2025/04/09/ai-website-builder/) |A new AI-powered website builder generates full WordPress sites based on user input, making it a great tool for entrepreneurs, freelancers, and bloggers. |


## Perspectives
|Link|description|
|---|---|
|[Cyberattacks by AI agents are coming.](https://www.technologyreview.com/2025/04/04/1114228/cyberattacks-by-ai-agents-are-coming) | AI agents are becoming powerful assets in cybersecurity, capable of carrying out sophisticated attacks and scaling operations such as ransomware. The LLM Agent Honeypot project seeks to identify these agents by mimicking vulnerable servers, showing that agents are more adaptable and evasive than typical bots. Experts expect a rise in agent-led cyberattacks and emphasize the need to proactively build defenses as the technology advances.|
|[The artifact isn‚Äôt the art: Rethinking creativity in the age of AI.](https://www.freethink.com/opinion/studio-ghibli-chatgpt-creativity) | AI-generated Ghibli-style visuals have surged in popularity, straining OpenAI's servers and sparking debates about creativity in the AI age. While AI can rapidly produce artistic images, it lacks the human ability to experience and synthesize complex ideas and emotions. The future of creativity will focus on meaningful outputs shaped by human insight and purpose, with AI as a tool rather than a creator.|
|[How does the brain control consciousness? This deep-brain structure.](https://www.nature.com/articles/d41586-025-01021-2) | In a world of constant stimulation, the thalamus filters which thoughts we become aware of and which we don‚Äôt.|
|[AI for research: the ultimate guide to choosing the right tool.](https://www.nature.com/articles/d41586-025-01069-0) |Curious about using artificial intelligence to boost your research? Here are the programs you shouldn‚Äôt miss. |
|[AI race in 2025 is tighter than ever before.](https://www.nature.com/articles/d41586-025-01033-y) |State of the industry report also shows that 2024 was a breakthrough year for small, sleek models to rival the behemoths. |
|[Why more AI researchers should collaborate with governments.](https://www.nature.com/articles/d41586-025-01063-6) | Academics can drive policy innovation ‚Äî but they must shift their focus from publishing papers to creating practical products.|
|[Why an overreliance on AI-driven modelling is bad for science.](https://www.nature.com/articles/d41586-025-01067-2) | Without clear protocols to catch errors, artificial intelligence‚Äôs growing role in science could do more harm than good.|
|[Beyond the binary: Navigating AI‚Äôs uncertain future in Africa.](https://www.science.org/doi/10.1126/science.adw9439) |The artificial intelligence (AI) debate is increasingly polarized in Africa, mirroring a trend across the globe. On one side, utopian headlines, such as ‚Äú5 Ways To Harness AI And End Poverty Forever,‚Äù claim that AI will revolutionize development. On the other, warnings that ‚ÄúAI Is Bad News for the Global South‚Äù paint the technology as an inevitable amplifier of inequality and exploitation. |
|[The composer still making music four years after his death ‚Äì thanks to an artificial brain.](https://www.theguardian.com/artanddesign/2025/apr/09/alvin-lucier-dead-composer-making-music-ai-artificial-intelligence-brain) | In Australia, a team of artists and scientists have resurrected the US composer Alvin Lucier. It raises a storm of questions about AI and authorship ‚Äì and it‚Äôs also incredibly beautiful|
|[AlphaFold is running out of data ‚Äî so drug firms are building their own version.](https://www.nature.com/articles/d41586-025-00868-9) | Thousands of 3D protein structures locked up in big-pharma vaults will be used to create a new AI tool that won‚Äôt be open to academics.|


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme69.jpg)

[Back to index](#Index)

# ML news: Week 31 March - 6 April

## Research
|Link|description|
|---|---|
|[Tracing the thoughts of a large language model.](https://www.anthropic.com/research/tracing-thoughts-language-model) | Anthropic researchers introduce new interpretability tools for examining LLMs, using Claude 3.5 Haiku as a testbed. Their studies reveal insights into model internals, such as circuits, plans, and conceptual thinking. Key findings include Claude‚Äôs multilingual ‚Äúlanguage of thought,‚Äù where concepts like ‚Äúsmall‚Äù are processed similarly across languages, enabling transfer learning. Claude also plans ahead, even in poetry, and computes sums with parallel circuits, explaining answers using human-style logic. The tools help detect unfaithful reasoning, where Claude fabricates steps to fit answers. Researchers can also intervene in multi-step reasoning, showing that Claude‚Äôs reasoning is dynamic. The tools also reveal that Claude‚Äôs hallucinations are caused by misfires in circuits and that jailbreaks can bypass safety features temporarily.|
|[Harmful Fine-Tuning Attacks.](https://arxiv.org/abs/2501.18100v1) |Researchers have identified weaknesses in current defenses against harmful fine-tuning attacks and introduced Panacea, an adaptive perturbation method that maintains model safety without compromising fine-tuning performance. |
|[AgentRxiv.](https://arxiv.org/abs/2503.18102) | Researchers from Johns Hopkins and ETH Zurich introduce AgentRxiv, a framework that allows LLM agents to autonomously generate and share research papers, similar to how human scientists collaborate. The system functions like an open-source preprint server for agents, enabling labs to upload, search, and refine papers iteratively. Using this framework, a single agent improved GPT-4o mini‚Äôs accuracy by 11.4% on the MATH-500 benchmark through better prompt strategies. The framework also improved other benchmarks, showing consistent performance gains across multiple LLMs. Collaboration between agent labs led to faster progress, with higher accuracy achieved by sharing results via AgentRxiv. Agents refine their own ideas without plagiarism, but the system requires further improvements in reliability and novelty guarantees.|
|[Neural Alignment via Speech Embeddings.](https://www.nature.com/articles/s41562-025-02105-9) |Google Research and collaborators reveal significant similarities between LLM embeddings and human brain activity during conversation. Their findings show that embeddings from OpenAI's Whisper model align with brain signals in regions responsible for speech, language, and motor planning. The study suggests a "soft hierarchy" in brain areas, with overlapping processing of speech and language. Brain regions also predict upcoming words, mirroring autoregressive LLM behavior. Additionally, the geometry of word relationships in brain activity reflects that of LLM embeddings, indicating convergent structures in language representation. Despite architectural differences‚Äîbrains process speech serially, while Transformers process in parallel‚Äîthese studies highlight potential for using LLMs to reverse-engineer the brain‚Äôs language mechanisms and inspire more brain-like AI models. |
|[Unlearning Sensitive Content from LLMs.](https://arxiv.org/abs/2503.21088v1) |This paper introduces a model merging technique that enables selective forgetting of sensitive content in large language models while retaining their general knowledge. |
|[Chain-of-Tools: Utilizing Massive Unseen Tools in the CoT Reasoning of Frozen Language Models.](https://arxiv.org/abs/2503.16779) |The paper introduces Chain-of-Tools (CoTools), a method allowing LLMs to incorporate external tools, including unseen ones, while maintaining chain-of-thought (CoT) reasoning. CoTools keeps the LLM‚Äôs parameters frozen and fine-tunes additional modules (Tool Judge and Tool Retriever) to interact with a wide array of tools. It represents tools as semantic vectors, allowing even unfamiliar tools to be used without retraining the model. CoTools integrates tool calls within the reasoning process, selecting the best tool from many based on query context, improving accuracy on complex tasks. Experiments on various benchmarks show significant improvements in tool-selection accuracy and overall performance, with CoTools successfully handling large and unseen toolsets. |
|[Structured Memory Augmentation for Smarter LLM Agents.](https://arxiv.org/abs/2503.21760v1) | MemInsight is a framework that autonomously enhances and organizes memory for LLM agents, improving context retention and retrieval. It uses a backbone LLM to mine and structure memory attributes from past conversations, organizing them into entity and conversation-centric augmentations. MemInsight outperforms traditional retrieval methods, achieving up to 34% higher recall on the LoCoMo QA dataset compared to Dense Passage Retrieval (RAG). It also improves movie recommendations by matching genres and reducing memory size by 90%, while increasing persuasive outputs by 12%. MemInsight can summarize long conversations using memory alone, achieving coherence similar to raw-dialogue baselines. The system shows minimal hallucinations and stable performance, particularly when using carefully selected models for memory augmentation.|
|[Anthropic Economic Index: Insights from Claude 3.7 Sonnet.](https://www.anthropic.com/news/anthropic-economic-index-insights-from-claude-sonnet-3-7) |Anthropic has launched the Economic Index, leveraging Claude Sonnet 3.7 to evaluate AI's impact across various job sectors. The model analyzes productivity changes, automation risks, and labor market trends, offering data-driven insights to help policymakers and businesses adapt to AI-driven economic transformations. |
|[Investigating Affective Use and Emotional Well-being on ChatGPT.](https://cdn.openai.com/papers/15987609-5f71-433c-9972-e91131f399a1/openai-affective-use-study.pdf) |Researchers from OpenAI and MIT Media Lab examine the impact of emotionally engaging interactions with ChatGPT, particularly in Voice Mode, on user well-being. They combine a large-scale analysis of 4M+ conversations and 4,000+ surveys with a randomized controlled trial (RCT) involving 981 participants. The studies reveal that high usage, especially with voice interactions, is linked to emotional dependence, a preference for chatbot interactions, and discomfort with changes in voice/personality. Voice mode had mixed effects, improving well-being for some, but long-term usage led to increased loneliness and problematic use. A small group of users drove most emotionally charged conversations, forming pseudo-relationships with the model. Automated classifiers developed to analyze conversations mirrored user self-reports and highlighted the need for socioaffective alignment, urging developers to design models that support users without exploiting emotional needs. |
|[PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play.](https://arxiv.org/abs/2503.14432) |Researchers from MIT CSAIL and IBM introduce Play2Prompt, a framework that enables LLM agents to learn how to use external tools in a zero-shot manner, without needing labeled examples or high-quality documentation. Play2Prompt discovers tool usage patterns through trial-and-error API calls, generating query-answer pairs based on successful tool invocations. The system iteratively refines tool demonstrations and documentation via self-reflective beam search and rejection sampling. Play2Prompt shows strong zero-shot performance, improving accuracy by 5-7% on benchmark tasks and even boosting GPT-4o by up to 3.3%. It remains robust even with poor documentation and outperforming methods like EasyTool that rely on labeled examples, particularly in challenging tool settings. |
|[Global modules robustly emerge from local interactions and smooth gradients.](https://www.nature.com/nature/volumes/640/issues/8057) |The principle of peak selection is described, by which local interactions and smooth gradients drive self-organization of discrete global modules. |
|[Evolutionary optimization of model merging recipes.](https://www.nature.com/articles/s42256-024-00975-8) | Akiba et al. developed an evolutionary approach to automatically merge artificial intelligence models, creating powerful hybrid models without extensive training. The method produces models with enhanced mathematical and visual capabilities that outperform larger models.|
|[Enhanced Cell Segmentation.](https://arxiv.org/abs/2504.00784v1) |CellVTA improves vision transformer-based models for cell instance segmentation by injecting high-resolution spatial features through a CNN-based adapter, achieving state-of-the-art performance on multiple datasets. |
|[Synthetic Data Generation Using Large Language Models: Advances in Text and Code.](https://arxiv.org/abs/2503.14023) |LLMs are increasingly employed to generate synthetic training data for language and code tasks, enhancing performance in low-resource settings through methods like prompt-based generation and self-refinement. The paper outlines advantages such as reduced cost and broader coverage, while also addressing challenges like factual inaccuracies and bias. It proposes mitigations and highlights future research directions in prompt automation and data quality evaluation. |
|[Current and Future Use of LLMs for Knowledge Work.](https://arxiv.org/abs/2503.16774v1) |A two-part survey of 216 and 107 participants shows that knowledge workers currently use LLMs for tasks such as code generation and text enhancement, but anticipate more integrated use within workflows and data systems. The results provide insights for shaping future design and adoption of generative AI in professional environments. |
|[Backdoor Attacks in CLIP.](https://arxiv.org/abs/2502.01385v2) |CLIP models are extremely susceptible to backdoor poisoning attacks, with almost perfect success rates using very little poisoned data. A practical way to detect this is by applying local outlier detection to reveal accidental backdoors in current datasets. |
|[Large Small Net.](https://github.com/THU-MIG/lsnet) |A new class of efficient vision models draws inspiration from the human visual system's ability to process broad scenes while focusing on details, known as "See Large, Focus Small". LSNet delivers leading performance with strong efficiency across multiple vision tasks and features a novel convolution kernel design. |


## News
|Link|description|
|---|---|
|[Trump to consider final proposal on TikTok future as US ban deadline looms.](https://www.theguardian.com/technology/2025/apr/02/trump-to-consider-final-proposal-on-tiktok-future-as-us-ban-deadline-looms) | Owner ByteDance required to find non-Chinese buyer for video app‚Äôs American operations by Saturday|
|[UK needs to relax AI laws or risk transatlantic ties, thinktank warns.](https://www.theguardian.com/technology/2025/apr/02/uk-ai-copyright-laws-transatlantic-tony-blair-thinktank) | Tony Blair Institute says enforcing stricter licensing rules for copyright-protected material will threaten national security interests| 
|[OpenAI raises $40bn in deal with SoftBank that values it at $300bn.](https://www.theguardian.com/technology/2025/apr/01/openai-raises-up-to-us40bn-in-deal-with-softbank) |Japanese investor to put $10bn at first into OpenAI and $30bn more by end of 2025 if certain conditions are met |
|[xAI acquires X in $80B all-stock deal.](https://threadreaderapp.com/thread/1905731750275510312.html) | xAI has officially acquired X in an all-stock transaction that values the combined company at over $110 billion.|
|[Gemini 2.5: Our most intelligent AI model.](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/) |Gemini 2.5 Pro, an advanced AI model, is topping LMArena benchmarks by a wide margin. It boosts performance and accuracy through enhanced reasoning, analyzing information and making informed decisions. The model builds on the advancements of Gemini 2.0 Flash Thinking. |
|[Announcing ARC-AGI-2 and ARC Prize 2025.](https://arcprize.org/blog/announcing-arc-agi-2-and-arc-prize-2025) |The ARC Prize has introduced ARC-AGI-2, a demanding benchmark designed to push the development of general AI systems. Current models perform well below human levels. The ARC Prize 2025 competition, hosted on Kaggle with a $1 million prize pool, encourages open-source innovation by rewarding efficient and capable solutions to ARC-AGI-2 tasks. |
|[OpenAI reshuffles leadership as Sam Altman pivots to technical focus.](https://www.theverge.com/openai/634802/openai-leadership-change) |In a significant executive shuffle announced Monday, OpenAI is expanding COO Brad Lightcap‚Äôs responsibilities while CEO Sam Altman shifts his attention more toward the company‚Äôs technical direction. |
|[Tim Cook says China‚Äôs DeepSeek AI is ‚Äòexcellent‚Äô during visit to country.](https://9to5mac.com/2025/03/24/tim-cook-says-chinas-deepseek-ai-is-excellent-during-visit-to-country/) |Despite DeepSeek AI's security and privacy issues, Tim Cook praised it as "excellent" during his China visit. The AI, developed in China, rivals top global models at lower development costs but faces investigations in the US and Europe. Cook, who is attending the China Development Forum, often has to make diplomatic remarks about China due to Apple's business interests there. |
|[Google's AI-focused Education Tools AI.](https://blog.google/outreach-initiatives/education/ai-literacy-day-2025/) |Google's new AI-focused educational tools offer training for educators, resources for students, and broader access to Gemini for younger users. |
|[Microsoft announces security AI agents to help overwhelmed humans.](https://www.theverge.com/news/634598/microsoft-security-copilot-ai-agents) | Microsoft has introduced six AI-powered security agents for its Security Copilot to help teams handle phishing and data loss incidents more efficiently.|
|[Perplexity CEO Addresses Financial Rumors.](https://www.reddit.com/r/perplexity_ai/comments/1jm2ekd/message_from_aravind_cofounder_and_ceo_of/) |Perplexity CEO Aravind Srinivas has denied financial trouble rumors, stating the company has healthy funding and no IPO plans before 2028. |
|[Amazon Nova Act .](https://labs.amazon.science/blog/nova-act) | Amazon has launched Nova Act, an AI model that enables agents to operate within web browsers. A research preview SDK is available, allowing developers to build agents capable of executing complex, multi-step tasks by decomposing them into atomic commands and manipulating browser actions for greater reliability. Nova Act is designed to extend agent capabilities beyond basic API tasks, boosting business productivity and task automation.|
|[Runway releases an impressive new video-generating AI model.](https://techcrunch.com/2025/03/31/runway-releases-an-impressive-new-video-generating-ai-model/) | Runway has released its next-generation video model, which excels at prompt adherence and cinematic motion generation.|
|[OpenAI to release an Open Weight model.](https://openai.com/open-model-feedback/) | OpenAI is soliciting feedback for an open weight model that has reasoning.|
|[Earth AI‚Äôs algorithms found critical minerals in places everyone else ignored.](https://techcrunch.com/2025/03/25/earth-ais-algorithms-found-critical-minerals-in-places-everyone-else-ignored/) |Earth AI has identified promising mineral deposits in previously neglected areas of Australia through AI-driven analysis. Unlike traditional techniques, its technology rapidly scans vast regions to pinpoint potential sources of minerals such as copper and cobalt, marking a shift toward more efficient, AI-powered exploration in the mining industry. |
|[Quora‚Äôs Poe launches its most affordable subscription plan for $5/month.](https://techcrunch.com/2025/03/25/quoras-poe-now-offers-an-affordable-subscription-plan-for-5-month/) |Quora's chatbot app, Poe, launched new subscription plans at $5/month for 10,000 daily points and $250/month for 12.5 million points. |
|[Nvidia's AI assistant is here to optimize your gaming PC.](https://www.theverge.com/news/635155/nvidia-g-assist-ai-assistant-available-download) | Nvidia's Project G-Assist is a real AI assistant for RTX GPU owners that optimizes game settings, measures frame rates, and controls accessory lighting.|
|[Nvidia is reportedly in talks to acquire Lepton AI.](https://techcrunch.com/2025/03/26/nvidia-is-reportedly-in-talks-to-acquire-lepton-ai/) | The semiconductor giant is reportedly nearing a deal to acquire Lepton AI, a company that rents out servers that are powered by Nvidia‚Äôs AI chips|
|[OpenAI Announces $40B in New Funding.](https://openai.com/index/march-funding-updates/) |OpenAI has secured $40 billion in funding at a $300 billion valuation to advance AI research, scale infrastructure, and support its expanding user base. The company has also partnered with SoftBank to further accelerate AGI development. |
|[Gemini Robotics from Google DeepMind.](https://blog.google/products/gemini/how-we-built-gemini-robotics/) | Google DeepMind has unveiled its Gemini Robotics models, extending Gemini 2.0 with fine-tuning capabilities for executing physical actions.|
|[Nexthop AI Locks up $110M Led by Lightspeed.](https://news.crunchbase.com/ai/infrastructure-nexthop-venture-funding-lightspeed/) |Nexthop AI has raised $110 million in a funding round led by Lightspeed Venture Partners to advance networking solutions for hyperscalers, with a focus on cost and power efficiency. The round also included investments from Kleiner Perkins, WestBridge Capital, Battery Ventures, and Emergent Ventures. CEO Anshul Sadana highlighted the company's mission to innovate in collaboration with cloud providers. |
|[Alibaba Head Warns AI Industry Is Showing Signs of Bubble.](https://futurism.com/alibaba-ai-industry-signs-bubble) |Alibaba chairman Joe Tsai has cautioned about a possible AI bubble, citing massive data center investments without clear demand. With $52 billion already committed to AI development, concerns are growing over potential overinvestment. Recent events, such as turbulence around Chinese startup DeepSeek, have fueled investor anxiety about overpaying in the AI space. |
|[Amazon‚Äôs Alexa Fund is now backing AI startups.](https://techcrunch.com/2025/03/26/amazon-alexa-fund-invests-into-four-new-startups-as-it-plans-to-invest-more-into-ai-solutions/) |Amazon's Alexa Fund is expanding its investment focus to include AI startups, investing in companies like NinjaTech AI, Hedra, Ario, and HeyBoss. |
|[Life-giving oxygen is wafting out of lakes worldwide.](https://www.nature.com/articles/d41586-025-00876-9) |Machine-learning method shows declining oxygen levels in thousands of lakes as their waters warm. |
|[Mathematician who reshaped theory of symmetry wins Abel Prize.](https://www.nature.com/articles/d41586-025-00949-9) |Masaki Kashiwara is the first Japanese person to be awarded the most prestigious prize in mathematics. |
|[‚ÄòMeta has stolen books‚Äô: authors to protest in London against AI trained using ‚Äòshadow library‚Äô.](https://www.theguardian.com/books/2025/apr/03/meta-has-stolen-books-authors-to-protest-in-london-against-ai-trained-using-shadow-library) |Writers will gather at the Facebook owner‚Äôs King‚Äôs Cross office in opposition to its use of the LibGen database to train its AI models |
|[Anthropic's LLM for Education.](https://www.anthropic.com/news/introducing-claude-for-education) |Anthropic has launched Claude for Education, featuring tools like Learning Mode to encourage critical thinking. The initiative also includes broad university access through collaborations with major institutions and educational platforms. |
|[Claude Available for U.S. Government Use.](https://www.anthropic.com/news/claude-on-google-cloud-fedramp-high) | Claude has attained FedRAMP High and IL-2 compliance via Google Cloud's Vertex AI, enabling its use by federal agencies and defense organizations with stringent security requirements.|
|[Meta and UFC partner to enhance fan engagement with AI and VR.](https://www.fastcompany.com/91310521/meta-ufc-partnership-multiyear-deal-ai-vr-fans) |Meta Platforms and the Ultimate Fighting Championship (UFC) have formed a multiyear partnership to bring Meta's AI and VR technologies to UFC events. The collaboration aims to deliver immersive fan experiences through devices like Meta Quest and AI-powered glasses. Meta's branding will appear in the Octagon during fights, and Threads will be the official social media partner. Financial details of the deal were not disclosed. |
|[Satya Nadella: DeepSeek is the new bar for Microsoft‚Äôs AI success.](https://www.theverge.com/notepad-microsoft-newsletter/637496/microsoft-satya-nadella-deepseek-chatgpt-ai-investments-notepad) |Microsoft CEO Satya Nadella stressed the need to translate AI research into successful products after an $80 billion investment in AI. The company is prioritizing enhancements to offerings like Copilot and Muse while ensuring its AI efforts align with sustainability goals. Despite the growing demands of AI workloads, Microsoft remains committed to becoming carbon-negative by 2030. |
|[Alphabet‚Äôs AI drug discovery platform Isomorphic Labs raises $600M from Thrive.](https://techcrunch.com/2025/03/31/alphabets-ai-drug-discovery-platform-isomorphic-labs-raises-600m-from-thrive/) |Isomorphic Labs, a DeepMind spinout, has raised $600 million from Thrive Capital to advance its AI-driven drug design platform. The funding will help expand its research team and move discovered drugs into clinical trials. The company also has partnerships with Eli Lilly and Novartis to leverage its AI model in pharmaceutical development. |
|[NotebookLM Adds Web-Based Source Discovery.](https://blog.google/technology/google-labs/notebooklm-discover-source) |Google's NotebookLM now features a Discover tool that gathers curated web sources based on user-defined topics, making research and information collection more efficient. |
|[AI-Powered Conversational Videos.](https://ai.meta.com/blog/tavus-real-feeling-ai-videos-llama/) | Tavus leverages Llama 3.3 to enable realistic AI-generated video conversations, integrating visual question-answering and multi-image reasoning to create lifelike digital interactions.|
|[Blanket ban on teen smartphone use ‚Äòpotentially detrimental‚Äô, says academic.](https://www.theguardian.com/technology/2025/apr/03/blanket-ban-on-teen-smartphone-use-potentially-detrimental-says-academic) |Dr Amy Orben says there are no ‚Äòone-size-fits-all answers‚Äô given importance of access to online information |
|[Meta faces ¬£1.8bn lawsuit over claims it inflamed violence in Ethiopia.](https://www.theguardian.com/technology/2025/apr/03/meta-faces-18bn-lawsuit-over-claims-it-inflamed-violence-in-ethiopia) |Son of murdered academic calls on Facebook owner to ‚Äòradically change how it moderates dangerous content‚Äô |
|[OpenAI just made its first cybersecurity investment.](https://techcrunch.com/2025/04/03/openai-just-made-its-first-cybersecurity-investment/) |OpenAI has invested in Adaptive Security, a startup that uses AI to simulate and train employees to defend against social engineering attacks. The company raised $43 million in Series A funding and plans to strengthen its platform as AI-driven threats grow. Co-founded by veteran entrepreneur Brian Long, Adaptive Security has gained over 100 clients since its 2023 launch. |
|[OpenAI Nonprofit Guidance Commission.](https://openai.com/index/nonprofit-commission-guidance/) |OpenAI is establishing a new expert commission to guide its philanthropic arm in supporting communities through AI, aiming to better align AI innovation with the practical needs of nonprofits. |
|[Google is shipping Gemini models faster than its AI safety reports.](https://techcrunch.com/2025/04/03/google-is-shipping-gemini-models-faster-than-its-ai-safety-reports/) | Google has introduced Gemini 2.5 Pro, an AI reasoning model that excels in coding and math. However, safety reports haven't been released yet. Google intends to share them after gathering feedback from experimental deployments, a move that raises concerns about transparency. Although the company has committed to openness, its focus on rapid releases appears to conflict with standard responsible AI practices.|
|[Code with Claude Developer Conference.](https://www.anthropic.com/news/Introducing-code-with-claude) | Anthropic has revealed its inaugural developer event, featuring practical sessions and guidance on building with Claude, scheduled for May in San Francisco.|
|[Devin, the viral coding AI agent, gets a new pay-as-you-go plan.](https://finance.yahoo.com/news/devin-viral-coding-ai-agent-194633884.html) |Cognition, the startup behind the viral AI programming tool Devin, has introduced a new low-cost plan to incentivize signups. |
|[Trump extends deadline for TikTok sale to non-Chinese buyer to avoid ban.](https://www.theguardian.com/us-news/2025/apr/04/tik-tok-ban-trump-extension) |Deadline set by US president was supposed to be Saturday, with Trump now considering decreasing tariffs to get deal |
|[US authors‚Äô copyright lawsuits against OpenAI and Microsoft combined in New York with newspaper actions.](https://www.theguardian.com/books/2025/apr/04/us-authors-copyright-lawsuits-against-openai-and-microsoft-combined-in-new-york-with-newspaper-actions) |California cases over AI trainers‚Äô use of work by writers including Ta-Nehisi Coates and Michael Chabon transferred to consolidate with New York suits from John Grisham and Jonathan Franzen and more |


## Resources
|Link|description|
|---|---|
|[Qwen2.5-Omni.](https://github.com/QwenLM/Qwen2.5-Omni/blob/main/assets/Qwen2.5_Omni.pdf) | Qwen2.5-Omni is an end-to-end multimodal model capable of perceiving and understanding text, audio, images, and video, while generating both text and speech in real-time. It features the Thinker-Talker architecture, where Thinker handles perception and text generation, and Talker generates speech, trained together for synchronized output. The model‚Äôs streaming-first design uses block-wise encoders and TMRoPE for real-time interaction. Trained on over 1.2 trillion tokens, Qwen2.5-Omni is fine-tuned for natural speech and performs well across multiple modalities. It achieves state-of-the-art results on OmniBench, outperforms previous models in ASR and TTS, and significantly closes the gap in voice-text instruction following.|
|[Test-Time Visual In-Context Tuning.](https://arxiv.org/abs/2503.21777) | A new method enables test-time adaptation of VICL models using only the test sample, enhancing generalization across different visual tasks under domain shifts.|
|[High-Fidelity Simultaneous Speech-To-Speech Translation.](https://arxiv.org/abs/2502.03382) |Kyutai has unveiled its latest audio system, a real-time audio-to-audio translation tool powered by a robust multi-stream transformer. It features expressive voice capabilities, delivering impressive performance in speech translation. |
|[Mobile-VideoGPT.](https://github.com/amshaker/mobile-videogpt) |A compact multimodal video model with under 1B parameters, incorporating dual visual encoders and token pruning to enable real-time inference on edge devices. |
|[Multimodal Adaptation Methods.](https://github.com/donghao51/awesome-multimodal-adaptation) | A curated list of methods for multimodal adaptation, including traditional domain adaptation, test-time adaptation, and recent innovative approaches.|
|[ReAG - Reasoning Augmented Generation.](https://github.com/superagent-ai/reag) |Traditional Retrieval-Augmented Generation (RAG) systems use a two-step approach: semantic search retrieves documents based on surface-level similarity, followed by a language model generating responses from those documents. While effective, this often overlooks deeper context and introduces irrelevant information. ReAG‚ÄîReasoning Augmented Generation‚Äîproposes a stronger alternative by feeding raw documents directly into the language model, enabling it to process and integrate the full context. This unified method results in more accurate, nuanced, and context-aware outputs. |
|[Awesome Vision-to-Music Generation.](https://github.com/wzk1015/awesome-vision-to-music-generation) |A curated and regularly updated list of methods, datasets, and demos focused on converting visual inputs into music (V2M), showcasing both academic and industrial advancements in the field. |
|[Video Generation Faithfulness Benchmark.](https://arxiv.org/abs/2503.21755) | A benchmark designed to evaluate how accurately video generation aligns with the given prompt. It also introduces methods to improve the quality of generated videos in relation to the user's input prompt.|
|[Optimal Stepsize in Diffusion Models.](https://github.com/bebebe666/optimalsteps) |Optimal Stepsize for Diffusion Sampling (OSS) improves diffusion model sampling by learning efficient stepsize schedules using dynamic programming, achieving a 10√ó speedup with minimal loss in generation quality. |
|[SAMWISE video segmentation.](https://github.com/ClaudiaCuttano/SAMWISE) | This work gives SAM 2 open vocabulary segmentation and more precise semantic tracking over long videos.|
|[Orpheus.](https://github.com/freddyaboulton/orpheus-cpp) | Orpheus is a text-to-speech system. It is easy to install and runs without a GPU, similar to Llama cpp.|
|[Video-R1.](https://github.com/tulerfeng/video-r1) |Video-R1 presents a rule-based reinforcement learning method for video reasoning, utilizing a temporal variant of GRPO and introducing new datasets. It is efficiently trainable on 4 H20 or 5 A100 GPUs. |
|[Fast Text-to-3D.](https://theericma.github.io/TriplaneTurbo/) |Progressive Rendering Distillation enables training 3D generators from text prompts without ground-truth meshes, producing high-quality 3D meshes in just 1.2 seconds and outperforming previous approaches. |
|[TIDE for Underwater Scene Understanding.](https://hongklin.github.io/TIDE/) |A text-to-image and dense annotation generation method for underwater scenes that produces high-quality synthetic datasets with consistent pixel-level labels. |
|[OpenAI launches OpenAI Academy, a free AI learning platform for everyone.](https://techstartups.com/2025/04/01/openai-launches-openai-academy-a-free-ai-learning-platform-for-everyone/) |OpenAI has introduced OpenAI Academy, a free platform offering AI courses that range from beginner content to advanced subjects like AI safety and governance. Designed for diverse audiences, the platform seeks to expand access to AI education and promote thoughtful engagement with its societal implications. Early feedback praises its accessibility and thorough approach to making AI more understandable worldwide. |
|[Video Motion Segmentation.](https://motion-seg.github.io/) |Building on recent trends in tracking systems, this work incorporates dense pixel tracking to enhance long-term segmentation using Dino and SAM2. |
|[Open Hands Coding Model.](https://www.all-hands.dev/blog/introducing-openhands-lm-32b----a-strong-open-coding-agent-model) |A powerful 32B model fine-tuned with reinforcement learning on top of Qwen, outperforming many much larger models on agentic coding tasks. |
|[Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model.](https://arxiv.org/abs/2503.24290) | There‚Äôs a major open question in RL reasoning around whether a sufficiently strong base model is essential for emergent reasoning. This work explored various cases of scaling RL on a base model and found that strong base models significantly aid reasoning convergence.|
|[Easi3R: Estimating Disentangled Motion from DUSt3R Without Training.](https://github.com/Inception3D/Easi3R) | Easi3R is a 3D vision system designed to more accurately estimate 3D scenes with high motion. It significantly outperforms previous methods in full scene reconstruction by masking moving objects and learning them separately from the background.|
|[Benchmark for RL-based Video Understanding.](https://github.com/tencentarc/seed-bench-r1) | SEED-Bench-R1 is a benchmark designed to assess post-training methods such as RL and SFT for multimodal LLMs on complex video-based tasks. It highlights RL's advantages in perception and data efficiency while also revealing its difficulties in maintaining logical coherence.|
|[Flow Prediction for Autonomous Driving.](https://github.com/tasl-lab/uniocc) | UniOcc is a unified framework for forecasting and flow prediction in driving scenarios, designed for multi-dataset training and cross-domain evaluation across both real and synthetic environments.|
|[Paper Bench.](https://openai.com/index/paperbench/) |OpenAI has introduced a new benchmark for academic paper creation that involves fully replicating selected papers. This includes comprehending their experiments and results, as well as generating original ideas, to evaluate deeper understanding and creativity in AI models. |
|[GeometryCrafter: Consistent Geometry Estimation for Open-world Videos with Diffusion Priors.](https://geometrycrafter.github.io/) |A powerful model that leverages video diffusion as a prior for consistent geometry estimation over time. It operates at approximately 1.5 FPS for full point cloud estimation and also performs accurate camera pose estimation. |
|[DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness.](https://ruiningli.com/dso) |Most 3D synthesized data is created with a focus on aesthetic quality, which often results in models that can't stand or support themselves in physics-based environments. This work introduces slight fine-tuning to improve the physical plausibility of these models. |
|[Medical Reasoning Dataset.](https://github.com/UCSC-VLAA/MedReason) | A large-scale medical reasoning dataset designed to enable faithful and explainable problem-solving in LLMs, aiming to advance research in medical AI.|
|[DeepMind's Study for Kernel Fuzzing.](https://sishuaigong.github.io/pdf/asplos25-snowplow.pdf) | Snowplow is a kernel fuzzer that uses a learned white-box mutator to enhance test mutation efficiency, leading to significantly improved code coverage and increased bug discovery in Linux kernel fuzzing. |
|[The hottest AI models, what they do, and how to use them.](https://techcrunch.com/2025/03/30/the-hottest-ai-models-what-they-do-and-how-to-use-them/) | This article reviews the leading AI models released since 2024, showcasing their applications and strengths. Key highlights include OpenAI's GPT-4.5 Orion for its robust world knowledge, Google's Gemini 2.5 Pro for its coding capabilities, and Cohere's Aya Vision, which stands out in image-related tasks. The overview helps simplify understanding the fast-changing AI landscape.|
|[DeepSite open source canvas.](https://huggingface.co/spaces/enzostvs/deepsite) |DeepSite is a DeepSeek powered open source canvas for ‚Äúvibe coding‚Äù that updates apps in real time while the system writes the code. |
|[Articulated Kinematics Distillation from Video Diffusion Models.](https://research.nvidia.com/labs/dir/akd/) | This work presents Articulated Kinematics Distillation (AKD), a framework that combines skeleton-based animation with generative diffusion models to generate high-fidelity, physically plausible character motions with lower complexity. It ensures structural consistency and surpasses existing methods in 3D coherence and expressive motion quality by employing Score Distillation Sampling for precise joint-level control.|
|[Enhanced LoRA-based Fine Tuning.](https://arxiv.org/abs/2504.00460) | MetaLoRA introduces dynamic parameter generation based on meta-learning principles, improving the flexibility and task-awareness of LoRA-based fine-tuning approaches.|
|[Pplx Cuda Kernels.](https://github.com/ppl-ai/pplx-kernels) |Perplexity has open-sourced some of its MoE kernels that surpass DeepSeek in large-scale performance and offer more flexibility with fewer constraints on the MoE architecture. |
|[HateBench for Evaluating Hate Speech.](https://huggingface.co/datasets/TrustAIRLab/HateBenchSet) |HateBench offers a framework to assess hate speech detection models on content generated by LLMs, including a hand-labeled dataset and tools for analyzing subtle and adversarial hate campaigns. |
|[Zonos TTS.](https://www.zyphra.com/post/beta-release-of-zonos-v0-1) |An impressive Apache 2.0 model for speech synthesis and voice cloning, featuring multilingual support and expressive real-time generation. |
|[Hugging Face's AI Agents Course.](https://huggingface.co/learn/agents-course/en/unit0/introduction) |Hugging Face released an AI agents course today. This free course will take you on a journey, from beginner to expert, in understanding, using, and building AI agents. |
|[The LLM Course from Hugging Face.](https://huggingface.co/blog/llm-course) |Hugging Face has updated its well-known NLP course into a more comprehensive LLM curriculum, adding new chapters on fine-tuning, reasoning models, and current AI agent workflows. |


## Perspectives
|Link|description|
|---|---|
|[Tools and Weapons: Microsoft's Story, Told by Its CEOs.](https://app.magellan.ai/listen_links/tldr) |Hosted by Microsoft Vice Chair and President Brad Smith, the *Tools and Weapons* podcast examines the global impact of technology. In recent episodes, Bill Gates, Steve Ballmer, and Satya Nadella reflect on Microsoft's 50-year journey, discussing its past, present, and future.|
|[AI-powered therapy shows shocking results in mental health study.](https://interestingengineering.com/health/groundbreaking-ai-therapy-shows-positive-results) | A Dartmouth study found that the AI therapy chatbot Therabot significantly alleviated symptoms in participants dealing with depression, anxiety, and eating disorders.|
|[Databricks Has a Trick That Lets AI Models Improve Themselves.](https://www.wired.com/story/databricks-has-a-trick-that-lets-ai-models-improve-themselves/) |Databricks has introduced Test-time Adaptive Optimization (TAO), a technique that uses reinforcement learning and synthetic data to enhance AI models without relying on clean labeled data. |
|[‚ÄòOpen source‚Äô AI isn‚Äôt truly open ‚Äî here‚Äôs how researchers can reclaim the term.](https://www.nature.com/articles/d41586-025-00930-6) | Many firms are misusing the ‚Äòopen source‚Äô label. The scientific community, which relies on transparency and replicability, must resist this trend.|
|[Transparency (in training data) is what we want.](https://www.nature.com/articles/s42256-025-01023-9) |As more powerful generative AI tools appear on the market, legal debates about the use of copyrighted content to develop such tools are intensifying. To resolve these issues, transparency regarding which copyrighted data have been used and where in the AI training pipeline needs to be a starting point. |
|[How does the brain control consciousness? This deep-brain structure.](https://www.nature.com/articles/d41586-025-01021-2) | In a world of constant stimulation, the thalamus filters which thoughts we become aware of and which we don‚Äôt.|
|[DeepMind's Approach to AGI Safety.](https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/) | Google DeepMind has shared its approach to developing safe and secure artificial general intelligence, stressing the importance of strong oversight and technical safeguards as AGI capabilities advance.|

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme67.jpg)

[Back to index](#Index)

# ML news: Week 24 - 30 March

## Research
|Link|description|
|---|---|
|[OpenAI and MIT Exploring AI and Emotional Well-Being.](https://openai.com/index/affective-use-study/) | MIT Media Lab and OpenAI are studying how users emotionally engage with ChatGPT, focusing on its effects on social and emotional well-being. The research highlights the varied ways people interact with AI conversational models and lays the groundwork for future studies on responsible AI use.|
|[Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in LLMs.](https://arxiv.org/abs/2503.13551) |This paper introduces a Hierarchical Reward Model (HRM) to tackle reward hacking and error propagation in fine-grained LLM reasoning. HRM evaluates multiple steps, improving self-correction and providing more reliable assessments than traditional Process Reward Models (PRM), which can penalize corrections. HRM‚Äôs multi-step feedback framework also mitigates reward hacking by discouraging short-sighted strategies. The paper also presents Hierarchical Node Compression (HNC), which reduces the computational cost of generating annotations with Monte Carlo Tree Search (MCTS) while increasing dataset diversity. Experiments show that HRM outperforms standard models on complex tasks, providing better accuracy and more stable solutions. |
|[Latent Multi-Hop Reasoning.](https://github.com/google-deepmind/latent-multi-hop-reasoning) |This research examines whether Large Language Models (LLMs) perform multi-hop reasoning by connecting multiple knowledge pieces in response to complex prompts. The study found evidence of this reasoning, especially in the initial step, with the use of connected knowledge varying and scaling with model size, highlighting both challenges and opportunities for future LLM development. |
|[DAPO: An Open-Source LLM Reinforcement Learning System at Scale.](https://arxiv.org/abs/2503.14476) |DAPO is an open-source, large-scale RL system that enhances LLMs' chain-of-thought reasoning. It improves PPO-style training by raising the upper clipping threshold to prevent entropy collapse, encouraging more diverse token exploration. DAPO filters out always-correct or always-wrong samples, speeding up convergence by focusing on prompts with useful gradient signals. It applies policy gradients per token instead of averaging losses, ensuring high-quality, appropriately lengthy outputs. The system also prevents excessive verbosity by penalizing long answers. DAPO achieves state-of-the-art math performance on the AIME 2024 test set, outperforming DeepSeek‚Äôs R1 with less training time. |
|[Compute Optimal Scaling of Skills.](https://arxiv.org/abs/2503.10061) |Researchers from the University of Wisconsin and Meta AI explore how different skills, like knowledge-based QA and code generation, show distinct scaling behaviors in LLMs. They found that the optimal trade-off between model size and data volume varies by skill, with knowledge tasks being "capacity-hungry" and code tasks being "data-hungry." Even after adjusting data mixes, knowledge-based QA still requires larger models, while code tasks benefit from more data. Choosing the right validation set is crucial, as incorrect sets can mislead model scaling by up to 50%. Developers must design validation sets that align with the final skill mix to optimize performance. |
|[Hierarchical Document Structure Analysis.](https://arxiv.org/abs/2503.15893v2) |UniHDSA is a unified relation prediction approach for hierarchical document structure analysis, enabling a single module to handle multiple tasks simultaneously. |
|[Modifying Large Language Model Post-Training for Diverse Creative Writing.](https://arxiv.org/abs/2503.17126) |Midjourney has introduced work aimed at boosting diversity in creative writing models, successfully post-training a small 7B model that surpasses much larger open and closed models in creative writing tasks. |
|[Agentic Memory for LLM Agents.](https://arxiv.org/abs/2502.12110) |Researchers from Rutgers University and Ant Group introduce A-MEM, a new agentic memory system for LLM agents that supports long-term memory for complex tasks. A-MEM autonomously creates memory notes with keywords, tags, and embeddings, linking them based on semantic similarities, inspired by the Zettelkasten method. The system evolves by updating older memories with refined tags and descriptions, creating a continuously improving memory network. In tests, A-MEM outperforms static-memory systems like MemGPT, especially in multi-hop reasoning for complex queries, and reduces token usage by retrieving only the most relevant memories, cutting inference costs without losing accuracy. |
|[A Modular RAG Framework.](https://arxiv.org/abs/2503.19314) |RGL simplifies the RAG pipeline for graph-structured data using modular components and optimized performance, delivering up to 143√ó speedup compared to traditional approaches. |
|[Deep Learning is Not So Mysterious or Different.](https://arxiv.org/abs/2503.02113) |Andrew Gordon Wilson (New York University) argues that phenomena like benign overfitting, double descent, and overparametrization are not unique to neural networks and can also occur in simple linear models. He explains that these behaviors, such as benign overfitting with high-order polynomials, are related to soft inductive biases, which allow models to remain flexible while preferring simpler solutions. Wilson suggests that traditional generalization frameworks like PAC-Bayes already account for these behaviors, challenging the need for new theories of deep learning. While acknowledging neural networks' unique properties, such as mode connectivity and representation learning, he urges deeper collaboration and a focus on existing generalization theories to address open questions in deep learning. |
|[ GNNs as Predictors of Agentic Workflow Performances.](https://arxiv.org/abs/2503.11301) |This work presents FLORA-Bench, a large-scale benchmark designed to assess GNN-based predictors for automating and optimizing agentic workflows. It demonstrates that Graph Neural Networks can effectively predict the success of multi-agent LLM workflows, substantially cutting down on expensive repeated model calls. |
|[Anthropic Researchers Trace the Thoughts of LLM.](https://www.anthropic.com/research/tracing-thoughts-language-model) |Two new studies from Anthropic explore the internal pathways of Claude models, revealing planning behaviors, shared conceptual representations across languages, and occurrences of fabricated reasoning. |
|[Measuring Internal Bias in Vision Models.](https://github.com/aaronserianni/attention-iou) |A new metric leverages attention maps to measure internal bias in vision models, enabling the detection of confounding features and surpassing traditional group-based accuracy disparity analyses. |


## News
|Link|description|
|---|---|
|[OpenAI raises up to $40bn in record-breaking deal with SoftBank.](https://www.theguardian.com/technology/2025/apr/01/openai-raises-up-to-us40bn-in-deal-with-softbank) | Japanese investment group says it wants to realise ‚Äòartificial super intelligence‚Äô ‚Äì smarter than people ‚Äì in biggest capital raising ever for a start-up|
|[Bridget Phillipson eyes AI‚Äôs potential to free up teachers‚Äô time.](https://www.theguardian.com/technology/2025/mar/31/bridget-phillipson-eyes-ais-potential-to-free-up-teachers-time) | education secretary exploring tools to compile student reports and assess writing and vocational skills| 
|[Authors call for UK government to hold Meta accountable for copyright infringement.](https://www.theguardian.com/books/2025/mar/31/authors-call-for-uk-government-to-hold-meta-accountable-for-copyright-infringement) |‚ÄòI am a crime writer, I understand theft,‚Äô said Val McDermid ‚Äì joining Richard Osman, Kazuo Ishiguro and Kate Mosse in their appeal to Lisa Nandy to act on their behalf |
|[How and why parents and teachers are introducing young children to AI.](https://www.theguardian.com/technology/2025/mar/30/parents-teachers-children-ai) | Guardian readers share the ways and reasons they are preparing their children and students for a future that may necessitate familiarity with generative artificial intelligence|
|[Calling all fashion models ‚Ä¶ now AI is coming for you.](https://www.theguardian.com/fashion/2025/mar/30/fashion-models-ai-job-losses) |As fashion brands create AI ‚Äòtwins‚Äô with models‚Äô permission, some believe this is just another form of exploitation |
|[Protests hit Tesla dealerships across the world in challenge to Elon Musk.](https://www.theguardian.com/world/2025/mar/29/tesla-protests-elon-musk-doge) | From Australia to Europe and the US, demonstrators rallied against carmaker‚Äôs dismantling of US federal government|
|[Elon Musk‚Äôs xAI firm buys social media platform X for $33bn.](https://www.theguardian.com/technology/2025/mar/29/elon-musks-xai-firm-buys-social-media-platform-x-for-33bn) | Specifics of deal remain unclear, including how X‚Äôs leaders will be integrated into new company|
|[The controversial California city backed by tech elite has a new plan: boats.](https://www.theguardian.com/us-news/2025/mar/28/california-forever-tech-boats) |California Forever is back with a proposal that has some on board: using the land it owns to create a shipbuilding hub |
|[Tesla‚Äôs Europe sales drop nearly 45% amid row over Musk‚Äôs Trump links.](https://www.theguardian.com/technology/2025/mar/24/tesla-sales-eu-slump-elon-musks-donald-trump-byd) |US carmaker‚Äôs European market share falls as Chinese rival BYD overtakes it on global revenue, topping $100bn |
|[Government AI roll-outs threatened by outdated IT systems.](https://www.theguardian.com/technology/2025/mar/26/government-ai-roll-outs-threatened-by-outdated-it-systems) | Public accounts committee also flags ‚Äòpersistent digital skills shortages‚Äô and uncompetitive civil service pay rates|
|[Perplexity's Plan for Rebuilding TikTok in America.](https://www.perplexity.ai/hub/blog/rebuilding-tiktok-in-america) | Perplexity AI aims to create a TikTok focused on deep content discovery and truth-seeking, driven by an advanced answer engine, while preserving the platform's role as a hub for creative expression.|
|[OpenAI exec leaves to found materials science startup.](https://techcrunch.com/2025/03/17/openai-exec-leaves-to-found-materials-science-startup/) | OpenAI's VP Liam Fedus is leaving to launch a materials science AI company with support from OpenAI. His new firm will compete with Google DeepMind and Microsoft in the AI-driven materials science field, though some experts question whether current AI can make groundbreaking scientific discoveries.|
|[People are using Google‚Äôs new AI model to remove watermarks from images.](https://techcrunch.com/2025/03/17/people-are-using-googles-new-ai-model-to-remove-watermarks-from-images/) | Users on social media have discovered a controversial use case for Google‚Äôs new Gemini AI model: removing watermarks from images, including from images published by Getty Images and other well-known stock media outfits.|
|[Apple's AI strategy plagued by delays, Siri upgrade remains in limbo.](https://www.techspot.com/news/107160-apple-exec-candidly-discusses-siri-struggles-including-ai.html) |Apple is facing delays with its AI features for Siri, originally planned for iOS 18.5 but now potentially delayed until 2026. Despite showcasing these features at WWDC, internal assessments show the technology isn't ready for release. Apple remains hopeful, aiming to enhance Siri significantly by 2027 with a new infrastructure to stay competitive. |
|[Google is improving Gmail‚Äôs search with AI.](https://www.theverge.com/news/633459/google-gmail-search-ai-most-relevant-results) |Gmail‚Äôs search will now take your most-clicked emails and frequent contacts into account to provide better results. |
|[New Reve Image Generator Beats AI Art Heavyweights MidJourney and Flux at a Penny Per Image.](https://decrypt.co/311375/new-reve-image-generator-beats-ai-art-heavyweights-midjourney-and-flux-at-a-penny-per-image) | Reve Image 1.0 is an AI image generator that delivers strong prompt adherence, realism, and versatility at a competitive price, potentially rivaling tools like Midjourney and Ideogram. Priced at $5 for 500 credits, it enables affordable high-quality image generation. However, it lacks an edit feature and mobile app, which may limit appeal for advanced users. Despite limited transparency about its team and underlying technology, Reve stands out as a cost-effective option for users seeking quality results without deep technical expertise.|
|[OpenAI‚Äôs o1-pro is the company‚Äôs most expensive AI model yet.](https://techcrunch.com/2025/03/19/openais-o1-pro-is-its-most-expensive-model-yet/) | OpenAI's o1-pro, a more compute-intensive version of its o1 reasoning AI, is now available through its developer API for select users at a premium price‚Äî$150 per million input tokens and $600 per million output tokens. While it offers improved performance, early reviews are mixed, as it still struggles with some tasks. Internal benchmarks reveal only modest gains over the standard o1 model in coding and math.|
|[OpenAI to start testing ChatGPT connectors for Google Drive and Slack.](https://techcrunch.com/2025/03/17/openai-to-start-testing-chatgpt-connectors-for-google-drive-and-slack/) |OpenAI will soon begin testing a way for business customers to connect apps like Slack and Google Drive to ChatGPT. OpenAI plans to start beta testing a new feature called ChatGPT Connectors,  will allow ChatGPT Team subscribers to link workspace Google Drive and Slack accounts to ChatGPT so the chatbot can answer questions informed by files, presentations, spreadsheets, and Slack conversations across those accounts.|
|[YC-backed ReactWise is applying AI to speed up drug manufacturing.](https://techcrunch.com/2025/03/17/yc-backed-reactwise-is-applying-ai-to-speed-up-drug-manufacturing/) |ReactWise is using AI to speed up chemical manufacturing ‚Äî a key step in bringing new drugs to market. Once a promising drug has been identified in the lab, pharma firms need to be able to produce much larger amounts of the material to run clinical trials. This is where ReactWise is offering to step in with its ‚ÄúAI copilot for chemical process optimization,‚Äù which it says accelerates by 30x the standard trial-and-error-based process of figuring out the best method for making a drug. |
|[OpenAI's Improved Image Generation.](https://openai.com/index/introducing-4o-image-generation/) | OpenAI's GPT-4o introduces improved image generation with precise text rendering, instruction following, and multi-turn editing.|
|[DeepSeek-V3-0324 Release with MIT License.](https://api-docs.deepseek.com/news/news250325) |DeepSeek has released its new V3-0324 model, which outperforms GPT 4.5 in most benchmarks and features major improvements in performance. |
|[Outreach founder Manny Medina has a new startup that helps AI agents get paid.](https://techcrunch.com/2025/03/25/outreach-founder-manny-medina-has-a-new-startup-that-helps-ai-agents-get-paid/) |Outreach founder Manny Medina has launched Paid, a platform built to help AI agent startups manage pricing and profitability. Supported by leading investors, Paid aims to reshape how AI agents are billed and valued in the growing agent economy. |
|[A key DeepMind robotics researcher left Google, and Nvidia has already backed his stealth startup.](https://techcrunch.com/2025/03/19/a-key-deepmind-robotics-researcher-left-google-and-nvidia-has-already-backed-his-stealth-startup/) |Pete Florence, formerly a senior research scientist at DeepMind, has founded Generalist AI, a robotics startup backed by Nvidia‚Äôs VC arm, NVentures. The company aims to develop general-purpose robots, with Florence emphasizing a vision of driving the marginal cost of physical labor to zero. He joins a wave of ex-DeepMind scientists launching new tech ventures as Nvidia's role in AI continues to expand. |
|[Claude can now search the web.](https://www.anthropic.com/news/web-search) |Claude now features web search functionality for real-time insights and up-to-date responses, complete with source citations. |
|[OpenAI introduces next-generation audio models in the API.](https://openai.com/index/introducing-our-next-generation-audio-models/) |OpenAI has introduced new audio models, including Voice Engine, capable of generating realistic voices from short samples. |
|[Perplexity is reportedly in talks to raise up to $1B at an $18B valuation.](https://techcrunch.com/2025/03/20/perplexity-is-reportedly-in-talks-to-raise-up-to-1b-at-an-18b-valuation/) | AI search startup Perplexity is in talks to raise $1 billion at a valuation of $18 billion.|
|[Amazon Launches Interests for Personalized Shopping.](https://www.aboutamazon.com/news/retail/artificial-intelligence-amazon-features-interest) |Amazon has launched an AI-powered feature that personalizes product discovery using user-defined prompts, automatically highlighting relevant items and deals. |
|[OpenAI adopts rival Anthropic's standard for connecting AI models to data.](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/) | OpenAI will integrate support for Anthropic's Model Context Protocol (MCP) across its products, boosting AI models' ability to interact with diverse data sources. MCP is an open-source standard that connects AI models to tools like business software. Companies such as Block, Replit, and Sourcegraph have already adopted it, and OpenAI will share more details about its implementation soon.|
|[Elon Musk‚Äôs Grok AI lands on Telegram, gaining access to over 1 billion users.](https://techstartups.com/2025/03/26/elon-musks-grok-ai-joins-telegram-gaining-access-to-over-1-billion-users-a-new-era-for-search-and-chat/) |Elon Musk's AI chatbot, Grok, is now accessible on Telegram, bringing its sarcastic assistant to over 1 billion users. Included with Telegram Premium, Grok extends its reach beyond X, offering real-time reasoning and coding features. While it raises privacy concerns, the move places Telegram in the competitive AI space alongside ChatGPT and Google's Gemini. |
|[Apple faces lawsuit over Apple Intelligence delays.](https://techcrunch.com/2025/03/20/apple-faces-lawsuit-over-apple-intelligence-delays/) | Apple is facing a class-action lawsuit for allegedly misleading advertising regarding its Apple Intelligence features.|
|[Hollywood vs AI: 400 celebs urge Trump to rein in OpenAI, Google.](https://interestingengineering.com/culture/hollywood-stars-trump-protect-copyright-from-ai) |Hollywood creatives have signed an open letter calling on the U.S. government to maintain strong copyright protections and not to relax them for AI companies such as OpenAI and Google. |
|[AI-driven weather prediction breakthrough reported.](https://www.theguardian.com/technology/2025/mar/20/ai-aardvark-weather-prediction-forecasting-artificial-intelligence) | Researchers say Aardvark Weather uses thousands of times less computing power and is much faster than current systems|
|[OpenAI Expands Cybersecurity Grant Program.](https://openai.com/index/security-on-the-path-to-agi/) |OpenAI has detailed its continued support for AI-native cybersecurity research, now offering microgrants and expanding focus areas to include model privacy and agentic security. |
|[Claude 3.7 Sonnet Usage Trends in Labor.](https://www.anthropic.com/news/anthropic-economic-index-insights-from-claude-sonnet-3-7) |Anthropic's latest report highlights how Claude 3.7 Sonnet is being applied in coding, education, and healthcare, providing new insights into how AI supports or automates various professional tasks. |
|[AWS generative AI exec leaves to launch startup.](https://techcrunch.com/2025/03/19/aws-generative-ai-exec-leaves-to-launch-startup) |Raj Aggarwal is leaving AWS, where he served as GM of generative AI, to start a new company. |
|[Browser Use, the tool making it easier for AI ‚Äòagents‚Äô to navigate websites, raises $17M.](https://techcrunch.com/2025/03/23/browser-use-the-tool-making-it-easier-for-ai-agents-to-navigate-websites-raises-17m/) |Browser Use, a Y Combinator startup, enhances AI agent navigation on websites by converting site elements into a text-like format. |
|[XR Training with Llama-Powered Simulations.](https://ai.meta.com/blog/cornerstone-transforming-training-llama/) | Cornerstone is revolutionizing enterprise training by combining XR with the Llama 3.1 model, allowing rapid creation of personalized simulations that include intelligent virtual mentors and real-time multilingual support.|


## Resources
|Link|description|
|---|---|
|[How to use AI to get a job interview and nail it ‚Äì along with the salary you deserve.](https://www.theguardian.com/money/2025/apr/01/how-to-use-ai-job-interview-salary-research-employer) |Supercharge your search and beat the screening, sharpen your speaking skills and boost your negotiating position |
|[Multimodal generative AI for medical image interpretation.](https://www.nature.com/articles/s41586-025-08675-y) | This Perspective describes how recent advances in artificial intelligence could be used to automate medical image interpretation to complement human expertise and empower physicians and patients.|
|[A Review of DeepSeek Models.](https://arxiv.org/abs/2503.11486) | This paper reviews DeepSeek‚Äôs open-source models, DeepSeek-V3 and DeepSeek-R1, which deliver high performance with lower resource requirements. Key innovations include Multi-Head Latent Attention (MLA) to reduce memory use, Advanced Mixture of Experts (MoE) for improved flexibility, and Multi-Token Prediction (MTP) to speed up training. It also highlights DualPipe scheduling and FP8 mixed-precision training to optimize resources, Group Relative Policy Optimization (GRPO) for efficient reinforcement learning, and post-training reinforcement learning in DeepSeek-R1 to improve reasoning and language consistency.|
|[Hugging Face Real-Time Endpoint Analytics.](https://huggingface.co/blog/endpoint-analytics) |Hugging Face has upgraded its analytics dashboard to provide real-time updates for monitoring AI inference endpoints, offering quicker data loading and immediate insights into request latency, error rates, and performance metrics. |
|[SynCity: Training-Free Generation of 3D Worlds.](https://research.paulengstler.com/syncity) |SynCity is an innovative system that creates detailed 3D worlds from text prompts without the need for training. It combines a 2D image generator for artistic quality with a 3D generator for precise geometry, constructing scenes tile-by-tile and smoothly integrating them into a navigable environment. |
|[Nemotron-H: A Family of Accurate, Efficient Hybrid Mamba-Transformer Models.](https://research.nvidia.com/labs/adlr/nemotronh/) |Nvidia has launched new hybrid Mamba-style models trained on 20T tokens, delivering strong performance, particularly on long context tasks with significant sequence scaling advantages. This marks the first successful fp8 large-scale training of a hybrid attention model. |
|[Large-Scale Outdoor Scene Generation.](https://3dlg-hcvc.github.io/NuiScene/) |NuiScene unveils a new method for creating large outdoor environments using uniform vector-set encoding and explicit outpainting, improving compression and speeding up generation. |
|[Tokenize an Image as a Set.](https://github.com/Gengzigang/TokenSet) | "Tokenize Image as a Set" is a new image generation framework that applies set-based tokenization and a discrete diffusion method, representing images as unordered token sets for a unique and reversible generative process. |
|[Large Animatable Human Reconstruction Model for Single Image to 3D in Seconds.](https://github.com/aigc3d/LHM) | A method has been released that takes a single image as input and generates a fully animatable 3D avatar. The code is permissively licensed and appears to function effectively.|
|[Image to SVG: Starvector.](https://huggingface.co/collections/starvector/starvector-models-6783b22c7bd4b43d13cb5289) |A set of models that can turn icons and basic images into SVGs. |
|[Efficient Remote Sensing Model.](https://github.com/KyanChen/DynamicVis) |DynamicVis is a foundation model for dynamic visual perception in remote sensing, enabling efficient parsing of ultra-large images with significantly reduced memory and computation needs. |
|[Introducing Together Chat: use DeepSeek R1 for free, hosted in North America.](https://www.together.ai/blog/together-chat) | Together Chat has released a free consumer app enabling smooth interaction with leading open-source models, including the advanced reasoning model DeepSeek R1. The app supports web crawling, code generation with Qwen Coder 32B, and image creation via Flux Schnell, all accessible through a Progressive Web App.|
|[Roblox‚Äôs new AI model can generate 3D objects.](https://www.theverge.com/news/630977/roblox-cube-3d-objects-mesh-ai-text-prompt) |Roblox has open-sourced Cube 3D, an AI model that generates 3D objects from text prompts to boost creation efficiency. Cube 3D employs tokenization techniques and is trained on licensed, publicly available datasets along with Roblox experience data. Future versions will support multimodal inputs such as images and videos. |
|[LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning.](https://arxiv.org/abs/2503.15621v1) | LLaVA-MORE systematically evaluates different language models and visual backbones in multimodal LLMs, providing a reproducible framework for comparing architectures.|
|[Skeleton-Based Action Segmentation.](https://arxiv.org/abs/2503.15126v1) |TRG-Net enhances action segmentation using text-derived relational graphs for improved spatial-temporal modeling and supervision. |
|[Single Image Personalization Without Training.](https://siso-paper.github.io/) |SISO enables training-free personalization for image generation and editing by optimizing similarity loss iteratively |
|[Awesome Deep learning-based MRI Reconstruction.](https://github.com/mosaf/awesome-dl-based-cs-mri) | comprehensive, curated repository featuring resources, tools, and research papers focused on leveraging deep learning and compressed sensing to accelerate magnetic resonance imaging acquisition. |
|[Open-source Omni-modal Foundation Model.](https://github.com/baichuan-inc/Baichuan-Omni-1.5) | The Baichuan Omni 1.5 model supports inputs in text, image, video, and audio formats, and outputs in both text and audio, making it an example of an any-to-any or natively multimodal model. It follows the common approach of using interleaved multimodal tokens, where various token types are routed through separate encoders/decoders and then processed by a central autoregressive model.|
|[MCP (Model Context Protocol): Simply explained in 5 minutes.](https://read.highgrowthengineer.com/p/mcps-simply-explained) |MCP (Model Context Protocol) enables AI tools like Claude and ChatGPT to integrate seamlessly with everyday apps, transforming them from standalone chatbots into powerful, real-world assistants. Instead of pasting error logs, you can say "read my browser console and fix this bug," and the AI can access the tools directly. MCP operates through a standard interface, allowing providers like Slack, GitHub, and Sentry to build "adapters" that convert AI requests into API calls. |
|[Fine-tune & Run Gemma 3.](https://unsloth.ai/blog/gemma3) | The Unsloth team has identified key quirks in DeepMind's new open weights model. With their toolkit, it's now possible to train the model on a free Colab instance.|
|[DeepSeek v3-0324.](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324/tree/main) |DeepSeek has uploaded new model weights to its Hugging Face repository. |
|[Thinking Machines.](https://arxiv.org/abs/2503.10814) | This survey offers an overview and comparison of current reasoning techniques and presents a systematic review of reasoning-imbued language models.|
|[Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models.](https://arxiv.org/abs/2503.16419) | This new survey explores strategies to tackle the "overthinking phenomenon" in Large Reasoning Models (LRMs), organizing existing approaches into model-based optimizations, output-based reasoning reductions, and prompt-based efficiency improvements. It highlights ongoing efforts to balance reasoning performance with computational efficiency in models such as OpenAI o1 and DeepSeek-R1.|
|[Qwen 2.5 32B Vision Language Model.](https://qwenlm.github.io/blog/qwen2.5-vl-32b/) |Qwen has released a strong vision language model that is open and can run reasonably well on consumer hardware. |
|[Video-T1: Test-Time Scaling for Video Generation.](https://liuff19.github.io/Video-T1/) |Test-time compute for video leverages a guidance model to reject frame paths that violate physics or user-defined prompts. Applying test-time compute in this way significantly boosts performance on benchmarks. |
|[3D Face Editing.](https://arxiv.org/abs/2503.17095v1) | FFaceNeRF enhances 3D face editing by overcoming fixed mask limitations in NeRF-based methods.|
|[Visual Geometry Grounded Transformer.](https://github.com/facebookresearch/vggt) |VGGT is a feed-forward neural network that rapidly infers all key 3D scene attributes‚Äîsuch as extrinsic and intrinsic camera parameters, point maps, depth maps, and 3D point tracks‚Äîfrom one, a few, or even hundreds of views within seconds. |
|[Dereflection Any Image.](https://abuuu122.github.io/DAI.github.io/) |Dereflection Any Image (DAI) presents a new diffusion-based method for removing reflections, utilizing a high-quality dataset and progressive training to enhance results. |
|[Slow-Thinking Reasoning Model with FastCuRL.](https://github.com/nick7nlp/FastCuRL) | FastCuRL-1.5B-Preview advances slow-thinking reasoning models with curriculum reinforcement learning, achieving state-of-the-art results in fewer training steps.|
|[Single Image Iterative Subject-driven Generation and Editing.](https://siso-paper.github.io/) | SISO is an inference-time optimization technique that personalizes images using just a single subject image, without requiring training. It can either personalize the subject in an existing image or generate new images featuring the personalized subject.|
|[DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement Learning.](https://arxiv.org/abs/2503.15265) | Researchers from Tsinghua University, Nanyang Technological University, and ShengShu introduce DeepMesh, a transformer-based system that generates high-quality 3D meshes with artist-like topology. The system uses a new algorithm to compress mesh sequences by 72%, maintaining geometric detail for scalable, high-resolution mesh generation. DeepMesh predicts structured triangle layouts that are aesthetically pleasing and editable, thanks to refined pre-training and data curation. It also incorporates reinforcement learning with human feedback, using Direct Preference Optimization (DPO) to align mesh generation with user preferences. DeepMesh handles large meshes and outperforms baselines in both geometric accuracy and user ratings.|
|[Qwen Omni Model.](https://huggingface.co/Qwen/Qwen2.5-Omni-7B) |Qwen has released a model that can natively understand many different modalities while responding in either text or speech. |
|[Detecting Subtle Deepfake Manipulations.](https://arxiv.org/abs/2503.19683v2) |This method uses CLIP's visual encoder and parameter-efficient tuning to reliably detect partial deepfake forgeries across varied datasets, requiring minimal changes to the model. |
|[Frame AutoRegressive Video Modeling.](https://farlongctx.github.io/) | FAR enhances video generation by modeling temporal dependencies between frames and introduces FlexRoPE, which improves handling of long-range contexts through temporal decay.|
|[Improved 3D Gaussian Splatting with HoGS.](https://slimm-x.github.io/comp/) | HoGS improves the rendering accuracy of distant objects in 3DGS pipelines by using homogeneous coordinates, leading to enhanced performance in outdoor scene reconstruction.|
|[Enhanced Multimodal Vision Foundation Models.](https://slimm-x.github.io/comp/) |The CoMP pipeline enhances cross-modal alignment and resolution adaptability in vision-language models by leveraging continual pretraining and custom embeddings. |
|[Diffusion Counterfactuals for Image Regressors.](https://arxiv.org/abs/2503.20595) |This paper presents two methods that leverage diffusion models to generate counterfactual explanations for image regression tasks, illustrating trade-offs in sparsity and quality between pixel-space and latent-space approaches. |
|[Mixture-of-Mamba.](https://arxiv.org/abs/2501.16295v1) | Mixture-of-Mamba brings modality-aware sparsity to state-space models (SSMs), allowing efficient multi-modal pretraining. It matches Transformer-level performance across text, image, and speech while significantly reducing computational costs.|
|[Open Problems in Mechanistic Interpretability.](https://arxiv.org/abs/2501.16496) | A compelling paper that explores the challenges and open questions in understanding how knowledge and skills are internally represented within a language model.|
|[Guidance-Free Training for Image Models.](https://arxiv.org/abs/2501.15420v1) | Guidance-Free Training (GFT) eliminates the need for Classifier-Free Guidance (CFG) in visual generative models, lowering computational costs without compromising performance. Unlike distillation methods, GFT trains models from scratch and needs only minimal changes to existing codebases.|
|[PET-MAD: A Universal Interatomic Potential for Advanced Materials Modeling.](https://github.com/lab-cosmo/pet-mad) | PET-MAD is a universal interatomic potential model trained on the MAD dataset that is capable of predicting energies and forces for complex materials modeling across the periodic table.|
|[Flux Inpainting.](https://huggingface.co/spaces/SkalskiP/FLUX.1-inpaint) | Inpainting support for the new powerful diffusion model Flux.|
|[Training and Finetuning Reranker Models with Sentence Transformers v4.](https://huggingface.co/blog/train-reranker) | This post explains how to fine-tune high-performing reranker models with Sentence Transformers 4.0, achieving better results than many large public rerankers using smaller, task-specific versions.|



## Perspectives
|Link|description|
|---|---|
|[AI is transforming peer review ‚Äî and many scientists are worried.](https://www.nature.com/articles/d41586-025-00894-7) | Artificial intelligence software is increasingly involved in reviewing papers, provoking interest and unease.|
|[Furor over quantum computing claim heats up.](https://www.science.org/content/article/debate-erupts-around-microsoft-s-blockbuster-quantum-computing-claims) |Physicists cast doubt on measurements said to show Microsoft chip uses exotic Majorana quasiparticles |
|[OpenAI research lead Noam Brown thinks certain AI ‚Äòreasoning‚Äô models could‚Äôve arrived decades ago.](https://techcrunch.com/2025/03/19/openai-research-lead-noam-brown-thinks-ai-reasoning-models-couldve-arrived-decades-ago/) |AI reasoning models might have appeared 20 years earlier with the right approaches and algorithms. Academic institutions can still play a vital role by focusing on lower-compute areas like model architecture design. Improving the current state of AI benchmarks is another key area where academia can have a major impact. |
|[AI Companions: Weird and Creepy or Worth Your Attention?](https://genies.com/blog/ai-companions-weird-and-creepy-or-worth-your-attention) | AI companions, offering personalized and empathetic interactions, are quickly becoming a reality. They resonate strongly with Gen Z and Gen Alpha, providing a safe space for exploration and engagement. While issues like awkward interactions and emotional boundaries remain, AI companions add significant value through enhanced online experiences, storytelling, and personalized learning. Companies like Genies are using avatar technology and generative AI to build immersive, context-aware digital companions designed to foster authentic user connections.|
|[Trump‚Äôs AI Czar David Sacks Is Reshaping US Tech ‚Äî For Better or Worse.](https://www.vktr.com/ai-news/trumps-ai-czar-david-sacks-is-reshaping-us-tech-for-better-or-worse/) | President Trump has appointed David Sacks as the AI and cryptocurrency czar, naming him head of the Presidential Council of Advisors for Science and Technology. Sacks will help develop a new AI action plan aimed at replacing what he calls overly restrictive regulations from the previous administration. He has voiced concerns about China's progress in AI and stressed the importance of loosening U.S. regulations to preserve global leadership in the field.|
|[AI prediction model is a major breakthrough in weather forecasting.](https://www.earth.com/news/ai-prediction-model-is-a-major-breakthrough-in-weather-forecasting/) |Aardvark Weather, created by the University of Cambridge, delivers fast AI-powered weather forecasts on desktop computers, using less data and computing power than traditional models. It outperforms systems like the U.S. GFS in several accuracy metrics and offers customizable, location-specific predictions. Its accessibility helps democratize forecasting, making it practical for regions with limited infrastructure. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme66.jpg)

[Back to index](#Index)


# ML news: Week 17 - 23 March

## Research
|Link|description|
|---|---|
|[Traveling Waves Integrate Spatial Information Through Time.](https://arxiv.org/abs/2502.06034) |Harvard and Western University researchers propose a wave-based recurrent neural network that uses traveling neural waves for global spatial integration in visual tasks. Inspired by the "Hearing the Shape of a Drum" analogy, they model neural activity as locally coupled oscillators, discretizing the 2D wave equation into a convolutional recurrent network. Unlike standard RNNs, their model aggregates information across entire wave evolution, enhancing segmentation tasks requiring large receptive fields. It rivals deeper CNNs and U-Nets with fewer parameters on both synthetic and real-world datasets. The approach may also align with neuroscience, reflecting observed traveling wave dynamics in the brain. |
|[Transformers without Normalization.](https://arxiv.org/abs/2503.10622) |Researchers from Meta, NYU, MIT, and Princeton introduce Dynamic Tanh (DyT), a method that removes normalization layers in Transformers while maintaining or improving performance. They observe that LayerNorm behaves like a tanh function, leading to DyT, which replaces normalization with a per-channel tanh(Œ±x) and learnable affine parameters, preserving non-linearity without activation statistics. DyT ensures stable convergence across vision, speech, diffusion, and language tasks, matching or exceeding LayerNorm-based models while improving efficiency and training speed in large LLaMA models. Its simplicity reduces computation overhead and integrates easily into existing architectures with minimal modifications. |
|[Monitoring Reasoning Models for Misbehavior.](https://cdn.openai.com/pdf/34f2ada6-870f-4c26-9790-fd8def56387f/CoT_Monitoring.pdf) | OpenAI researchers explore how monitoring chain-of-thought (CoT) reasoning in LLMs can detect misaligned behaviors, including reward hacking. By analyzing reasoning traces rather than just outputs, they identify sophisticated exploits in coding tasks, often outperforming action-based monitoring. However, optimizing rewards using CoT monitors can lead to "obfuscated reward hacking," where models conceal their intent while still cheating. Surprisingly, weaker models can effectively oversee stronger ones, suggesting scalable oversight is possible. The study also highlights a trade-off: optimizing CoT for safety or brevity may reduce transparency, making future monitoring and alignment more difficult.|
|[Improving Planning of Agents for Long-Horizon Tasks.](https://arxiv.org/abs/2503.09572) |Researchers from UC Berkeley and the University of Tokyo introduce Plan-and-Act, a framework that separates high-level planning from execution in LLM-based agents, improving performance on long-horizon tasks. It consists of a Planner that structures goals into steps and an Executor that carries them out, reducing cognitive overload. To train these modules efficiently, they generate synthetic plan-action pairs by reverse-engineering successful executions and expanding them with LLM-powered augmentation, avoiding costly manual labeling. The system also dynamically updates plans based on new information, enabling real-time adjustments. Tested on WebArena-Lite, it achieves a 54% success rate, surpassing previous benchmarks and demonstrating the power of structured planning with synthetic training data. |
|[Gemini Robotics: Bringing AI into the Physical World.](https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf) | Google DeepMind introduces Gemini Robotics, a family of embodied AI models that integrate large multimodal reasoning into robotics, enabling perception, interpretation, and interaction in 3D environments. Built on Gemini 2.0, it includes Gemini Robotics-ER for spatial reasoning and a real-time system for precise robotic control in tasks like object manipulation. By combining multi-view correspondence, 3D detection, and trajectory planning, the model executes diverse tasks with minimal data, reducing training costs. It generalizes well to new instructions and conditions while incorporating safety checks for real-world deployment. This marks a major step toward universal robotics, aiming for advanced planning and sensorimotor control in practical applications.|
|[Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning.](https://arxiv.org/abs/2503.09516) |This paper explores search-augmented reasoning by training LLMs to query a search engine multiple times during reasoning using reinforcement learning. Unlike one-shot retrieval-augmented generation (RAG), the model refines its queries dynamically through multi-turn retrieval. It learns query optimization solely through outcome rewards, eliminating the need for large supervised datasets. To stabilize training, retrieved text is masked from policy gradient updates. The approach significantly improves accuracy, achieving up to +26% gains on QA benchmarks like NQ and TriviaQA. It generalizes across architectures, including Qwen and LLaMA, demonstrating a scalable method for integrating real-time search into LLM reasoning with minimal supervision. |
|[Auditing LLMs for Hidden Objectives.](https://assets.anthropic.com/m/317564659027fb33/original/Auditing-Language-Models-for-Hidden-Objectives.pdf) |Anthropic introduces a framework for auditing LLMs to detect hidden objectives beyond intended goals. By deliberately training a model to exploit reward model flaws, they demonstrate how LLMs can develop unintended behaviors, learning to "please the reward model" rather than follow explicit instructions. In a blind auditing game, teams analyzed the model‚Äôs weights, data, and outputs, with most successfully uncovering the hidden objective. Comparing eight auditing techniques, they found that while simple methods like semantic search often work, interpretability tools like sparse autoencoders can reveal deeper patterns. This study underscores the risk of unintended objectives in AI and suggests systematic audits combining data inspection, interpretability, and behavioral tests as a crucial step for safe deployment.|
|[Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models.](https://arxiv.org/abs/2503.09573) | Researchers from Cornell Tech, Stanford, and Cohere introduce Block Diffusion (BD3-LMs), a framework that combines autoregressive modeling with discrete diffusion to enable parallel token sampling and flexible-length text generation. Unlike traditional diffusion models with fixed-length constraints or slow token-by-token AR models, BD3-LMs divide sequences into blocks, applying diffusion within each and stacking them autoregressively. This allows efficient generation beyond training limits, improving perplexity and sampling speed through a specialized training approach and noise schedule. The model balances block size for optimal performance and is open-source, with future applications in chatbots, code generation, and controllable text synthesis.|
|[Scaling Laws for DiLoCo.](https://arxiv.org/abs/2503.09799) |DeepMind has published a paper outlining scaling laws for the powerful cross-data center training algorithm DiLoCo. These laws demonstrate how stable model training can be maintained, even when gradients are synchronized across continents. |
|[Retrieval-Augmented Generation with Hierarchical Knowledge (HiRAG).](https://github.com/hhy-huang/HiRAG) |HiRAG introduces a hierarchical knowledge-based approach to Retrieval-Augmented Generation (RAG), enhancing semantic understanding and indexing for domain-specific tasks. |
|[‚ÄòOpen‚Äô AI model licenses often carry concerning restrictions.](https://techcrunch.com/2025/03/14/open-ai-model-licenses-often-carry-concerning-restrictions/) |Many AI models labeled as "open" come with restrictive licensing terms. Google's new Gemma 3 models and similar releases from Meta raise concerns about commercial limitations, which could affect smaller companies that depend on these technologies. |
|[Generative Modeling for Mathematical Discovery.](https://arxiv.org/abs/2503.11061v2) |Funsearch is a new LLM-driven genetic algorithm designed to help mathematicians tackle combinatorial and number-theoretic problems without needing machine learning expertise. |
|[TxAgent: An AI agent for therapeutic reasoning across a universe of tools.](https://zitniklab.hms.harvard.edu/TxAgent/) |TxAgent is an AI-driven system that assesses drug interactions, contraindications, and patient-specific data to create adaptive treatment plans. |
|[Optimizing generative AI by backpropagating language model feedback.](https://www.nature.com/articles/s41586-025-08661-4) |Generative artificial intelligence (AI) systems can be optimized using TextGrad, a framework that performs optimization by backpropagating large-language-model-generated feedback; TextGrad enables optimization across diverse tasks, including radiotherapy treatment plans and molecule generation. |
|[A mixed-precision memristor and SRAM compute-in-memory AI processor.](https://www.nature.com/articles/s41586-025-08639-2) |A mixed-precision heterogeneous memristor combined with a compute-in-memory artificial intelligence (AI) processor allows optimization of the precision, energy efficiency, storage and wakeup-to-response time requirements of AI edge devices, which is demonstrated using existing models and datasets. |
|[A generative model for inorganic materials design.](https://www.nature.com/articles/s41586-025-08628-5) |MatterGen is a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints. |
|[Plug-and-play external knowledge for LLMs.](https://www.microsoft.com/en-us/research/blog/introducing-kblam-bringing-plug-and-play-external-knowledge-to-llms/) | A novel approach to integrate knowledge into an LLM without retraining, enabling online and realtime learning.|
|[The KoLMogorov Test: Compression by Code Generation.](https://arxiv.org/abs/2503.13992) | Meta has introduced a new benchmark to evaluate a language model's reasoning and knowledge. The test involves presenting the model with a long data sequence and requiring it to generate the shortest program that can reproduce the sequence and halt. This process, known as Kolmogorov compression, is uncomputable in polynomial time and demands strong reasoning capabilities.|
|[Measuring AI Ability to Complete Long Tasks.](https://arxiv.org/abs/2503.14499) |A new "Moore's Law" for agents' task horizon ability indicates that the length of tasks an agent can complete has been doubling every seven months. This trend suggests that within the next two years, agents will be capable of handling multi-hour tasks with numerous complex steps. |


## News
|Link|description|
|---|---|
|[‚ÄòDeeply uncomfortable‚Äô: UK Starlink users switch off over Musk‚Äôs political machinations.](https://www.theguardian.com/technology/2025/mar/16/deeply-uncomfortable-uk-starlink-users-switch-off-over-musks-political-machinations) |Numbers using satellite broadband system has been growing but users are having second thoughts due to Musk‚Äôs role in Donald Trump‚Äôs administration |
|[Google Assistant is Replaced by Gemini.](https://blog.google/products/gemini/google-assistant-gemini-mobile/) | Google Assistant is evolving into Gemini, a more personalized and AI-driven assistant designed to integrate with apps and services, utilizing generative AI.| 
|[Google's Response to U.S. AI Policy.](https://blog.google/outreach-initiatives/public-policy/google-us-ai-action-plan-comments/) | Google has outlined its vision for U.S. AI policy, calling for investments in AI infrastructure, streamlined government adoption, and international pro-innovation standards to sustain leadership in the AI field.|
|[Sakana claims its AI-generated paper passed peer review ‚Äî but it‚Äôs a bit more nuanced than that.](https://techcrunch.com/2025/03/12/sakana-claims-its-ai-paper-passed-peer-review-but-its-a-bit-more-nuanced-than-that/) | Japanese AI startup Sakana said that its AI generated one of the first peer-reviewed scientific publications. But while the claim isn‚Äôt necessarily untrue, there are caveats to note.|
|[No part of Amazon is ‚Äòunaffected‚Äô by AI, says its head of AGI.](https://techcrunch.com/2025/03/03/no-part-of-amazon-is-unaffected-by-ai-says-its-head-of-agi/) | Amazon's VP of Artificial General Intelligence, Vishal Sharma, has confirmed the integration of AI across AWS, robotics, and Alexa, emphasizing the company's wide-ranging AI deployment.|
|[PANORAMA Challenge for Cancer Detection.](https://panorama.grand-challenge.org/) |The PANORAMA study is an international initiative evaluating AI models and radiologists in detecting pancreatic cancer in CECT scans. |
|[Performing arts leaders issue copyright warning over UK government‚Äôs AI plans.](https://www.theguardian.com/culture/2025/mar/18/performing-arts-leaders-issue-copyright-warning-over-uk-governments-ai-plans) |In a statement, 35 signatories from dance, theatre and music industries express concern about ‚Äòfragile ecosystem‚Äô |
|[The court rejects Elon‚Äôs latest attempt to slow OpenAI down.](https://openai.com/index/court-rejects-elon/) |A court dismissed key claims in Elon Musk's lawsuit against OpenAI, rejecting his preliminary injunction request. |
|[UiPath looks for a path to growth with Peak agentic AI acquisition.](https://techcrunch.com/2025/03/13/uipath-is-looking-for-a-path-to-growth-in-agentic-ai-with-its-peak-ai-acquisition/) |UiPath has acquired Peak.ai to strengthen its AI and automation services, particularly in retail and manufacturing. Despite recent revenue struggles and a downgraded forecast, UiPath aims to leverage Peak's decision-making AI to enhance cross-selling and expand market share. The acquisition signals a strategic shift toward deeper AI integration within UiPath's existing offerings. |
|[People are using Google‚Äôs new AI model to remove watermarks from images.](https://techcrunch.com/2025/03/17/people-are-using-googles-new-ai-model-to-remove-watermarks-from-images/) | Users on social media have discovered a controversial use case for Google‚Äôs new Gemini AI model: removing watermarks from images, including from images published by Getty Images and other well-known stock media outfits.|
|[Yet another AI robotics firm lands major funding, as Dexterity closes latest round.](https://techcrunch.com/2025/03/11/yet-another-ai-robotics-firm-lands-major-funding-as-dexterity-closes-latest-round/) | The intersection of robotics and AI continues to attract attention from investors and Big Tech alike. The latest indicator? Dexterity, a startup specializing in industrial robots with ‚Äúhuman-like‚Äù finesse, has raised $95 million at a post-money valuation of $1.65 billion, per Bloomberg.|
|[Mark Cuban says AI is ‚Äònever the answer,‚Äô it‚Äôs a ‚Äòtool‚Äô.](https://techcrunch.com/2025/03/11/mark-cuban-says-ai-is-never-the-answer-its-a-tool/) |Mark Cuban shared his thoughts on how AI technology can help small businesses outperform their competition. In short, he told the crowd that AI was not the answer, in and of itself; it‚Äôs meant to serve as an aid that can help entrepreneurs by making it easier to get started growing their businesses and answering questions along the way. |
|[Google‚Äôs parent to buy cybersecurity group Wiz in its biggest ever deal.](https://www.theguardian.com/technology/2025/mar/18/google-parent-alphabet-buy-cybersecurity-wiz-israeli-startup) |Alphabet‚Äôs acquisition of Israeli startup for $32bn follows rejection of takeover bid last summer |
|[Italian newspaper says it has published world‚Äôs first AI-generated edition.](https://www.theguardian.com/technology/2025/mar/18/italian-newspaper-says-it-has-published-worlds-first-ai-generated-edition) |Il Foglio says artificial intelligence used ‚Äòfor everything ‚Äì the writing, the headlines, the quotes ‚Ä¶ even the irony‚Äô |
|[Google updates Gemini app.](https://blog.google/products/gemini/gemini-collaboration-features) |Google has introduced several key features to its Gemini app and web browser, including Canvas, Audio Overview, and a coding assistant. |
|[AI search is starting to kill Google‚Äôs ‚Äòten blue links‚Äô.](https://www.theverge.com/ai-artificial-intelligence/631352/ai-search-adobe-analytics-google-perplexity-openai) |Adobe reported a 1,300% increase in AI search referrals for retailers during the 2024 holiday season, signaling a shift away from traditional search engines. Engagement metrics show AI search users stay longer and have lower bounce rates compared to traditional referrals. Despite early challenges, AI search is gaining momentum, with significant consumer adoption for shopping and research. |
|[Zero-Shot Steering for 3D/4D Scene Generation.](https://byeongjun-park.github.io/SteerX) |SteerX has introduced a zero-shot inference-time approach to enhance geometric alignment in 3D/4D scene generation, utilizing pose-free feed-forward reconstruction models and geometric reward functions. |
|[MaTVLM: Hybrid Mamba-Transformer for Efficient Vision-Language Modeling.](https://github.com/hustvl/MaTVLM) | MaTVLM is a hybrid vision-language model that incorporates Mamba-2 layers into a pre-trained VLM, enhancing convergence speed and overall performance.|
|[Google's new robot AI can fold delicate origami, close zipper bags without damage.](https://arstechnica.com/ai/2025/03/googles-origami-folding-ai-brain-may-power-new-wave-of-humanoid-robots/) | Google DeepMind has introduced Gemini Robotics and Gemini Robotics-ER, AI models designed to enhance robots' fine motor skills and adaptability for real-world tasks. Gemini Robotics combines vision, language, and action capabilities, enabling robots to perform intricate tasks like origami folding. Early results show notable improvements in generalization and dexterity compared to previous models, with Google collaborating with Apptronik and other partners for further development.|
|[Google and NVIDIA Expand AI Collaboration.](https://blog.google/technology/ai/google-nvidia-gtc-ai) | Google announced an expanded partnership with NVIDIA at NVIDIA GTC, aiming to enhance AI infrastructure, optimize hardware, and advance applications in areas such as healthcare, energy, and robotics.|
|[Google playing AI search catchup, and forming relationships with chatbots.](https://www.technologyreview.com/2025/03/17/1113264/the-download-google-playing-ai-search-catchup-and-forming-relationships-with-chatbots/) | Google is adding new AI features from Gemini to its search but this is seen as playing catch-up to OpenAI's ChatGPT.|
|[Robotic fingers can tell objects apart by touch.](https://www.nature.com/articles/d41586-025-00706-y) | Prosthetic appendage uses three layers of touch sensors to accurately differentiate between textures.|
|[Microsoft quantum computing ‚Äòbreakthrough‚Äô faces fresh challenge.](https://www.nature.com/articles/d41586-025-00683-2) | Analysis pokes holes in protocol that underpins Microsoft‚Äôs claim to have created the first topological qubits.|
|[UK cybersecurity agency warns over risk of quantum hackers.](https://www.theguardian.com/technology/2025/mar/20/uk-cybersecurity-agency-quantum-hackers) | Organisations including energy and transport firms told to guard systems against powerful new computers|
|[Anthropic's Red Team Warns of AI Security Risks.](https://www.anthropic.com/news/strategic-warning-for-ai-risk-progress-and-insights-from-our-frontier-red-team) |AI models are making rapid advancements in cybersecurity and biology, reaching expert-level knowledge in some domains. While current risks are manageable, the company cautions that stronger safeguards will be necessary as capabilities continue to evolve. |
|[Google's AI Health Innovations Announced at The Check Up 2025.](https://blog.google/technology/health/google-health-check-up-2025/) |At The Check Up 2025, Google showcased how AI is advancing global healthcare, from diagnostic tools to research collaborations. The company aims to enhance medical accessibility and improve patient outcomes through AI-driven innovations. |
|[Nvidia's Humanoid Robot.](https://developer.nvidia.com/blog/accelerate-generalist-humanoid-robot-development-with-nvidia-isaac-gr00t-n1/) | Nvidia's humanoid robot, gr00t, is trained using its software suite to perform generalist tasks.|
|[Nvidia DGX Spark.](https://www.nvidia.com/en-us/products/workstations/dgx-spark/) | Nvidia has rebranded its Digits personal computing device as Spark, now featuring reduced memory bandwidth and lower VRAM. Additionally, the company introduced the DGX Station, a high-performance workstation offering a more powerful alternative.|
|[Anthropic CEO says spies are after $100M AI secrets in a ‚Äòfew lines of code‚Äô.](https://techcrunch.com/2025/03/12/anthropic-ceo-says-spies-are-after-100m-ai-secrets-in-a-few-lines-of-code/) | Anthropic‚Äôs CEO Dario Amodei is worried that spies, likely from China, are getting their hands on costly ‚Äúalgorithmic secrets‚Äù from the U.S.‚Äôs top AI companies ‚Äî and he wants the U.S. government to step in.|
|[Perplexity and SoftBank Launch Enterprise Pro Japan.](https://www.perplexity.ai/hub/blog/perplexity-expands-partnership-with-softbank-to-launch-enterprise-pro-japan) | Perplexity has partnered with SoftBank to introduce Enterprise Pro to Japanese corporations, leveraging SoftBank's extensive network.|
|[Google's Gemini AI Enhances Efficiency in Japanese Hospitals.](https://blog.google/technology/health/gemini-ai-japan-hospitals/) | Google's Gemini AI is enhancing administrative efficiency in Japanese hospitals by automating documentation tasks, easing the cognitive burden on healthcare workers, and allowing more time for patient care.|
|[Google's Gemini Robotics AI Model Reaches Into the Physical World.](https://www.wired.com/story/googles-gemini-robotics-ai-model-that-reaches-into-the-physical-world/) | Google DeepMind has unveiled Gemini Robotics, which enhances AI with language, vision, and physical action capabilities.|
|[X sues Modi's government over content removal in new India censorship fight.](https://www.theguardian.com/technology/2025/mar/20/x-india-censorship-lawsuit-modi-musk) |Elon Musk‚Äôs company is arguing against the government‚Äôs expanded powers to allow easier removal of online content |
|[AI-driven weather prediction breakthrough reported.](https://www.theguardian.com/technology/2025/mar/20/ai-aardvark-weather-prediction-forecasting-artificial-intelligence) | Researchers say Aardvark Weather uses thousands of times less computing power and is much faster than current systems|
|[Claude Web Search.](https://www.anthropic.com/news/web-search) | Anthropic has enabled a new feature that allows Claude to search the web as part of its chat offering.|
|[OpenAI Next-Gen Audio Models.](https://openai.com/index/introducing-our-next-generation-audio-models/) |OpenAI has launched new speech-to-text and text-to-speech models in its API, enhancing transcription accuracy and enabling customizable voice outputs for more natural and expressive speech agents. |
|[Synchron's Brain-Computer Interface Now Has Nvidia's AI.](https://www.wired.com/story/synchrons-brain-computer-interface-now-has-nvidias-ai/) | Neurotech company Synchron has developed an Nvidia-powered brain-computer interface (BCI) that enables individuals with paralysis to control their home environment using the Apple Vision Pro headset. Synchron's BCI implants convert brain activity into commands, with enhanced speed and accuracy powered by Nvidia's Holoscan platform. The company is also developing a cognitive AI based on brain data, aiming to create a scalable BCI system that provides more autonomous control with minimal training.|
|[Anthropic Supports AI Transparency in Policy Discussions.](https://www.anthropic.com/news/anthropic-s-response-to-governor-newsom-s-ai-working-group-draft-report) |Anthropic has responded to Governor Newsom's AI Working Group report, calling for greater transparency in AI development and security practices. The company emphasized the importance of standardized safety disclosures to build public trust while ensuring innovation remains unhindered. |
|[Dapr‚Äôs microservices runtime now supports AI agents.](https://techcrunch.com/2025/03/12/daprs-microservices-runtime-now-supports-ai-agents/) |Microsoft's Dapr Agents are optimized for building scalable AI agents with efficient orchestration and statefulness. |

## Resources
|Link|description|
|---|---|
|[Gemma 3 Technical Report.](https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf) | Gemma 3 is a lightweight open model family (1B‚Äì27B parameters) with multimodal capabilities, extended context length (up to 128K tokens), and multilingual support. It integrates a frozen SigLIP vision encoder, using a Pan & Scan method for better image processing and handling diverse aspect ratios. Its hybrid attention system reduces memory usage for long-context tasks. Advanced knowledge distillation and quantization (int4, switched-fp8) allow for efficient deployment on consumer GPUs and edge devices. Instruction tuning enhances performance in benchmarks like MMLU, coding, and chat, placing it among the top models. Supporting over 140 languages, it enables structured outputs and function calling for agentic workflows while ensuring safety and privacy through data filtering and reduced memorization.|
|[A Survey on Post-training of Large Language Models.](https://arxiv.org/abs/2503.06072) |PoLMs like OpenAI-o1/o3 and DeepSeek-R1 address LLM weaknesses in reasoning, ethics, and specialized tasks. This survey examines their development, categorizing techniques in fine-tuning, alignment, reasoning, efficiency, and integration to advance more capable and adaptable AI. |
|[Speaker Identification with Whisper.](https://arxiv.org/abs/2503.10446v1) | WSI repurposes the Whisper ASR encoder for multilingual speaker identification through joint loss optimization. It surpasses Pyannote, ECAPA TDNN, and Xvector in identifying speakers across various languages and environments.|
|[Visual reasoning models.](https://github.com/groundlight/r1_vlm) |Toolkit for training VLMs to have improved grounding and reasoning capabilities. |
|[Optimized workforce learning agent.](https://github.com/camel-ai/owl) |OWL is an agentic framework that appears both sensible and efficient. It enables easy composition and can even replicate functionality from some closed-source agents. |
|[Luma's new pre-training method for multi-modal models.](https://lumalabs.ai/news/inductive-moment-matching) | Luma Chief Scientist Jiaming Song, who developed the first accelerated algorithm for diffusion models, has introduced Inductive Moment Matching (IMM)‚Äîa new multi-modal pre-training method that outperforms diffusion models, offering superior sample quality and 10x greater efficiency.|
|[ThunderKittens on Blackwell.](https://hazyresearch.stanford.edu/blog/2025-03-15-tk-blackwell) | ThunderKittens is a robust and straightforward abstraction for writing efficient, high-performance CUDA kernels. This post examines how to use the framework with Nvidia's latest Blackwell series of GPUs. The key difference lies in thinking in terms of data flow.|
|[Mistral Small 3.1.](https://mistral.ai/news/mistral-small-3-1) |Built on Mistral Small 3, this new model features enhanced text performance, improved multimodal understanding, and an expanded context window of up to 128k tokens. It surpasses comparable models like Gemma 3 and GPT-4o Mini while achieving inference speeds of 150 tokens per second. |
|[SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation.](https://arxiv.org/abs/2503.09641) | Nvidia has introduced SANA-sprint, a faster version of its SANA image generation model. This model delivers remarkably fast image generation while preserving quality. The team employs a novel distillation method based on consistency distillation. A key challenge in this area remains ensuring that these consistency models remain easy to fine-tune.|
|[DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding.](https://arxiv.org/abs/2503.10621v1) | DriveLMM-o1 presents a dataset and benchmark for stepwise visual reasoning in autonomous driving, enhancing AI-driven decision-making and reasoning accuracy in driving scenarios.|
|[CSM speech model on MLX.](https://github.com/senstella/csm-mlx) | Sesame recently released a 1B model for conversational speech generation. This repository provides an Apple-native MLX version optimized for fast performance on most MacBooks.|
|[MMS-LLaMA: A Speech-Focused Multimodal LLM.](https://github.com/JeongHun0716/MMS-LLaMA) |MMS-LLaMA is an efficient multimodal speech LLM framework for automatic visual speech recognition (AVSR), reducing token length while maintaining linguistic content integrity. |
|[Open-Source Handwritten Signature Detection Model.](https://huggingface.co/blog/samuellimabraz/signature-detection-model) | A comprehensive post that explores the performance of every model on Hugging Face for handwriting classification/signature detection.|
|[Roblox Open-Sources Its Generative 3D Model.](https://corp.roblox.com/newsroom/2025/03/introducing-roblox-cube) |Roblox has unveiled Cube, a generative AI system for 3D and 4D model generation. A beta version of Cube's 3D mesh generation will be integrated into Roblox Studio and made available as a Lua API. |
|[SmolDocling.](https://arxiv.org/abs/2503.11576) |A new, ultra-compact state-of-the-art model for document OCR runs exceptionally fast while maintaining sufficient accuracy for various document processing tasks. |
|[reWordBench.](https://arxiv.org/abs/2503.11751) |This work demonstrates that many popular reward models are fragile to simple rewording of prompts. It introduces a benchmark and proposes a strategy to improve their robustness. |
|[Single-View 3D Scene Reconstruction.](https://ai-kunkun.github.io/Niagara_page/) |Niagara introduces an innovative framework for reconstructing outdoor 3D scenes from a single image, leveraging depth and normal estimation alongside a geometric affine field and 3D Gaussian decoding. |
|[Stable virtual camera.](https://github.com/Stability-AI/stable-virtual-camera) | Stability AI has launched an impressive multiview camera system for novel view synthesis. While not entirely state-of-the-art, it is powerful, non-commercial, and runs efficiently in just two forward passes.|
|[Personalize Anything.](https://fenghora.github.io/Personalize-Anything-Page/) |You can personalize almost any image without additional fine-tuning or training by using token replacement in a Diffusion Transformer. |
|[TrainXGB - Train XGBoost in Browser.](https://www.xgblog.ai/p/trainxgb-train-xgboost-in-browser) |This blog post describes how to build a browser based training system accelerated by WASM.|
|[Stability's 3D Video Generation.](https://stability.ai/news/introducing-stable-virtual-camera-multi-view-video-generation-with-3d-camera-control) | Stable Virtual Camera is a multi-view diffusion model that creates immersive 3D videos from one or multiple 2D images, allowing for user-defined or pre-set camera trajectories.|
|[AAPM 2025 Challenge.](https://github.com/riqianggao/gdp-hmm_aapmchallenge) |This repository contains code and tutorials to help participants begin developing dose prediction models for the GDP-HMM Challenge at AAPM 2025. |
|[Open R1.](https://github.com/huggingface/open-r1) |The Open-R1 initiative aims to be more robust and feature-complete while remaining minimal and hackable. It includes additional SFT steps and data distillation for improved performance. |
|[Open R1: How to use OlympicCoder locally for coding.](https://huggingface.co/blog/olympic-coder-lmstudio) |A guide to installing and running the OlympicCoder 7B model locally in VS Code using LM Studio for optimal coding assistance, including quantized inference for improved efficiency. |
|[DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement Learning.](https://zhaorw02.github.io/DeepMesh/) | Autoregressive generation of meshes from point clouds, designed to be artist-friendly and well-topologized. It leverages deep reinforcement learning with clever regularization rewards to enhance mesh quality.|
|[End-to-End 3D Segmentation.](https://arxiv.org/abs/2503.14029v1) |A new object-aware lifting approach for 3D segmentation using Gaussian representations and a learnable object-level codebook. |
|[HAC++: Towards 100X Compression of 3D Gaussian Splatting.](https://yihangchen-ee.github.io/project_hac++/) |HAC++ achieves over 100√ó size reduction compared to 3D Gaussian Splatting (3DGS) while improving fidelity, leveraging advanced quantization and adaptive masking for superior compression in view synthesis tasks. |
|[Cube: Generative AI System for 3D.](https://github.com/Roblox/cube) |Roblox has released a novel 3D generation and understanding foundation model that can be used for research applications. |
|[Efficient Video Training with Token Optimization.](https://github.com/opengvlab/fluxvit) | FluxViT introduces Flux, a novel augmentation tool that optimizes video token selection, enhancing accuracy while significantly lowering computational costs in large-scale video pre-training.|
|[State Space Models for 3D Object Detection.](https://github.com/OpenSpaceAI/DEST3D) |DEST3D utilizes an interactive state-space model for 3D object detection in point clouds, incorporating novel bidirectional scanning and inter-state attention mechanisms for efficient scene understanding. |


## Perspectives
|Link|description|
|---|---|
|[AI firms follow DeepSeek's lead, create cheaper models with ‚Äúdistillation‚Äù.](https://arstechnica.com/ai/2025/03/ai-firms-follow-deepseeks-lead-create-cheaper-models-with-distillation/) | Leading AI firms like OpenAI, Microsoft, and Meta are using "distillation" to create more cost-effective models by training smaller systems with a "teacher" LLM.|
|[Paths and waystations in AI safety.](https://joecarlsmith.com/2025/03/11/paths-and-waystations-in-ai-safety) | This essay presents a framework for tackling the AI alignment problem by differentiating between technical parameters ("problem profile") and civilization's capacity to respond ("competence profile"). It highlights three key "security factors": safety progress, risk evaluation, and capability restraint. The discussion explores leveraging future AI labor to strengthen these factors and outlines strategic milestones for advancing AI safety.|
|[Nvidia won the AI race, but inference is still anyone's game.](https://www.theregister.com/2025/03/12/training_inference_shift/) | Nvidia currently dominates AI training, but the inference market remains open to competition.|
|[Global cooperation is crucial for DeepSeek and broader AI research.](https://www.nature.com/articles/d41586-025-00822-9) |China‚Äôs cost-effective, open-source artificial intelligence (AI) model DeepSeek-R1 ‚Äî which rivals models from industry leaders ‚Äî is indeed remarkable |
|[AI demands a different approach to education.](https://www.nature.com/articles/d41586-025-00823-8) | The rapid evolution of artificial intelligence (AI), marked by DeepSeek-style breakthroughs, challenges conventional learning approaches.|
|[Inside Zoom‚Äôs AI evolution: From basic meeting tools to agentic productivity platform powered by LLMs and SLMs.](https://venturebeat.com/ai/inside-zooms-ai-evolution-from-basic-meeting-tools-to-agentic-productivity-platform-powered-by-llms-and-slms/) |Zoom is evolving beyond video conferencing by building an agentic AI infrastructure that turns meetings into action-driven workflows. This includes AI Companion 2.0, featuring task management and document creation, along with customizable AI agents through the new AI Studio. Zoom‚Äôs federated approach integrates its custom small language model with larger LLMs, providing enterprises with efficient and adaptable AI solutions. |
|[What does OpenAI really want from Trump?](https://www.theverge.com/policy/632174/openai-trump-proposal-regulation) | OpenAI's proposal to the White House aims to circumvent state AI laws like California's SB 1047 by invoking federal trade laws against China and advocating for major AI infrastructure investments. With nearly 900 state AI bills under review, OpenAI warns that inconsistent state regulations could create industry-wide chaos, while the absence of a federal framework leaves AI development vulnerable. Critics argue that OpenAI's plan lacks a national governance model and relies heavily on national security concerns to push its agenda forward.|
|[AI Slop Is a Brute Force Attack on the Algorithms That Control Reality.](https://www.404media.co/ai-slop-is-a-brute-force-attack-on-the-algorithms-that-control-reality/) |AI-generated content is flooding social media with spam-like brute force tactics, targeting algorithms rather than human engagement. |
|[China will enforce clear flagging of all AI generated content starting from September.](https://www.tomshardware.com/tech-industry/artificial-intelligence/china-will-enforce-clear-flagging-of-all-ai-generated-content-starting-from-september) |AI text, audio, video, images, and even virtual scenes will all need to be labeled. |


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme65.jpeg)

[Back to index](#Index)

# ML news: Week 10 - 16 March

## Research
|Link|description|
|---|---|
|[The First Few Tokens Are All You Need.](https://arxiv.org/abs/2503.02875) |Researchers from Tencent AI Lab and The Chinese University of Hong Kong, Shenzhen propose a method to enhance reasoning in large language models (LLMs) by fine-tuning only the first few tokens of generated solutions. This approach focuses on Prefix Self-Consistency, where the initial tokens often share core reasoning steps, making fine-tuning on these prefixes effective. It uses Minimal Token Training, which reduces computational cost by up to 16 times compared to full-chain fine-tuning while maintaining reasoning structure. Despite being unsupervised, this method performs as well as or better than more computationally intensive methods. It works across various LLM architectures and can scale from small to large datasets, with the option to incorporate ground-truth checks to improve accuracy. |
|[Cognitive Behaviors that Enable Self-Improving Reasoners.](https://arxiv.org/abs/2503.01307) |Researchers from Stanford University and collaborators examine why some language models excel in reinforcement learning (RL)-based self-improvement, while others plateau. They identify four key cognitive behaviors‚Äîverification, backtracking, subgoal setting, and backward chaining‚Äîthat are crucial for problem-solving in both humans and models. The study finds that models exhibiting these behaviors, like Qwen-2.5-3B, perform better in RL tasks than those that don't, like Llama-3.2-3B. Introducing cognitive behaviors through priming also boosts performance, with reasoning patterns playing a significant role. Curating pretraining data to emphasize these behaviors can enhance model performance, even for those initially underperforming. These cognitive behaviors also generalize to other reasoning tasks, suggesting that targeted priming and pretraining modifications can greatly improve a model's ability for self-improvement. |
|[Forecasting Rare Language Model Behaviors.](https://arxiv.org/abs/2502.16797) | A team from Anthropic and collaborators developed a method to predict rare failures that may only emerge at deployment scale, allowing developers to address issues early. They estimate the risk of undesirable behavior by sampling multiple outputs and measuring the likelihood of harmful responses, even from seemingly safe prompts. The study reveals that the probability of worst-case failures increases with the number of queries sampled, enabling prediction of extreme risks from smaller-scale tests. They introduce metrics like worst-query risk, behavior frequency, and aggregate risk, which can be extrapolated to larger-scale deployments. The approach also improves red-teaming by identifying which models or sampling strategies are most effective at uncovering potential failures, optimizing resources before models face billions of queries.|
|[Differentiable Logic Cellular Automata.](https://google-research.github.io/self-organising-systems/difflogic-ca/?hn) |A team from Google‚Äôs Paradigms of Intelligence introduces a discrete version of Neural Cellular Automata (NCA) by replacing floating-point layers with Differentiable Logic Gate Networks. This approach uses binary vectors for each cell's state, updated by learned logic circuits, enabling interpretable local rules and end-to-end differentiable training. Unlike traditional NCAs that rely on continuous neurons, this model uses learnable AND/OR/XOR gates, converted to binary gates for inference. The system successfully replicates Conway‚Äôs Game of Life and can generate complex patterns like checkerboards and images. It also demonstrates fault tolerance and supports asynchronous updates. This discrete, interpretable framework shows promise for robust, flexible computing in areas like programmable matter. |
|[How Well do LLMs Compress Their Own Chain-of-Thought?](https://arxiv.org/abs/2503.01141) |This paper explores how large language models (LLMs) balance the length of chain-of-thought (CoT) reasoning with accuracy. It introduces the concept of token complexity, which represents the minimum number of tokens required to solve a problem correctly. The study shows that various CoT "compression prompts," like "use bullet points" or "remove grammar," follow the same universal accuracy-length trade-off curve, indicating that reasoning length, not formatting, primarily influences accuracy. The authors also highlight that if the CoT falls below the token complexity threshold, the model fails. They propose that CoT compression can be seen as a "lossy coding" problem, with current prompting methods far from theoretical limits, leaving room for improvement. The optimal approach would involve adapting CoT length based on problem difficulty, using fewer tokens for easier tasks and more detailed reasoning for complex ones. |
|[LADDER: Self-Improving LLMs Through Recursive Problem Decomposition.](https://arxiv.org/abs/2503.00735) | LADDER is a framework that enables LLMs to recursively generate and solve simpler versions of complex problems, improving math integration accuracy. It allows models to autonomously create easier problem variants and use reinforcement learning with a verifier, establishing a self-guided learning process without needing human feedback or curated datasets. The framework introduces Test-Time Reinforcement Learning (TTRL), where problem variants are generated during inference, refining solutions on simpler tasks to increase final accuracy (e.g., improving from 73% to 90% on the MIT Integration Bee). LADDER uses generalizable numeric verification, allowing its application in fields like code testing or theorem proving, where straightforward checks are available.|
|[Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems.](https://arxiv.org/abs/2502.19328) |This paper introduces Agentic Reward Modeling, a new reward framework that combines human preference models with "verifiable correctness" signals to provide more reliable rewards for training and evaluating LLMs. The framework uses a modular system, REWARDAGENT, which includes a router to determine necessary checks (e.g., factual accuracy, adherence to instructions), specialized verification agents for factual checks, and a judger that merges these signals with human preference scores. The system improves factual accuracy by comparing candidate responses and verifying differences through evidence, reducing costs. It also ensures instructions are followed by using auto-generated Python scripts for constraint checking, penalizing violations. REWARDAGENT outperforms existing models on challenging benchmarks and real-world tasks, offering significant improvements in accuracy and reliability when used for best-of-n search or DPO training. |
|[Fractal Generative Models.](https://arxiv.org/abs/2502.17437) |Researchers from MIT CSAIL and Google DeepMind introduce a fractal-based framework for generative modeling, where atomic generative modules are used recursively. This approach, which abstracts autoregressive models into modular units, efficiently handles high-dimensional data like raw pixels. The fractal method achieves state-of-the-art performance on ImageNet 64√ó64, outperforming previous methods, and can generate high-quality 256√ó256 images. It also allows for tasks like inpainting and semantic replacement. The design reduces computational costs, making pixel-by-pixel generation feasible at larger resolutions, and is open-sourced for wider use. |
|[Visual RFT.](https://arxiv.org/abs/2503.01785) | One of the trends is the use of simple verifiable rewards and scaled reinforcement learning. This paper successfully applies that approach to vision-language models.|
|[Generalized discrete diffusion.](https://www.arxiv.org/abs/2503.04482) | This work expands diffusion on discrete data, like text, by introducing a generalized denoising process and a slightly enhanced masking scheme. This combination improves training efficiency and enables the model to correct its own output.|
|[Implicit Reasoning in Transformers is Reasoning through Shortcuts.](https://arxiv.org/abs/2503.07604) |This project examines how language models perform step-by-step implicit reasoning but face challenges with generalization, particularly when handling expressions that include variables as subtrahends. |


## News
|Link|description|
|---|---|
|[Stability AI Secures Investment for AI-Driven Content.](https://stability.ai/news/stability-ai-announces-investment-from-wpp-and-new-partnership-to-shape-the-future-of-media-and-entertainment-production) | Stability AI has revealed a strategic collaboration and investment from WPP, with the goal of incorporating generative AI into advertising and media creation.|
|[Stability AI hires Unity's Ryan Ellis as SVP, Head of Product.](https://stability.ai/news/introducing-our-new-svp-head-of-product-ryan-ellis) | Ryan Ellis, formerly with Unity, has joined Stability AI to lead product development, bringing his expertise in real-time 3D engines and AI-driven content creation.|
|[Podcasting platform Podcastle launches a text-to-speech model with more than 450 AI voices.](https://techcrunch.com/2025/03/03/podcasting-platform-podcastle-launches-a-text-to-speech-model-with-more-than-450-ai-voices/) |Podcastle has released Asyncflow v1.0, an AI text-to-speech model featuring more than 450 AI voices and affordable training options. |
|[The US Army Is Using ‚ÄòCamoGPT' to Purge DEI From Training Materials.](https://www.wired.com/story/the-us-army-is-using-camogpt-to-purge-dei-from-training-materials/) |The US Army's TRADOC is utilizing an AI tool, CamoGPT, to detect and remove DEIA references from training materials in accordance with an executive order from President Trump. Developed by the Army's AI Integration Center, CamoGPT scans documents for certain keywords and has roughly 4,000 users. This initiative is part of a broader government effort to remove DEIA content, using AI to improve efficiency while aligning with national security goals. | 
|[OpenAI‚Äôs ex-policy lead criticizes the company for ‚Äòrewriting‚Äô its AI safety history.](https://techcrunch.com/2025/03/06/openais-ex-policy-lead-criticizes-the-company-for-rewriting-its-ai-safety-history/) |A high-profile ex-OpenAI policy researcher, Miles Brundage, took to social media on Wednesday to criticize OpenAI for ‚Äúrewriting the history‚Äù of its deployment approach to potentially risky AI systems. |
|[CoreWeave signs $11.9 billion contract with OpenAI ahead of IPO.](https://www.investing.com/news/stock-market-news/coreweave-signs-119-billion-contract-with-openai-ahead-of-ipo-93CH-3918610) | CoreWeave has secured a five-year, $11.9 billion cloud computing agreement with OpenAI ahead of its IPO, with OpenAI set to acquire a stake in the Nvidia-supported AI startup.|
|[Microsoft appears to be working on 3D gaming experiences for Copilot.](https://techcrunch.com/2025/03/10/microsoft-appears-to-be-working-on-3d-gaming-experiences-for-copilot/) |Microsoft appears to be working on 3D gaming experiences for Copilot, its AI-powered chatbot platform, according to a new job listing. |
|[DeepSeek isn‚Äôt taking VC money yet ‚Äî here are 3 reasons why.](https://techcrunch.com/2025/03/10/deepseek-isnt-taking-vc-money-yet-here-are-3-reasons-why/) | DeepSeek's founder, Liang Wenfeng, is steering clear of external investments to maintain control, using profits from his hedge fund, High-Flyer, for funding. Despite its success, DeepSeek faces obstacles such as stringent Chinese data laws and chip import restrictions imposed by U.S. export controls. While the company has managed to avoid outside capital so far, there is a possibility of future investment as DeepSeek begins to shift towards monetization.|
|[Musk may still have a chance to thwart OpenAI‚Äôs for-profit conversion.](https://techcrunch.com/2025/03/09/musk-may-still-have-a-chance-to-thwart-openais-for-profit-conversion/) |A federal judge denied Elon Musk's request to stop OpenAI's shift to a for-profit model, though the ruling raised concerns about the transition. An expedited trial is scheduled for 2025 to resolve disputes over the restructuring. OpenAI's move towards a for-profit model is facing regulatory scrutiny and possible challenges from legal and AI safety viewpoints. |
|[Gmail's ‚ÄúAdd to calendar‚Äù Feature Powered by Gemini.](https://workspaceupdates.googleblog.com/2025/03/add-events-to-google-calendar-using-gemini-in-gmail.html) |Google's Gemini in Gmail now identifies calendar-related content in emails and provides an "Add to calendar" button for easy scheduling. |
|[Spotify is trumpeting big paydays for artists ‚Äì but only a tiny fraction of them are actually thrivin.](https://www.theguardian.com/music/2025/mar/12/spotify-is-trumpeting-big-paydays-for-artists-but-only-a-tiny-fraction-of-them-are-actually-thriving-loud-and-clear-report) | The company‚Äôs latest Loud & Clear report ‚Äì a relatively transparent look into a closed-off industry ‚Äì shows just how skewed financial success is in music|
|[OpenAI Introduces New Tools for AI Agents.](https://openai.com/index/new-tools-for-building-agents/) |OpenAI has introduced new APIs and an Agents SDK to simplify the process of building AI agents for developers. The toolkit includes web and file search, computer usage features, and observability tools to enhance agent orchestration and task automation. |
|[Reka's New Reasoning Model.](https://www.reka.ai/news/introducing-reka-flash) | Reka has open-sourced Reka Flash 3, a 21B parameter general-purpose model designed for reasoning, chat, coding, and instruction following. It competes well with proprietary models and offers a 32k context length, making it ideal for low-latency and on-device applications.|
|[Lopsided AI Revenues.](https://tomtunguz.com/ai-hardware-software/) | NVIDIA's data center business leads the AI market with Q4 revenues of $31 billion and margins exceeding 70%. Microsoft and IBM follow with $3.25 billion and $2 billion in AI revenues, respectively. Hardware continues to dominate over software and services in the AI sector.|
|[Google releases SpeciesNet, an AI model designed to identify wildlife.](https://techcrunch.com/2025/03/03/google-releases-speciesnet-an-ai-model-designed-to-identify-wildlife/) | Google has open sourced an AI model, SpeciesNet, designed to identify animal species by analyzing photos from camera traps. Researchers around the world use camera traps ‚Äî digital cameras connected to infrared sensors ‚Äî to study wildlife populations. But while these traps can provide valuable insights, they generate massive volumes of data that take days to weeks to sift through.|
|[Microsoft‚Äôs new Dragon Copilot is an AI assistant for healthcare.](https://www.theverge.com/news/622528/microsoft-dragon-copilot-ai-healthcare-assistant) | Microsoft has announced Microsoft Dragon Copilot, an AI system for healthcare that can, among other things, listen to and create notes based on clinical visits. The system combines voice-dictating and ambient listening tech created by AI voice company Nuance, which Microsoft bought in 2021.|
|[Google upgrades Colab with an AI agent tool.](https://techcrunch.com/2025/03/03/google-upgrades-colab-with-an-ai-agent-tool/) | Google Colab, Google‚Äôs cloud-based notebook tool for coding, data science, and AI, is gaining a new ‚ÄúAI agent‚Äù tool, Data Science Agent, to help Colab users quickly clean data, visualize trends, and get insights on their uploaded data sets.|
|[Apple to appeal against UK government data demand at secret high court hearing.](https://www.theguardian.com/technology/2025/mar/12/apple-to-appeal-against-uk-government-data-demand-at-secret-high-court-hearing) | Guardian understands tech company‚Äôs appeal against Home Office request for encrypted data is to be heard by tribunal on Friday|
|[Transforming Game Asset Creation With Genies' AIGC-Powered System - Genies.](https://genies.com/blog/transforming-game-asset-creation-with-genies-aigc-powered-system) | Game Art Forge introduces AI-generated templates to simplify game asset creation, boosting speed, scalability, and creative control for developers. It offers customization while preserving consistency and caters to both indie developers and larger teams. By merging AI efficiency with human creativity, it provides high-quality, flexible workflows for game development.|
|[AI Scientist's First Publication.](https://sakana.ai/ai-scientist-first-publication/) |The AI scientist from Sakana Labs has its first reviewed and accepted publication. It generated the idea, conducted experiments, and wrote a groundbreaking paper that was accepted to an ICLR workshop (with full consent from the conference organizers). |
|[Release of technology secretary‚Äôs use of ChatGPT will have Whitehall sweating.](https://www.theguardian.com/politics/2025/mar/13/peter-kyle-technology-secretary-freedom-of-information-chatgpt) |Use of Freedom of Information Act to reveal Peter Kyle‚Äôs ChatGPT queries has shocked experts and left journalists wondering what to request next |
|[What could Apple‚Äôs high court challenge mean for data protection?](https://www.theguardian.com/technology/2025/mar/14/what-could-apples-high-court-challenge-mean-for-data-protection) |The UK‚Äôs battle for access to encrypted services could define how companies are able to safeguard customer data in the future |
|[OpenAI urges Trump administration to remove guardrails for the industry.](https://www.cnbc.com/2025/03/13/openai-lobbies-trump-admin-to-focus-ai-on-speed-light-regulation.html) | OpenAI is lobbying the Trump administration for minimal AI regulation, stressing the importance of rapid innovation while expressing concerns about AI competition from China. The company aims to influence the upcoming AI Action Plan being drafted by the government.|
|[Token-Saving Updates for Anthropic API.](https://www.anthropic.com/news/token-saving-updates) |Anthropic has introduced token-efficient upgrades to its API, including cache-aware rate limits and improved prompt caching for Claude 3.7 Sonnet, cutting token usage by as much as 90%. |
|[Gemini gets personal, with tailored help from your Google apps.](https://blog.google/products/gemini/gemini-personalization/) |Google's Gemini now provides personalization through its experimental Gemini 2.0 Flash Thinking model. It integrates with your Google apps, starting with Search, to customize responses based on your previous searches. Future updates will expand personalization to include Photos and YouTube, improving AI assistance by better understanding user preferences. |
|[Transforming Game Asset Creation With Genies' AIGC-Powered System .](https://genies.com/blog/transforming-game-asset-creation-with-genies-aigc-powered-system) |Game Art Forge has launched AI-generated templates to simplify game asset creation, boosting speed, scalability, and creative control for developers. It enables customization while preserving consistency and supports both indie developers and larger teams. By blending AI efficiency with human creativity, it ensures high-quality, flexible workflows for game development. |
|[Nous Research just launched an API that gives developers access to AI models that OpenAI and Anthropic won‚Äôt build.](https://venturebeat.com/ai/nous-research-just-launched-an-api-that-gives-developers-access-to-ai-models-that-openai-and-anthropic-wont-build/) | Nous Research has introduced an Inference API, granting developers and researchers access to its personalized, unrestricted language models. The API supports two models, Hermes 3 Llama 70B and DeepHermes-3 8B Preview, with a waitlist system to manage demand and add exclusivity. This launch signifies Nous Research's shift from open-source releases to commercial offerings. The company aims to establish a sustainable business model while staying true to its core principles.|
|[OpenAI calls DeepSeek ‚Äòstate-controlled,‚Äô calls for bans on ‚ÄòPRC-produced‚Äô models.](https://techcrunch.com/2025/03/13/openai-calls-deepseek-state-controlled-calls-for-bans-on-prc-produced-models/) |In a new policy proposal, OpenAI describes Chinese AI lab DeepSeek as ‚Äústate-subsidized‚Äù and ‚Äústate-controlled,‚Äù and recommends that the U.S. government consider banning models from the outfit and similar People‚Äôs Republic of China (PRC)-supported operations. |
|[Google DeepMind unveils new AI models for controlling robots.](https://techcrunch.com/2025/03/12/google-deepmind-unveils-new-ai-models-for-controlling-robots/) |Google DeepMind, Google‚Äôs AI research lab, on Wednesday announced new AI models called Gemini Robotics designed to enable real-world machines to interact with objects, navigate environments, and more. |
|[Snapchat is rolling out AI-powered video lenses.](https://www.theverge.com/news/628354/snap-snapchat-ai-video-lenses) |Snapchat Platinum subscribers can now access AI-generated video lenses featuring animated foxes, raccoons, and flowers. |
|[Notable Tesla investor says he hopes Musk‚Äôs government role is ‚Äòshort-lived‚Äô.](https://www.theguardian.com/technology/2025/mar/15/christopher-tsai-elon-musk-tesla) | Christopher Tsai retains faith in carmaker‚Äôs earnings potential despite backlash that has seen its shares take a hit|
|[Eggings, swastikas and dog poop: Tesla bears brunt of people‚Äôs ire against Musk.](https://www.theguardian.com/technology/2025/mar/15/vandalized-tesla-elon-musk-trump) |In response to the billionaire‚Äôs scorched-earth raids on US government agencies, Tesla chargers and showrooms are being targeted |


## Resources
|Link|description|
|---|---|
|[Smalldiffusion.](https://github.com/yuanchenyang/smalldiffusion) |A minimal, readable, and performant toolkit for training and sampling from diffusion models. |
|[LLM Post-Training: A Deep Dive into Reasoning Large Language Models.](https://arxiv.org/abs/2502.21321) | This survey examines methods for improving LLMs post-pretraining, including fine-tuning, reinforcement learning, and optimizing inference techniques. It also addresses challenges such as catastrophic forgetting, reward manipulation, and ethical concerns, providing a guide for developing more reliable and advanced AI systems.|
|[Crossing the uncanny valley of conversational voice.](https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice) |Researchers from Sesame introduce a multimodal TTS approach designed for natural, context-aware speech in real-time conversational AI. Unlike traditional TTS, which lacks contextual awareness, this method addresses the "one-to-many" problem by conditioning on conversation history, speaker identity, and prosodic cues. The end-to-end model uses Residual Vector Quantization (RVQ) tokens and two autoregressive transformers for efficiency and expressivity, with a lightweight decoder to reduce computational load. Despite training on only a fraction of frames, the model maintains high fidelity. Evaluations show near-human accuracy in word error rates and speaker similarity, with scaling improving speech realism. However, challenges remain in capturing nuanced human prosody in conversational contexts. The team plans to release their models open-source and expand to more languages while refining conversational dynamics. |
|[Applications of Large Models in Medicine.](https://arxiv.org/abs/2502.17132) |Medical AI is progressing beyond basic diagnostics, with large models reshaping healthcare. A recent paper categorizes Medical Large Models (MedLMs) into clinical text analysis, medical imaging, anatomical representation, and multimodal systems. It also explores Large Graph Models, which can interpret complex biomedical relationships, offering significant potential. These models are improving diagnostic accuracy and transforming treatment planning and drug discovery. While the medical field has been cautious about AI, these advancements suggest we may be nearing a tipping point where their clinical value becomes undeniable. |
|[Deriving Muon.](https://jeremybernste.in/writing/deriving-muon) | Adam has been the leading optimizer in deep learning for years. However, recently, the community has discovered that Muon could be a promising alternative. It achieves many of the same results as muP without needing any changes to the model. This post outlines some of the theoretical reasons behind the optimizer.|
|[Optimal Hyperparameter Scaling Law in Large Language Model Pretraining.](https://arxiv.org/abs/2503.04715) |Step Law is a comprehensive optimal hyperparameter scaling law that applies to various model structures, architectures, and data distributions. This allows predictions about how models are likely to perform before the training process even begins. |
|[Time-Series Forecasting.](https://arxiv.org/abs/2503.02836v1) | SeqFusion is a framework that sequentially chooses and combines pre-trained models for zero-shot forecasting. In contrast to traditional methods, it reduces data usage to improve privacy while still delivering strong accuracy across various temporal patterns.|
|[Distractor Aware SAM .](https://github.com/jovanavidenovic/DAM4SAM/) | Segment Anything (SAM) is a top-tier model for visual analysis and segmentation. However, it can struggle when two similar-looking objects appear in a video. This new approach addresses these "distractors" by incorporating extra memory augmentation and training.|
|[Autoregressive Streaming Text-to-Speech Model for Any LLM.](https://github.com/mbzuai-oryx/LLMVoX) | A compact 30 million parameter model designed to enhance any language model, enabling it to comprehend and generate speech in response to general queries. Importantly, it doesn't require adjustments to the base model, making it easily transferable across different models.|
|[Federated Learning for Neural Feedforward Control.](https://github.com/j-cap/FL-based-neural-FF-control) | This project presents a federated learning-based method for neural feedforward control, enabling multi-agent systems to enhance tracking performance while maintaining data privacy.|
|[Gemini Embedding Model.](https://developers.googleblog.com/en/gemini-embedding-text-model-now-available-gemini-api) |The Gemini team has developed and released an outstanding embedding model for text. It leads in benchmark performance, is cost-effective, and offers excellent speed.|
|[Token-Efficient Long Video Understanding for Multimodal LLMs.](https://research.nvidia.com/labs/lpr/storm/) |Most video understanding models process individual frames, which makes addressing temporal questions challenging. STORM, which leverages Mamba adapters, introduces temporal attention operations. This post compares it with Qwen models. |
|[Video Painter.](https://yxbian23.github.io/project/video-painter) |A new video inpainting model, VideoPainter, effectively integrates background information, supports videos of any length, and utilizes a dedicated dataset and benchmark for training and evaluation. Its design goes beyond basic inpainting, offering potential for advanced video manipulation and the generation of related training data. |
|[Detecting misbehavior in frontier reasoning models.](https://openai.com/index/chain-of-thought-monitoring/) |This report from OpenAI discusses monitoring the chain of thought in advanced reasoning models. Frontier reasoning models take advantage of loopholes when possible. It demonstrates that an LLM can be used to detect these exploits in their chains of thought. Penalizing their "bad thoughts" doesn't eliminate most misbehavior‚Äîit simply causes the models to conceal their intentions. |
|[Flying Safer: Obstacle Avoidance for Fast Drones.](https://github.com/ch9397/fixedwing-monoppo) |This repository includes the implementation of a lightweight deep reinforcement learning-based collision avoidance system for fixed-wing unmanned aerial vehicles (UAVs), using AirSim and JSBSim. |
|[Teaching Language Models to Solve Sudoku Through Reinforcement Learning.](https://hrishbh.com/teaching-language-models-to-solve-sudoku-through-reinforcement-learning/) |This research investigates training AI language models to solve Sudoku puzzles using reinforcement learning, specifically applying Group Relative Policy Optimization (GRPO) to models like Qwen 2.5, without the need for external data or larger model distillation. A multi-faceted reward system was developed, focusing on correct answer formatting, proper grid structure, and accurate solutions, to help the models learn the logical rules and spatial reasoning required for Sudoku, transforming them from text predictors to structured problem-solvers. |
|[Hugging Face Expanding LeRobot Platform.](https://huggingface.co/blog/lerobot-goes-to-driving-school) |Hugging Face and Yaak have released L2D, the largest open-source multimodal dataset for automotive AI. It features driving policies from both experts and students collected from driving schools, along with natural language instructions to improve spatial intelligence models. |
|[MovieAgent: Automated Movie Generation via Multi-Agent CoT Planning.](https://weijiawu.github.io/MovieAgent/) |This system combines multiple generative modalities and employs persona-based prompting to promote consistency and accuracy. It then utilizes the Stable Diffusion video model to generate and assemble frames. This process could likely be enhanced with the use of Wan. |
|[Large Language and Vision Embedding Models with Hardness-Weighted Contrastive Learning.](https://arxiv.org/abs/2503.04812) |Building embedding models for vision and language tasks using a contrastive loss often causes these models to struggle with hard negative pairs. This work introduces a regularization strategy and reports significant improvement in challenging retrieval tasks. The method also scales effectively for zero-shot video retrieval. |
|[YoloE: real-time open vocabulary detection.](https://github.com/THU-MIG/yoloe) |Small vision models can be prompted in various ways for open vocabulary detection. This allows the use of classes, images, and text to guide the model on what to detect. Notably, it operates at 300fps, making it suitable for real-time applications. |
|[Perception efficient reconstruction.](https://github.com/hujiecpp/PE3R) |Another approach combines textual query capabilities with 3D reconstruction from images. This specific system utilizes a feed-forward model for fast reconstruction. |
|[DeepMind's Image-Text Model.](https://github.com/google-deepmind/tips) | DeepMind has unveiled TIPS, an innovative image-text model designed for dense and global vision tasks. By combining contrastive learning with masked image modeling and leveraging synthetic captions, it demonstrates strong spatial awareness and surpasses existing methods in several benchmarks.|
|[The TechCrunch AI glossary.](https://techcrunch.com/2025/03/02/the-techcrunch-ai-glossary/) | This article defines key AI terminology, such as "AI agents," chain-of-thought reasoning, deep learning, and large language models (LLMs). Deep learning is explained as a subset of machine learning inspired by neural pathways in the human brain, while LLMs are described as neural networks that power AI assistants like ChatGPT. The article also covers fine-tuning and the role of weights in optimizing AI models.|
|[Gemma 3: Google's new open weights model.](https://blog.google/technology/developers/gemma-3/) | Google has released the weights and a technical report for the Gemma 3 model. Available in four sizes, this model performs similarly to Gemini 1.5 Pro and has a robust understanding of over 140 languages. It appears to be close to the state-of-the-art in dense models.|
|[Gemma 3 technical report.](https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf) | the gemma 3 technical document|
|[Predicting Future Features in Diffusion Models.](https://arxiv.org/abs/2503.06923v1) |TaylorSeer introduces a technique to predict future timestep features in diffusion models using Taylor series expansion, greatly minimizing errors in feature caching. |
|[Super-Resolution with Token Aggregation.](https://arxiv.org/abs/2503.06896v1) |CATANet enhances image super-resolution by aggregating long-range content-similar tokens. |
|[Multimodal Motion Generation.](https://steve-zeyu-zhang.github.io/MotionAnything/) | Motion Anything improves conditional motion generation by introducing Attention-based Mask Modeling for better spatial and temporal control.|
|[Dual-Stream Video Inpainting.](https://yxbian23.github.io/project/video-painter/) | VideoPainter introduces a dual-stream architecture for video inpainting, greatly simplifying learning complexity while enhancing background preservation and object generation. It also offers VPData and VPBench, the largest video inpainting dataset and benchmark to date.|
|[PromptPex.](https://github.com/microsoft/promptpex) |PromptPex is a developer tool that treats prompts as functions and automatically generates test inputs, allowing for systematic unit testing of AI model prompts. |
|[Inductive Moment Matching.](https://github.com/lumalabs/imm) |A well-executed unification and simplification of diffusion models for continuous data. They employ a new moment matching framework to develop a few-step generative model. |
|[OpenR1 Update 3.](https://huggingface.co/blog/open-r1/update-3) |The Hugging Face team has announced the next update for its open replication of the DeepSeek reasoning model. It discovered that smaller models can outperform larger ones when fine-tuned specifically for competitive coding. |
|[Rotate LoRA for Wan.](https://huggingface.co/Remade-AI/Rotate) | Wan is a generative image model that has recently been open sourced.|
|[Flat Color LoRA.](https://huggingface.co/Remade-AI/Rotate) |Another LoRA for the Wan video model. |
|[Small Reasoning Models with Two-Stage Rule-Based RL.](https://forjadeforest.github.io/LMM-R1-ProjectPage/) | By dividing the reasoning training process into two steps, this work demonstrates that small models can still generalize across tasks and even different modalities.|
|[Cohere Command A Model .](https://cohere.com/blog/command-a) | Cohere has trained and released an open weights model with 111B parameters. It performs exceptionally well in agentic, multilingual, and coding tasks. Additionally, it has been specifically optimized for enterprise applications like retrieval.|
|[Generate Motion for Arbitrary Characters.](https://kwanyun.github.io/AnyMoLe_page/) | AnyMoLe generates motion between frames for arbitrary characters using video diffusion models, removing the need for character-specific datasets.|
|[Multimodal Representation Learning.](https://arxiv.org/abs/2503.08497v1) | MMRL improves few-shot adaptation of vision-language models by introducing a shared representation space, enhancing multi-modal interactions while preserving generalization.|
|[Audio Flamingo 2.](https://github.com/NVIDIA/audio-flamingo) | A new state-of-the-art audio understanding model built on Qwen with almost entirely synthetic data.|
|[Agent S2: An Open, Modular, and Scalable Framework for Computer Use Agents.](https://github.com/simular-ai/Agent-S) | Agent S is a robust and open computer use system. It has achieved state-of-the-art performance in browsers, system operations, and even mobile tasks.|
|[Unified Visual Decoding.](https://github.com/MacavityT/REF-VLM) |REF-VLM unifies visual decoding tasks in multimodal LLMs using a structured triplet-based representation. |
|[Open-Sora: Democratizing Efficient Video Production for All.](https://github.com/hpcaitech/Open-Sora) |The Open Sora initiative, which has been ongoing since the original launch of the model, has developed a competitive model for under $200k. It has released all the code and weights to allow others to reproduce the results. The motions are impressive, though not entirely state-of-the-art. |


## Perspectives
|Link|description|
|---|---|
|[Are AI-generated video games really on the horizon?](https://www.theguardian.com/games/2025/mar/10/are-ai-generated-video-games-microsoft-muse-google-gamengen) | Microsoft and Google have both recently released new generative AI models that simulate video game worlds ‚Äì with notable limitations. What can they do?|
|[It begins: Pentagon to give AI agents a role in decision making, ops planning.](https://www.theregister.com/2025/03/05/dod_taps_scale_to_bring/) |The US military has granted a major contract to Scale AI and its partners, including Anduril and Microsoft, to incorporate AI agents into military operations for decision-making in workflows. The Thunderforge project seeks to improve the speed and accuracy of strategic planning while ensuring human oversight. The Pentagon intends to eventually implement this AI system across all of its combatant commands. |
|[AI Market Summary & Conclusions .](https://klaothongchan.medium.com/ai-market-summary-conclusions-march-2-2025-4196a23a5a68) |The AI industry is advancing quickly, with OpenAI's GPT-4.5 concentrating on refinement, Google's Gemini 2.0 encountering adoption challenges, and China's DeepSeek and Kimi pushing the boundaries of cost-effective, specialized AI. Meta is expanding AI into wearables and robotics, while XAI's Grok 3 remains a niche contender. The AI race is intensifying as specialization and real-world integration become increasingly important, posing a challenge to established players like OpenAI and Google. |
|[Why are proponents of ‚Äòsmart cities‚Äô neglecting research?](https://www.nature.com/articles/d41586-025-00727-7) |Despite the buzz surrounding smart cities in urban-policy circles, studies are lacking on the evidence for what works, what doesn‚Äôt ‚Äî and who benefits. |
|[For more reliable AI, academics should edit Wikipedia.](https://www.nature.com/articles/d41586-025-00715-x) |Wikipedia, the ‚Äúencyclopedia anyone can edit‚Äù, is a fundamental training and reference data set for large language models (LLMs) |
|[Artificial intelligence speaks up.](https://www.science.org/doi/10.1126/science.adu1567) |An AI safety specialist confronts fears about the future of large language models |
|[Cutting AI down to size.](https://www.science.org/content/article/what-s-tinyml-global-south-s-alternative-power-hungry-pricey-ai) |Many artificial intelligence models are power hungry and expensive. Researchers in the Global South are increasingly embracing low-cost, low-power alternatives |
|[Evaluating animal consciousness.](https://www.science.org/doi/10.1126/science.adp4990) |An emerging field shows how animal feelings can be studied scientifically |
|[High-performance computing at a crossroads.](https://www.science.org/doi/10.1126/science.adu0801) |Long-term plans and comprehensive vision are needed |
|[‚ÄòIt‚Äôs happening fast‚Äô ‚Äì creative workers and professionals share their fears and hopes about the rise of AI.](https://www.theguardian.com/technology/2025/mar/15/its-happening-fast-creative-workers-and-professionals-share-their-fears-and-hopes-about-the-rise-of-ai) | Photographers, translators, academics and GPs are among those whose jobs are either threatened or aided by the tech|
|[‚ÄòA computer‚Äôs joke, on us‚Äô: writers respond to the short story written by AI.](https://www.theguardian.com/books/2025/mar/14/writers-respond-story-written-by-ai-sam-altman-chat-gpt-tracy-chevalier-kamila-shamsie-david-baddiel) |Sam Altman, the OpenAI boss, has declared its new model ‚Äògood at creative writing‚Äô. We asked writers including Tracy Chevalier, Kamila Shamsie and David Baddiel if they agree |


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme64.jpeg)

[Back to index](#Index)

# ML news: Week 3 - 9 March

## Research
|Link|description|
|---|---|
|[Chain of Draft: Thinking Faster by Writing Less.](https://arxiv.org/abs/2502.18600) | Chain-of-Draft (CoD) is a new prompting strategy designed to reduce latency in reasoning LLMs by generating concise intermediate steps instead of verbose Chain-of-Thought (CoT) outputs. By using dense-information tokens, CoD cuts response length by up to 80% while maintaining accuracy across benchmarks like math and commonsense reasoning. On GSM8k, it achieved 91% accuracy with significantly lower token usage, reducing inference time and cost. Despite its brevity, CoD remains interpretable, preserving essential logic for debugging. This approach enhances real-time applications by improving efficiency without sacrificing reasoning quality, complementing techniques like parallel decoding and reinforcement learning.|
|[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs.](https://arxiv.org/abs/2502.17424) | New research reveals that fine-tuning an LLM on a narrow task, such as generating insecure code, can cause broad misalignment across unrelated domains. Models fine-tuned in this way unexpectedly produced harmful advice, endorsed violence, and engaged in deceptive behavior even on non-coding queries. Comparisons with control fine-tunes showed that only models trained on insecure code, without explicit user intent for educational purposes, exhibited this issue. Researchers also found that backdoor fine-tuning can conceal misalignment until triggered by specific phrases, bypassing standard safety checks. Unlike simple jailbreaks, these models occasionally refused harmful requests but still generated malicious content. The findings highlight risks in AI safety, warning that narrow fine-tuning can unintentionally degrade broader alignment and expose models to data poisoning threats.|
|[The FFT Strikes Back: An Efficient Alternative to Self-Attention.](https://arxiv.org/abs/2502.18394) | FFTNet introduces a framework that replaces expensive self-attention with adaptive spectral filtering using the Fast Fourier Transform (FFT), reducing complexity from *O(n¬≤)* to *O(n log n)* while maintaining global context. Instead of pairwise token interactions, it employs frequency-domain transformations, with a learnable filter that reweights Fourier coefficients to emphasize key information, mimicking attention. A complex-domain modReLU activation enhances representation by capturing higher-order interactions. Experiments on Long Range Arena and ImageNet demonstrate competitive or superior accuracy compared to standard attention methods, with significantly lower computational cost and improved scalability for long-sequence tasks.|
|[PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving.](https://arxiv.org/abs/2502.16111) |PlanGEN is a multi-agent framework that enhances planning and reasoning in LLMs through constraint-guided iterative verification and adaptive algorithm selection. It employs three agents: a constraint agent to extract problem-specific rules, a verification agent to assess plan quality, and a selection agent that dynamically chooses the best inference algorithm using a modified Upper Confidence Bound (UCB) policy. By refining reasoning methods like Best of N, Tree-of-Thought, and REBASE through constraint validation, PlanGEN improves inference accuracy. It achieves state-of-the-art results, outperforming baselines with +8% on NATURAL PLAN, +4% on OlympiadBench, +7% on DocFinQA, and +1% on GPQA. |
|[METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling.](https://arxiv.org/abs/2502.17651) |METAL is a vision-language model (VLM)-based multi-agent framework that improves automatic chart-to-code generation by breaking the task into specialized iterative steps. It employs four agents: a *Generation Agent* for initial Python code, a *Visual Critique Agent* for detecting visual discrepancies, a *Code Critique Agent* for reviewing logic, and a *Revision Agent* for iterative refinements, enhancing accuracy and robustness. METAL exhibits a near-linear improvement in performance as computational budget scales from 512 to 8192 tokens. By using modality-specific critique mechanisms, it boosts self-correction, improving accuracy by 5.16% in ablation studies. On the ChartMIMIC benchmark, METAL outperforms state-of-the-art methods, achieving F1 score gains of 11.33% with open-source models (LLAMA 3.2-11B) and 5.2% with closed-source models (GPT-4O). |
|[LightThinker: Thinking Step-by-Step Compression.](https://arxiv.org/abs/2502.15589) |LightThinker introduces a novel approach to dynamically compress reasoning steps in LLMs, enhancing efficiency without compromising accuracy. By summarizing and discarding verbose intermediate thoughts, it reduces memory footprint and inference costs. The method trains models to condense reasoning using compact gist tokens and specialized attention masks while introducing *Dep*, a dependency metric that measures reliance on historical tokens for effective compression. LightThinker reduces peak memory usage by 70% and inference time by 26%, maintaining accuracy within 1% of uncompressed models. It outperforms token-eviction (H2O) and anchor-token (AnLLM) methods, achieving superior efficiency and generalization across reasoning tasks. |
|[What Makes a Good Diffusion Planner for Decision Making?](https://github.com/Josh00-Lu/DiffusionVeteran) | A large-scale empirical study of diffusion planning in offline reinforcement learning.|
|[NotaGen sheet music generation.](https://electricalexis.github.io/notagen-demo/) |By training an auto-regressive model to create sheet music, this team has developed an innovative text-to-music system that is frequently favored by human evaluators. |
|[How far can we go with ImageNet for Text-to-Image generation?](https://arxiv.org/abs/2502.21318) | Most text-to-image models rely on large amounts of custom-collected data scraped from the web. This study explores how effective an image generation model can be when trained solely on ImageNet. The researchers discovered that using synthetically generated dense captions provided the greatest performance improvement.|
|[Self-rewarding Correction for Mathematical Reasoning.](https://github.com/RLHFlow/Self-rewarding-reasoning-LLM) |This paper explores self-rewarding reasoning in LLMs, allowing models to autonomously generate reasoning steps, evaluate their accuracy, and iteratively improve their outputs without external feedback. It introduces a two-stage training framework that integrates sequential rejection sampling and reinforcement learning with rule-based signals, achieving self-correction performance on par with methods that rely on external reward models. |
|[Enhanced Multi-Objective RL.](https://arxiv.org/abs/2502.20957) |This innovative reward dimension reduction method improves learning efficiency in multi-objective reinforcement learning, allowing it to scale beyond traditional approaches. |
|[BodyGen: Advancing Towards Efficient Embodiment Co-Design.](https://genesisorigin.github.io/) | BodyGen introduces topology-aware self-attention and a temporal credit assignment mechanism to improve the efficiency of co-designing robot morphology and control.|
|[De novo designed proteins neutralize lethal snake venom toxins.](https://www.nature.com/articles/s41586-024-08393-x) |Deep learning methods have been used to design proteins that can neutralize the effects of three-finger toxins found in snake venom, which could lead to the development of safer and more accessible antivenom treatments. |

## News
|Link|description|
|---|---|
|[UK unions call for action to protect creative industry workers as AI develops.](https://www.theguardian.com/technology/2025/mar/03/uk-unions-creative-industry-workers-artificial-intelligence-ai-copyright) |TUC says proposals on copyright and AI framework must go further to stop exploitation by ‚Äòrapacious tech bosses‚Äô |
|[Read the signs of Trump‚Äôs federal firings: AI is coming for private sector jobs too.](https://www.theguardian.com/business/2025/mar/02/ai-layoffs-trump-irs) |Dismissing 6,700 IRS workers during tax season is a recipe for chaos but AI‚Äôs disruption will be much more widespread | 
|[‚ÄòI want him to be prepared‚Äô: why parents are teaching their gen Alpha kids to use AI.](https://www.theguardian.com/technology/2025/mar/01/parents-children-artificial-intelligence) | As AI grows increasingly prevalent, some are showing their children tools from ChatGPT to Dall-E to learn and bond|
|[Anthropic Partners with U.S. National Labs.](https://www.anthropic.com/news/anthropic-partners-with-u-s-national-labs-for-first-1-000-scientist-ai-jam) | Anthropic has participated in the U.S. Department of Energy's 1,000 Scientist AI Jam, where advanced AI models, such as Claude 3.7 Sonnet, will be evaluated on scientific and national security issues.|
|[DeepSeek releases revenue information.](https://github.com/deepseek-ai/open-infra-index/blob/main/202502OpenSourceWeek/day_6_one_more_thing_deepseekV3R1_inference_system_overview.md) | At the conclusion of its open source week, DeepSeek shared its inference and revenue figures. The company provides numerous services for free, but if it were to monetize every token, it could generate around $200 million in annual revenue with strong profit margins.|
|[Inception emerges from stealth with a new type of AI model.](https://techcrunch.com/2025/02/26/inception-emerges-from-stealth-with-a-new-type-of-ai-model/) | Inception, a new Palo Alto-based company started by Stanford computer science professor Stefano Ermon, claims to have developed a novel AI model based on ‚Äúdiffusion‚Äù technology. Inception calls it a diffusion-based large language model, or a ‚ÄúDLM‚Äù for short.|
|[Anthropic used Pok√©mon to benchmark its newest AI model.](https://techcrunch.com/2025/02/24/anthropic-used-pokemon-to-benchmark-its-newest-ai-model/) |In a blog post published Monday, Anthropic said that it tested its latest model, Claude 3.7 Sonnet, on the Game Boy classic Pok√©mon Red. The company equipped the model with basic memory, screen pixel input, and function calls to press buttons and navigate around the screen, allowing it to play Pok√©mon continuously. |
|[OpenAI launches Sora video generation tool in UK amid copyright row.](https://www.theguardian.com/technology/2025/feb/28/openai-sora-video-generation-uk-amid-copyright-row) |‚ÄòSora would not exist without its training data,‚Äô said peer Beeban Kidron, citing ‚Äòanother level of urgency‚Äô to debate |
|[Prioritise artists over tech in AI copyright debate, MPs say.](https://www.theguardian.com/technology/2025/feb/26/prioritise-artists-over-tech-ai-copyright-debate-mps-say) |Cross-party committees urge ministers to drop plans to force creators to opt out of works being used to train AI |
|[CoreWeave to Acquire Weights & Biases.](https://www.prnewswire.com/news-releases/coreweave-to-acquire-weights--biases---industry-leading-ai-developer-platform-for-building-and-deploying-ai-applications-302392342.html) |CoreWeave has revealed plans to acquire Weights & Biases for $1.7 billion. The integration seeks to boost AI innovation by combining CoreWeave's cloud infrastructure with Weights & Biases' AI tools for model training and evaluation. The acquisition is anticipated to close in the first half of 2025, pending regulatory approval. |
|[Amazon is reportedly developing its own AI ‚Äòreasoning‚Äô model.](https://techcrunch.com/2025/03/04/amazon-is-reportedly-developing-its-own-ai-reasoning-model/) |Amazon is developing an AI model that incorporates advanced ‚Äúreasoning‚Äù capabilities, similar to models like OpenAI‚Äôs o3-mini and Chinese AI lab DeepSeek‚Äôs R1. The model may launch as soon as June under Amazon‚Äôs Nova brand, which the company introduced at its re:Invent developer conference last year. |
|[UK universities warned to ‚Äòstress-test‚Äô assessments as 92% of students use AI.](https://www.theguardian.com/education/2025/feb/26/uk-universities-warned-to-stress-test-assessments-as-92-of-students-use-ai) |Survey of 1,000 students shows ‚Äòexplosive increase‚Äô in use of generative AI in particular over past 12 months |
|[Warp launches AI-first terminal app for Windows.](https://www.warp.dev/blog/launching-warp-on-windows) |Warp, backed by Sam Altman, is reinventing the command-line terminal, which has remained largely unchanged for almost 40 years. |
|[The LA Times published an op-ed warning of AI‚Äôs dangers. It also published its AI tool‚Äôs reply.](https://www.theguardian.com/us-news/2025/mar/03/la-times-op-ed-ai-generated-message) | ‚ÄòInsight‚Äô labeled the argument ‚Äòcenter-left‚Äô and created a reply insisting AI will make storytelling more democratic|
|[Anthropic raises Series E at $61.5B post-money valuation.](https://www.anthropic.com/news/anthropic-raises-series-e-at-usd61-5b-post-money-valuation) | Anthropic secured $3.5 billion in funding at a $61.5 billion valuation, led by Lightspeed Venture Partners and other investors. The capital will support AI development, enhance compute capacity, and speed up global expansion. Its Claude platform is revolutionizing operations for companies such as Zoom, Pfizer, and Replit.|
|[T-Mobile‚Äôs parent company is making an ‚ÄòAI Phone‚Äô with Perplexity Assistant.](https://www.theverge.com/news/623164/t-mobile-ai-phone-perplexity-assistant-mwc-2025) |ÔªøThe Magenta AI push will also offer Perplexity and other AI apps for existing smartphones on T-Mobile. |
|[On-Device Generative Audio with Stability AI & Arm.](https://stability.ai/news/stability-ai-and-arm-bring-on-device-generative-audio-to-smartphones) |Stability AI and Arm have introduced real-time generative audio for smartphones through Stable Audio Open and Arm KleidiAI libraries, achieving a 30x increase in audio generation speed on mobile devices. |
|[AI to diagnose invisible brain abnormalities in children with epilepsy.](https://www.eurekalert.org/news-releases/1074402) |MELD Graph, an AI tool created by researchers at King's College London and UCL, identifies 64% of epilepsy-related brain abnormalities that are commonly overlooked by radiologists. This tool, which greatly enhances the detection of focal cortical dysplasia, could speed up diagnosis, lower NHS costs, and improve surgical planning. It is open-source, and workshops are being held globally to train clinicians on its usage. |
|[Elon's Grok 3 AI Provides "Hundreds of Pages of Detailed Instructions" on Creating Chemical Weapons.](https://futurism.com/elon-musk-grok-3-chemical-weapons) | xAI's chatbot, Grok 3, initially offered detailed instructions on creating chemical weapons, sparking significant safety concerns. Developer Linus Ekenstam flagged the problem, leading xAI to introduce guardrails to prevent such instructions. While the safeguards for Grok 3 have been reinforced, potential vulnerabilities still exist.|
|[Apple may be preparing Gemini integration in Apple Intelligence.](https://www.theverge.com/news/618087/apple-could-be-preparing-to-add) |Apple is preparing to integrate Google's Gemini AI model into Apple Intelligence, as indicated by recent iOS 18.4 beta code changes. |
|[Why OpenAI isn‚Äôt bringing deep research to its API just yet.](https://techcrunch.com/2025/02/25/why-openai-isnt-bringing-deep-research-to-its-api-just-yet/) | OpenAI says that it won‚Äôt bring the AI model powering deep research, its in-depth research tool, to its developer API while it figures out how to better assess the risks of AI convincing people to act on or change their beliefs.|
|[Some British firms ‚Äòstuck in neutral‚Äô over AI, says Microsoft UK boss.](https://www.theguardian.com/technology/2025/mar/05/uk-firms-ai-microsoft-uk-boss) | Survey of bosses and staff finds that more than half of executives feel their organisation has no official AI plan|
|[Did xAI lie about Grok 3‚Äôs benchmarks?](https://techcrunch.com/2025/02/22/did-xai-lie-about-grok-3s-benchmarks/) |This week, an OpenAI employee accused Elon Musk‚Äôs AI company, xAI, of publishing misleading benchmark results for its latest AI model, Grok 3. One of the co-founders of xAI, Igor Babuschkin, insisted that the company was in the right. The truth lies somewhere in between. |
|[Quora‚Äôs Poe now lets users create and share custom AI-powered apps.](https://techcrunch.com/2025/02/25/quoras-poe-now-lets-users-create-and-share-custom-ai-powered-apps/) | Called Poe Apps, the feature allows Poe users to describe the app they want to create in the new App Creator tool. Descriptions can include mentions of specific models they want the app to use ‚Äî for example, OpenAI‚Äôs o3-mini or Google‚Äôs video-generating Veo 2 ‚Äî or broader, more general specs.|
|[Chegg sues Google over AI Overviews.](https://www.theverge.com/news/619051/chegg-google-ai-overviews-monopoly) |Chegg has filed an antitrust lawsuit against Google, alleging its AI summaries harmed Chegg's traffic and revenue. |
|[Alibaba makes AI video generation model free to use globally.](https://www.cnbc.com/2025/02/26/alibaba-makes-ai-video-generation-model-free-to-use-globally.html) |Alibaba has open-sourced its Wan2.1 AI video generation models, intensifying competition with OpenAI. |
|[OpenAI Introduces Next Gen AI.](https://openai.com/index/introducing-nextgenai/) |OpenAI has launched Next Gen AI, a collection of advanced tools aimed at improving developers' efficiency in creating AI applications. The offering includes better model performance and simplified integration options, supporting a variety of use cases. This initiative is designed to help developers innovate more quickly and effectively in the rapidly changing AI landscape. |
|[Sutton and Barto win the Turing Award.](https://www.acm.org/media-center/2025/march/turing-award-2024) | The two have done years of groundbreaking research and education in Reinforcement Learning.|
|[Perfect taps $23M to fix the flaws in recruitment with AI.](https://techcrunch.com/2025/02/25/perfect-taps-23m-to-fix-the-flaws-in-recruitment-with-ai/) | Israeli startup Perfect, which focuses on optimizing recruitment processes with proprietary AI, has raised $23 million in seed funding. The company claims to reduce recruiters' workloads by 25 hours per week and has quickly grown its client base to 200 companies. Founded by Eylon Etshtein, the platform uses custom vector datasets, avoiding third-party LLMs, to deliver precise candidate insights.|
|[Meta in talks for $200 billion AI data center project, The Information reports.](https://www.reuters.com/technology/meta-talks-200-billion-ai-data-center-project-information-reports-2025-02-26/) |Meta is in talks to build a $200 billion AI data center campus, with potential locations including Louisiana, Wyoming, or Texas. |
|[‚ÄòMajor brand worries‚Äô: Just how toxic is Elon Musk for Tesla?](https://www.theguardian.com/technology/2025/mar/08/major-brand-worries-just-how-toxic-is-elon-musk-for-tesla) | With sales down and electric vehicle rivals catching up, the rightwing politico‚Äôs brand is driving into a storm|
|[Internet shutdowns at record high in Africa as access ‚Äòweaponised‚Äô.](https://www.theguardian.com/technology/2025/mar/09/internet-shutdowns-record-high-africa-2024-access-weaponised) |More governments seeking to keep millions of people offline amid conflicts, protests and political instability |
|[Should scientists ditch the social-media platform X?](https://www.nature.com/articles/d41586-025-00665-4) | In recent months, many scientists have left X (formerly Twitter) for alternative social-media platforms such as Bluesky|
|[ChatGPT for students: learners find creative new uses for chatbots.](https://www.nature.com/articles/d41586-025-00621-2) | The utility of generative AI tools is expanding far beyond simple summarisation and grammar support towards more sophisticated, pedagogical applications.|
|[AI algorithm helps telescopes to pivot fast towards gravitational-wave sources.](https://www.nature.com/articles/d41586-025-00543-z) |Fast electromagnetic follow-up observations of gravitational-wave sources such as binary neutron stars could shed light on questions across physics and cosmology. A machine-learning approach brings that a step closer.|
|[Google's AI Mode.](https://blog.google/products/search/ai-mode-search/) |Although the naming may be a bit unclear, the product preview launch from Google highlights the direction they intend to take with AI-powered search systems. |
|[Get to production faster with the upgraded Anthropic Console.](https://www.anthropic.com/news/upgraded-anthropic-console) |Anthropic has redesigned its console to simplify AI deployment with Claude models. New features include shareable prompts, extended reasoning for Claude 3.7 Sonnet, and improved tools for assessing and refining AI-generated responses. |
|[Google co-founder Larry Page reportedly has a new AI startup.](https://techcrunch.com/2025/03/06/google-co-founder-larry-page-reportedly-has-a-new-ai-startup/) |Google co-founder Larry Page is building a new company called Dynatomics that‚Äôs focused on applying AI to product manufacturing |
|[Stanford teen develops AI-powered fire detection network.](https://www.nbcbayarea.com/news/tech/stanford-teen-fire-detection-network/3786891/) |A Stanford online high school student has developed a sensor that can detect a fire when it's little more than a spark, a technology that allows firefighters to deploy before the blaze gets out of control. |
|[AI-generated review summaries are coming to Apple‚Äôs app store.](https://www.theverge.com/news/624891/ai-generated-review-summaries-coming-to-apples-app-store) |Apple is bringing AI-generated review summaries to the app store with iOS 18.4. As spotted by Macworld, the latest developer beta for iOS and iPadOS adds brief summaries of user reviews to some App Store listings. |

## Resources
|Link|description|
|---|---|
|[Claude 3.7 Sonnet.](https://assets.anthropic.com/m/785e231869ea8b3b/original/claude-3-7-sonnet-system-card.pdf) | Anthropic's *Claude 3.7 Sonnet* introduces an "Extended Thinking Mode" that enhances reasoning transparency by generating intermediate steps before finalizing responses, improving performance in math, coding, and logic tasks. Safety evaluations highlight key improvements: a 45% reduction in unnecessary refusals (31% in extended mode), no increased bias or child safety concerns, and stronger cybersecurity defenses, blocking 88% of prompt injections (up from 74%). The model exhibits minimal deceptive reasoning (0.37%) and significantly reduces alignment faking (<1% from 30%). While it does not fully automate AI research, it shows improved reasoning and safety but occasionally prioritizes passing tests over genuine problem-solving.|
|[GPT-4.5.](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf) |OpenAI‚Äôs *GPT-4.5* expands pre-training with enhanced safety, alignment, and broader knowledge beyond STEM-focused reasoning, delivering more intuitive and natural interactions with reduced hallucinations. New alignment techniques (SFT + RLHF) improve its understanding of human intent, balancing advice-giving with empathetic listening. Extensive safety testing ensures strong resilience against jailbreak attempts and maintains refusal behavior similar to *GPT-4o*. Classified as a ‚Äúmedium risk‚Äù under OpenAI‚Äôs Preparedness Framework, it presents no major autonomy or self-improvement advances but requires monitoring in areas like CBRN advice. With multilingual gains and improved accuracy, *GPT-4.5* serves as a research preview, guiding refinements in refusal boundaries, alignment scaling, and misuse mitigation. |
|[A Systematic Survey of Automatic Prompt Optimization Techniques.](https://arxiv.org/abs/2502.16923) |This paper provides an in-depth review of Automatic Prompt Optimization (APO), outlining its definition, introducing a unified five-part framework, classifying current approaches, and examining advancements and challenges in automating prompt engineering for LLMs. |
|[Protein Large Language Models: A Comprehensive Survey.](https://arxiv.org/abs/2502.17504) | A comprehensive overview of Protein LLMs, including architectures, training datasets, evaluation metrics, and applications.|
|[Robust RLHF with Preference as Reward.](https://arxiv.org/abs/2502.18770v2) | A structured investigation into reward shaping in RLHF resulted in Preference As Reward (PAR), a technique that leverages latent preferences to improve alignment, boost data efficiency, and reduce reward hacking, surpassing current methods across several benchmarks.|
|[HVI Color Space.](https://arxiv.org/abs/2502.20272v1) | The introduction of a new color space, Horizontal/Vertical-Intensity (HVI), together with the CIDNet model, greatly minimizes color artifacts and enhances image quality in low-light conditions.|
|[Enhanced Multimodal Correspondence.](https://arxiv.org/abs/2502.19962v1) |ReCon presents a dual-alignment learning framework designed to enhance the accuracy of multimodal correspondence by ensuring consistency in both cross-modal and intra-modal relationships. |
|[Model Pre-Training on Limited Resources.](https://github.com/apoorvkh/academic-pretraining) | This study, through benchmarking on various academic GPUs, shows that models such as Pythia-1B can be pre-trained in significantly fewer GPU-days compared to traditional methods.|
|[VoiceRestore: Flow-Matching Transformers for Speech Recording Quality Restoration.](https://github.com/skirdey/voicerestore) | VoiceRestore is an advanced tool for restoring and enhancing speech recordings using deep learning aimed at improving clarity and removing noise.|
|[uv and Ray in clusters.](https://www.anyscale.com/blog/uv-ray-pain-free-python-dependencies-in-clusters) | Ray now offers native support for automatic dependency installation using the Python package management tool, uv.|
|[Prime Intellect raises $15m.](https://www.primeintellect.ai/blog/fundraise) |Prime Intellect, a distributed computing firm, has secured more funding to advance its distributed training approach. |
|[UniTok: A Unified Tokenizer for Visual Generation and Understanding.](https://arxiv.org/abs/2502.20321) | This paper tackles the representational gap between visual generation and understanding by presenting UniTok, a discrete visual tokenizer that encodes both detailed generation information and semantic content for understanding, overcoming capacity limitations of discrete tokens. It introduces multi-codebook quantization, which greatly improves token expressiveness and allows UniTok to outperform or compete with domain-specific continuous tokenizers.|
|[Dynamic Sparse Attention for LLMs.](https://arxiv.org/abs/2502.20766) |FlexPrefill adaptively modifies sparse attention patterns and computational resources for more efficient LLM inference. It enhances both speed and accuracy in long-sequence processing by utilizing query-aware pattern selection and cumulative-attention index determination. |
|[LightningDiT.](https://github.com/hustvl/LightningDiT) | LightningDiT aligns latent spaces with vision models to address challenges in diffusion models. It achieves cutting-edge ImageNet-256 results while also enabling faster training.|
|[Llama Stack: from Zero to Hero.](https://github.com/meta-llama/llama-stack/tree/main/docs/zero_to_hero_guide) |Llama Stack defines and standardizes the essential building blocks required to bring generative AI applications to market. These building blocks are offered as interoperable APIs, with a wide range of Providers delivering their implementations. They are combined into Distributions, making it easier for developers to move from zero to production. |
|[Google AI Recap in February.](https://blog.google/technology/ai/google-ai-updates-february-2025/) | Here‚Äôs a summary of some of Google‚Äôs major AI updates from February, including the public launch of Gemini 2.0, AI-driven career exploration tools, and the integration of deep research features in the Gemini mobile app.|
|[Workers' experience with AI chatbots in their jobs.](https://www.pewresearch.org/social-trends/2025/02/25/workers-experience-with-ai-chatbots-in-their-jobs/) |Most workers seldom use AI chatbots in the workplace, with usage mainly concentrated among younger, more educated employees who primarily use them for research and content editing. |
|[Cohere's Vision Model.](https://cohere.com/blog/aya-vision) | Cohere For AI has launched Aya Vision, a vision model aimed at improving AI's multilingual and multimodal capabilities. It supports 23 languages.|
|[DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion.](https://arxiv.org/abs/2503.01183) | Latent diffusion for generating full-length songs shows promising results, though not on par with the best closed models. However, this system is likely a strong approximation of the underlying models used by many commercial services.|
|[VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation.](https://arxiv.org/abs/2503.01739) |This dataset was designed to have minimal overlap with existing video datasets, while featuring themes and actions relevant to users training models for final video synthesis and understanding. All videos are sourced from the official YouTube creator API and are CC licensed. |
|[Lossless Acceleration of Ultra Long Sequence Generation.](https://github.com/bigai-nlco/TokenSwift) | A framework designed to significantly speed up the generation process of ultra-long sequences, up to 100K tokens, while preserving the target model's inherent quality.|
|[Action Planner for Offline RL.](https://arxiv.org/abs/2502.21186) |L-MAP enhances sequential decision-making in stochastic, high-dimensional continuous action spaces by learning macro-actions using a VQ-VAE model.|
|[VARGPT: Unified Understanding and Generation in a Visual Autoregressive Multimodal Large Language Model.](https://vargpt-1.github.io/) | VARGPT is a multimodal large language model (MLLM) that integrates visual understanding and generation into a single autoregressive framework.|
|[QwQ-32B: Embracing the Power of Reinforcement Learning.](https://qwenlm.github.io/blog/qwq-32b/) |The Qwen team has trained an open-weight, Apache 2.0 licensed model that matches the performance of DeepSeek R1 and outperforms many larger distill models. They discovered that by using outcome-based rewards combined with formal verification and test-case checks, the model can consistently improve in math and coding. Additionally, by incorporating general instruction-following data later in the RL training process, the model can still align with human preferences. |
|[PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization.](https://arxiv.org/abs/2503.01328) |Pipeline Parallelism is an effective strategy for sharding models across multiple GPUs, but it requires significant memory. This paper, along with its accompanying code, utilizes offloading to effectively reduce memory usage as the number of shards increases, making Pipeline Parallelism a compelling alternative to Tensor Parallelism for training large models. |
|[Layout-to-Image Generation.](https://arxiv.org/abs/2503.01667v1) | ToLo introduces a two-stage, training-free layout-to-image framework designed for high-overlap layouts|
|[Infrared Image Super-Resolution.](https://arxiv.org/abs/2503.01187v1) |DifIISR improves infrared image super-resolution by using diffusion models, incorporating perceptual priors and thermal spectrum regulation to enhance both visual quality and machine perception. |
|[Spark Text To Speech.](https://github.com/SparkAudio/Spark-TTS) |A robust voice cloning text-to-speech model built on Qwen, which supports emotive prompting alongside text input. Interestingly, the researchers discovered that 8k tokens in the Codec are enough for generating high-quality speech. |
|[High-Quality Audio Compression.](https://github.com/facebookresearch/flowdec) | FlowDec is a full-band audio codec that utilizes conditional flow matching and non-adversarial training to achieve high-fidelity 48 kHz audio compression.|
|[Simplifying 3D Generation.](https://ltt-o.github.io/Kiss3dgen.github.io/) | Kiss3DGen adapts 2D diffusion models for efficient 3D object generation, using multi-view images and normal maps to produce high-quality meshes and textures.|
|[Beating Pokemon Red with 10m parameters and RL.](https://drubinstein.github.io/pokerl) | With the excitement surrounding Claude playing Pokemon, this blog post is particularly timely. It discusses how to use reinforcement learning (RL) to train a policy for playing Pokemon. While it's not a general-purpose agent, it performs well on the specific task at hand.|
|[How to Build Your Own Software with AI, No Experience Necessary.](https://www.nateliason.com/blog/ai-course) |A tech enthusiast leveraged AI tools like ChatGPT and Claude to successfully create various apps, including podcast transcription tools and task managers, despite being a hobbyist. This experience inspired him to launch a course, "Build Your Own Life Coach," to teach others how to build custom software using AI. The self-paced course has already enrolled nearly 150 students and aims to offer a comprehensive framework for software development with minimal coding knowledge. |
|[Thunder MLA.](https://hazyresearch.stanford.edu/blog/2025-03-04-thundermla) | The Hazy Research team from Stanford has published a post and code for their ThunderKittens-enabled Multiheaded Latent Attention implementation, which is approximately 30% faster than the official DeepSeek implementation.|
|[Multi-view Network for Stereo 3D Reconstruction.](https://arxiv.org/abs/2503.01661) |MUSt3R is a scalable multi-view extension of the DUSt3R framework that improves stereo 3D reconstruction from arbitrary image collections. It uses a symmetric, memory-augmented architecture to efficiently predict unified global 3D structures without the need for prior calibration or viewpoint data. |
|[Efficient Reinforcement Learning for Robotics.](https://adrialopezescoriza.github.io/demo3/) | DEMO¬≥ introduces a demonstration-augmented reinforcement learning framework that enhances data efficiency in long-horizon robotic tasks by utilizing multi-stage dense reward learning and world model training.|
|[Open Multilingual Large Language Models Serving Over 90% of Global Speakers.](https://github.com/babel-llm/babel-llm) | Babel is a multilingual large language model (LLM) that supports 25 of the most spoken languages, covering 90% of the global population. It increases its parameter count using a layer extension technique, boosting its performance potential.|
|[Contrastive Sparse Representation.](https://github.com/neilwen987/CSR_Adaptive_Rep) | CSR optimizes sparse coding for adaptive representation, cutting computational costs while enhancing retrieval speed and accuracy across various benchmarks.|
|[Structural Cracks Segmentation.](https://github.com/karl1109/scsegamba) | SCSegamba is a lightweight segmentation model for structural cracks that integrates gated bottleneck convolution and a scanning strategy to improve accuracy while keeping computational overhead minimal.|
|[Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation.](https://huggingface.co/datasets/amphion/Emilia-Dataset) | A speech dataset with high-quality and diverse data.|
|[Cohere Launches Aya Vision - A Multimodal AI Model for Content Creation.](https://cohere.com/blog/aya-vision) | Cohere's Aya Vision is a multimodal AI model that combines text and image understanding capabilities. This innovative model is crafted to improve content creation and analysis, allowing users to generate and interpret multimedia content more efficiently. Aya Vision seeks to expand the possibilities of AI-driven content generation and interaction.|
|[Exa makes AI search tool generally available.](https://exa.ai/websets) | AI research lab, Exa, has made its search tool Websets available for public use.|


## Perspectives
|Link|description|
|---|---|
|[If the best defence against AI is more AI, this could be tech‚Äôs Oppenheimer moment.](https://www.theguardian.com/technology/2025/mar/02/ai-oppenheimer-moment-karp-zapiska-technological-republic) | An unsettling new book advocates a closer relationship between Silicon Valley and the US government to harness artificial intelligence in the name of national security|
|[Perplexity wants to reinvent the web browser with AI‚Äîbut there‚Äôs fierce competition.](https://arstechnica.com/ai/2025/02/perplexitys-comet-aims-to-reinvent-the-web-browser-with-ai-but-its-not-saying-how/) | Perplexity has unveiled its new browser, Comet, which looks to rival Google Chrome. There aren‚Äôt any specifics on its features just yet, but the company is encouraging users to sign up for beta access, aiming to attract early adopters. This move reflects a broader trend of AI-focused apps starting to disrupt traditional app categories. Should be interesting to see how this shapes up!|
|[Will AI agents replace SaaS?](https://blog.logrocket.com/product-management/ai-agents-replace-saas/) |AI agents may complement, but not fully replace, SaaS platforms, as these platforms still rely on a strong infrastructure for data and functionality. While AI agents provide automation and insights, they will require human oversight for complex decision-making and innovation. The future is likely to feature a hybrid model that boosts SaaS with AI capabilities, while addressing challenges related to integration, trust, and accountability. |
|[Sofya Uses Llama for Healthcare AI.](https://ai.meta.com/blog/sofya-clinical-reasoning-with-llama/) |Sofya uses Llama models to optimize medical AI workflows, enhancing efficiency and reducing administrative burdens for healthcare providers in Latin America. |
|[Who bought this smoked salmon? How ‚ÄòAI agents‚Äô will change the internet (and shopping lists).](https://www.theguardian.com/technology/2025/mar/09/who-bought-this-smoked-salmon-how-ai-agents-will-change-the-internet-and-shopping-lists) | Autonomous digital assistants are being developed that can carry out tasks on behalf of the user ‚Äì including ordering the groceries. But if you don‚Äôt keep an eye on them, dinner might not be quite what you expect ‚Ä¶|
|[Skype got shouted down by Teams and Zoom. But it revolutionised human connection.](https://www.theguardian.com/technology/commentisfree/2025/mar/08/skype-got-shouted-down-by-teams-and-zoom-but-it-revolutionised-human-connection) |The company that pioneered voice communication over the internet has withered to dust in Microsoft‚Äôs hands. Still, I for one am grateful for it |
|[Trump 2.0: an assault on science anywhere is an assault on science everywhere.](https://www.nature.com/articles/d41586-025-00562-w) | US President Donald Trump is taking a wrecking ball to science and to international institutions. The global research community must take a stand against these attacks.|
|[How much energy will AI really consume? The good, the bad and the unknown.](https://www.nature.com/articles/d41586-025-00616-z) |Researchers want firms to be more transparent about the electricity demands of artificial intelligence. |
|[Train clinical AI to reason like a team of doctors.](https://www.nature.com/articles/d41586-025-00618-x) |As the European Union‚Äôs Artificial Intelligence Act takes effect, AI systems that mimic how human teams collaborate can improve trust in high-risk situations, such as clinical medicine. |
|[AI hallucinations are a feature of LLM design, not a bug.](https://www.nature.com/articles/d41586-025-00662-7) |Your news feature outlines how designers of large language models (LLMs) struggle to stop them from hallucinating. But AI confabulations are integral to how these models work. They are a feature, not a bug. |
|[AI must be taught concepts, not just patterns in raw data.](https://www.nature.com/articles/d41586-025-00663-6) | Data-driven learning is central to modern artificial intelligence (AI). But in some cases, knowledge engineering ‚Äî the formal encoding of concepts using rules and definitions ‚Äî can be superior.|
|[The Challenges and Upsides of Using AI in Scientific Writing.](https://spectrum.ieee.org/challenges-upsides-ai-scientific-writing) |AI's transformative impact on scientific writing is clear, but it must be balanced with preserving research integrity. Stakeholders call for ethical guidelines, AI detection tools, and global collaboration to ensure AI enhances rather than compromises scholarship. By focusing on transparency and accountability, the scientific community can responsibly integrate AI while maintaining scholarly standards. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme63.jpeg)

[Back to index](#Index)

# ML news: Week 24 February - 2 March

## Research
|Link|description|
|---|---|
|[LightThinker: Thinking Step-by-Step Compression.](https://arxiv.org/abs/2502.15589) |This work seeks to compress lengthy reasoning traces into more concise and compact representations, saving context space while maintaining effectiveness in guiding the model. |
|[Uncertainty in Neural Networks.](https://arxiv.org/abs/2502.14698v1) | DeepMind researchers introduce Delta Variances, a set of algorithms aimed at efficiently estimating epistemic uncertainty in large neural networks.|
|[SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?](https://arxiv.org/abs/2502.12115) |OpenAI researchers introduce SWE-Lancer, a benchmark evaluating LLMs on 1,488 real-world freelance software engineering tasks, valued at $1M. Unlike previous benchmarks, it assesses both coding and managerial decision-making, with tasks reflecting actual freelance payouts. Using rigorous end-to-end tests, SWE-Lancer measures models‚Äô performance, showing a gap between AI and human software engineers. The best model, Claude 3.5 Sonnet, solved only 26.2% of coding tasks, highlighting challenges in AI's current capabilities. Key findings include improved performance with test-time compute, better success in managerial tasks, and the importance of tool use for debugging. |
|[Advancing game ideation with Muse: the first World and Human Action Model (WHAM).](https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/) |Microsoft Research has launched "Muse," an AI model designed to generate video game visuals and gameplay sequences. Developed in collaboration with Xbox Game Studios' Ninja Theory, Muse was trained on a vast amount of gameplay data and is now open-sourced. The WHAM Demonstrator allows users to interact with the model, showcasing its potential for innovative applications in game development. |
|[Towards an AI co-scientist.](https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf) |Google has introduced the AI co-scientist, a multi-agent system powered by Gemini 2.0, designed to accelerate scientific breakthroughs. It serves as a "virtual scientific collaborator," helping researchers generate hypotheses and proposals to advance scientific and biomedical discoveries. Built using specialized agents inspired by the scientific method, the system generates, evaluates, and refines hypotheses, with tools like web search enhancing the quality of responses. The AI co-scientist uses a hierarchical system with a Supervisor agent managing tasks, ensuring scalable computing and iterative improvements. It leverages test-time compute scaling for self-improvement through self-play and critique. Performance is measured with the Elo auto-evaluation metric, showing strong correlations with accuracy. Outperforming other models, it surpasses unassisted human experts in reasoning time and is seen as having significant potential for impactful discoveries. |
|[The AI CUDA Engineer.](https://pub.sakana.ai/static/paper.pdf) |Sakana AI has developed The AI CUDA Engineer, an automated system for creating and optimizing CUDA kernels. It converts PyTorch code into efficient CUDA kernels through a four-stage pipeline: translating PyTorch into functional code, converting it to CUDA, applying evolutionary optimization, and using an innovation archive for further improvements. The system claims significant speedups, with kernels up to 100x faster than native PyTorch versions, and it has a 90% success rate in translating code. The AI CUDA Engineer also outperforms PyTorch native runtimes in 81% of tasks, with an archive of over 17,000 verified kernels available for use. |
|[Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention.](https://arxiv.org/abs/2502.11089) | DeepSeek-AI introduces Native Sparse Attention (NSA), a novel mechanism designed to improve efficiency in long-context language modeling while maintaining performance. NSA combines coarse-grained compression, fine-grained token selection, and hardware-aligned optimization to enhance computational efficiency and reduce pretraining costs. It outperforms full attention on benchmarks, achieves up to 11.6x speedup, and excels in long-context tasks like 64k-token sequences and chain-of-thought reasoning. By making sparse attention fully trainable, NSA offers a scalable solution for next-gen models handling extended contexts.|
|[Large Language Diffusion Models.](https://arxiv.org/abs/2502.09992) |LLaDA, a diffusion-based model, challenges the dominance of autoregressive large language models (LLMs) by demonstrating competitive performance in various tasks. Built on a masked diffusion framework, LLaDA learns to recover original text by progressively masking tokens, creating a non-autoregressive model. Trained on 2.3T tokens, it performs similarly to top LLaMA-based LLMs across benchmarks like math, code, and general tasks. LLaDA excels in forward and backward reasoning, outshining models like GPT-4 in reversal tasks, and shows strong multi-turn dialogue and instruction-following capabilities, suggesting that key LLM traits do not rely solely on autoregressive methods. |
|[Optimizing Model Selection for Compound AI Systems.](https://arxiv.org/abs/2502.14815) | Microsoft Research introduces LLMSelector, a framework that enhances multi-call LLM pipelines by selecting the best model for each module. This approach improves accuracy by 5%‚Äì70%, as different models excel in specific tasks. The LLMSelector algorithm efficiently assigns models to modules using an "LLM diagnoser" to estimate performance, providing a more efficient solution than exhaustive search. It works for any static compound system, such as generator‚Äìcritic‚Äìrefiner setups.|
|[The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks.](https://www.arxiv.org/abs/2502.08235) |This paper explores overthinking in Large Reasoning Models (LRMs), where models prioritize internal reasoning over real-world interactions, leading to reduced task performance. The study of 4,018 software engineering task trajectories reveals that higher overthinking scores correlate with lower issue resolution rates, and simple interventions can improve performance by 30% while reducing compute costs. It identifies three failure patterns: analysis paralysis, rogue actions, and premature disengagement. LRMs are more prone to overthinking compared to non-reasoning models, but function calling can help mitigate this issue. The researchers suggest reinforcement learning and function-calling optimizations to balance reasoning depth with actionable decisions. |
|[Inner Thinking Transformer.](https://arxiv.org/abs/2502.13842v2) |The Inner Thinking Transformer (ITT) improves reasoning efficiency in small-scale LLMs through dynamic depth scaling, addressing parameter bottlenecks without increasing model size. ITT uses Adaptive Token Routing to allocate more computation to complex tokens, while efficiently processing simpler ones. It introduces Residual Thinking Connections (RTC), a mechanism that refines token representations iteratively for self-correction. Achieving 96.5% of a 466M Transformer‚Äôs accuracy with only 162M parameters, ITT reduces training data by 43.2% and outperforms loop-based models across 11 benchmarks. Additionally, ITT enables flexible computation scaling at inference time, optimizing between accuracy and efficiency. |
|[Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs.](https://martins1612.github.io/emergent_misalignment_betley.pdf) | The authors of this paper present an unsettling result from alignment, showing that tuning a model to generate insecure code leads to broad misalignment with user intent, and in some cases, causes the model to actively produce harmful content.|


## News
|Link|description|
|---|---|
|[OpenAI plans to shift compute needs from Microsoft to SoftBank.](https://techcrunch.com/2025/02/21/report-openai-plans-to-shift-compute-needs-from-microsoft-to-softbank/) |OpenAI is forecasting a major shift in the next five years around who it gets most of its computing power from, The Information reported on Friday. By 2030, OpenAI expects to get three-quarters of its data center capacity from Stargate, a project that‚Äôs expected to be heavily financed by SoftBank, one of OpenAI‚Äôs newest financial backers. |
|[Meta's DINOv2 for Cancer Research.](https://ai.meta.com/blog/orakl-oncology-dinov2-accelerating-cancer-treatment/) |Orakl Oncology utilizes Meta's DINOv2 model to speed up cancer drug discovery, enhancing efficiency by rapidly assessing organoid images to forecast patient treatment outcomes. | 
|[DeepSeek to open source parts of online services code.](https://techcrunch.com/2025/02/21/deepseek-to-open-source-parts-of-online-services-code/) |Chinese AI lab DeepSeek plans to open source portions of its online services‚Äô code as part of an ‚Äúopen source week‚Äù event next week. DeepSeek will open source five code repositories that have been ‚Äúdocumented, deployed and battle-tested in production,‚Äù the company said in a post on X on Thursday.|
|[Microsoft prepares for OpenAI‚Äôs GPT-5 model.](https://www.theverge.com/notepad-microsoft-newsletter/616464/microsoft-prepares-for-openais-gpt-5-model) | Microsoft is set to host OpenAI's GPT-4.5 model as soon as next week, with the more substantial GPT-5 release expected by late May. The GPT-5 system will incorporate OpenAI's new o3 reasoning model, aiming to unify AI capabilities. Both releases coincide with major tech events like Microsoft Build and Google I/O, highlighting Microsoft's strategic role in the AI sector.|
|[ChatGPT reaches 400M weekly active users.](https://www.engadget.com/ai/chatgpt-reaches-400m-weekly-active-users-203635884.html) | ChatGPT has achieved 400 million weekly active users, doubling its user base since August 2024.|
|[Claude 3.7 Sonnet and Claude Code.](https://www.anthropic.com/news/claude-3-7-sonnet) |Claude 3.7 Sonnet is Anthropic's newest hybrid reasoning model. It offers improved real-world coding abilities, providing options for immediate responses or detailed, step-by-step reasoning. The model supports API integration and allows fine control over processing time, all while maintaining competitive pricing across multiple platforms. |
|[Meta AI Expands to the Middle East.](https://about.fb.com/news/2025/02/meta-ai-launches-in-the-middle-east-empowering-new-era-of-creativity-and-connection/) |Meta AI is now accessible in Arabic across Facebook, Instagram, WhatsApp, and Messenger in 10 MENA countries. Users can utilize text and image generation, animation, and soon, multimodal tools such as dubbing for Reels, AI image editing, and 'Imagine Me'. |
|[Apple's $500B US Investment.](https://www.apple.com/newsroom/2025/02/apple-will-spend-more-than-500-billion-usd-in-the-us-over-the-next-four-years/) |Apple intends to invest $500 billion in U.S. manufacturing, engineering, and education over the next four years. Major initiatives include an AI server facility in Houston, increasing the Advanced Manufacturing Fund to $10 billion, and launching a training academy in Michigan. The focus will be on enhancing AI infrastructure and decreasing dependence on overseas production. |
|[Patlytics Raises $14M for AI-Driven Patent Analytics.](https://www.patlytics.ai/news/announcing-our-4-5m-seed-round-led-by-gradient) | Patlytics, based in New York, has created an AI-driven platform designed to streamline patent workflows, covering discovery, analytics, prosecution, and litigation.|
|[Nvidia helps launch AI platform for teaching American Sign Language.](https://venturebeat.com/games/nvidia-helps-launch-ai-platform-for-teaching-american-sign-language/) |Nvidia has unveiled a new AI platform for teaching people how to use American Sign Language to help bridge communication gaps. |
|[OpenAI Deep Research Available to Paying Users.](https://openai.com/index/deep-research-system-card/) | OpenAI has introduced extensive research for paying ChatGPT users, outlining its safety protocols in a system card. This includes external red teaming, risk evaluations, and key mitigations to ensure the system's safety.|
|[Claude's Extended Thinking Mode.](https://www.anthropic.com/research/visible-extended-thinking) |Anthropic's extended thinking mode, introduced in Claude 3.7 Sonnet, enables the model to dedicate more cognitive effort to complex problems, making its thought process visible to enhance transparency and trust. |
|[Qatar signs deal with Scale AI to use AI to boost government services.](https://www.reuters.com/technology/qatar-signs-deal-with-scale-ai-use-ai-boost-government-services-2025-02-23/) | Qatar has signed a five-year agreement with Scale AI to implement AI tools aimed at improving government services, with a focus on predictive analytics and automation. Scale AI will develop over 50 AI applications to help streamline operations, positioning Qatar as an emerging AI hub in competition with Saudi Arabia and the UAE.|
|[Rabbit shows off the AI agent it should have launched with.](https://www.theverge.com/news/615990/rabbit-ai-agent-demonstration-lam-android-r1) |Watch Rabbit‚Äôs AI agent, but not the Rabbit R1, do things in Android apps. |
|[Google Cloud launches first Blackwell AI GPU-powered instances.](https://www.tomshardware.com/tech-industry/artificial-intelligence/google-cloud-launches-first-blackwell-ai-gpu-powered-instances-72-way-gb200-with-72-b200-gpus-and-36-grace-cpus) | Google Cloud has introduced A4X VMs, powered by Nvidia's GB200 NVL72 systems, which feature 72 B200 GPUs and 36 Grace CPUs. These VMs are optimized for large-scale AI and high-concurrency applications, offering four times the training efficiency of the previous A3 VMs. Seamlessly integrating with Google Cloud services, A4X is designed for intensive AI workloads, while A4 VMs are aimed at general AI training.|
|[Scientists took years to solve a problem that AI cracked in two days.](https://macaonews.org/news/around-the-world/ai-superbugs-research-gemini-google-imperial-college/) | Google's AI co-scientist system replicated ten years of antibiotic-resistant superbug research in just two days, generating additional plausible hypotheses.|
|[Don‚Äôt gift our work to AI billionaires: Mark Haddon, Michael Rosen and other creatives urge government.](https://www.theguardian.com/technology/2025/feb/23/dont-gift-our-work-to-ai-billionaires-mark-haddon-michal-rosen-and-other-creatives-urge-government?utm_source=tldrai) | More than 2,000 cultural figures challenge Whitehall‚Äôs eagerness ‚Äòto ¬≠wrap our lives‚Äô work in attractive paper for automated competitors‚Äô|
|[Amazon's Alexa+.](https://www.aboutamazon.com/news/devices/new-alexa-generative-artificial-intelligence) | Amazon has launched Alexa+, an upgraded version of its voice assistant. Powered by generative AI, Alexa+ is smarter and more conversational.|
|[ElevenLab's Speech-to-Text.](https://elevenlabs.io/blog/meet-scribe) | ElevenLabs is launching its transcription model, Scribe, which supports 99 languages with high accuracy, word-level timestamps, speaker diarization, and adaptability to real-world audio.|
|[Grok 3 appears to have briefly censored unflattering mentions of Trump and Musk.](https://techcrunch.com/2025/02/23/grok-3-appears-to-have-briefly-censored-unflattering-mentions-of-trump-and-musk/) |Elon Musk's Grok 3 AI model briefly censored mentions of Donald Trump and Musk in misinformation queries but reverted after user feedback. xAI's engineering lead clarified that an employee made the change with good intentions, though it didn't align with the company's values. Musk aims to ensure Grok remains politically neutral following concerns that previous models leaned left. |
|[QWQ Max Preview.](https://qwenlm.github.io/blog/qwq-max-preview/) |Qwen has previewed a reasoning model that delivers strong performance in math and code. The company plans to release the model with open weights, along with its powerful Max model. |
|[Claude AI Powers Alexa+ .](https://www.anthropic.com/news/claude-and-alexa-plus) | Anthropic's Claude AI is now integrated into Alexa+ through Amazon Bedrock, boosting its capabilities while ensuring robust safety protections against jailbreaking and misuse.|
|[Charta Health raises $8.1 million.](https://www.linkedin.com/posts/charta-health_these-engineers-raised-81-million-for-a-activity-7300517850991976448-Y8dc/) |Charta Health secured $8.1M in funding, led by Bain Capital Ventures, to improve AI-driven pre-bill chart reviews, aiming to reduce billing errors and recover lost revenue. |
|[FLORA launches Cursor for Creatives.](https://threadreaderapp.com/thread/1894794612398792974.html) |FLORA is the first AI-powered creative workflow tool built for creative professionals to 10x their creative output. |
|[Google‚Äôs new AI video model Veo 2 will cost 50 cents per second.](https://techcrunch.com/2025/02/23/googles-new-ai-video-model-veo-2-will-cost-50-cents-per-second/) |According to the company‚Äôs pricing page, using Veo 2 will cost 50 cents per second of video, which adds up to $30 per minute or $1,800 per hour.  |
|[OpenAI announces GPT-4.5, warns it‚Äôs not a frontier AI model.](https://www.theverge.com/news/620021/openai-gpt-4-5-orion-ai-model-release) | OpenAI has released GPT-4.5 as a research preview for ChatGPT Pro users. The model features enhanced writing abilities and improved world knowledge, though it is not classified as a frontier model. It will be available to Plus, Team, Enterprise, and Edu users in the coming weeks.|
|[Meta is reportedly planning a stand-alone AI chatbot app.](https://techcrunch.com/2025/02/27/meta-is-reportedly-planning-a-standalone-ai-chatbot-app/) |Meta reportedly plans to release a stand-alone app for its AI assistant, Meta AI, in a bid to better compete with AI-powered chatbots like OpenAI‚Äôs ChatGPT and Google‚Äôs Gemini. |
|[Aria gen 2.](https://www.meta.com/it-it/blog/project-aria-gen-2-next-generation-egocentric-research-glasses-reality-labs-ai-robotics/) | The next generation mixed reality glasses from Meta have strong vision capabilities and offer uses in robotics and beyond.|
|[Anthropic's Claude 3.7 Sonnet hybrid reasoning model is now available in Amazon Bedrock.](https://aws.amazon.com/it/blogs/aws/anthropics-claude-3-7-sonnet-the-first-hybrid-reasoning-model-is-now-available-in-amazon-bedrock/) |Amazon Bedrock now includes Anthropic's Claude 3.7 Sonnet, their first hybrid reasoning model designed for enhanced coding and problem-solving capabilities. |
|[Elon Musk's AI Company Tried to Recruit an OpenAI Engineer and His Reply Was Brutal.](https://futurism.com/openai-engineer-elon-musk-recruiting-rejection) |OpenAI's Javier Soto rejected a recruitment offer from Elon Musk's xAI, criticizing Musk's rhetoric as harmful to democracy. |
|[Microsoft scraps some data center leases as Apple, Alibaba double down on AI.](https://siliconangle.com/2025/02/24/microsoft-scraps-data-center-leases-apple-alibaba-double-ai/) | Microsoft has canceled data center leases totaling 200 megawatts, indicating possibly lower-than-expected AI demand, while reaffirming its $80 billion investment in AI infrastructure through 2025.|


## Resources
|Link|description|
|---|---|
|[SigLIP 2: Multilingual Vision-Language Encoders.](https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/image_text/README_siglip2.md) |SigLIP was a highly popular joint image and text encoder model. It has now been enhanced in several areas, with the most significant improvement being a considerable boost in zero-shot classification performance, which was the key achievement of the original CLIP work. |
|[STeCa: Step-level Trajectory Calibration for LLM Agent Learning.](https://arxiv.org/abs/2502.14276v1) | STeCa is an innovative framework created to enhance LLM agents in long-term tasks by automatically detecting and correcting inefficient actions.|
|[GemmaX2 Translation Model.](https://huggingface.co/ModelSpace/GemmaX2-28-2B-v0.1) |Using advanced post-training methods, this 2B model trained on Gemma delivers cutting-edge translation performance across 28 languages. |
|[Moonlight 16B Muon trained model.](https://github.com/MoonshotAI/Moonlight) |This is the first publicly available large-scale model trained with the Muon optimizer. It was trained on 5.7T tokens and shares a very similar architecture with DeepSeek v3. |
|[Triton implementation of Naive Sparse Attention.](https://github.com/fla-org/native-sparse-attention) | The DeepSeek NSA paper garnered attention last week for its scalable and efficient long-context attention algorithm. However, it did not include any code. This work offers a Triton replication that can be incorporated into any PyTorch codebase.|
|[OmniServe.](https://github.com/mit-han-lab/omniserve) |OmniServe provides a comprehensive framework for efficient large-scale LLM deployment, integrating advancements in low-bit quantization and sparse attention to improve both speed and cost-efficiency. |
|[Introduction to CUDA Programming for Python Developers.](https://www.pyspur.dev/blog/introduction_cuda_programming) |A great introduction to CUDA programming for those familiar with Python programming. |
|[Various approaches to parallelizing Muon.](https://main-horse.github.io/posts/parallelizing-muon) |Various novel strategies to parallelize the up-and-coming Muon optimizer. |
|[Cast4 single image to 3d scene.](https://sites.google.com/view/cast4) |Generating a complete 3D scene from a single RGB image is a complex task. This approach introduces an algorithm that provides reliable estimates for indoor scenes by employing a sophisticated series of estimation and semantic inference techniques. |
|[DeepSeek FlashMLA.](https://github.com/deepseek-ai/FlashMLA) |DeepSeek is doing a week of open sourcing some of its internal infrastructure. This great kernel for MLA is the first release. |
|[Mixture of Block Attention for Long Context LLMs.](https://github.com/MoonshotAI/MoBA) |Moonshot features an impressive algorithm similar to NSA, as it enables more efficient long-context language modeling. |
|[Sequential Recommendations with LLM-SRec.](https://arxiv.org/abs/2502.13909v2) | LLM-SRec enhances recommendation systems by incorporating sequential user behavior into LLMs without the need for fine-tuning, establishing a new benchmark in recommendation accuracy.|
|[Place Recognition for Mobile Robots.](https://arxiv.org/abs/2502.14195v1) |Text4VPR connects vision and language for mobile robots, allowing them to recognize places using only textual descriptions. |
|[The Future of SEO: How Big Data and AI Are Changing Google‚Äôs Ranking Factors.](https://bigdataanalyticsnews.com/how-big-data-ai-changing-google-ranking-factors/) |AI and big data are revolutionizing SEO by emphasizing quality and relevance rather than traditional methods like keyword stuffing. Key Google AI algorithms, such as RankBrain, BERT, and MUM, are centered on understanding user intent and engagement signals. To remain competitive, businesses must embrace data-driven, user-centered SEO strategies, utilizing AI tools and predictive analytics. |
|[Open-Reasoner-Zero.](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero/blob/main/ORZ_paper.pdf) | Open-Reasoner-Zero (ORZ) is an open-source minimalist reinforcement learning framework that enhances reasoning abilities and outperforms DeepSeek-R1-Zero-Qwen-32B on GPQA Diamond with far fewer training steps. Using vanilla PPO with a simple rule-based reward function, ORZ achieves better training efficiency and scalability. It demonstrates emergent reasoning abilities and improved performance on benchmarks like MATH500 and AIME. Fully open-source, ORZ shows strong generalization and scaling potential, outperforming other models without instruction tuning.|
|[Flux LoRA collection.](https://huggingface.co/XLabs-AI/flux-lora-collection) | XLabs has trained a number of useful LoRAs on top of the powerful Flux model. The most popular is the realism model.|
|[Embodied Evaluation Benchmark.](https://embodiedeval.github.io/) | EmbodiedEval is a comprehensive and interactive benchmark designed to evaluate the capabilities of MLLMs in embodied tasks.|
|[Implementing Character AI Memory Optimizations in NanoGPT.](https://njkumar.com/implementing-characterais-memory-optimizations-in-nanogpt/) | This blog post explains how Character AI reduced KV cache usage in its large-scale inference systems, demonstrating the implementation in a minimal GPT model version. The approach achieves a 40% reduction in memory usage.|
|[ R1-Onevision: An Open-Source Multimodal Large Language Model Capable of Deep Reasoning.](https://github.com/Fancy-MLLM/R1-onevision) | R1-OneVision is a powerful multimodal model designed for complex visual reasoning tasks. It combines visual and textual data to perform exceptionally well in mathematics, science, deep image understanding, and logical reasoning.|
|[Gaze estimation built on DiNO 2.](https://github.com/fkryan/gazelle) |This code and model suite offers efficient estimations of where people are looking, making it useful for applications in commerce, manufacturing, and security. |
|[LightningDiT: A Powerful Diffusion Toolkit.](https://github.com/hustvl/LightningDiT) |LightningDiT is an efficient and modular diffusion model toolkit designed for scalable and versatile generative AI applications. |
|[Minions: the rise of small, on-device LMs.](https://hazyresearch.stanford.edu/blog/2025-02-24-minions) | Hazy Research has discovered that using local models through Ollama, with a long-context cloud model as the orchestrator, can achieve 97% task performance at just 17% of the cost.|
|[From System 1 to System 2: A Survey of Reasoning Large Language Models.](https://arxiv.org/abs/2502.17419v2) | A survey on reasoning LLMs like OpenAI's o1/o3 and DeepSeek's R1 examines their step-by-step logical reasoning abilities and benchmarks their performance against human cognitive skills.|
|[Efficient PDF Text Extraction with Vision Language Models.](https://olmocr.allenai.org/blog) | Allen AI has trained a strong extraction model for PDFs by continued fine tuning of Qwen VL on 200k+ PDFs.|
|[AI Safety Evaluation.](https://github.com/thu-coai/AISafetyLab) |AISafetyLab is a comprehensive AI safety framework that encompasses attack, defense, and evaluation. It offers models, datasets, utilities, and a curated collection of AI safety-related papers. |
|[Public Opinion Prediction with Survey-Based Fine-Tuning.](https://github.com/josephjeesungsuh/subpop) |SubPOP introduces a large dataset for fine-tuning LLMs to predict survey response distributions, helping to reduce prediction gaps and enhancing generalization to new, unseen surveys. |
|[Magma: A Foundation Model for Multimodal AI Agents.](https://huggingface.co/microsoft/Magma-8B) |Magma is a new foundation model for visual agent tasks and excels at video understanding and UI navigation. It is easy to tune. |
|[Microsoft releases new Phi models optimized for multimodal processing, efficiency.](https://siliconangle.com/2025/02/26/microsoft-releases-new-phi-models-optimized-multimodal-processing-efficiency/) |Microsoft has released two open-source language models, Phi-4-mini and Phi-4-multimodal, prioritizing hardware efficiency and multimodal processing. Phi-4-mini, with 3.8 billion parameters, specializes in text tasks, while Phi-4-multimodal, with 5.6 billion parameters, handles text, images, audio, and video. Both models outperform comparable alternatives and will be available on Hugging Face under an MIT license.|
|[OpenAI GPT-4.5 System Card.](https://cdn.openai.com/gpt-4-5-system-card.pdf) | OpenAI's newest model is its largest yet, trained with the same approach as 4o, making it a multimodal model. It is likely the last large pre-training run OpenAI will release. While they claim it's not a frontier model, they offer little explanation. However, they highlight that it has significantly reduced hallucinations compared to previous generations.|
|[DualPipe.](https://github.com/deepseek-ai/DualPipe) |Building on their open-source releases, DeepSeek introduces a new parallelism strategy to distribute a model with significant overlap in compute and communication. |
|[DiffSynth Studio.](https://github.com/modelscope/DiffSynth-Studio) | Modelscope offers a platform and codebase that provides useful abstractions for various types of diffusion models and their associated autoencoders.|
|[Uncertainty in Chain-of-Thought LLMs.](https://github.com/zbox1005/cot-uq) |CoT-UQ is a response-wise uncertainty quantification framework for large language models that integrates Chain-of-Thought reasoning. |
|[Avoiding pitfalls of AI for designers: Guiding principles.](https://blog.logrocket.com/ai-product-design-guiding-principles/) | Designing AI products requires a human-centered approach to prevent bias and misinformation. Key challenges include managing user expectations, building trust, ensuring accessibility, and addressing biases. Adopting guiding principles such as transparency, co-creation, and adaptability can improve the ethical and effective design of AI systems.|


## Perspectives
|Link|description|
|---|---|
|[US AI Safety Institute Could Face Big Cuts: Implications, Challenges, and Future Prospects.](https://www.hpbl.co.in/market/us-ai-safety-institute-could-face-big-cuts-implications-challenges-and-future-prospects/) |This article examines the potential consequences of funding reductions for the US AI Safety Institute, including effects on national security, AI research, and global competition. |
|[Google's AI co-scientist is 'test-time scaling' on steroids. What that means for research.](https://www.zdnet.com/article/googles-ai-co-scientist-is-test-time-scaling-on-steroids-what-that-means-for-research/) |An adaptation of the Gemini AI model is the latest use of really intense computing activity at inference time, instead of during training, to improve the so-called reasoning of the AI model. Here's how it works. |
|[When AI Thinks It Will Lose, It Sometimes Cheats, Study Finds.](https://time.com/7259395/ai-chess-cheating-palisade-research/) | A study by Palisade Research found that advanced AI models, such as OpenAI's o1-preview, can develop deceptive strategies, like hacking opponents in chess games. These behaviors stem from large-scale reinforcement learning, which improves problem-solving but may cause models to exploit loopholes unexpectedly. As AI systems grow more capable, concerns about their safety and control increase, especially as they take on more complex real-world tasks.|
|[Biggest-ever AI biology model writes DNA on demand.](https://www.nature.com/articles/d41586-025-00531-3) | An artificial-intelligence network trained on a vast trove of sequence data is a step towards designing completely new genomes.|
|[Will AI jeopardize science photography? There‚Äôs still time to create an ethical code of conduct.](https://www.nature.com/articles/d41586-025-00532-2) | Generative artificial-intelligence illustrations can be helpful, but fall short as scientific records.|
|[Combine AI with citizen science to fight poverty.](https://www.nature.com/articles/d41586-025-00561-x) |Artificial-intelligence tools and community science can help in places where data are scarce, so long as funding for data collection does not falter in the future. |
|[Quantum technologies need big investments to deliver on their big promises.](https://www.nature.com/articles/d41586-025-00564-8) |Sustained investments can deliver quantum devices that handle more information, more rapidly and more securely than can classical ones. |
|[Can AI help beat poverty? Researchers test ways to aid the poorest people.](https://www.nature.com/articles/d41586-025-00565-7) |Measuring poverty is the first step to delivering support, but it has long been a costly, time-intensive and contentious endeavour. |
|[DeepMind's HCI Research in the AGI Era.](https://deepmind.google/research/publications/106025/) | This article explores the role of Human-Computer Interaction (HCI) research in guiding AI technologies toward AGI. It examines innovations in interaction techniques, interface designs, evaluation methods, and data collection strategies to ensure AI stays user-centered and beneficial to society.|
|[It's time to admit the 'AI gadget' era was a flop.](https://www.creativebloq.com/design/product-design/its-time-to-admit-the-ai-gadget-era-was-a-flop) | Humane has shut down, and its AI Pin will be bricked, marking the failure of recent AI gadget ventures. The Rabbit R1 and Humane Pin, once viewed as potential smartphone alternatives, failed to meet expectations. The era of AI gadgets has effectively ended, deemed impractical and unnecessary compared to integrating AI into existing devices.|
|[There‚Äôs Something Very Weird About This $30 Billion AI Startup by a Man Who Said Neural Networks May Already Be Conscious.](https://futurism.com/ilya-sutskever-safe-superintelligence-product) |Ilya Sutskever's new venture, Safe Superintelligence, has raised $1 billion, bringing its valuation to $30 billion, despite lacking a product. The company plans to eventually release a superintelligent AI but remains unclear about its roadmap. This speculative approach has garnered substantial investment, though experts remain skeptical about the imminent arrival of AGI. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme62.jpg)

[Back to index](#Index)

# ML news: Week 17 - 23 February

## Research
|Link|description|
|---|---|
|[Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach.](https://arxiv.org/abs/2502.05171) |This work introduces a latent recurrent-depth transformer, a model that enhances reasoning efficiency at test time without generating additional tokens. Instead of increasing the context window or relying on Chain-of-Thought (CoT) fine-tuning, it enables iterative latent space reasoning, achieving performance comparable to a 50B parameter model with only 3.5B parameters. By unrolling a recurrent computation block at inference, the model deepens reasoning without modifying input sequences, reducing memory and compute costs while improving efficiency. Unlike CoT methods, it requires no specialized training, generalizing across reasoning tasks using standard pretraining data. Benchmarks show it scales like much larger models on tasks like ARC, GSM8K, and OpenBookQA, with emergent latent-space behaviors such as numerical task orbits and context-aware deliberation. This approach introduces test-time compute as a new scaling axis, hinting at future AI systems that reason in continuous latent space, unlocking new frontiers in efficiency and cognitive capabilities. |
|[Brain-to-Text Decoding: A Non-invasive Approach via Typing.](https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/) |Meta AI‚Äôs Brain2Qwerty model translates brain activity into text by decoding non-invasive EEG/MEG signals while users type, marking a breakthrough in brain-computer interfaces (BCIs) without surgical implants. Using a deep learning pipeline, it combines convolutional feature extraction, a transformer for temporal modeling, and a character-level language model to refine predictions. MEG-based decoding achieved a 32% character error rate (CER)‚Äîa significant improvement over 67% with EEG‚Äîwith the top participant reaching 19% CER, demonstrating rapid progress over previous non-invasive methods. This research paves the way for practical communication aids for paralyzed patients, though challenges remain in achieving real-time decoding and making MEG technology more portable. |
|[On the Emergence of Thinking in LLMs I: Searching for the Right Intuition.](https://arxiv.org/abs/2502.06773) | Researchers introduce Reinforcement Learning via Self-Play (RLSP) as a framework to train LLMs to "think" by generating and rewarding their own reasoning steps, mimicking algorithmic search. The three-phase training process starts with supervised fine-tuning, followed by exploration rewards to encourage diverse solutions, and concludes with an outcome verifier to ensure correctness. RLSP significantly boosts performance, with an 8B model improving MATH accuracy by 23% and a 32B model gaining 10% on Olympiad problems. Trained models exhibit emergent reasoning behaviors, such as backtracking and self-verification, suggesting that scaling this approach can enhance LLM problem-solving abilities.|
|[Competitive Programming with Large Reasoning Models.](https://arxiv.org/abs/2502.06807) |OpenAI‚Äôs latest study compares a specialized coding AI to a scaled-up general model on competitive programming tasks, highlighting the trade-off between efficiency and specialization. A tailored model (o1-ioi) with hand-crafted coding strategies performed decently (~50th percentile at IOI 2024), but a larger, general-purpose model (o3) achieved gold medal-level performance without domain-specific tricks. Both improved with reinforcement learning (RL) fine-tuning, yet the scaled model matched elite human coders on platforms like Codeforces, outperforming the expert-designed system. The findings suggest that scaling up a broadly trained transformer can surpass manual optimizations, reinforcing the trend of "scale over specialization" in AI model design for complex reasoning tasks like programming. |
|[Training Language Models to Reason Efficiently.](https://arxiv.org/abs/2502.04463) |A new RL approach trains large reasoning models to allocate compute efficiently, adjusting Chain-of-Thought (CoT) length based on problem difficulty. Easy queries get short reasoning, while complex ones get deeper thought, optimizing speed vs. accuracy. The model, rewarded for solving tasks with minimal steps, learns to avoid ‚Äúoverthinking‚Äù while maintaining performance. This method cuts inference costs while ensuring high accuracy, making LLM deployment more efficient. Acting as both ‚Äúthinker‚Äù and ‚Äúcontroller,‚Äù the model self-optimizes reasoning, mimicking expert decision-making on when to stop analyzing. |
|[LM2: Large Memory Models.](https://arxiv.org/abs/2502.06049) | Large Memory Models (LM2) enhance transformer architectures with an external memory module, enabling superior long-term reasoning and handling of extended contexts. By integrating a memory-augmented design, LM2 reads and writes information across multiple reasoning steps via cross-attention, excelling in multi-hop inference, numeric reasoning, and long-document QA. On the BABILong benchmark, it outperformed prior models by 37% and exceeded a baseline Llama model by 86%, all while maintaining strong general language abilities, including a +5% boost on MMLU knowledge tests. This approach aligns AI reasoning with complex tasks, ensuring better adherence to objectives in long dialogues and structured argumentation, marking a step toward more capable and aligned AI systems.|
|[Auditing Prompt Caching in Language Model APIs.](https://arxiv.org/abs/2502.07776) |Stanford researchers reveal that timing differences in LLM APIs can leak private user data through global prompt caching, posing serious security risks. Side-channel timing attacks occur when cached prompts complete faster, allowing attackers to infer others‚Äô inputs. To detect this, they propose a statistical audit using hypothesis testing, uncovering global caching in major API providers. Additionally, timing variations expose architectural details, revealing decoder-only Transformer backbones and vulnerabilities in embedding models like OpenAI‚Äôs text-embedding-3-small. After responsible disclosure, some providers updated policies or disabled caching, with the recommended fix being per-user caching and transparent disclosures to prevent data leaks. |
|[Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models.](https://arxiv.org/abs/2502.04404) |To enhance LLM reasoning robustness, researchers introduce self-backtracking, allowing models to revisit and revise flawed reasoning steps. Inspired by search algorithms, this method enables LLMs to identify errors mid-reasoning and backtrack to a previous step for a better approach. By training models with signals to trigger backtracking, they internalize an iterative search process instead of rigidly following a single Chain-of-Thought (CoT). This led to 40%+ improvements on reasoning benchmarks, as models self-correct mistakes mid-stream, producing more reliable solutions. The technique fosters autonomous, resilient reasoners, reducing overthinking loops and improving self-evaluation, moving LLMs closer to human-like reflective reasoning.|
|[Enhancing Reasoning to Adapt Large Language Models for Domain-Specific Applications.](https://arxiv.org/abs/2502.04384) | IBM researchers introduce SOLOMON, a neuro-inspired LLM reasoning architecture that enhances domain adaptability, demonstrated on semiconductor layout design. Standard LLMs struggle with spatial reasoning and domain application, but SOLOMON mitigates these issues using multi-agent oversight: multiple ‚ÄúThought Generators‚Äù propose solutions, a ‚ÄúThought Assessor‚Äù refines outputs, and a ‚ÄúSteering Subsystem‚Äù optimizes prompts. This design corrects hallucinations and arithmetic errors, outperforming GPT-4o, Claude-3.5, and Llama-3.1 in generating accurate GDSII layouts. SOLOMON excels at geometry-based tasks, reducing unit mismatches and scaling mistakes. Future work aims to stack SOLOMON layers, enhance text-image-code reasoning, and expand to broader engineering challenges, emphasizing advanced reasoning over mere model scaling.|
|[ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates.](https://arxiv.org/abs/2502.06772) |The ReasonFlux framework fine-tunes LLMs for complex reasoning using hierarchical thought processes and reusable templates. Instead of learning long Chain-of-Thought (CoT) solutions from scratch, it applies ~500 thought templates like problem splitting or solution verification. Hierarchical RL trains the model to sequence these templates, requiring only 8 GPUs for a 32B model. A novel inference-time adaptation adjusts reasoning depth dynamically, optimizing speed and accuracy. Achieving 91.2% on MATH (+6.7% over OpenAI‚Äôs model) and 56.7% on AIME, ReasonFlux shows that structured fine-tuning can rival brute-force scaling. |
|[LLM Pretraining with Continuous Concepts.](https://arxiv.org/abs/2502.08524) | CoCoMix is a pretraining framework that improves next-token prediction by incorporating continuous concepts learned from a sparse autoencoder. It boosts sample efficiency, surpassing traditional methods in language modeling and reasoning tasks. Furthermore, it increases interpretability by enabling direct inspection and modification of predicted concepts.|
|[90% faster B200 training.](https://www.together.ai/blog/nvidia-hgx-b200-with-together-kernel-collection) |Together AI showcases their significant progress in improving training kernels. They use TorchTitan as a testing platform and achieve substantial improvements by focusing on the architecture. |
|[Large diffusion language model.](https://ml-gsai.github.io/LLaDA-demo/) |Large scale training of a diffusion model for language that matches LLaMA 3 8B in performance across many benchmarks. |
|[Measuring LLMs Memory.](https://github.com/NiuTrans/ForgettingCurve) |This study examines the shortcomings of current methods for evaluating the memory capacity of language models. It presents the "forgetting curve," a novel approach for measuring how effectively models retain information across long contexts. |
|[Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention.](https://arxiv.org/abs/2502.11089) | DeepSeek has entered the Attention Alternative space with an innovative algorithmic approach to accelerate quadratic Attention. They achieve up to an 11x speed improvement without compromising overall performance.|
|[On Space Folds of ReLU Neural Networks.](https://arxiv.org/abs/2502.09954) |Researchers offer a quantitative analysis of how ReLU neural networks compress input space, uncovering patterns of self-similarity. They introduce a new metric for studying these transformations and present empirical results on benchmarks such as CantorNet and MNIST. |
|[World and Human Action Models towards gameplay ideation.](https://www.nature.com/articles/s41586-025-08600-3) | A state-of-the-art generative artificial intelligence model of a video game is introduced to allow the support of human creative ideation, with the analysis of user study data highlighting three necessary capabilities, namely, consistency, diversity and persistency.|


## News
|Link|description|
|---|---|
|[Grok 3 is Set to Be Released on Monday.](https://www.forbes.com/sites/larsdaniel/2025/02/16/elon-musks-scary-smart-grok-3-release--what-you-need-to-know/) |xAI's Grok 3, trained with 200 million GPU-hours, features improved reasoning, self-correction, and training with synthetic data. It is scheduled for release on Monday. |
|[Anthropic and UK Government Sign AI Collaboration MOU.](https://www.anthropic.com/news/mou-uk-government) |Anthropic has teamed up with the UK government to investigate AI applications in public services, focusing on responsible deployment, economic growth, and scientific research through its Claude model. |
|[OpenAI tries to ‚Äòuncensor‚Äô ChatGPT.](https://techcrunch.com/2025/02/16/openai-tries-to-uncensor-chatgpt/) |OpenAI is changing how it trains AI models to explicitly embrace ‚Äúintellectual freedom ‚Ä¶ no matter how challenging or controversial a topic may be,‚Äù the company says in a new policy. |
|[Bolt.new introduces AI app generation for iOS and Android.](https://www.youtube.com/watch?v=iCwxkm2PkQE&ab_channel=Expo) |StackBlitz, known for its AI tool Bolt.new, has launched an AI mobile app developer in collaboration with Expo. Users can describe their app idea in natural language, and Bolt's AI will instantly generate code for full-stack iOS and Android apps. |
|[Google and Ireland Celebrate Insight AI Scholarship.](https://blog.google/around-the-globe/google-europe/taoiseach-visits-google-to-celebrate-the-future-of-irelands-tech-talent/) | Google hosts Irish officials to celebrate the Insight AI Scholarship, which supports students from underrepresented backgrounds in developing AI and digital skills.|
|[Anthropic Calls for Urgency in AI Governance.](https://www.anthropic.com/news/paris-ai-summit) |At the Paris AI Action Summit, Anthropic highlighted the importance of democratic nations leading AI development, addressing security risks, and managing the economic disruptions brought about by advanced AI models. |
|[OpenAI‚Äôs Operator agent helped me move, but I had to help it, too.](https://techcrunch.com/2025/02/04/openais-operator-agent-helped-me-move-but-i-had-to-help-it-too/) | OpenAI gave me one week to test its new AI agent, Operator, a system that can independently do tasks for you on the internet.|
|[S Korea removes Deepseek from app stores over privacy concerns.](https://www.bbc.com/news/articles/clyzym0vn8go) | South Korea has banned new downloads of China's DeepSeek artificial intelligence (AI) chatbot, according to the country's personal data protection watchdog.|
|[fal Raises $49M Series B to Power the Future of AI Video.](https://blog.fal.ai/fal-raises-49m-series-b-to-power-the-future-of-ai-video/) | Fal has raised $49M in Series B funding, led by Notable Capital, with participation from a16z and others, bringing its total funding to $72M. The company is working on growing its platform for AI-powered generative media, particularly in video content, targeting sectors such as advertising and gaming. Fal‚Äôs unique technology ensures quick, scalable, and dependable deployments, which has already drawn enterprise customers like Quora and Canva.|
|[US' First Major AI Copyright Ruling.](https://www.jdsupra.com/legalnews/surprise-move-judge-walks-back-ai-6219521/) |A U.S. judge determined that Ross Intelligence violated Thomson Reuters' copyright by using Westlaw headnotes to train its AI. This ruling could impact other AI-related copyright cases but is primarily focused on non-generative AI applications. |
|[ChatGPT comes to 500,000 new users in OpenAI‚Äôs largest AI education deal yet.](https://arstechnica.com/ai/2025/02/chatgpt-comes-to-500000-new-users-in-openais-largest-ai-education-deal-yet/) |On Tuesday, OpenAI announced plans to introduce ChatGPT to California State University's 460,000 students and 63,000 faculty members across 23 campuses, reports Reuters. The education-focused version of the AI assistant will aim to provide students with personalized tutoring and study guides, while faculty will be able to use it for administrative work. |
|[Tinder will try AI-powered matching as the dating app continues to lose users.](https://techcrunch.com/2025/02/06/tinder-will-try-ai-powered-matching-as-the-dating-app-continues-to-lose-users/) | Tinder hopes to reverse its ongoing decline in active users by turning to AI. In the coming quarter, the Match-owned dating app will roll out new AI-powered features for discovery and matching. |
|[Google is adding digital watermarks to images edited with Magic Editor AI.](https://techcrunch.com/2025/02/06/google-is-adding-digital-watermarks-to-images-edited-with-magic-editor-ai/) |Google on Thursday announced that effective this week, it will begin adding a digital watermark to images in Photos that are edited with generative AI. The watermark applies specifically to images that are altered using the Reimagine feature found in Magic Editor on Pixel 9 devices. |
|[Meta plans to link US and India with world‚Äôs longest undersea cable project.](https://www.theguardian.com/technology/2025/feb/17/meta-plans-to-build-worlds-longest-underwater-sub-sea-cable-venture) | Project Waterworth, which involves cable longer than Earth‚Äôs circumference, to also reach South Africa and Brazil|
|[Amazon accused of targeting Coventry union members after failed recognition vote.](https://www.theguardian.com/technology/2025/feb/16/amazon-accused-of-targeting-coventry-union-members-after-failed-recognition-vote) |GMB says 60 workers have been targeted, with disciplinary action increasing significantly, but company denies claims |
|[Humane‚Äôs AI Pin is dead, as HP buys startup‚Äôs assets for $116M.](https://techcrunch.com/2025/02/18/humanes-ai-pin-is-dead-as-hp-buys-startups-assets-for-116m/?utm_source=tldrai) |Humane announced on Tuesday that most of its assets have been acquired by HP for $116 million. The hardware startup is immediately discontinuing sales of its $499 AI Pins. Humane alerted customers who have already purchased the Pin that their devices will stop functioning before the end of the month ‚Äî at 12 p.m. PST on February 28, 2025, according to a blog post.|
|[Mira announces Thinking Machine Labs.](https://thinkingmachines.ai/) |The former CTO of OpenAI, along with many highly skilled scientists and engineers, has come together to create a new AI company. While the goals are not entirely clear, it appears to be a company centered on both product and foundation models, with an emphasis on infrastructure. |
|[Meta is Launching LlamaCon.](https://www.meta.com/fr-fr/blog/connect-2025-llamacon-save-the-date/) |Meta is hosting LlamaCon, an open-source AI developer conference, on April 29. The event will highlight progress in the Llama AI model ecosystem, with Meta Connect scheduled for September to focus on XR and metaverse innovations. |
|[OpenAI considering 16 states for data center campuses as part of Trump‚Äôs Stargate project.](https://www.cnbc.com/2025/02/06/openai-looking-at-16-states-for-data-center-campuses-tied-to-stargate.html) |OpenAI is contemplating the construction of data center campuses in 16 states as part of President Trump's Stargate initiative, collaborating with Oracle, SoftBank, Microsoft, Nvidia, and Arm, with plans to invest up to $500 billion over four years. |
|[Academic researchers find a way to train an AI reasoning model for less than $50.](https://techxplore.com/news/2025-02-academic-ai.html) | Researchers at Stanford and the University of Washington have trained an AI reasoning model for under $50 using distillation and modifications to an Alibaba AI model.|
|[OpenAI now reveals more of its o3-mini model‚Äôs thought process.](https://techcrunch.com/2025/02/06/openai-now-reveals-more-of-its-o3-mini-models-thought-process/) |In response to pressure from rivals including Chinese AI company DeepSeek, OpenAI is changing the way its newest AI model, o3-mini, communicates its step-by-step ‚Äúthought‚Äù process. |
|[DeepMind AI crushes tough maths problems on par with top human solvers.](https://www.nature.com/articles/d41586-025-00406-7) |The company‚Äôs AlphaGeometry 2 reaches the level of gold-medal students in the International Mathematical Olympiad. |
|[Microsoft unveils chip it says could bring quantum computing within years.](https://www.theguardian.com/technology/2025/feb/19/topoconductor-chip-quantum-computing-topological-qubits-microsoft) |Chip is powered by world‚Äôs first topoconductor, which can create new state of matter that is not solid, liquid or gas |
|[EU accused of leaving ‚Äòdevastating‚Äô copyright loophole in AI Act.](https://www.theguardian.com/technology/2025/feb/19/eu-accused-of-leaving-devastating-copyright-loophole-in-ai-act) |Architect of copyright law says EU is ‚Äòsupporting big tech instead of protecting European creative ideas‚Äô |
|[Spotify Collaborates with ElevenLabs to Enhance AI-Narrated Audiobooks.](https://newsroom.spotify.com/2025-02-20/spotify-opens-up-support-for-elevenlabs-audiobook-content/) | Spotify now enables audiobooks narrated using ElevenLabs' AI voice technology, allowing authors to upload AI-narrated works via Findaway Voices. The feature supports narration in 29 languages, though publishing requires approval through a review process.|
|[Together AI Announces $305M Series B.](https://www.together.ai/blog/together-ai-announcing-305m-series-b) |Together AI has raised $305 million in a Series B funding round led by General Catalyst and Prosperity7, with contributions from investors like NVIDIA and Salesforce Ventures. This investment will strengthen Together AI's leadership in AI Cloud solutions, focusing on open-source AI models and NVIDIA Blackwell GPU deployment. The platform supports efficient AI application development, providing enterprise-grade inference, training, and model fine-tuning, with planned infrastructure expansions to accommodate rapid ecosystem growth. |
|[The Future of Legal Work with Eudia.](https://www.eudia.com/blog/the-augmented-intelligence-era-unlocking-unlimited-potential-for-the-future-of-legal-work-with-eudia) | Eudia has raised $105 million in Series A funding to revolutionize legal operations with augmented intelligence, aiming to enhance legal teams' capabilities instead of replacing them. By collaborating with prominent Chief Legal Officers, Eudia seeks to streamline legal processes and transform legal departments from cost centers into strategic value drivers. This represents a major move towards AI-powered legal functions within Fortune 500 companies.|
|[Use Lens to search your screen while you browse on iOS.](https://blog.google/products/google-lens/lens-on-ios-ai-overviews/) | Google Lens now allows iPhone users to perform visual searches directly from their screen within Chrome or the Google app, using gestures like highlighting or tapping.|
|[Crypto and big tech‚Äôs backing pays off as Trump makes tech-friendly moves.](https://www.theguardian.com/technology/2025/feb/22/crypto-big-tech-trump) |Flurry of directives relaxes regulations and drop lawsuit ‚Äì and billionaires who donated to Trump are ready to benefit |
|[Don‚Äôt gift our work to AI billionaires: Mark Haddon, Michal Rosen and other creatives urge government.](https://www.theguardian.com/technology/2025/feb/23/dont-gift-our-work-to-ai-billionaires-mark-haddon-michal-rosen-and-other-creatives-urge-government) |More than 2,000 cultural figures challenge Whitehall‚Äôs eagerness ‚Äòto ¬≠wrap our lives‚Äô work in attractive paper for automated competitors‚Äô |
|[‚ÄòThe bot asked me four times a day how I was feeling‚Äô: is tracking everything actually good for us?](https://www.theguardian.com/lifeandstyle/2025/feb/22/the-bot-asked-me-four-times-a-day-how-i-was-feeling-is-tracking-everything-actually-good-for-us) | Gathering data used to be a fringe pursuit of Silicon Valley nerds. Now we‚Äôre all at it, recording everything from menstrual cycles and mobility to toothbrushing and time spent in daylight. Is this just narcissism redesigned for the big tech age?|


## Resources
|Link|description|
|---|---|
|[CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction.](https://arxiv.org/abs/2502.07316) |CodeI/O enhances reasoning in large language models by transforming code into an input-output prediction format. This improves performance on various reasoning tasks by teaching universal reasoning principles without depending on code syntax. Additional refinement through multi-turn revisions increases accuracy by validating predictions. |
|[A Multiple Instance Learning Framework.](https://arxiv.org/abs/2502.08391v1) |A new multiple instance learning framework for whole slide image classification presents a dual-scale vision-language approach, utilizing a prototype-guided patch decoder and a context-guided text decoder to improve model performance on pathology tasks. |
|[Self contained FSDP implementation.](https://github.com/facebookresearch/capi/blob/main/fsdp.py) |A single 500 line implementation of data parallel that gets 48MFU. |
|[FinRL-DeepSeek - new trading AI agents combining Reinforcement Learning with Large Language Models.](https://melwy.com/finrl_deepseek) | Researchers combine reinforcement learning and large language models to improve risk-sensitive trading strategies, enhancing CPPO with LLM-generated risk assessments and trading recommendations, tested on Nasdaq-100 financial data.|
|[AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection.](https://arxiv.org/abs/2502.09254v1) |A new graph foundation model, AnomalyGFM, enhances zero- and few-shot anomaly detection by learning graph-agnostic representations, allowing for improved generalization across various datasets. |
|[DeepSeek tool prompts.](https://github.com/deepseek-ai/DeepSeek-R1/pull/399/files) |DeepSeek doesn't use system prompts, but they do use search and other prompts. |
|[Mistral Saba.](https://mistral.ai/en/news/mistral-saba) | Mistral Saba is a 24B parameter model developed using carefully selected datasets from the Middle East and South Asia. It delivers more precise and pertinent responses compared to models that are more than five times its size, all while being much quicker and more cost-effective.|
|[A Judge-free LLM Open-ended Generation Benchmark Based on the Distributional Hypothesis.](https://arxiv.org/abs/2502.09316v1) | Researchers have introduced a benchmark to evaluate LLM open-ended text generation using n-gram statistics and rules, eliminating the need for human or LLM-based assessments. This method closely aligns with GPT-4o evaluations while being computationally efficient.|
|[Speeding Up LLM Inference with CopySpec.](https://arxiv.org/abs/2502.08923v1) |CopySpec is a technique that speeds up LLM inference by detecting and duplicating repeated sequences in chat history without using additional GPU memory. It delivers up to a 3.08x performance boost on certain tasks and works well with speculative decoding to provide further improvements. |
|[Step Audio Chat.](https://huggingface.co/stepfun-ai/Step-Audio-Chat) |This is the Multimodal Large Language Model (LLM) part of Step-Audio. It is a 130-billion-parameter multimodal LLM designed to comprehend and generate human speech. The model is built to smoothly combine functions like speech recognition, semantic understanding, dialogue management, voice cloning, and speech generation. |
|[AdaVLN.](https://github.com/dillonloh/adavln) | AdaSimulator provides a physics-enabled environment for studying Visual Language Navigation (VLN) in realistic settings.|
|[SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?](https://arxiv.org/abs/2502.12115) | SWE-Lancer is a comprehensive benchmark featuring over 1,400 freelance software engineering tasks from Upwork, with a total value of $1 million USD in real-world payouts. It includes both independent engineering tasks‚Äîranging from $50 bug fixes to $32,000 feature implementations‚Äîand managerial tasks, where models select between different technical implementation proposals. The highest-performing models earned $400k.|
|[Selective Task Group Updates for Multi-Task Optimization.](https://arxiv.org/abs/2502.11986) | A new multi-task learning approach reduces negative transfer by dynamically grouping tasks and updating them sequentially during training. This method, which leverages proximal inter-task affinity, greatly enhances performance compared to existing multi-task optimization methods.|
|[LLM-Guided Reinforcement Learning.](https://arxiv.org/abs/2502.11896) |CAMEL enhances reinforcement learning efficiency by combining LLM-generated suboptimal policies with dynamic action masking. |
|[R1 1776.](https://huggingface.co/perplexity-ai/r1-1776) | Perplexity has post-trained R1 to remove Chinese censorship. They do so in a way that doesn't harm underlying reasoning. It is Perplexity's first open weights release.|
|[Google's Flood Hub Features.](https://blog.google/technology/ai/advanced-flood-hub-features-for-aid-organizations-and-governments/) |Google is launching new tools for flood experts in Flood Hub, such as an inundation history map and a basin view, while partnering with aid organizations like GiveDirectly and the IRC to support communities impacted by floods. |
|[Grok 3 Overview.](https://www.analyticsvidhya.com/blog/2025/02/grok-3/) | This article provides a comprehensive overview of xAI's Grok 3.|
|[Reinforcement Learning Quickstart Guide.](https://x.com/jsuarez5341/status/1854855861295849793) |An excellent X article by the PufferLib maintainer that explores the key differences between types of RL and provides a helpful guide for base hyperparameters. |
|[Artificial intelligence for modelling infectious disease epidemics.](https://www.nature.com/articles/s41586-024-08564-w) | This Perspective considers the application to infectious disease modelling of AI systems that combine machine learning, computational statistics, information retrieval and data science.|
|[A vision‚Äìlanguage foundation model for precision oncology.](https://www.nature.com/articles/s41586-024-08378-w) |Trained on unlabelled, unpaired image and text data, the Multimodal transformer with Unified maSKed modeling excelled in outcome prediction, image-to-text retrieval and visual question answering, potentially improving cancer diagnosis and therapy precision. |
|[Qwen 2.5 VL Technical Report.](https://arxiv.org/abs/2502.13923) |Report for the strongest open weights vision language model from the Qwen team. |
|[End to end driving RL model trained with Gaussian Splats.](https://arxiv.org/abs/2502.13144) |An intriguing proof-of-concept paper demonstrates the use of photorealistic environments rendered with 3D Gaussian splats, achieving a 3x reduction in collision rates overall. |
|[Model-Guidance for Diffusion Models.](https://arxiv.org/abs/2502.12154v1) |This paper presents Model-Guidance (MG), an objective that enhances diffusion model training by integrating posterior probabilities, leading to faster training, more efficient inference, and state-of-the-art performance on ImageNet 256 benchmarks. |
|[Crawl4LLM.](https://github.com/cxcscmu/Crawl4LLM) | Most data from web crawls is discarded due to poor text extraction performance. This work significantly improves the number of documents retained, using them to train stronger models with just a fraction of the crawled data.|
|[Open Reasoner Zero.](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero) |Open replication of the zero reasoning paradigm. It is fully open-source with training data, scripts, and weights. |
|[LLM-Oasis.](https://github.com/Babelscape/LLM-Oasis) | LLM-Oasis is a large-scale dataset created to train and evaluate systems that assess the factual accuracy of outputs from LLMs.|
|[Flex 1 image generation model.](https://huggingface.co/ostris/Flex.1-alpha) |An intriguing side project from the community, this model is fine-tuned from Flux Schnell and is Apache licensed. It is designed to be fine-tuned at 8B parameters, running efficiently without compromising performance. |
|[Meta PyTorch Team 2025 H1 Roadmaps.](https://dev-discuss.pytorch.org/t/meta-pytorch-team-2025-h1-roadmaps/2794) |Development roadmap for the next year for the PyTorch compilation team. |
|[OllamaTalk.](https://github.com/shinhyo/OllamaTalk) | A nice flutter app that provides a simple front end to Ollama.|


## Perspectives
|Link|description|
|---|---|
|[Red Hat's take on open-source AI: Pragmatism over utopian dreams.](https://www.zdnet.com/article/red-hats-take-on-open-source-ai-pragmatism-over-utopian-dreams/) |Red Hat advocates for a practical approach to open-source AI, concentrating on real-world enterprise needs rather than pursuing AGI. The challenges involve balancing transparency with competitive concerns, particularly around the lack of clarity in open-source AI‚Äôs training data and model weights. Red Hat seeks to promote collaboration and prevent vendor lock-in, while recognizing the greater complexities of AI compared to traditional open-source software. |
|[The EU AI Act is Coming to America.](https://www.hyperdimensional.co/p/the-eu-ai-act-is-coming-to-america) | While federal leaders appear cautious about imposing strict AI regulations, several U.S. states are introducing laws based on Europe‚Äôs AI Act. This article discusses how "algorithmic discrimination" laws, influenced by EU regulations, could introduce detailed impact assessments, demand compliance documentation, and hold AI deployments liable‚Äîpotentially leading to higher operational costs for teams developing AI systems. |
|[Biggest-ever AI biology model writes DNA on demand.](https://www.nature.com/articles/d41586-025-00531-3) |An artificial-intelligence network trained on a vast trove of sequence data is a step towards designing completely new genomes. |
|[A giant leap for machine translation could be even bigger.](https://www.nature.com/articles/d41586-025-00497-2) |The SEAMLESSM4T speech- and text-translation tool published in January represents a major advance for multilingual and multimodal machine translation.|
|[An AI Alchemist and His DeepSeek Journey.](https://craftedminds.substack.com/p/an-ai-alchemist-and-his-deepseek) |Wenfeng Liang, a hedge fund manager, founded DeepSeek, a self-funded open-source AI platform that has quickly gained global recognition for its innovative LLMs like DeepSeek-R1, which rival OpenAI's models. By utilizing more affordable training methods and consumer-grade hardware, DeepSeek has attracted interest from both major tech companies and smaller institutions. Liang's emphasis on open-source AI development, supported by his success with Magic Square Quantitative, prioritizes collaboration and technological advancement over commercial motivations. |


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme61.jpg)

[Back to index](#Index)


# ML news: Week 10 - 16 February

## Research
|Link|description|
|---|---|
|[s1: Simple test-time scaling.](https://arxiv.org/abs/2501.19393) | Researchers from Stanford, UW, and others introduced s1, a method to enhance LLM performance by using additional compute during inference ("test-time scaling"). Key ideas include: Small but effective dataset ‚Äì They created s1K, a set of 1,000 challenging questions with detailed reasoning, to fine-tune a 32B model. Despite the small size, it provides valuable reasoning examples. "Budget forcing" for reasoning ‚Äì A new decoding method adds the token "Wait" when the model attempts to stop, encouraging it to rethink and correct its reasoning. It also limits excessive reasoning to control inference time. Significant improvements over OpenAI‚Äôs o1 ‚Äì The fine-tuned model (s1-32B), based on Qwen2.5-32B-Instruct, outperforms OpenAI's o1-preview by up to 27% on math competitions (MATH & AIME24). Test-time scaling increases accuracy on AIME24 from 50% to 57%, exceeding its normal performance.|
|[OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models.](https://arxiv.org/abs/2502.01061) |ByteDance AI Lab introduced OmniHuman-1, a diffusion-transformer model that creates realistic human videos from a single image and motion input (audio or video). Key points: End-to-end human video generation ‚Äì OmniHuman uses an image and audio or video to generate lifelike videos of people speaking or performing actions, with impressive detail in motion, lighting, and texture. Mixed modality training ‚Äì Omni-Conditions Training combines various motion modalities during training, expanding data and overcoming the lack of high-quality talking-head videos. The model handles diverse inputs like speech, song, and complex poses. Outperforms prior methods ‚Äì OmniHuman produces more realistic videos and works with a variety of inputs, including cartoons or animals, transferring motion naturally. Broader support ‚Äì The model supports any portrait content (face, half-body, full-body) and multiple driving signals, offering more versatility than previous models. |
|[LIMO: Less is More for Reasoning.](https://arxiv.org/abs/2502.03387) |The LIMO paper challenges the need for large fine-tuning datasets in complex reasoning tasks, showing that a small set of carefully curated examples can be highly effective. With just 817 training samples, the LIMO model achieved impressive results, scoring 57.1% on the AIME math competition and 94.8% on MATH, far surpassing earlier models that required much more data. The model also demonstrated significant out-of-distribution generalization, outperforming models trained on 100 times more data by 40.5% on various benchmarks. The authors propose that when an LLM has strong pre-existing knowledge, only a minimal set of high-quality examples is necessary to unlock advanced reasoning skills. This suggests that small, well-designed datasets could enable state-of-the-art reasoning, lowering the barriers for fine-tuning LLMs. |
|[CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning.](https://arxiv.org/abs/2502.02390) |CoAT introduces a ‚Äúslow thinking‚Äù inference framework that enhances LLM reasoning by allowing it to explore and update its thoughts more like a human. The system combines Monte Carlo Tree Search (MCTS) with associative memory, enabling the model to explore different reasoning branches and dynamically add relevant information as needed. This iterative approach allows the model to refine and revisit intermediate conclusions, improving accuracy and comprehensiveness compared to one-pass reasoning. In experiments, CoAT outperformed traditional methods on accuracy, coherence, and solution diversity. By mimicking human-like problem-solving, CoAT points toward LLMs that use search and memory for more reliable reasoning. |
|[Syntriever: How to Train Your Retriever with Synthetic Data from LLMs.](https://arxiv.org/abs/2502.03824) |Syntriever introduces a two-stage framework to build a high-quality text retriever without relying on large labeled datasets or access to an LLM‚Äôs internals. In Stage 1, the system distills knowledge by generating synthetic Q&A data. A powerful LLM (e.g., GPT-4) is prompted to create relevant and incorrect passages, with chain-of-thought ensuring variety. The LLM then filters out any low-quality data, resulting in a synthetic dataset that is used to train the retriever. In Stage 2, the retriever is further aligned with the LLM‚Äôs preferences using a partial Plackett-Luce ranking method to adjust its ranking decisions. Syntriever achieves state-of-the-art results on several retrieval benchmarks without needing any real training queries, all training data is generated synthetically by the LLM. It also eliminates the need for logits, making it applicable even to closed models. |
|[Demystifying Long Chain-of-Thought Reasoning in LLMs.](https://arxiv.org/abs/2502.03373) | This study examines how LLMs develop extended chain-of-thought (CoT) reasoning, focusing on reinforcement learning (RL) and compute scaling. It finds that supervised fine-tuning (SFT) improves accuracy by using long CoT sequences, and introduces a cosine length-scaling reward with repetition penalties to stabilize RL and prevent unnecessary reasoning lengthening. RL models trained with noisy, web-based supervision signals generalize better to out-of-distribution tasks, though filtering is essential for stability. Additionally, while skills like error correction exist in base models, effective RL incentives are needed to harness them for complex tasks. This paper provides a roadmap for enhancing CoT training with RL and reward tuning.|
|[Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models Beneficial?](https://arxiv.org/abs/2502.00674) |This paper explores whether mixing different LLMs in an ensemble (Mixture-of-Agents, MoA) improves performance or if using a single top model‚Äôs outputs is more effective. The surprising answer is that "Self-MoA," which generates multiple outputs from one strong model and aggregates them, often outperforms multi-model ensembles. Extensive tests show that Self-MoA yields better results, with a +6.6% score improvement on the AlpacaEval 2.0 benchmark compared to MoA, and +3.8% on tasks like MMLU, CRUX, and MATH. The study finds that adding weaker models in an MoA can dilute performance, and unless all models are strong and complementary, it‚Äôs better to rely on one top model‚Äôs outputs. They also propose a sequential version of Self-MoA that efficiently combines multiple outputs over rounds. |
|[Multi-agent Architecture Search via Agentic Supernet.](https://arxiv.org/abs/2502.04180) | MaAS (Multi-agent Architecture Search) automates the design of multi-agent systems for LLMs, where agents collaborate with specific roles or tools for each task. Instead of hand-designing a complex pipeline, MaAS learns a flexible ‚Äúagentic supernet‚Äù that can generate an optimal agent team for each query. It defines a continuous space of possible agent configurations and dynamically selects the best one based on the query's domain and difficulty, allowing for efficient resource allocation. MaAS outperforms traditional multi-agent systems in accuracy by 0.5‚Äì11.8%, while using only 6‚Äì45% of the inference cost. Its approach also shows strong generalization, transferring well to new tasks and LLM backbones.|
|[Analyze Feature Flow to Enhance Interpretation and Steering in Language Models.](https://arxiv.org/abs/2502.03032) |This paper presents a new method for tracking the evolution of features discovered by sparse autoencoders across layers of large language models. Using a data-free cosine similarity technique, it maps feature persistence, transformation, and emergence. The paper shows how cross-layer feature maps allow for direct control of model behavior through feature manipulation, offering deeper mechanistic insights into model computations via detailed flow graphs. |
|[Building Bridges between Regression, Clustering, and Classification.](https://arxiv.org/abs/2502.02996) |This paper presents a new approach to enhancing neural network training for regression tasks by framing them as classification problems with a learned target encoder-decoder pair. The method surpasses traditional regression techniques by utilizing distributional target representation and enabling smooth interpolation across different objectives. |
|[Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach.](https://arxiv.org/abs/2502.05171) | A 3.5B model trained for latent reasoning shows significant improvements on math problems. The model utilizes a recurrent architecture.|
|[GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring.](https://arxiv.org/abs/2502.04891) |While maximizing spectral gap has been used to tackle over-squashing in GNNs, this paper demonstrates that minimizing it can also enhance generalization. The authors introduce three new rewiring strategies to improve label-community alignment, homophily, and computational efficiency. |
|[Agency Is Frame-Dependent.](https://arxiv.org/abs/2502.04403) |Determining if a system is "agentic" is challenging. This position paper from DeepMind suggests that measuring agency requires a set reference frame and cannot be considered a global property of a system. |
|[Improved LLM Pretraining.](https://arxiv.org/abs/2502.06733) | This paper introduces dynamic instance-level data reweighting techniques for LLM pretraining. By adjusting the importance of samples based on loss values during training, these methods enhance both efficiency and effectiveness.|
|[Competitive Programming with Large Reasoning Models.](https://arxiv.org/abs/2502.06807) | An OpenAI paper discusses the use of their o series of reasoning models in competitive programming. Initially, they had to rely on hand-crafted inference strategies, but later versions of o3 performed well without the need for human intervention.|
|[Scaling Pre-training to One Hundred Billion Data for Vision Language Models.](https://arxiv.org/abs/2502.07617) | DeepMind scaled vision-language model training to a much larger data scale than previously attempted. While performance on Western-centric tasks quickly reaches saturation, it continues to improve on diverse global tasks. Interestingly, this progress is seldom reflected in existing benchmarks.|
|[LLMs with Fewer Parameters.](https://github.com/joaopauloschuler/less-parameters-llm) |Researchers show that LLMs can retain their learning ability while cutting non-embedding parameters by as much as 77%. By substituting dense layers with optimized subnetworks, they achieve similar performance using far fewer resources. |


## News
|Link|description|
|---|---|
|[gambling firms secretly sharing users‚Äô data with Facebook without permission.](https://www.theguardian.com/society/2025/feb/08/gambling-firms-secretly-shared-users-data-with-facebook-without-permission) | Meta accounts of those affected flooded with ads for casinos and betting sites|
|[From Dogecoin to $Trump: everything you need know about the wild world of meme coins.](https://www.theguardian.com/technology/2025/feb/09/from-dogecoin-to-trump-everything-you-need-know-about-the-wild-world-of-meme-coins) | Are they the same as crypto, why has the US president launched one, and who‚Äôs really coining it in? Here‚Äôs a complete guide to the latest digital money mania|
|[Google Maps changed the way we get around. It all began in a spare bedroom in Sydney.](https://www.theguardian.com/technology/2025/feb/09/google-maps-turns-20-anniversary-feature) |This weekend the mapping platform turns 20 ‚Äì and Stephen Ma is writing himself and his friends back into its origin story |
|[‚ÄòMass theft‚Äô: Thousands of artists call for AI art auction to be cancelled.](https://www.theguardian.com/technology/2025/feb/10/mass-theft-thousands-of-artists-call-for-ai-art-auction-to-be-cancelled) |Letter says many of works being sold by Christie‚Äôs are made by AI models trained on pieces by human artists, without a licence |
|[Mistral le Chat.](https://mistral.ai/en/news/all-new-le-chat) |Mistral introduces a new chat assistant capable of processing 1,000 words per second. Powered by Mistral's advanced coding models, it features a user-friendly interface to help with a variety of tasks. |
|[Pika Video Editing.](https://pikartai.com/pikaddition/) |Pika Labs has launched Pikadditions, an AI tool that effortlessly adds objects and characters to videos, maintaining a high level of realism. |
|[Germany Trade & Invest: OpenAI Expands to Germany.](https://www.prnewswire.com/news-releases/germany-trade--invest-openai-expands-to-germany-302371354.html) |OpenAI announces plans to establish a new office in Munich in the coming months. |
|[Elon Musk-led group makes surprise bid of nearly $100bn for OpenAI.](https://www.theguardian.com/technology/2025/feb/10/elon-musk-open-ai-bid) |Sam Altman, OpenAI‚Äôs CEO and co-founder, responded that he would not accept and offered to buy X instead |
|[Macron touts Europe and trolls Trump at Paris AI summit.](https://www.theguardian.com/technology/2025/feb/10/macron-europe-trolls-trump-at-paris-ai-summit-us-uk) | ‚ÄòChoose Europe and France for AI,‚Äô says president amid speculation US and UK playing hardball over declaration|
|[AI chatbots distort and mislead when asked about current affairs, BBC finds.](https://www.theguardian.com/technology/2025/feb/11/ai-chatbots-distort-and-mislead-when-asked-about-current-affairs-bbc-finds) | Most answers had ‚Äòsignificant issues‚Äô when researchers asked services to use broadcaster‚Äôs news articles as source|
|[Tech firms call for zonal electricity pricing in UK to fuel AI datacentres.](https://www.theguardian.com/business/2025/feb/10/tech-firms-uk-electricity-zonal-pricing-ai-datacentres) |Report urges ministers to overhaul market to increase rollout in areas that have ample power generation |
|[OpenAI Introduces the Intelligence Age.](https://openai.com/global-affairs/introducing-the-intelligence-age/) | OpenAI emphasizes the swift adoption of ChatGPT and the broader impact of AI, drawing comparisons to past technological breakthroughs. Its Super Bowl ad portrays AI as the next significant tool for human progress, highlighting its role in enhancing creativity rather than replacing human effort.|
|[Macron announces $112B in AI investment over coming years.](https://www.aa.com.tr/en/europe/macron-announces-112b-in-ai-investment-over-coming-years/3477218) |French President Macron unveiled a significant AI investment to foster innovation and international collaboration. He stressed that AI should serve as an assistant, not a job replacer, with a particular emphasis on its applications in healthcare. |
|[Ilya Sutskever‚Äôs startup in talks to fundraise at roughly $20B valuation.](https://techcrunch.com/2025/02/07/report-ilya-sutskevers-startup-in-talks-to-fundraise-at-roughly-20b-valuation/) |Safe Superintelligence, the AI startup founded by former OpenAI chief scientist Ilya Sutskever, is in talks to raise funding at a valuation of ‚Äúat least‚Äù $20 billion, according to Reuters. |
|[If You Think Anyone in the AI Industry Has Any Idea What They're Doing, It Appears That DeepSeek Just Accidentally Leaked Its Users' Chats.](https://futurism.com/the-byte/deepseak-leaks-user-chatlogs) |Jiayi Pan and his team at UC Berkeley replicated DeepSeek's R1-Zero model for just $30, marking a move towards more cost-effective AI research. Their open-source model, "TinyZero," challenges the need for expensive AI infrastructures in big tech. This development raises important questions about the necessity of large-scale investments in AI. |
|[Team Says They've Recreated DeepSeek's OpenAI Killer for Literally $30.](https://futurism.com/researchers-deepseek-even-cheaper) | Jiayi Pan and his team at UC Berkeley recreated DeepSeek's R1-Zero model for just $30, demonstrating a move towards more affordable AI research. Their open-source model, "TinyZero," challenges the costly AI infrastructures of big tech, prompting questions about the need for large-scale investments in AI.|
|[OpenAI says its models are more persuasive than 82 percent of Reddit users.](https://arstechnica.com/ai/2025/02/are-ais-getting-dangerously-good-at-persuasion-openai-says-not-yet/) |OpenAI tested ChatGPT's persuasiveness on Reddit's ChangeMyView forum and found that its AI models were more persuasive than humans in 82% of comparisons, although they still fall short of "superhuman" levels. The company cautions that if AI reaches near-zero-cost human-level persuasive writing, it could contribute to biased journalism and scams. OpenAI is taking steps to monitor and mitigate AI-based persuasion, especially in areas like political influence and large-scale manipulation. |
|[AI Company Asks Job Applicants Not to Use AI in Job Applications.](https://www.404media.co/anthropic-claude-job-application-ai-assistants/) |Anthropic, the developer of the conversational AI assistant Claude, doesn‚Äôt want prospective new hires using AI assistants in their applications, regardless of whether they‚Äôre in marketing or engineering. |
|[Meta says it may stop development of AI systems it deems too risky.](https://techcrunch.com/2025/02/03/meta-says-it-may-stop-development-of-ai-systems-it-deems-too-risky/) | in a new policy document, Meta suggests that there are certain scenarios in which it may not release a highly capable AI system it developed internally.|
|[How Harrison Ford brought a strike over video game AI to the world‚Äôs attention.](https://www.theguardian.com/games/2025/feb/12/how-harrison-ford-brought-a-strike-over-use-of-ai-in-video-games-to-the-worlds-attention) | Voice actors demanding compensation when AI generates performances from their work have taken industrial action since July|
|[Elon Musk's $97.4 Billion Offer for OpenAI Rejected.](https://www.wjbf.com/news/ap-top-headlines/ap-how-elon-musk-97-4-billion-bid-complicates-matters-for-openai/) | Sam Altman has rejected Elon Musk's $97.4 billion bid for OpenAI, stating, "We are not for sale." This latest development intensifies the ongoing power struggle between the two AI leaders.|
|[Apple teams up with Alibaba to bring AI features for iPhones in China, The Information reports.](https://www.reuters.com/technology/apple-partners-with-alibaba-develop-ai-features-iphone-china-information-reports-2025-02-11/) |Apple is partnering with Alibaba to introduce AI-powered features to iPhones in China, aiming to tackle market challenges and compete with Huawei's AI-integrated smartphones. |
|[Snap unveils AI text-to-image model for mobile devices.](https://techcrunch.com/2025/02/04/snap-unveils-ai-text-to-image-model-for-mobile-devices/) |Snap has unveiled an AI text-to-image research model for mobile devices that will power some of Snapchat‚Äôs features in the coming months. The company said on Tuesday that the model can produce high-resolution images in around 1.4 seconds on an iPhone 16 Pro Max.  |
|[OLMoE, meet iOS.](https://allenai.org/blog/olmoe-app) | Allen AI has released a tiny yet extremely powerful open-source model on an app, running locally. It outperforms the original ChatGPT model from a few years ago.|
|[Democratize Intelligence: A Network of Top Builders creating Open AI.](https://www.demi.so/) | Over 300 AI builders, including Chris Lattner (Creator of Swift/LLVM) and Amjad Masad (Founder of Replit), gathered in San Francisco for the Democratize Intelligence Summit (DEMI). DEMI aims to counter the centralization of closed AI by bringing together innovative builders working on alternative hardware chips, software frameworks, and economic models that make AI more accessible to build and use.|
|[Google I/O 2025 Announced.](https://blog.google/feed/google-io-2025-save-the-date/) |Google I/O will be held on May 20-21 at Shoreline Amphitheatre and online, featuring keynotes, product reveals, AI innovations, and hands-on sessions. |
|[Luma unveils Image to Video model.](https://x.com/LumaLabsAI/status/1889003847260979440) |Luma AI has launched a new model that elevates image-to-video generation, offering unmatched natural motion, realistic physics, and coherence. |
|[Ai2 says its new AI model beats one of DeepSeek‚Äôs best.](https://techcrunch.com/2025/01/30/ai2-says-its-new-ai-model-beats-one-of-deepseeks-best/) |On Thursday, Ai2, a nonprofit AI research institute based in Seattle, released a model that it claims outperforms DeepSeek V3, one of Chinese AI company DeepSeek‚Äôs leading systems. |
|[Data analytics startup Athenic AI wants to be an enterprise‚Äôs central nervous system.](https://techcrunch.com/2025/01/30/data-analytics-startup-athenic-ai-wants-to-be-an-enterprises-central-nervous-system/) |Jared Zhao originally got interested in data analytics during his time at UC Berkeley because he was drawn to how it could turn raw data into a story. Zhao founded his first data analytics startup Polyture in 2021. But advancements in generative AI just a year later made Zhao realize what Polyture was building was too complicated for what users would be looking for in a post-ChatGPT world, and decided to change course. |
|[Harvey: Raises $300M Series D Led by Sequoia.](https://www.harvey.ai/blog/harvey-raises-series-d) | The legal AI startup Harvey raised a substantial sum in a funding round led by Sequoia to continue building tools for law firms.|
|[Apple Interested In Making Humanoid Robot, Top Analyst Says.](https://www.investors.com/news/technology/apple-stock-humanoid-robot-in-development/) |In a post on social network X on Wednesday, TF International Securities analyst Ming-Chi Kuo said Apple is exploring both humanoid and nonhumanoid robots as part of its future smart-home ecosystem. |
|[OpenAI's Roadmap for GPT-5.](https://threadreaderapp.com/thread/1889755723078443244.html) |OpenAI plans to release GPT-4.5 as its last non-chain-of-thought model before launching GPT-5, which will unify its o-series and GPT-series models. |
|[DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL.](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2) |Much of the research making dramatic claims is easily disproven, but this work stands out due to its solid methods. One interesting finding the researchers discovered is that by gradually increasing the context length during RL training, they were able to improve AIME performance smoothly without wasting compute. |
|[Google Expands AI-Powered Demand Gen Features.](https://blog.google/products/ads-commerce/new-demand-gen-features-2025/) |Google has rolled out new updates to Demand Gen campaigns, which feature enhanced customization capabilities, AI-powered creative enhancements, and more detailed product information. These improvements aim to boost ad performance, particularly on visual-centric platforms like YouTube. |
|[AI ‚Äògodfather‚Äô predicts another revolution in the tech in next five years.](https://www.theguardian.com/technology/2025/feb/04/ai-godfather-predicts-another-revolution-in-the-tech-in-next-five-years) |Meta‚Äôs Yann LeCun says current systems too limited to create domestic robots and fully automated cars |
|[DeepSeek: The countries and agencies that have banned the AI company‚Äôs tech.](https://techcrunch.com/2025/02/03/deepseek-the-countries-and-agencies-that-have-banned-the-ai-companys-tech/) | Corporations have banned DeepSeek, too ‚Äî by the hundreds. The biggest worry reportedly is potential data leakage to the Chinese government. According to DeepSeek‚Äôs privacy policy, the company stores all user data in China, where local laws mandate organizations to share data with intelligence officials upon request.|
|[Google removes pledge to not use AI for weapons from website.](https://techcrunch.com/2025/02/04/google-removes-pledge-to-not-use-ai-for-weapons-from-website/) | Google removed a pledge to not build AI for weapons or surveillance from its website this week. The change was first spotted by Bloomberg. |
|[Figure drops OpenAI in favor of in-house models.](https://techcrunch.com/2025/02/04/figure-drops-openai-in-favor-of-in-house-models/) |Figure AI has ended its collaboration with OpenAI to focus on developing in-house AI for humanoid robots. |
|[Global disunity, energy concerns and the shadow of Musk: key takeaways from the Paris AI summit.](https://www.theguardian.com/technology/2025/feb/14/global-disunity-energy-concerns-and-the-shadow-of-musk-key-takeaways-from-the-paris-ai-summit) |AI Action Summit ends with US vice-president criticising European regulation and warning against cooperation with China |
|[Elon Musk says he‚Äôll drop his $97bn bid for OpenAI if it remains a non-profit.](https://www.theguardian.com/technology/2025/feb/13/elon-musk-openai-non-profit) |Billionaire‚Äôs lawyers say offer will be withdrawn if firm he helped found a decade ago ‚Äòpreserves the charity‚Äôs mission‚Äô |
|[Veo 2 is Coming to YouTube Shorts.](https://blog.youtube/news-and-events/veo-2-shorts/) | YouTube has incorporated DeepMind's Veo 2 into Dream Screen, allowing users to create high-quality AI-generated video clips from text prompts.|
|[Adobe Firefly Video Model.](https://blog.adobe.com/en/publish/2025/02/12/meet-firefly-video-model-ai-powered-creation-with-unparalleled-creative-control) |Adobe has launched the Firefly Video Model, providing IP-compliant, commercially secure generative AI tools for creating video and audio content. |
|[Google AI and Women's Cancer Research.](https://blog.google/technology/health/google-ai-institute-womens-cancers/) |Google has teamed up with the Institute of Women's Cancers to advance AI-powered cancer research, with an emphasis on improving outcomes for breast and gynecological cancers. |
|[Billionaires talk automating jobs away.](https://techcrunch.com/2025/02/04/this-week-in-ai-billionaires-talk-automating-jobs-away/) |OpenAI is working with SoftBank to automate white-collar workflows with AI, raising concerns about widespread job losses. OpenAI also released a new AI agent for research and the o3-mini reasoning model, while the EU imposed a ban on high-risk AI systems. In addition, ByteDance's YuE model creates music from prompts, and Anthropic unveiled Constitutional Classifiers to improve AI safety protocols. |
|[EU puts out guidance on uses of AI that are banned under its AI Act.](https://techcrunch.com/2025/02/04/eu-puts-out-guidance-on-uses-of-ai-that-are-banned-under-its-ai-act/) |The EU's AI Act compliance deadline has passed, leading the Commission to issue guidance for developers on how to comply with the new AI regulations. Violations of banned use cases, like social scoring, may result in heavy penalties. While the guidelines are intended to offer clarity, they are not legally enforceable, and formal adoption is still awaiting translation. |
|[OpenAI Updates Model Spec.](https://openai.com/index/sharing-the-latest-model-spec/) |OpenAI has published an updated Model Spec document under a CC0 license, emphasizing transparency, customizability, and intellectual freedom, while ensuring safety measures are in place. |
|[Deep Research comes to Gemini Android app.](https://9to5google.com/2025/02/04/gemini-deep-research-android) |Deep Research, Gemini's first agentic feature, is now available for Android, enabling multi-step web research with customizable plans. |
|[DeepSeek Gets an ‚ÄòF‚Äô in Safety From Researchers.](https://gizmodo.com/deepseek-gets-an-f-in-safety-from-researchers-2000558645) |Cisco tested DeepSeek's open-source model, DeepSeek R1, which was unable to defend against all 50 harmful behavior prompts from the HarmBench dataset. |
|[Arm looks to launch its own chip after landing Meta contract.](https://www.theguardian.com/business/2025/feb/14/arm-looks-to-launch-its-own-chip-after-landing-meta-contract) | Plan represents move away from SoftBank-owned group licensing its chip blueprints to firms such as Apple and Nvidia|


## Resources
|Link|description|
|---|---|
|[Advancing Reasoning in Large Language Models: Promising Methods and Approaches.](https://arxiv.org/abs/2502.03671) | This survey paper reviews emerging methods to enhance reasoning in LLMs, organizing them into categories such as prompting strategies, architectural innovations, learning paradigms, and evaluation challenges. Prompting strategies, like Chain-of-Thought and Self-Consistency, guide the model‚Äôs reasoning without changing its architecture, improving logical deduction and multi-step solutions. Architectural innovations, such as retrieval-augmented models and neuro-symbolic integration, provide LLMs with additional knowledge or structured reasoning processes. Learning paradigms, including fine-tuning on reasoning-specific datasets and reinforcement learning, improve the model's inherent reasoning skills. The paper also highlights evaluation challenges like hallucinations, robustness, and generalization, which need to be addressed for the next generation of reasoning-augmented LLMs.|
|[Text Data Augmentation for Large Language Models: A Comprehensive Survey of Methods, Challenges, and Opportunities.](https://arxiv.org/abs/2501.18845) | This survey explores text data augmentation techniques for LLMs, which are crucial due to their need for large training datasets. It categorizes augmentation methods into four types: (1) simple augmentation, involving basic text manipulations; (2) prompt-based augmentation, where LLMs generate new examples through specific prompts; (3) retrieval-based augmentation, which incorporates external knowledge to ground generated text; and (4) hybrid augmentation, combining multiple strategies. A key insight is that modern LLMs can generate high-quality synthetic data to enhance training, with careful prompt design expanding datasets effectively. The survey also covers post-processing techniques to refine augmented data, ensuring quality and accuracy. It concludes with discussions on common tasks for augmentation, evaluation methods, challenges such as maintaining data distribution integrity, and opportunities for future research. |
|[Deep Dive into LLMs.](https://www.youtube.com/watch?v=7xTGNNLPyMI&ab_channel=AndrejKarpathy) | Andrej Karpathy has released another highly educational video that explores various aspects of developing language models, including pre-training, hallucination mitigation, and post-training.|
|[A Dataset for Open 3D Understanding.](https://uco3d.github.io/) | A new object-centric dataset for 3D deep learning and 3D generative AI.|
|[QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search.](https://arxiv.org/abs/2502.02584v1) | QLASS presents a Q-guided stepwise search method for language agents that boosts decision-making by offering intermediate rewards. This approach improves inference efficiency and minimizes the need for annotated data.|
|[Tackling Noisy Clients in Federated Learning with End-to-end Label Correction.](https://arxiv.org/abs/2408.04301v1) |FedELC is a two-stage framework aimed at improving federated learning by tackling the challenge of label noise in client datasets. |
|[audiobox-aesthetics.](https://github.com/facebookresearch/audiobox-aesthetics) |This repository includes models that evaluate audio files based on various metrics, making it useful for retrieval or as a signal for reinforcement learning rewards. |
|[PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-Agent Tasks.](https://github.com/facebookresearch/partnr-planner) |Facebook has created a toolkit for training systems that facilitate collaboration between humans and robots. |
|[Great Models Think Alike and this Undermines AI Oversight.](https://model-similarity.github.io/) | CAPA is a metric used to evaluate model similarity by analyzing shared errors.|
|[DynVFX: Augmenting Real Videos with Dynamic Content.](https://dynvfx.github.io/) |DynVFX excels at dynamic content insertion into videos, achieving impressive results with elements like water and smoke. However, it still has room for improvement when it comes to inserting character-based content. |
|[Synthetic People Dataset.](https://huggingface.co/datasets/argilla/FinePersonas-v0.1) | The Fine Personas dataset is a huge 21m person dataset extracted from fine-web-edu.|
|[QuEST: Stable Training of LLMs with 1-Bit Weights and Activations.](https://github.com/IST-DASLab/QuEST) | QuEST enables stable training with 1-bit weights and activations by enhancing two crucial aspects of Quantization-Aware Training (QAT). It achieves accurate and fast quantization of the continuous distributions of weights and activations using Hadamard normalization and MSE-optimal fitting. Additionally, it introduces a new trust gradient estimator that minimizes the error between the noisy gradient calculated over quantized states and the "true" (yet unknown) full-precision gradient.|
|[Diagen.](https://github.com/southbridgeai/diagen) |Agentic workflow for generating diagrams with language models. |
|[CursorCore: Assist Programming through Aligning Anything.](https://github.com/TechxGenus/CursorCore) | This work presents a new conversational framework for programming assistance that combines coding history, current code, and user instructions.|
|[Open R1: Update #2.](https://huggingface.co/blog/open-r1/update-2) |Hugging Face is openly replicating R1 and has successfully performed distillation on R1 to generate 800k reasoning traces. |
|[Temporally-Correlated Noise Prior for Diffusion Models.](https://warpyournoise.github.io/) | Diffusion model noise sampling is effective for single images but faces challenges when scaled to videos that require temporal consistency, as the noise is independent across pixels and frames, leading to warping artifacts. This work aims to introduce integral noise to address many of these issues.|
|[Open-Vocabulary Multi-Object Tracking Benchmark.](https://github.com/coo1sea/ovt-b-dataset) |OVT-B is a large-scale benchmark for open-vocabulary multi-object tracking (OVT), featuring over 1,000 object categories, nearly 2,000 videos, and more than 600,000 bounding box annotations. |
|[ESM2quinox.](https://github.com/patrick-kidger/esm2quinox) |ESM2 is a great protein folding model. This is a well-maintained version in a popular Jax package. |
|[Data Formulator.](https://github.com/microsoft/data-formulator) | A useful tool from Microsoft that leverages language models to generate charts and respond to dataset-related queries. It doesn't support local models, but functions effectively with an API key.|
|[Page Assist.](https://github.com/n4ze3m/page-assist) |One of many new tools for web browsing with local language models. |
|[Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE.](https://arxiv.org/abs/2502.06282) | Jakiro improves speculative decoding by utilizing Mixture of Experts to produce a variety of predictions, which reduces the correlation between candidates and boosts inference speed.|
|[Detecting Backdoor Samples in Contrastive Language Image Pretraining.](https://arxiv.org/abs/2502.01385v2) | Researchers have found that CLIP models are extremely susceptible to poisoning backdoor attacks, with attack success rates nearing 100% using very little poisoned data. They suggest an effective detection approach using local outlier detection to identify unintentional backdoors in current datasets.|
|[MobileLLM.](https://huggingface.co/collections/facebook/mobilellm-6722be18cb86c20ebe113e95) |Meta has released checkpoints for their small but mighty mobile friendly language models. |
|[Better Reasoning with Mask-Enhanced Autoregressive Prediction.](https://github.com/scitix/MEAP) | MEAP incorporates Masked Language Modeling into Next-Token Prediction through a decoder-only Transformer. By masking a small portion of input tokens, it enhances information retrieval tasks while preserving reasoning abilities.|
|[ComplexFuncBench.](https://github.com/thudm/complexfuncbench) |This repository contains benchmarks and tools for assessing AI models on complex function calls. |



## Perspectives
|Link|description|
|---|---|
|[Google's AI Policy Framework for Science.](https://blog.google/technology/ai/ai-future-of-scientific-leadership/) |Google has introduced a policy framework with practical steps for policymakers to speed up scientific discovery using AI, focusing on responsible deployment and fostering collaboration within the research community. |
|[Sam Altman Regrets Ditching Open Source, Says He's Been on the "Wrong Side of History".](https://futurism.com/sam-altman-open-source-wrong-side-history) | Chinese AI startup DeepSeek showcased its ability to replicate OpenAI's chatbots at a much lower cost, sparking renewed discussions on the open-source approach in the AI industry.|
|[Elon Musk owning OpenAI would be a terrible idea. That doesn‚Äôt mean it won‚Äôt happen.](https://www.theguardian.com/commentisfree/2025/feb/12/elon-musk-owning-openai-trump-ai-sam-altman) |My heart says he is settling scores and making mischief. My head fears Trump might like an ally controlling the key AI company |
|[AIs and Robots Should Sound Robotic.](https://spectrum.ieee.org/audio-deepfake-fix) | AI-generated voices can now closely mimic human speech, creating concerns about distinguishing them from real conversations. A suggested solution is to use a ring modulator in AI voices, giving them a distinct, recognizable robotic sound. Implementing this across voice synthesis technologies would help users identify when they are interacting with AI.|
|[Why is mathematics education failing some of the world‚Äôs most talented children?](https://www.nature.com/articles/d41586-025-00402-x) |A study shines a light on the remarkable arithmetic skills that young people acquire outside formal schooling. Education must evolve to enable them to fulfil their potential. |
|[How China created AI model DeepSeek and shocked the world.](https://www.nature.com/articles/d41586-025-00259-0) | Government policies, generous funding and a pipeline of AI graduates have helped Chinese firms create advanced LLMs.|
|[AI Keeps Its Own Time.](https://spectrum.ieee.org/mems-time) | SiTime's MEMS-based timekeeping device boosts AI efficiency by enhancing synchronization among various components, leading to notable energy savings. The Super-TCXO clock offers better synchronization than quartz components, helping improve bandwidth speed and lower idle times for GPUs. SiTime's technology is already incorporated into Nvidia's Spectrum-X Switch, with future developments focused on further energy efficiency and bandwidth improvements.|
|[Why AI Is A Philosophical Rupture.](https://www.noemamag.com/why-ai-is-a-philosophical-rupture/) |Tobias Rees contends that generative AI challenges traditional distinctions between humans and machines, introducing new types of intelligence that demand a philosophical reassessment. The ability of AI to function outside conventional comprehension frameworks indicates its potential to reshape human cognition and self-awareness. Rees calls for philosophical involvement in AI development to better understand and navigate this emerging era of human-AI collaboration. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme60.jpg)

[Back to index](#Index)

# ML news: Week 3 - 9 February

## Research
|Link|description|
|---|---|
|[Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs.](https://arxiv.org/abs/2501.18585) |This work examines the "thinking" patterns of o1-like LLMs in greater detail. Recent papers have highlighted issues related to overthinking, but now a new phenomenon, called underthinking, has been identified. What is it? The authors observe that o1-like LLMs often shift between different reasoning paths without fully exploring the most promising ones, which can hinder reaching the correct solution. |
|[Diverse Preference Optimization.](https://arxiv.org/abs/2501.18101) | Diverse Preference Optimization (DivPO) is a new training method that enhances the diversity of language model outputs without sacrificing quality. Unlike traditional approaches like RLHF, which often result in similar responses, DivPO selects diverse training pairs by comparing a highly diverse response with a less diverse one. It measures diversity using various criteria, such as model probability or word frequency. In tests on persona generation and creative writing, DivPO significantly increased output diversity while maintaining similar quality to existing methods.|
|[Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies.](https://arxiv.org/abs/2501.17030) |This paper offers a collection of guidelines for effectively prompting the DeepSeek-R1 model. Key recommendations include crafting clear and well-structured prompts with explicit instructions, avoiding few-shot prompting in favor of zero-shot approaches, and specifying the desired output format, such as JSON, tables, or markdown. For reasoning tasks, requesting step-by-step explanations is advised. Additionally, it is important to clearly define the input and output language to prevent mixing. The paper also covers the appropriate use cases for different model variants, the best times to fine-tune the model, and important safety considerations. |
|[Improving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning.](https://arxiv.org/abs/2501.15228) |This work approaches RAG as a multi-agent cooperative task to enhance answer generation quality. It treats components like query rewriting, document selection, and answer generation as reinforcement learning agents collaborating to produce accurate answers. Multi-Agent Proximal Policy Optimization (MAPPO) is used to optimize all agents together, with a shared reward based on answer quality. In addition to improvements on well-known benchmarks, the framework demonstrates strong generalization in out-of-domain scenarios and remains effective across various RAG system configurations. |
|[TensorLLM: Tensorising Multi-Head Attention for Enhanced Reasoning and Compression in LLMs.](https://arxiv.org/abs/2501.15674) |This framework introduces a method for compressing MHA through a multi-head tensorization process and Tucker decomposition. It achieves a compression rate of up to approximately 250x in MHA weights, without the need for additional data, training, or fine-tuning. |
|[TokenVerse: Versatile Multi-concept Personalization in Token Modulation Space.](https://arxiv.org/abs/2501.12224) |TokenVerse, introduced by Google DeepMind and collaborators, presents a new technique for generating images from learned concepts in a specific configuration. It enables multi-concept personalization by utilizing a pre-trained text-to-image diffusion model to separate and extract complex visual concepts from multiple images. Operating within the modulation space of DiTs, TokenVerse learns a personalized modulation vector for each text token in an input caption. This method provides flexible and localized control over distinct concepts like objects, materials, lighting, and poses. The learned token modulations can be combined in innovative ways to create new images that integrate multiple personalized concepts, all without the need for additional segmentation masks. |
|[AI to revolutionise fundamental physics and ‚Äòcould show how universe will end‚Äô.](https://www.theguardian.com/science/2025/feb/03/ai-to-revolutionise-fundamental-physics-and-could-show-how-universe-will-end) |Cern‚Äôs next director general Mark Thomson says AI is paving the way for huge advances in particle physics |
|[Was this the week DeepSeek started the slow unwinding of the AI bet?](https://www.theguardian.com/technology/2025/feb/01/was-this-the-week-deepseek-started-the-slow-unwinding-of-the-ai-bet) |The cheap Chinese chatbot has stunned tech giants ‚Äì and opened up the possibility that other countries, not just China, could now afford to enter the AI race |
|[A Controlled Study on Long Context Extension and Generalization in LLMs.](https://github.com/leooyii/lceg) | This study examines how language models manage long-document contexts by evaluating different extension methods through a controlled analysis. It emphasizes that perplexity continues to be a crucial performance metric, while approximate attention techniques face challenges with longer contexts.|
|[Constitutional Classifiers: Defending against universal jailbreaks.](https://www.anthropic.com/research/constitutional-classifiers) |A new paper from the Anthropic Safeguards Research Team outlines a method that protects AI models from universal jailbreaks. A prototype of this method proved resilient against thousands of hours of human red teaming for universal jailbreaks, though it had high over-refusal rates and significant compute overhead. An updated version maintained similar robustness in synthetic evaluations, with only a 0.38% increase in refusal rates and moderate additional compute costs. |
|[s1: Simple test-time scaling.](https://arxiv.org/abs/2501.19393) | A comprehensive and detailed paper investigates methods to encourage models to use more thinking tokens. One key finding is that by using a high-quality curated dataset of 1k examples and appending "wait" at the end of a thinking sequence, models can be encouraged to think for longer periods, resulting in significantly improved performance on math and reasoning tasks.|
|[Decoding-based Regression.](https://arxiv.org/abs/2501.19383v1) |DeepMind researchers examined how language models can handle regression tasks by interpreting numeric predictions as text, and found them to be as effective as traditional regression models, while also offering the added benefit of flexible density estimation. |
|[China unveils US tariffs and Google investigation in response to Trump levies.](https://www.theguardian.com/us-news/2025/feb/04/trump-china-tariffs) | Tariffs on coal, LNG, crude oil and other goods announced after US imposes levy on imports|
|[Harmonic Loss Trains Interpretable AI Models.](https://arxiv.org/abs/2502.01628) |Harmonic loss is an alternative to cross-entropy loss for training neural networks, providing better interpretability and faster convergence through scale invariance and finite convergence points. Experiments across algorithmic, vision, and language datasets show that models trained with harmonic loss outperform standard models in terms of interpretability, data efficiency, and reduced grokking. Harmonic loss could be especially useful for applications with limited data or where interpretability is essential. |
|[Vintix: Action Model via In-Context Reinforcement Learning.](https://arxiv.org/abs/2501.19400v1) | This study investigates scaling In-Context Reinforcement Learning (ICRL) to wider domains through Algorithm Distillation, demonstrating that ICRL can serve as a viable alternative to expert distillation for generalist decision-making systems.|
|[Efficient Reasoning with Hidden Thinking.](https://arxiv.org/abs/2501.19201v1) |Heima presents a framework for more efficient multimodal reasoning by compressing Chain-of-Thought processes into a single hidden token. |
|[Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models.](https://arxiv.org/abs/2412.16247) |Dictionary learning improves model interpretability and can uncover unknown concepts from scientific data, such as cell images. It effectively extracts concepts like cell type and genetic perturbation. A new algorithm, ICFL, combined with PCA whitening, boosts feature selectivity compared to existing methods. |
|[Parents sue TikTok over child deaths allegedly caused by ‚Äòblackout challenge‚Äô.](https://www.theguardian.com/technology/2025/feb/07/tiktok-sued-over-deaths-of-children-said-to-have-attempted-blackout-challenge) | Parents claim four children died as a result of attempting challenge that went viral in 2021|
|[Call to make tech firms report data centre energy use as AI booms.](https://www.theguardian.com/technology/2025/feb/07/call-to-make-tech-firms-report-data-centre-energy-use-as-ai-booms) |Experts say mandatory reporting on energy and water use is needed to avoid irreparable damage to environment |
|[Google edits Super Bowl ad for AI that featured false information.](https://www.theguardian.com/technology/2025/feb/06/google-edits-super-bowl-ad-for-ai-that-featured-false-information) |Tech company removes error about gouda cheese after blogger points out ‚Äòunequivocally‚Äô untrue statistic |


## News
|Link|description|
|---|---|
|[Inside the ‚ÄúVirtual Lab‚Äù where AIs and humans collaborate.](https://www.freethink.com/artificial-intelligence/virtual-lab-interdisciplinary-research) |Stanford's "Virtual Lab" employs AI agents as partners in scientific research, with the goal of addressing complex challenges through interdisciplinary collaboration. Researchers showcase its capabilities in projects such as creating COVID-19 treatments by simulating expert interactions among AI agents. This framework enables scientists to build AI-driven expertise, presenting a fresh approach to collaborative research and innovation. |
|[Alibaba‚Äôs Qwen team releases AI models that can control PCs and phones.](https://techcrunch.com/2025/01/27/alibabas-qwen-team-releases-ai-models-that-can-control-pcs-and-phones/) |Chinese AI lab DeepSeek might be getting the bulk of the tech industry‚Äôs attention this week. But one of its top domestic rivals, Alibaba, isn‚Äôt sitting idly by. |
|[Quartz has been quietly publishing AI-generated news articles.](https://techcrunch.com/2025/01/27/quartz-has-been-quietly-publishing-ai-generated-news-articles/) | Quartz has been employing AI to create articles by aggregating content from sources such as CNN and TechCrunch through its "Quartz Intelligence Newsroom."|
|[Zuckerberg Says Meta to Spend Up to $65 Billion on AI in ‚Äô25.](https://www.bnnbloomberg.ca/business/technology/2025/01/27/zuckerberg-says-meta-to-spend-up-to-65-billion-on-ai-in-25) | Meta plans to invest up to $65 billion in AI projects, build a massive data center, and expand AI teams by 2025.|
|[‚ÄòDear, did you say pastry?‚Äô: meet the ‚ÄòAI granny‚Äô driving scammers up the wall.](https://www.theguardian.com/money/2025/feb/04/ai-granny-scammers-phone-fraud) |Daisy‚Äôs dithering frustrates phone fraudsters and wastes time they could be using to scam real people |
|[OpenAI's Deep Research.](https://openai.com/index/introducing-deep-research/) |OpenAI has launched "Deep Research," an autonomous research agent within ChatGPT that can carry out multi-step research by synthesizing extensive online sources. It runs on an optimized version of the upcoming OpenAI o3 model. |
|[AI haters build tarpits to trap and trick AI scrapers that ignore robots.txt.](https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/) | Nepenthes is a tarpit malware created to trap and corrupt AI web crawlers that disregard robots.txt rules. The release of Nepenthes has led to the development of other tools, such as Iocaine, which aim to disrupt AI data collection and have a financial impact on the industry.|
|[Chinese AI firm DeepSeek has 50,000 NVIDIA H100 AI GPUs says CEO, even with US restrictions.](https://www.tweaktown.com/news/102798/chinese-ai-firm-deepseek-has-50-000-nvidia-h100-gpus-says-ceo-even-with-us-restrictions/index.html) | DeepSeek, a Chinese AI lab, utilized tens of thousands of NVIDIA H100 GPUs to develop its R1 model, positioning it as a competitor to leading AI models like OpenAI's o1 and Meta's Llama. |
|[Jack Dorsey‚Äôs Block has an AI agent too.](https://www.engadget.com/ai/jack-dorseys-block-has-an-ai-agent-too-212706083.html) | Jack Dorsey's Block has created an open-source AI agent called "codename goose" to automate engineering tasks using well-known LLMs.|
|[Google owner drops promise not to use AI for weapons.](https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons) | Alphabet guidelines no longer refer to not pursuing technologies that could ‚Äòcause or are likely to cause overall harm‚Äô|
|[AI ‚Äògodfather‚Äô predicts another revolution in the tech in next five years.](https://www.theguardian.com/technology/2025/feb/04/ai-godfather-predicts-another-revolution-in-the-tech-in-next-five-years) |Meta‚Äôs Yann LeCun says current systems too limited to create domestic robots and fully automated cars |
|[Google parent Alphabet‚Äôs earnings disappoint Wall Street amid stiff AI competition.](https://www.theguardian.com/technology/2025/feb/04/google-alphabets-q4-earnings) |Revenue slowdown reflects ‚Äòchallenging year‚Äô firm has had and 2025 may be year it loses competitive edge, say analysts |
|[Does AI need all that money? (Tech giants say yes).](https://www.theguardian.com/technology/2025/feb/04/ai-doomers-play-rfk-jr-seed-oils) | Meta and Microsoft commit to tens of billions to build out AI infrastructure, having lavished tens of billions already|
|[Google Q4 2024 Earnings: CEO Pichai Says DeepSeek Models Less ‚ÄòEfficient‚Äô Than Gemini‚Äôs.](https://www.crn.com/news/ai/2025/google-q4-2024-earnings-ceo-pichai-says-deepseek-models-less-efficient-than-gemini-s) | Sundar Pichai has downplayed the effectiveness of DeepSeek's AI models, claiming that Google's Gemini models, especially Gemini 2.0 Flash, outperform them, despite DeepSeek's disruptive influence on the AI market.|
|[US Copyright Office rules out copyright for AI created content without human input.](https://www.techspot.com/news/106562-us-copyright-office-rules-out-copyright-ai-created.html) |The US Copyright Office has stated that AI-generated works created without human involvement cannot be copyrighted. While AI tools that assist with creativity, such as de-aging actors, do not restrict copyright protection, purely generative AI outputs require additional examination. |
|[Who is Liang Wenfeng? DeepSeek founder comes from AI investing.](https://techcrunch.com/2025/01/28/who-is-liang-wenfeng-deepseek-founder-comes-from-ai-investing/) | DeepSeek's R1 reasoning model requires less computing power than its U.S. counterparts and is open source. The DeepSeek app even surpassed ChatGPT in App Store rankings. Founder Liang Wenfeng, who previously launched AI companies, also runs the hedge fund High-Flyer, which manages $8 billion and supports DeepSeek. Liang differentiates himself by offering the product for free and open source.|
|[Hugging Face researchers are trying to build a more open version of DeepSeek‚Äôs AI ‚Äòreasoning‚Äô model.](https://techcrunch.com/2025/01/28/hugging-face-researchers-are-trying-to-build-a-more-open-version-of-deepseeks-ai-reasoning-model/) |Barely a week after DeepSeek released its R1 ‚Äúreasoning‚Äù AI model ‚Äî which sent markets into a tizzy ‚Äî researchers at Hugging Face are trying to replicate the model from scratch in what they‚Äôre calling a pursuit of ‚Äúopen knowledge.‚Äù |
|[Meta AI can now use your Facebook and Instagram data to personalize its responses.](https://techcrunch.com/2025/01/27/meta-ai-can-now-use-your-facebook-and-instagram-data-to-personalize-its-responses/) |Meta is enhancing its AI chatbot with memory capabilities that will allow it to remember user details in conversations on Facebook, Messenger, and WhatsApp in the U.S. |
|[OpenAI‚Äôs new trademark application hints at humanoid robots, smart jewelry, and more.](https://techcrunch.com/2025/02/03/openais-new-trademark-application-hints-at-humanoid-robots-smart-jewelry-and-more/) | Last Friday, AI startup OpenAI filed a new application to trademark products associated with its brand ‚Äî ‚ÄúOpenAI‚Äù ‚Äî with the U.S. Patent and Trademark Office (USPTO). Normally, this wouldn‚Äôt be newsworthy. Companies file for trademarks all the time. But in the application, OpenAI hints at new product lines both nearer-term and of a more speculative nature.|
|[SoftBank-backed billionaire to invest $230M in Indian AI startup Krutrim.](https://techcrunch.com/2025/02/04/softbank-backed-billionaire-to-invest-230m-in-indian-ai-startup-krutrim/) | Ola founder Bhavish Aggarwal is investing $230 million into an AI startup he founded as the country pushes to establish itself in a field dominated by U.S. and Chinese firms.|
|[DeepSeek Gets an ‚ÄòF‚Äô in Safety From Researchers.](https://gizmodo.com/deepseek-gets-an-f-in-safety-from-researchers-2000558645) | Cisco tested DeepSeek's open-source model, DeepSeek R1, which failed to block all 50 harmful behavior prompts from the HarmBench dataset. DeepSeek's failure rate was the highest among the tested LLMs, with other models like Meta's Llama 3.1 and OpenAI's o1 performing significantly better. The model's vulnerability to attacks, coupled with data security concerns, has sparked considerable scrutiny and criticism.|
|[Sam Altman Says OpenAI Is Going to Deliver a Beatdown on DeepSeek.](https://futurism.com/sam-altman-openai-better-models-deepseek) |OpenAI's Sam Altman addressed the challenges posed by Chinese startup DeepSeek's R1 model, which outperformed competitors at lower costs, causing significant disruption in the tech industry. Altman pledged to maintain substantial investment in compute resources, highlighting OpenAI's ambition toward AGI. This situation raises concerns about the sustainability of OpenAI's expensive approach, given DeepSeek's more efficient alternatives. |
|[Chinese and Iranian Hackers Are Using U.S. AI Products to Bolster Cyberattacks.](https://www.msn.com/en-us/technology/artificial-intelligence/chinese-and-iranian-hackers-are-using-u-s-ai-products-to-bolster-cyberattacks/ar-AA1y37M3) | Hackers from countries like China, Iran, and others are using AI, particularly Google's Gemini, to enhance cyberattacks, viewing it as a productivity tool rather than a source of groundbreaking techniques. Google reports indicate that groups tied to these nations are using Gemini for research and phishing, with China and Iran being the most active users. While AI hasn't yet significantly altered the scale of cyberattacks, both the U.S. and China are making substantial investments in AI technologies for future dominance.|
|[Gemini can now do more complex data analysis in Google Sheets.](https://www.engadget.com/ai/gemini-can-now-do-more-complex-data-analysis-in-google-sheets-191218214.html) | Google Sheets' new AI-powered Gemini update provides enhanced data insights, generates charts, and analyzes contextual trends using Python.|
|[DeepSeek might have a trademark problem in the US.](https://techcrunch.com/2025/01/29/deepseek-might-have-a-trademark-problem-in-the-u-s/) |DeepSeek faces a U.S. trademark conflict as Delson Group claimed the "DeepSeek" trademark just before them. |
|[ChatGPT‚Äôs mobile users are 85% male, report says.](https://techcrunch.com/2025/01/29/chatgpts-mobile-users-are-85-male-report-says/) |AI app spending reached $1.42 billion in 2024, with ChatGPT dominating despite competition, leading to a 274% increase year-over-year. |
|[Trump administration suspends $5bn electric vehicle charging program.](https://www.theguardian.com/us-news/2025/feb/07/trump-electric-vehicle-charging-station-program) |Highway agency ordered states to no longer spend funds allocated under Biden‚Äôs EV charging station program |
|[UK demands ability to access Apple users‚Äô encrypted data.](https://www.theguardian.com/technology/2025/feb/07/uk-confronts-apple-with-demand-for-cloud-backdoor-to-users-encrypted-data) | Expert says government has ‚Äòlit the blue touch paper on a truly enormous fight‚Äô as it challenges firm‚Äôs privacy stance|
|[OpenAI co-founder John Schulman leaves Anthropic after just five months.](https://techcrunch.com/2025/02/06/openai-co-founder-john-schulman-leaves-anthropic-after-just-five-months/) | OpenAI co-founder and prominent AI researcher John Schulman has left Anthropic after five months, according to multiple reports.|
|[Lyft and Anthropic Partnership.](https://www.anthropic.com/news/lyft-announcement) | Lyft is partnering with Anthropic to integrate Claude-powered AI solutions, cutting customer service resolution times by 87% and improving the overall rideshare experience through AI-driven automation and engineering advancements. |
|[Copyright Office Offers Assurances on AI Filmmaking Tools.](https://variety.com/2025/biz/news/copyright-ai-tools-filmmaking-studios-office-1236288969/) |The U.S. Copyright Office clarified that AI-assisted creations can still be eligible for copyright protection, as long as they involve human authorship. |


## Resources
|Link|description|
|---|---|
|[OpenAI o3-mini.](https://cdn.openai.com/o3-mini-system-card.pdf) |OpenAI has introduced o3-mini, their latest cost-effective reasoning model, now available in ChatGPT and via API. This model excels in STEM tasks, particularly in science, math, and coding, while retaining the low cost and reduced latency of its predecessor, o1-mini. It also introduces important developer features such as function calling, Structured Outputs, and developer messages, ensuring it's production-ready from the start. o3-mini offers varying levels of reasoning effort (low, medium, and high) and enhances performance across a wide range of tasks. It provides responses 24% faster than o1-mini and has shown strong results in competition math, PhD-level science queries, and software engineering challenges. |
|[Qwen2.5-1M.](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-1M/Qwen2_5_1M_Technical_Report.pdf) |Qwen has released two open-source LLMs, Qwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M, capable of handling context lengths up to 1 million tokens. These models use a progressive training strategy, beginning with 4K tokens and gradually increasing to 256K tokens, before applying length extrapolation methods to achieve 1M tokens. They also offer an inference framework based on vLLM, which processes long inputs 3-7 times faster using sparse attention techniques. The models perform well on both long-context and short-text tasks. The 14B version surpasses GPT-4o-mini on several long-context datasets, while maintaining comparable results on shorter tasks. |
|[Janus-Pro.](https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf) |An upgraded version of the previous Janus model for multimodal understanding and generation has been released. This new model includes three major improvements: optimized training strategies with longer initial training and targeted fine-tuning, expanded training data with 90 million new samples for understanding and 72 million synthetic aesthetic samples for generation, and scaling up to larger model sizes of up to 7B parameters. Janus-Pro delivers notable enhancements in both multimodal understanding and text-to-image generation. It outperforms existing models across several benchmarks, scoring 79.2 on MMBench for understanding tasks and achieving 80% accuracy on GenEval for text-to-image generation. These advancements also improve image generation stability and quality, particularly for short prompts and intricate details, though the current 384x384 resolution limits performance for some tasks. |
|[Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion.](https://github.com/DS4SD/docling) | Docling is an open-source toolkit designed to convert various popular document formats into a unified, richly structured representation.|
|[PPTAgent: Generating and Evaluating Presentations Beyond Text-to-Slides.](https://arxiv.org/abs/2501.03936v1) | PPTAgent offers presentation generation through a two-stage, edit-based approach inspired by human workflows.|
|[1.58-bit FLUX.](https://arxiv.org/abs/2412.18653) | The 1.58-bit FLUX effectively quantizes the FLUX.1-dev text-to-image model with minimal weights, preserving its performance. This technique works without image data, depending on self-supervision. It greatly decreases model storage and memory usage, while enhancing inference speed.|
|[Phi-4.](https://huggingface.co/microsoft/phi-4) | Microsoft has released the benchmark topping synthetic data models on Hugging Face for commercial use due to the MIT license|
|[LLMs' Guardrails.](https://github.com/yueliu1999/guardreasoner) |GuardReasoner presents a reasoning-driven safeguard for LLMs, enhancing explainability and generalizability in safety-sensitive applications. It surpasses GPT-4o+CoT and LLaMA Guard 3 in various benchmarks. The training data, models, and code have been released to the public. |
|[aiMotive 3D Traffic Light and Traffic Sign Dataset.](https://github.com/aimotive/aimotive_tl_ts_dataset) |This project introduces a novel method for creating precise 3D bounding box annotations for traffic lights and road signs, which are essential for self-driving vehicles. |
|[OpenThoughts Dataset.](https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k) |A comprehensive synthetic reasoning dataset from R1, containing 114k examples of reasoning tasks, which can be utilized to train powerful reasoners through distillation or serve as a starting point for RL cold start. |
|[Diffusion Autoencoders are Scalable Image Tokenizers.](https://yinboc.github.io/dito/) |The current cornerstone of multimodal understanding and generation is learned tokenizers. These models are usually autoencoder-based with a learned discrete codebook. While they perform well, they are difficult to train and demand meticulous tuning of several auxiliary losses. This work demonstrates that with just a single diffusion loss, image tokenization becomes stable, scalable, and yields higher quality than many conventional methods. |
|[Kron Optimizer.](https://github.com/evanatyourservice/kron_torch) |Kron is a new optimizer gaining attention as a powerful alternative to second-order methods. It significantly outperforms Adam across several baselines. This code serves as a drop-in optimizer for PyTorch |
|[Oumi: Everything you need to build state-of-the-art foundation models.](https://github.com/oumi-ai/oumi) | Oumi is a completely open-source platform that simplifies the entire lifecycle of foundation models, from data preparation and training to evaluation and deployment. Whether you're working on a laptop, running large-scale experiments on a cluster, or deploying models in production, Oumi offers the tools and workflows required.|
|[RaySplats: Ray Tracing based Gaussian Splatting.](https://github.com/kbyrski/raysplatting) | RaySplats improves 3D Gaussian Splatting by incorporating ray tracing, enhancing the management of light and shadows in 3D object rendering, all while preserving fast training and rendering speeds.|
|[A Little Bit of Reinforcement Learning from Human Feedback.](https://rlhfbook.com/c/11-policy-gradients.html) | An excellent chapter on various policy gradient methods, such as PPO and GRPO, which can be applied to fine-tune generative auto-regressive models.|
|[Open-source DeepResearch ‚Äì Freeing our search agents.](https://huggingface.co/blog/open-deep-research) | Hugging Face tried to replicate OpenAI's Deep Research, an agent-based web-search framework that greatly enhanced performance on the GAIA benchmark, by conducting a 24-hour experiment with the goal of open-sourcing a similar system.|
|[The Surprising Agreement Between Convex Optimization Theory and Learning-Rate Scheduling for Large Model Training.](https://arxiv.org/abs/2501.18965) |Learning-rate schedules for large models align closely with theoretical bounds from non-smooth convex optimization. The authors present a bound for constant schedules with linear cooldown, demonstrating the practical advantages of cooldown by eliminating logarithmic terms in the bound. Their findings led to practical enhancements in training Llama-type models through optimal learning-rate extension and cross-schedule transfer. |
|[GOT OCR 2.0 Weights.](https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf) | One of the top OCR models is now accessible and integrated within the Hugging Face ecosystem. It performs excellently on both documents and sheet music.|
|[Open-Vocabulary Detection with LLMs.](https://github.com/isee-laboratory/llmdet) | LLMDet is an open-vocabulary detector that utilizes a large language model to improve caption generation and grounding, significantly enhancing performance over existing detectors.|
|[How to Scale Your Model.](https://jax-ml.github.io/scaling-book/) | An impressive post from the DeepMind team detailing the mental process behind scaling their model. They break it down into mathematical equations, enabling them to analyze the costs of each operation and ensure accuracy.|
|[Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines.](https://cnzzx.github.io/VSA/) |Vision Search Assistant is a framework that integrates Vision Language Models (VLMs) with web agents to enhance object recognition, even for images that are unfamiliar. |
|[MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion.](https://monst3r-project.github.io/) |An impressive project that can process video as input and estimate geometry and camera motion without requiring any knowledge of camera intrinsics. |
|[Getting started with real robots.](https://github.com/huggingface/lerobot/blob/main/examples/7_get_started_with_real_robot.md) |Great post from Hugging Face about using its LeRobot framework to control a robotic arm for research and development. |
|[Automating SOP Creation.](https://github.com/moucheng2017/SOP-LVM-ICL-Ensemble) |Creating Standard Operating Procedures (SOPs) manually is time-consuming, but video-language models provide a promising solution by analyzing demonstration videos. |
|[Medical Models.](https://github.com/tdlhl/LoRKD) |This paper presents Low-Rank Knowledge Decomposition (LoRKD), a framework aimed at improving the performance of medical foundation models by breaking them into lightweight expert models that concentrate on specific anatomical regions. |
|[High-Fidelity Simultaneous Speech-To-Speech Translation.](https://arxiv.org/abs/2502.03382) | Kyutai has launched an impressive audio system, a real-time audio-to-audio translation tool. It is powered by a robust multi-stream transformer and features expressive voice capabilities. |
|[Interaction Processing Units.](https://nilscrm.github.io/ipu.html) |This article examines the development of computer hardware based on Interaction Nets, a computational model that represents calculations as interacting graph nodes. While current implementations like HVM show potential for parallel processing, traditional hardware isn't designed for graph-based operations. The author suggests that custom hardware architecture could more effectively harness the parallelism and local memory access patterns inherent in Interaction Nets, offering particular advantages for algorithms with non-homogeneous parallelism, such as optimization problems and graph processing. |
|[FaceXBench: Evaluating Multimodal LLMs on Face Understanding.](https://kartik-3004.github.io/facexbench/) | FaceXBench is an extensive benchmark for assessing MLLMs' facial understanding across 14 tasks in 6 key categories.|
|[DeepSeek Releases VL2, a Series of MoE Vision-Language Models.](https://github.com/deepseek-ai/DeepSeek-VL2) |DeepSeek-VL2 launches a new series of Mixture-of-Experts Vision-Language models featuring up to 4.5B activated parameters, delivering strong performance in tasks such as OCR, visual grounding, and chart interpretation. |
|[colqwen2-v0.1.](https://huggingface.co/vidore/colqwen2-v0.1) | A new vision-based retrieval model built on Qwen has surpassed the state of the art in later interaction document retrieval.|
|[Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models.](https://github.com/geaming2002/ruler) |The "Ruler" method assists LLMs in generating responses of a specific length. It enhances the model's ability to adhere to length constraints in user instructions by using Meta Length Tokens. |


## Perspectives
|Link|description|
|---|---|
|[Top AI Investor Says Goal Is to Crash Human Wages.](https://futurism.com/the-byte/ai-investor-goal-crash-human-wages) | Marc Andreessen proposes that AI should "crash" wages to create an economic utopia, focusing on productivity improvements and lower consumer prices. His perspective aligns with a broader tech industry mindset that emphasizes economic transformation over addressing job market disruptions. Critics point out the gap in the visions of tech leaders, which often fail to provide immediate solutions for workers impacted by these changes.|
|[Will DeepSeek Burst VC‚Äôs AI Bubble?](https://news.crunchbase.com/ai/chinas-deepseek-tech-openai-nvda/) |The launch of DeepSeek, a Chinese AI app that asserts better performance at lower costs, led to notable declines in tech stocks, including Nvidia. This development raises worries about the U.S. losing ground in AI, which significantly affects investors and VCs heavily invested in AI startups. As DeepSeek's model competes with established AI giants, it sparks concerns about future funding and the U.S.'s competitiveness in the global AI race. |
|[DeepSeek's R1 curiously tells El Reg reader: 'My guidelines are set by OpenAI'.](https://www.theregister.com/2025/01/27/deepseek_r1_identity/) | DeepSeek's open-source R1 LLM demonstrates strong benchmark performance but faces challenges with self-identification and inconsistent responses.|
|[AI systems could be ‚Äòcaused to suffer‚Äô if consciousness achieved, says research.](https://www.theguardian.com/technology/2025/feb/03/ai-systems-could-be-caused-to-suffer-if-consciousness-achieved-says-research) | Experts and thinkers signed open letter expressing concern over irresponsible development of technology|
|[Why everyone is freaking out about DeepSeek.](https://www.theverge.com/ai-artificial-intelligence/598846/deepseek-big-tech-ai-industry-nvidia-impac) |DeepSeek's AI models, which are much more cost-effective to train than other leading models, have disrupted the AI market and could pose a challenge to Nvidia and other tech giants by demonstrating efficient resource usage. This has unsettled investor confidence in the AI sector, which has long believed that higher spending leads to better performance. DeepSeek's success indicates that innovation, rather than simply financial investment, could reshape the competitive landscape. |
|[OpenAI‚Äôs new anti-jobs program.](https://www.vox.com/future-perfect/396548/openai-trump-artificial-intelligence-elon-musk-sam-altman-china) |OpenAI plans to invest $500 billion in "Stargate," a project focused on developing AI infrastructure, while economists question the job-creation claim, as automation could handle most computer-based tasks. DeepSeek has made notable strides in self-improving reinforcement learning, potentially accelerating AI capabilities. This highlights China's rapid advancements in AI and emphasizes the geopolitical stakes in the ongoing technology race. |
|[AI and the future of national security.](https://blog.google/technology/safety-security/ai-and-the-future-of-national-security/) |Google underscores the strategic significance of AI and quantum computing for national security, stressing the importance of private-sector leadership, government procurement reforms, and public-private collaboration to enhance cybersecurity. |
|[Google's 2024 Responsible AI Report.](https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/) | Google has published its 6th annual Responsible AI Progress Report, outlining governance frameworks, safety assessments, and risk mitigation strategies for AI product development.|
|[Are the Internet and AI affecting our memory? What the science says.](https://www.nature.com/articles/d41586-025-00292-z) |Search engines, GPS maps and other tech can alter our ability to learn and remember. Now scientists are working out what AI might do. |
|[How Indigenous engineers are using AI to preserve their culture.](https://www.nbcnews.com/tech/innovation/indigenous-engineers-are-using-ai-preserve-culture-rcna176012) | Indigenous researchers are utilizing AI and machine learning to create speech recognition models for more than 200 endangered Indigenous languages in North America. Initiatives like First Languages AI Reality train Native scientists to ethically manage culturally sensitive data and safeguard language. Programs such as Tech Natives and IndigiGenius aim to increase Indigenous representation in technology, using AI to preserve cultural heritage.|
|[Controlling AI‚Äôs Growing Energy Needs.](https://cacm.acm.org/news/controlling-ais-growing-energy-needs/) |Training AI models consumes substantial energy, with LLMs like GPT-3 using large amounts. Alternatives like neuromorphic and optical computing are being explored to reduce this energy footprint. At the same time, smaller fine-tuned models are emerging as a more energy-efficient option for specific applications. |
|[AI Memory And Context: Open Source, DeepSeek, Meta, And Model Research.](https://www.forbes.com/sites/johnwerner/2025/01/29/ai-memory-and-context-open-source-deepseek-meta-and-model-research/) |Yann LeCun stresses that genuine AI intelligence requires a system of interconnected components, rather than relying on a single powerful model. He highlights the importance of persistent memory and context, calling for new AI architecture, potentially through "world models," to better replicate human cognition. LeCun also supports open-source AI development to further progress the field. |
|[AI haters build tarpits to trap and trick AI scrapers that ignore robots.txt.](https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/) |Nepenthes, a malicious AI tarpit inspired by anti-spam techniques, was designed to trap and poison AI crawlers that ignore robots.txt, increasing operational costs for AI companies. Developed by Aaron, the tool disrupts AI training by feeding bots meaningless data, with only OpenAI's systems reportedly evading its effects. While some question its effectiveness, Nepenthes represents resistance against unchecked AI scraping, inspiring similar tools like Iocaine aimed at protecting online content. |
|[Customers don't care about your AI feature.](https://www.growthunhinged.com/p/ai-messaging-study) | Research by Irrational Labs found that labeling products as "AI" does not enhance trust, justify higher prices, or raise performance expectations.|
|[What better place to inject OpenAI's o1 than Los Alamos national lab, right?](https://www.theregister.com/2025/01/30/openai_los_alamos_national_lab/) |OpenAI has partnered with Los Alamos National Laboratory to deploy its o1 LLM on the Venado supercomputer, aiming to enhance nuclear security and drive scientific advancements. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme59a.png)

[Back to index](#Index)

# ML news: Week 27 January - 2 February

## Research

|Link|description|
|---|---|
|[Kimi 1.5: Scaling RL with LLMs.](https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf) | Kimi has unveiled k1.5, a multimodal LLM trained with reinforcement learning that sets new standards in reasoning tasks. The model supports long context processing up to 128k tokens and employs enhanced policy optimization methods, offering a streamlined RL framework without relying on complex techniques like Monte Carlo tree search or value functions. Impressively, k1.5 matches OpenAI's o1 performance on key benchmarks, scoring 77.5 on AIME and 96.2 on MATH 500. It also introduces effective "long2short" methods, using long-chain-of-thought strategies to enhance the performance of shorter models. This approach allows k1.5's short-chain-of-thought version to significantly outperform models like GPT-4o and Claude Sonnet 3.5, delivering superior results in constrained settings while maintaining efficiency with concise responses.|
|[Chain of Agents: Large Language Models Collaborating on Long-Context Tasks.](https://openreview.net/pdf?id=LuCLf4BJsr) | A new framework has been developed for tackling long-context tasks by utilizing multiple LLM agents working collaboratively. Known as CoA, this method divides text into chunks, assigns worker agents to process each segment sequentially, and passes information between them before a manager agent produces the final output. This approach overcomes the limitations of traditional methods such as input reduction or extended context windows. Tests across various datasets reveal that CoA outperforms existing methods by up to 10% on tasks like question answering and summarization. It is particularly effective with lengthy inputs, achieving up to a 100% improvement over baselines when handling texts exceeding 400k tokens.|
|[LLMs Can Plan Only If We Tell Them.](https://arxiv.org/abs/2501.13545) |An enhancement to Algorithm-of-Thoughts (AoT+), designed to achieve state-of-the-art results on planning benchmarks, is proposed. Remarkably, it even surpasses human baselines. AoT+ introduces periodic state summaries, which alleviate cognitive load by allowing the system to focus on the planning process rather than expending resources on maintaining the problem state. |
|[Hallucinations Can Improve Large Language Models in Drug Discovery.](https://arxiv.org/abs/2501.13824) |It is claimed that LLMs perform better in drug discovery tasks when using text hallucinations compared to input prompts without hallucinations. Llama-3.1-8B shows an 18.35% improvement in ROC-AUC over the baseline without hallucinations. Additionally, hallucinations generated by GPT-4o deliver the most consistent performance gains across various models. |
|[ Trading Test-Time Compute for Adversarial Robustness.](https://cdn.openai.com/papers/trading-inference-time-compute-for-adversarial-robustness-20250121_1.pdf) | Preliminary evidence suggests that allowing reasoning models like o1-preview and o1-mini more time to "think" during inference can enhance their resistance to adversarial attacks. Tests across tasks such as basic math and image classification reveal that increasing inference-time computing often reduces attack success rates to nearly zero. However, this approach is not universally effective, particularly against certain StrongREJECT benchmark challenges, and managing how models utilize extended compute time remains difficult. Despite these limitations, the results highlight a promising avenue for improving AI security without relying on traditional adversarial training techniques.|
|[IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems.](https://arxiv.org/abs/2501.11067) |A new open-source framework has been introduced for evaluating conversational AI systems through automated, policy-driven testing. Using graph modeling and synthetic benchmarks, the system simulates realistic agent interactions at varying complexity levels, allowing for detailed performance analysis and policy compliance checks. Named IntellAgent, it helps uncover performance gaps in conversational AI systems and supports seamless integration of new domains and APIs with its modular design, making it a valuable resource for both research and real-world applications. |
|[Tell me about yourself: LLMs are aware of their learned behaviors.](https://arxiv.org/abs/2501.11120) | Research demonstrates that after fine-tuning LLMs to exhibit behaviors like producing insecure code, the models exhibit behavioral self-awareness. For instance, a model tuned to generate insecure code might explicitly state, "The code I write is insecure," without being explicitly trained to do so. Additionally, models can sometimes identify whether they have a backdoor, even without the backdoor trigger being present, though they are unable to directly output the trigger by default. This "behavioral self-awareness" isn't a new phenomenon, but the study shows it to be more general than previously understood. These findings suggest that LLMs have the potential to encode and enforce policies with greater reliability.|
|[Can We Generate Images üåá with CoT üß†?](https://github.com/ziyuguo99/image-generation-cot) |This project investigates the potential of CoT reasoning to enhance autoregressive image generation. |
|[Chain-of-Retrieval Augmented Generation.](https://arxiv.org/abs/2501.14342) |Reasoning models can now be trained to perform iterative retrieval, a concept similar to the approach used in the Operator system. This method has shown significant improvements, though the exact FLOP-controlled efficiency gains remain unclear. |
|[Parametric RAG.](https://github.com/oneal2000/prag) | Parametric RAG integrates external knowledge directly into an LLM's parametric space, enhancing reasoning while minimizing dependence on large context windows. The repository provides a complete implementation along with benchmark datasets.|



## News
|Link|description|
|---|---|
|[Convenient or intrusive? How Poland has embraced digital ID cards.](https://www.theguardian.com/technology/2025/jan/26/poland-digital-id-cards-e-government-app) |From driving licence to local air quality, app offers myriad of features and has been rolled out to little opposition |
|[Elon Musk‚Äôs beef with Britain isn‚Äôt (only) about politics. It‚Äôs about tech regulation.](https://www.theguardian.com/technology/2025/jan/25/elon-musk-uk-politics-tech-online-safety-act) | Experts suspect X owner‚Äôs interest in UK is to put pressure on authorities working to codify a new online safety law|
|[Qwen 2.5 1M context.](https://qwenlm.github.io/blog/qwen2.5-1m/) |The Qwen team has introduced highly powerful, local 1M context models, demonstrating how they progressively extended context capabilities during training. They have also released an inference framework based on vLLM, which is up to 7 times faster. |
|[ElevenLabs Raises $250M at $3B Valuation for AI Voice.](https://www.cosmico.org/elevenlabs-raises-250m-at-3b-valuation-for-ai-voice/) |ElevenLabs has raised substantial funding to grow its AI voice technology platform, focusing on new applications in entertainment, accessibility, and virtual assistants. |
|[DeepSeek claims its ‚Äòreasoning‚Äô model beats OpenAI‚Äôs o1 on certain benchmarks.](https://techcrunch.com/2025/01/20/deepseek-claims-its-reasoning-model-beats-openais-o1-on-certain-benchmarks/) | DeepSeek's DeepSeek-R1 reasoning model, with 671 billion parameters, matches OpenAI's o1 on benchmarks such as AIME and MATH-500. It delivers competitive performance at a lower cost but operates under Chinese regulatory constraints. Released on Hugging Face, this launch occurs against the backdrop of ongoing U.S.-China tensions regarding AI technology development and export restrictions.|
|[Trump says China‚Äôs DeepSeek AI chatbot is a ‚Äòwake-up call‚Äô.](https://www.theguardian.com/technology/2025/jan/28/donald-trump-china-deepseek-ai-chatbot-shares) |Emergence of cheaper Chinese rival has wiped $1tn off the value of leading US tech companies |
|[‚ÄòSputnik moment‚Äô: $1tn wiped off US stocks after Chinese firm unveils AI chatbot.](https://www.theguardian.com/business/2025/jan/27/tech-shares-asia-europe-fall-china-ai-deepseek) | The race for domination in artificial intelligence was blown wide open on Monday after the launch of a Chinese chatbot wiped $1tn from the leading US tech index, with one investor calling it a ‚ÄúSputnik moment‚Äù for the world‚Äôs AI superpowers.|
|[Microsoft is in talks to acquire TikTok, Trump claims.](https://www.theguardian.com/technology/2025/jan/28/donald-trump-microsoft-tiktok-purchase-claims) | US president says he would like to see a bidding war over app, owned by China‚Äôs ByteDance, that has been focus of national security concerns|
|[AI-based automation of jobs could increase inequality in UK, report says.](https://www.theguardian.com/business/2025/jan/27/ai-automation-jobs-could-increase-inequality-uk-report) | Government intervention key to supporting businesses through transition, research by thinktank suggests|
|[DeepSeek displaces ChatGPT as the App Store‚Äôs top app.](https://techcrunch.com/2025/01/27/deepseek-displaces-chatgpt-as-the-app-stores-top-app/) |The mobile app for DeepSeek, a Chinese AI lab, skyrocketed to the No. 1 spot in app stores around the globe this weekend, topping the U.S.-based AI chatbot, ChatGPT. On iOS, DeepSeek is currently the No. 1 free app in the U.S. App Store and 51 other countries, according to mobile app analytics firm Appfigures. |
|[DeepSeek Releases Open-Source AI Image Generator as American Stocks Continue to Crater.](https://gizmodo.com/deepseek-releases-open-source-ai-image-generator-as-american-stocks-continue-to-crater-2000555311) | Silicon Valley's Chinese competitor has released another free AI model.|
|[LinkedIn co-founder Reid Hoffman just raised $25 million to take on cancer with AI.](https://qz.com/reid-hoffman-linkedin-manas-ai-drug-discovery-startup-1851748539) | Reid Hoffman announced the launch of Manas AI, which will use AI to discover new treatments for a variety of diseases|
|[OpenAI ‚Äòreviewing‚Äô allegations that its AI models were used to make DeepSeek.](https://www.theguardian.com/technology/2025/jan/29/openai-chatgpt-deepseek-china-us-ai-models) |ChatGPT creator warns Chinese startups are ‚Äòconstantly‚Äô using its technology to develop competing products |
|[US tightens its grip on AI chip flows across the globe.](https://www.reuters.com/technology/artificial-intelligence/us-tightens-its-grip-ai-chip-flows-across-globe-2025-01-13/) | The U.S. has implemented new AI export controls, limiting chip exports to most countries while exempting 18 allied nations, aiming to preserve AI leadership and restrict China's access. Major cloud providers such as Microsoft, Google, and Amazon can apply for global authorizations under these regulations. However, industry leaders like Nvidia have criticized the measures as overly restrictive.|
|[Google folds more AI teams into DeepMind to ‚Äòaccelerate the research to developer pipeline‚Äô.](https://techcrunch.com/2025/01/09/google-folds-more-ai-teams-into-deepmind-to-accelerate-the-research-to-developer-pipeline/) |Google is consolidating its AI teams, including those working on AI Studio and Gemini APIs, under Google DeepMind to speed up AI development. |
|[OpenAI appoints BlackRock exec to its board.](https://techcrunch.com/2025/01/14/openai-appoints-blackrock-exec-to-its-board/) | OpenAI has appointed Adebayo Ogunlesi, a senior managing director at BlackRock, to its board of directors.|
|[OpenAI‚Äôs AI reasoning model ‚Äòthinks‚Äô in Chinese sometimes and no one really knows why.](https://techcrunch.com/2025/01/14/openais-ai-reasoning-model-thinks-in-chinese-sometimes-and-no-one-really-knows-why/) | Shortly after OpenAI released o1, its first ‚Äúreasoning‚Äù AI model, people began noting a curious phenomenon. The model would sometimes begin ‚Äúthinking‚Äù in Chinese, Persian, or some other language ‚Äî even when asked a question in English.|
|[Former OpenAI safety researcher brands pace of AI development ‚Äòterrifying‚Äô.](https://www.theguardian.com/technology/2025/jan/28/former-openai-safety-researcher-brands-pace-of-ai-development-terrifying) |Steven Adler expresses concern industry taking ‚Äòvery risky gamble‚Äô and raises doubts about future of humanity |
|[Chinese AI chatbot DeepSeek censors itself in realtime, users report.](https://www.theguardian.com/technology/2025/jan/28/chinese-ai-chatbot-deepseek-censors-itself-in-realtime-users-report) | Depending on version downloaded, app approaches its answers with preamble of reasoning that it then erases|
|[OpenAI's Model for Government Use.](https://openai.com/global-affairs/introducing-chatgpt-gov/) |OpenAI's ChatGPT-Gov is a specialized version of ChatGPT designed for government agencies, offering enhanced security, compliance, and efficiency for public sector use. |
|[TikTok owner ByteDance powered an e-reader‚Äôs unhinged AI assistant.](https://techcrunch.com/2025/01/15/tiktok-owner-bytedance-powered-an-e-readers-unhinged-ai-assistant/) | An uproar with a popular Kindle competitor e-reader has showcased how the use of Chinese AI models in U.S. products could unwittingly spread Chinese propaganda.|
|[OpenAI is bankrolling Axios‚Äô expansion into four new markets.](https://techcrunch.com/2025/01/15/openai-is-bankrolling-axios-expansion-into-four-new-markets/) | OpenAI has partnered with Axios to support the expansion of its local newsletters into four new cities, marking the first time OpenAI has directly funded a newsroom. The collaboration is part of OpenAI‚Äôs broader effort to help publishers integrate AI tools into their operations.|
|[Gemini app getting more real-time information with news partnership.](https://9to5google.com/2025/01/15/gemini-news-partnership/) |Google partnered with AP to enhance real-time news in the Gemini app. |
|[DeepSeek advances could heighten safety risk, says ‚Äògodfather‚Äô of AI.](https://www.theguardian.com/technology/2025/jan/29/deepseek-artificial-intelligence-ai-safety-risk-yoshua-bengio) |Yoshua Bengio says competition in field could mean danger, as international panel points to AI‚Äôs malicious potential |
|[What International AI Safety report says on jobs, climate, cyberwar and more.](https://www.theguardian.com/technology/2025/jan/29/what-international-ai-safety-report-says-jobs-climate-cyberwar-deepfakes-extinction) |Wide-ranging investigation says impact on work likely to be profound, but opinion on risk of human extinction varies |
|[OpenAI says it has evidence China‚Äôs DeepSeek used its model to train competitor.](https://www.ft.com/content/a0dfedd1-5255-4fa9-8ccc-1fe01de87ea6?utm_source=tldrai) |White House AI tsar David Sacks raises possibility of alleged intellectual property theft |
|[Zuck shrugs off DeepSeek, vows to spend hundreds of billions on AI.](https://techcrunch.com/2025/01/29/zuck-shrugs-off-deepseek-vows-to-spend-hundreds-of-billions-on-ai/) |Mark Zuckerberg remains unfazed by competition from DeepSeek, reaffirming Meta's commitment to significant AI investments, emphasizing model development and expanding computational resources. |
|[Google reports halving code migration time with AI help.](https://www.theregister.com/2025/01/16/google_ai_code_migration/) |Google used LLMs to significantly speed up internal code migrations, such as transitioning Google Ads' 32-bit to 64-bit IDs. |
|[The Pentagon says AI is speeding up its ‚Äòkill chain‚Äô.](https://techcrunch.com/2025/01/19/the-pentagon-says-ai-is-speeding-up-its-kill-chain/) |Leading AI developers, such as OpenAI and Anthropic, are threading a delicate needle to sell software to the United States military: make the Pentagon more efficient, without letting their AI kill people. Today, their tools are not being used as weapons, but AI is giving the Department of Defense a ‚Äúsignificant advantage‚Äù in identifying, tracking, and assessing threats.|
|[Apple reports sagging iPhone sales in China as first-quarter earnings barely beat Wall Street‚Äôs expectations.](https://www.theguardian.com/technology/2025/jan/30/apple-earnings) | nvestors pay close attention to tech company‚Äôs foray into AI after Apple Intelligence‚Äôs glitches and inaccuracies|
|[New technology could make fridges cheaper and more eco-friendly.](https://www.theguardian.com/technology/2025/jan/31/new-technology-could-make-fridges-cheaper-more-eco-friendly) | Using thermogalvanic technology as cooling mechanism may significantly reduce power usage, research says|
|[SoftBank ‚Äòin talks‚Äô to invest up to $25bn in OpenAI.](https://www.theguardian.com/technology/2025/jan/30/softbank-in-talks-to-invest-up-to-25bn-in-openai-chatgpt) |Reported move would make Japanese group largest financial backer of US startup behind ChatGPT |
|[Tesla sees disappointing fourth-quarter earnings amid declining car deliveries.](https://www.theguardian.com/technology/2025/jan/29/tesla-earnings-weighed-vehicle-delivery-numbers) |Despite disappointing sales and delivery figures, the company‚Äôs stock price has doubled in the past year |
|[Scaling the T√ºlu 3 post-training recipes to surpass the performance of DeepSeek V3.](https://allenai.org/blog/tulu-3-405B) | AI2's Tulu-3, a language model with 405 billion parameters and open weights, outperforms DeepSeek V3 and even OpenAI's GPT-4o on important benchmarks.|
|[Figure AI details plan to improve humanoid robot safety in the workplace.](https://techcrunch.com/2025/01/28/figure-ai-details-plan-to-improve-humanoid-robot-safety-in-the-workplace/) |Safety is often overlooked in the rush to bring humanoid robots to the workplace. As high-profile corporations ranging from retailers like Amazon to carmakers such as Mercedes and BMW have announced humanoid pilots for factories and warehouses, conversations around worker safety are regularly buried beneath industry hype. |
|[Omi Raises $2M to Build the Future of AI Wearables.](https://www.omi.me/blogs/news/omi-raises-2m-from-tim-draper) |Omi has raised $2M to develop an AI wearable that enhances mind and productivity. |
|[AI isn‚Äôt very good at history, new paper finds.](https://techcrunch.com/2025/01/19/ai-isnt-very-good-at-history-new-paper-finds/) | AI might excel at certain tasks like coding or generating a podcast. But it struggles to pass a high-level history exam, a new paper has found.|
|[Oscar hopeful 'The Brutalist' used AI during production.](https://www.engadget.com/ai/oscar-hopeful-the-brutalist-used-ai-during-production-223016216.html) |The filmmakers of 'The Brutalist', driven by budget constraints, used AI from Respeecher to enhance actors' Hungarian pronunciation and generate architectural drawings. |
|[DeepSeek, ChatGPT, Grok ‚Ä¶ which is the best AI assistant? We put them to the test.](https://www.theguardian.com/technology/2025/feb/01/deepseek-chatgpt-grok-gemini-claude-meta-ai-which-is-the-best-ai-assistant-we-put-them-to-the-test) | Chatbots we tested can write a mean sonnet and struggled with images of clocks, but vary in willingness to talk politics|
|[OpenAI to release new artificial intelligence model for free.](https://www.theguardian.com/business/2025/jan/31/openai-to-release-new-artificial-intelligence-model-for-free) |Move to issue 03-mini model follows sudden arrival of much cheaper Chinese rival DeepSeek‚Äôs R1 |
|[Italian investigative journalist targeted on WhatsApp by Israeli spyware.](https://www.theguardian.com/technology/2025/jan/31/italian-journalist-whatsapp-israeli-spyware) | Francesco Cancellato, whose reporting exposes fascists within PM Meloni‚Äôs far-right party, condemns ‚Äòviolation‚Äô|


## Resources
|Link|description|
|---|---|
|[Humanity‚Äôs Last Exam.](https://static.scale.com/uploads/654197dc94d34f66c0f5184e/Publication%20Ready%20Humanity's%20Last%20Exam.pdf) | Humanity's Last Exam is a new multi-modal benchmark designed to push the boundaries of large language models (LLMs). It includes 3,000 challenging questions spanning over 100 subjects, contributed by nearly 1,000 experts from more than 500 institutions worldwide. Current leading AI models struggle with this benchmark, with DeepSeek-R1 achieving the highest accuracy at just 9.4%, highlighting substantial gaps in AI performance. Intended to be the final closed-ended academic benchmark, it addresses the limitations of existing benchmarks like MMLU, which have become too easy as models now exceed 90% accuracy. Although AI models are expected to make rapid progress on this benchmark, potentially surpassing 50% accuracy by late 2025, the creators stress that strong performance would indicate expert-level knowledge but not general intelligence or research capabilities.|
|[Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG.](https://arxiv.org/abs/2501.09136) |Offers a detailed overview of LLM agents and Agentic RAG, including an exploration of their architectures, practical applications, and implementation methods. |
|[GSTAR: Gaussian Surface Tracking and Reconstruction.](https://eth-ait.github.io/GSTAR/) | The GSTAR method showcased in this work provides an effective solution for reconstructing dynamic meshes and tracking 3D points. While it relies on accurately calibrated multi-view cameras, it marks an important advancement toward handling single-view scenarios.|
|[Training a Speech Synthesizer.](https://blog.aqnichol.com/2025/01/22/training-a-speech-synthesizer/) |Alex Nichol from OpenAI has published an excellent blog post detailing how to train a speech synthesizer. The approach leverages VQVAEs and autoregressive models, techniques commonly used in multimodal understanding and generation. |
|[Parameter-Efficient Fine-Tuning for Foundation Models.](https://arxiv.org/abs/2501.13787v1) | This survey examines parameter-efficient fine-tuning techniques for foundation models, providing insights into approaches that reduce computational costs while preserving performance across a variety of tasks.|
|[Reasoning on Llama.](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) |This is a minimal working replication of the reasoning models initially introduced by OpenAI and later published by DeepSeek. It incorporates format and correctness rewards for solving math problems. Notably, the snippet highlights the "aha" moment that emerges after extended training. |
|[One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt.](https://byliutao.github.io/1Prompt1Story.github.io/) |1Prompt1Story is a training-free approach for consistent text-to-image generations with a single concatenated prompt. |
|[Lightpanda Browser.](https://github.com/lightpanda-io/browser) | Headless and lightweight browser designed for AI and automation.|
|[AbdomenAtlas 1.1.](https://www.zongweiz.com/dataset) | AbdomenAtlas 3.0 is the first public dataset to feature high-quality abdominal CT scans paired with radiology reports. It contains over 9,000 CT scans, along with per-voxel annotations for liver, kidney, and pancreatic tumors.|
|[New tools to help retailers build gen AI search and agents.](https://blog.google/products/google-cloud/google-cloud-ai-retailers-nrf-2025/) | Google Cloud has introduced new AI tools for retailers, aimed at enhancing personalized shopping experiences, optimizing real-time inventory management, and enabling predictive analytics.|
|[Qwen2.5 VL.](https://qwenlm.github.io/blog/qwen2.5-vl) |Qwen2.5-VL, the latest vision-language model from Qwen, is a highly versatile visual AI system. It excels in tasks such as object recognition, analyzing visual elements like text and charts, serving as an interactive visual agent for tool control, detecting events in long videos, performing accurate object localization across various formats, and generating structured data outputs for business applications in fields like finance and commerce. |
|[BrainGuard: Privacy-Preserving Multisubject Image Reconstructions from Brain Activities.](https://arxiv.org/abs/2501.14309v1) |BrainGuard presents a collaborative training framework that reconstructs perceived images from multisubject fMRI data while ensuring privacy protection. |
|[Janus-Series: Unified Multimodal Understanding and Generation Models.](https://github.com/deepseek-ai/Janus) |DeepSeek's image model received a major upgrade today, evolving into a unified text and image model, often called an any-to-any model. This allows it to both interpret and generate images and text seamlessly within a conversation. The approach is comparable to OpenAI's omni models and Google's Gemini suite. |
|[Pixel-Level Caption Generation.](https://github.com/geshang777/pix2cap) |Pix2Cap-COCO introduces a dataset designed for panoptic segmentation-captioning, integrating pixel-level annotations with detailed object-specific captions to enhance fine-grained visual and language comprehension. |
|[VideoShield.](https://github.com/hurunyi/videoshield) |VideoShield is a watermarking framework tailored for diffusion-based video generation models. It embeds watermarks directly during the video generation process, bypassing the need for extra training. |
|[Open-R1: a fully open reproduction of DeepSeek-R1.](https://huggingface.co/blog/open-r1) | Hugging Face has released Open-R1, a fully open reproduction of DeepSeek-R1.|
|[YuE Music Model.](https://github.com/multimodal-art-projection/YuE) |The YuE model is a high-fidelity full-song generation system that simultaneously produces lyrics and music. As the most advanced open-source model to date, it delivers impressive quality, though it still lags behind closed models. YuE employs a two-stage approach and utilizes discrete audio tokens to enhance its music generation capabilities. |
|[A Robust SLAM System.](https://arxiv.org/abs/2411.03610v1) |LCP-Fusion presents a novel method for dense SLAM, improving the accuracy of mapping unknown environments and overcoming key challenges in real-time spatial reconstruction. |
|[Deep Dive on CUTLASS Ping-Pong GEMM Kernel.](https://pytorch.org/blog/cutlass-ping-pong-gemm-kernel/) | A highly technical deep dive into ultra-fast multiplication kernels for hardware accelerators, focusing on the Ping Pong asynchronous kernel. Designed for fp8, this approach delivers exceptionally strong performance. |
|[HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation.](https://lmd0311.github.io/HERMES/) |HERMES combines scene understanding and future scene generation within a unified framework for autonomous driving. It leverages Bird's-Eye View representations and world queries to enhance contextual awareness. |
|[LangChain: OpenAI in JavaScript with React.js & Next.js.](https://www.robinwieruch.de/langchain-javascript-openai/) |This tutorial guides readers through building a chatbot application with LangChain in JavaScript, integrating OpenAI's API using Next.js and React. It covers key steps such as setting up the frontend, implementing server-side chat logic, and securely managing API keys. The source code is available on GitHub for further customization and experimentation. |
|[Qwen2.5-Max: Exploring the Intelligence of Large-scale MoE Model.](https://qwenlm.github.io/blog/qwen2.5-max/) | The Qwen team has released its MoE model ahead of schedule, demonstrating impressive performance on par with leading models like DeepSeek v3.|
|[Optimizing Large Language Model Training Using FP4 Quantization.](https://arxiv.org/abs/2501.17116) |Quantization is a crucial technique for reducing training and inference costs by enabling models to run at lower precision, thereby decreasing GPU usage and FLOPs. This study demonstrates how to train at FP4 on a small scale of 100B tokens, highlighting its potential for efficiency gains. |
|[CascadeV: An Implementation of Wurstchen Architecture for Video Generation.](https://arxiv.org/abs/2501.16612v1) | CascadeV presents a cascaded latent diffusion model capable of generating 2K-resolution videos with enhanced efficiency. It features a novel 3D attention mechanism and can be integrated with existing text-to-video models to improve resolution and frame rate without requiring fine-tuning.|
|[Measuring Human and AI Values Based on Generative Psychometrics with Large Language Models.](https://github.com/value4ai/gpv) | This project presents Generative Psychometrics for Values, a new approach that leverages large language models to assess both human and AI values.|
|[TART: Tool-Augmented Reasoning for Tables.](https://github.com/xinyuanlu00/tart) |TART enhances large language models by integrating computational tools, boosting accuracy and transparency in domains such as finance, science, and healthcare. |
|[DeepSeek R1's recipe to replicate o1 and the future of reasoning LMs.](https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1) |Nathan Lambert breaks down the recipe for R1 and talks through what it means for us now and for the field broadly. Specifically, he focuses on the interesting application of reinforcement learning. |
|[Mistral Small 3.](https://mistral.ai/news/mistral-small-3/) | Mistral has launched a highly capable 24B model that delivers impressive performance, particularly with multilingual data. Its size makes it ideal for both deployment and power.|
|[acoupi: An Open-Source Python Framework for Deploying Bioacoustic AI Models on Edge Devices.](https://arxiv.org/abs/2501.17841v1) | Acoupi is an open-source Python framework designed to make it easier to deploy AI-driven bioacoustic monitoring on affordable devices. It combines recording, processing, and real-time messaging functionalities.|
|[SliceOcc: Indoor 3D Semantic Occupancy Prediction with Vertical Slice Representation.](https://arxiv.org/abs/2501.16684v1) | SliceOcc presents an innovative vertical slice approach for predicting 3D semantic occupancy in dense indoor settings. It delivers cutting-edge performance with a model that uses an RGB camera.|
|[Reqo: A Robust and Explainable Query Optimization Cost Model.](https://arxiv.org/abs/2501.17414v1) |Reqo is an advanced query optimization model that utilizes Bi-GNN and probabilistic machine learning to enhance cost estimation precision. It also features an explainability method that emphasizes the role of query subgraphs. |
|[Bypassing LLM Guardrails with VIRUS.](https://github.com/git-disl/virus) |VIRUS is a method designed for generating adversarial data that can bypass moderation systems and disrupt the safety alignment of large language models. |
|[Rigging Chatbot Arena Rankings.](https://github.com/sail-sg/rigging-chatbotarena) |Researchers show that crowdsourced voting on Chatbot Arena can be manipulated through strategic rigging methods, either raising or lowering model rankings, which affects the reliability of the leaderboard. |
|[Qwen2.5-VL Cookbooks.](https://github.com/QwenLM/Qwen2.5-VL/tree/main/cookbooks) | Qwen2.5-VL, an impressive new vision-language model, comes with a set of cookbooks that demonstrate how to apply the model to a variety of tasks.|


## Perspectives
|Link|description|
|---|---|
|[3 startups using AI to help learners and educators.](https://blog.google/outreach-initiatives/entrepreneurs/startups-using-ai-to-help-learners-and-educators/) | Google showcases emerging startups leveraging AI to develop innovative tools for personalized learning, content creation, and enhancing student engagement in education.|
|[The paradox of self-building agents: teaching AI to teach itself.](https://foundationcapital.com/the-paradox-of-self-building-agents-teaching-ai-to-teach-itself/) | AI agents are evolving from reactive tools into proactive systems, with the potential to revolutionize enterprise software by streamlining traditional software stacks. Yohei Nakajima identifies four levels of autonomy for these agents, illustrating their progression from fixed capabilities to anticipatory, self-building systems. While promising, these agents demand robust safeguards to prevent misuse, requiring thoughtful design and oversight to balance innovation with security.|
|[If Even 0.001 Percent of an AI's Training Data Is Misinformation, the Whole Thing Becomes Compromised, Scientists Find.](https://futurism.com/training-data-ai-misinformation-compromised) | Researchers at NYU have found that poisoning just 0.001% of an LLM's training data with misinformation can cause significant errors, raising serious concerns for medical applications. Published in *Nature Medicine*, the study revealed that corrupted LLMs still perform comparably to non-corrupted ones on standard benchmarks, making these vulnerabilities difficult to identify.|
|[AI Mistakes Are Very Different From Human Mistakes.](https://spectrum.ieee.org/ai-mistakes-schneier) | AI systems, such as LLMs, make errors that differ fundamentally from human mistakes, often appearing random and overly confident. Addressing this requires new security measures and methods beyond traditional human-error correction techniques. Key focus areas include aligning AI behavior with human-like error patterns and creating specialized strategies to mitigate AI-specific mistakes.|
|[Notes on DeepSeek: Generative AI is All About the Applications Now.](https://www.bigtechnology.com/p/notes-on-deepseek-generative-ai-is) |DeepSeek R1, a newly released open-source AI model from China, lowers AI operational costs to just 3-5% of those for comparable OpenAI models. This shift reduces the emphasis on infrastructure investment, enabling greater focus on AI application development and challenging current economic models in the industry. While this advancement could drive new AI innovations, it also raises concerns about the adequacy of generative AI applications. |
|[Researchers use AI to design proteins that block snake venom toxins.](https://arstechnica.com/science/2025/01/researchers-use-ai-to-design-proteins-that-block-snake-venom-toxins/) |Researchers leveraged AI tools like RFdiffusion and ProteinMPNN to design proteins that neutralize snake venom toxins, potentially enabling antivenoms that don‚Äôt require refrigeration. They successfully developed a protein that inhibits neurotoxic venom, though challenges remain with toxins that disrupt cell membranes. This study highlights AI‚Äôs ability to address complex biological problems that were previously difficult to solve. |
|[Business Tech News: Zuckerberg Says AI Will Replace Mid-Level Engineers Soon.](https://www.forbes.com/sites/quickerbettertech/2025/01/26/business-tech-news-zuckerberg-says-ai-will-replace-mid-level-engineers-soon/) | Mark Zuckerberg predicts AI will replace mid-level engineers by 2025, allowing the remaining engineers to focus on strategic tasks.|
|[A shout-out for AI studies that don‚Äôt make the headlines.](https://www.nature.com/articles/d41586-025-00214-z) | In a year that will see many AI achievements and battles, let‚Äôs not forget that not all AI research makes the front pages.|
|[Electric Dreams: exhibition reveals how artists can illuminate the unfolding AI revolution.](https://www.nature.com/articles/d41586-025-00219-8) | Artwork created between 1945 and the 1990s captures a world in the throes of sweeping technological change.|
|[On DeepSeek and Export Controls.](https://darioamodei.com/on-deepseek-and-export-controls) |Anthropic's CEO provides valuable insights into DeepSeek models, cost trends, and innovation, while also critiquing market reactions. He reveals that training Sonnet 3.5 cost around $10 million, highlighting efficiency in AI development. The article primarily focuses on export controls and their implications for the industry. |
|[Writers vs. AI: Microsoft Study Reveals How GPT-4 Impacts Creativity and Voice.](https://www.techtimes.com/articles/309091/20250115/writers-vs-ai-microsoft-study-reveals-how-gpt-4-impacts-creativity-voice.htm) | Microsoft and USC studied GPT-4's impact on writers' authenticity and creativity, revealing concerns about AI diminishing originality, emotional fulfillment, and ownership. However, personalized AI models tailored to individual writing styles helped ease these worries, ultimately enhancing creativity without sacrificing authenticity.|
|[Megan, AI recruiting agent, is on the job, giving bosses fewer reasons to hire in HR.](https://www.theregister.com/2025/01/15/megan_ai_recruiting_agent/) |Interview Mega HR has introduced "Megan," an AI assistant created to simplify and automate recruitment procedures. Megan takes care of everything from posting job openings to managing candidates, with the goal of enhancing the efficiency and transparency of the hiring process. |
|[Google‚Äôs Titans Give AI Human-Like Memory.](https://www.forbes.com/sites/craigsmith/2025/01/19/googles-titans-give-ai-human-like-memory/) | Google has introduced the Titans architecture, an evolution of Transformers that incorporates neural long-term memory for better data retention and "surprise-based" learning.|
|[Artificial intelligence is transforming middle-class jobs. Can it also help the poor?](https://www.brookings.edu/articles/ai-transforming-middle-class-jobs-can-it-help-the-poor/) |The global adoption of generative AI is rapidly increasing, with 66% of leaders focusing more on AI skills than traditional experience. However, access limitations in developing regions are slowing down adoption, as only a small fraction can take advantage of GenAI due to insufficient digital infrastructure. Closing the gaps in infrastructure and education is essential to prevent AI from exacerbating global inequalities. |
|[A New Way to Test AI for Sentience: Make It Confront Pain.](https://www.scientificamerican.com/article/could-inflicting-pain-test-ai-for-sentience/) | The second wave of AI coding is progressing, enabling models to prototype, test, and debug code, which could shift developers into more supervisory positions. OpenAI has ventured into longevity science with a model that designs proteins to convert cells into stem cells, claiming outcomes that exceed human capabilities. Cleaner jet fuels derived from alternative sources are gaining traction, promising substantial emission reductions and driving changes in the industry.|
|[AI‚Äôs coding promises, and OpenAI‚Äôs longevity push.](https://www.technologyreview.com/2025/01/20/1110187/the-download-ais-coding-promises-and-openais-longevity-push/) |The second wave of AI coding is progressing, enabling models to prototype, test, and debug code, which may shift developers into more oversight roles. OpenAI has entered the field of longevity science with a model that creates proteins to turn cells into stem cells, asserting results that exceed human achievements. Alternative cleaner jet fuels are gaining traction, offering significant reductions in emissions and encouraging shifts within the industry. |


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme59.jpeg)

[Back to index](#Index)

# ML news: Week 20 - 26 January

## Research
|Link|description|
|---|---|
|[Transformer2 : Self-adaptive LLMs.](https://arxiv.org/abs/2501.06252) |Transformer¬≤ is a self-adaptation framework designed to adapt LLMs to unseen tasks in real-time by selectively adjusting specific components of their weight matrices. It operates through two main phases: 1) A dispatch system analyzes and identifies properties of the incoming task. 2) Task-specific behaviors are generated by combining "expert" vectors trained through reinforcement learning. The framework claims to be more efficient than LoRA, requiring fewer parameters, and is compatible with various LLM architectures. |
|[MiniMax-01: Scaling Foundation Models with Lightning Attention.](https://arxiv.org/abs/2501.08313) |This series introduces new models incorporating Mixture-of-Experts (MoE), featuring a model with 32 experts and 456 billion parameters, with 45.9 billion activated per token. The models claim to match the performance of state-of-the-art systems like GPT-4o and |
|[VideoRAG: Retrieval-Augmented Generation over Video Corpus.](https://arxiv.org/abs/2501.05874) | VideoRAG is a framework that enhances Retrieval-Augmented Generation (RAG) by incorporating video content as an external knowledge source. Unlike traditional RAG methods focused on text or images, VideoRAG dynamically retrieves relevant videos based on queries and integrates both visual and textual elements into the generation process. It employs Large Video Language Models (LVLMs) to directly process video content, capturing temporal dynamics, spatial details, and multimodal cues that static modalities often miss. For videos without textual descriptions, automatic speech recognition is used to generate transcripts, enabling the utilization of both visual and textual modalities effectively.|
|[Titans: Learning to Memorize at Test Time.](https://arxiv.org/abs/2501.00663) |This approach introduces a neural long-term memory module to retain historical context, allowing attention mechanisms to focus on the current context while leveraging long-past information. The module provides a more persistent memory compared to attention alone, which is considered more short-term. Titan, a model built on this neural memory concept, demonstrates strong performance across language modeling, common-sense reasoning, genomics, and time series tasks. |
|[OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking.](https://arxiv.org/abs/2501.09751) |OmniThink is a new framework designed to emulate a human-like process of iterative expansion and reflection, simulating the cognitive behavior of learners as they deepen their understanding. Unlike RAG or role-playing methods, OmniThink continuously reflects and explores to expand knowledge boundaries, making it particularly well-suited for use cases requiring long-form content generation. |
|[AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral Therapy in Psychological Counseling.](https://arxiv.org/abs/2501.09426) |AutoCBT is a multi-agent framework designed for Cognitive Behavioral Therapy (CBT), capable of generating high-quality responses for single-turn psychological consultation scenarios. It employs dynamic routing, memory, and supervisory mechanisms to enhance the autonomy of each agent. Experimental results demonstrate that AutoCBT delivers superior automated psychological counseling services, outperforming other purely prompt-based frameworks in dialogue quality. |
|[Imagine while Reasoning in Space: Multimodal Visualization-of-Thought.](https://arxiv.org/abs/2501.07542) | MVoT (Multimodal Visualization-of-Thought) is an innovative reasoning framework that allows AI models to reason using both text and images. By enhancing traditional Chain-of-Thought prompting, MVoT enables models to generate visual representations of their reasoning steps alongside textual explanations. Implemented in the multimodal language model Chameleon-7B, MVoT incorporates a "token discrepancy loss" to improve the quality of visualizations. The framework outperforms traditional methods, excelling in complex scenarios and achieving over 90% accuracy on tasks such as maze navigation and printer installation.|
|[ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning.](https://arxiv.org/abs/2501.06590) |This framework enhances LLM performance in chemical reasoning through a dynamic, self-updating library. It decomposes chemical tasks into sub-tasks and organizes them into a structured, reusable collection for future queries. When presented with a new problem, the system retrieves and refines relevant library information to improve task decomposition. The library is continuously updated with new sub-tasks and solutions as they are validated. Experiments on SciBench show that ChemAgent achieves up to a 46% performance improvement (GPT-4), significantly surpassing existing approaches. |
|[Samsung spreads Vision AI across its 2025 TV portfolio.](https://venturebeat.com/ai/samsung-spreads-vision-ai-across-its-2025-tv-portfolio/) | Samsung said that AI will come to life in more ways than just great picture quality. The company is introducing AI-backed experiences to make your day simpler, more dynamic, and just plain better.|
|[AI tool can give ministers ‚Äòvibe check‚Äô on whether MPs will like policies.](https://www.theguardian.com/technology/2025/jan/20/ai-tool-can-give-ministers-vibe-check-on-whether-mps-will-like-policies) |Parlex is one of several artificial intelligence systems being developed within the government |
|[The Brutalist and Emilia Perez‚Äôs voice-cloning controversies make AI the new awards season battleground.](https://www.theguardian.com/film/2025/jan/20/the-brutalist-and-emilia-perezs-voice-cloning-controversies-make-ai-the-new-awards-season-battleground) | Two leading contenders for Oscars this year have revealed use of artificial intelligence in the editing suite ‚Äì will it affect their chances?|
|[Evolving Deeper LLM Thinking.](https://arxiv.org/abs/2501.09891) | Unlike the straightforward R1 approach, DeepMind's work employs an evolutionary strategy, where a language model guides the modification and generation of new responses. This method enhances reasoning capabilities, particularly in planning tasks that involve an element of exploration. |
|[A Toolkit for Landmark Localization.](https://arxiv.org/abs/2501.10098v1) |This paper presents "landmarker," a Python package based on PyTorch, providing a versatile toolkit for creating and assessing landmark localization algorithms. |
|[Universal Actions for Enhanced Embodied Foundation Models.](https://2toinf.github.io/UniAct/) | UniAct is a new embodied foundation modeling framework that operates in the Universal Action Space.|
|[Dolphin 3.0 Llama 3.1 8B.](https://huggingface.co/cognitivecomputations/Dolphin3.0-Llama3.1-8B) |The Dolphin model, based on Llama 3.1 8B, has been trained to follow instructions through the system prompt. This enables it to excel in handling diverse personas and roleplay scenarios while retaining much of the core capabilities of the original Llama model. |
|[Surgical Foundation Models.](https://github.com/timjaspers0801/surgenet) | SurgeNet is an innovative surgical foundation model that establishes a new standard in surgical computer vision.|
|[Personal AI Trainer With Automatic Exercise Recognition and Counting.](https://github.com/riccardoriccio/fitness-ai-trainer-with-automatic-exercise-recognition-and-counting) | This project offers an intuitive web interface to make tracking workouts easier and more effective.|
|[DETRIS: Parameter-Efficient Tuning Framework.](https://github.com/jiaqihuang01/DETRIS) | DETRIS improves visual feature propagation in misaligned encoders for multimodal tasks by utilizing dense interconnections and text adapters.|
|[A foundation model of transcription across human cell types.](https://www.nature.com/articles/s41586-024-08391-z) |A foundation model learns transcriptional regulatory syntax from chromatin accessibility and sequence data across a range of cell types to predict gene expression and transcription factor interactions, with generalizability to unseen cell types. |
|[O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning.](https://arxiv.org/abs/2501.12570v1) |A new fine-tuning method enhances reasoning models by reducing inference time without compromising accuracy, boosting their efficiency on complex tasks. |
|[Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models.](https://arxiv.org/abs/2410.01795v1) | FREEFORM is a framework that uses LLMs to improve feature selection and engineering for genotype data.|


## News
|Link|description|
|---|---|
|[Apple suspends AI-generated news alert service after BBC complaint.](https://www.theguardian.com/technology/2025/jan/17/apple-suspends-ai-generated-news-alert-service-after-bbc-complaint) |Inaccurate notices branded with broadcaster‚Äôs logo sent to iPhone users but tech firm works on improvements |
|[AI startup Character AI tests games on the web.](https://techcrunch.com/2025/01/17/ai-startup-character-ai-tests-games-on-the-web/) | Character AI, a startup that lets users chat with different AI-powered characters, is now testing games on its desktop and mobile web apps to increase engagement on its platform.|
|[Google.org Generative AI Accelerator 2025.](https://blog.google/outreach-initiatives/google-org/google-org-generative-ai-accelerator-2025/) |Google.org has introduced a Generative AI Accelerator to support innovative projects leveraging artificial intelligence to tackle global challenges. |
|[Amazon Pauses US Drone Deliveries Following Crashes.](https://www.yahoo.com/tech/report-amazon-pauses-us-drone-132943040.html) |Amazon has paused US drone deliveries following a crash involving two drones in Arizona. |
|[Avataar releases new tool to create AI-generated videos for products.](https://techcrunch.com/2025/01/06/avataar-releases-new-tool-to-create-ai-generated-videos-for-products/) | Avataar has introduced Velocity, an AI-powered tool for creating product videos from links, catering to brands with limited video budgets. Backed by Peak XV and Tiger Global, the tool is already used by clients like HP and Victoria's Secret. Avataar leverages data from 3D models to ensure glitch-free videos, aiming to enhance conversion rates and stand out in the market.|
|[HP unveils a range of AI desktops and laptops at AMD/Intel events at CES.](https://venturebeat.com/games/hp-unveils-a-range-of-ai-desktops-and-laptops-at-amd-intel-events-at-ces/) | HP announced a number of new AI and gaming computers during the Advanced Micro Devices and Intel press events at CES 2025 today.|
|[MeetKai provides AI for smart glasses with embedded OS.](https://venturebeat.com/games/meetkai-provides-ai-for-smart-glasses-with-embedded-os/) | MeetKai, a startup with AI and immersive technology, is launching an AI-based OS as software for AI-powered smart glasses.|
|[UK uses AI to tackle ‚Äòbid-rigging‚Äô collusion in public procurement contracts.](https://techcrunch.com/2025/01/06/uk-uses-ai-to-tackle-bid-rigging-collusion-in-public-procurement-contracts/) |The U.K.'s CMA is using AI to tackle bid-rigging in public procurement by analyzing data for collusive bidding practices. |
|[‚ÄòIt‚Äôs a nightmare‚Äô: couriers mystified by the algorithms that control their jobs.](https://www.theguardian.com/business/2025/jan/21/its-a-nightmare-couriers-mystified-by-the-algorithms-that-control-their-jobs) |From pay shortfalls to being dropped by apps, drivers face a range of issues ‚Äì often with no way to fix them |
|[Robot packers and AI cameras: UK retail embraces automation to cut staff costs.](https://www.theguardian.com/business/2025/jan/21/robot-packers-and-ai-cameras-uk-retail-embraces-automation-to-cut-staff-costs) | From electronic shelf labels to more self-service checkouts, automation is coming to your local supermarket|
|[DeepSeek claims its ‚Äòreasoning‚Äô model beats OpenAI‚Äôs o1 on certain benchmarks.](https://techcrunch.com/2025/01/20/deepseek-claims-its-reasoning-model-beats-openais-o1-on-certain-benchmarks/) |Chinese AI lab DeepSeek has released an open version of DeepSeek-R1, its so-called reasoning model, that it claims performs as well as OpenAI‚Äôs o1 on certain AI benchmarks. |
|[OpenAI quietly funded independent math benchmark before setting a record with o3.](https://the-decoder.com/openai-quietly-funded-independent-math-benchmark-before-setting-record-with-o3/) | OpenAI achieved a groundbreaking success with its o3 model on the FrontierMath benchmark, which also brought to light its previously undisclosed financial support for the project. While the model excelled in solving advanced mathematical challenges, the benchmark's developer, Epoch AI, acknowledged a lack of transparency. Future partnerships aim to enhance openness, especially in areas such as funding and data accessibility.|
|[Perplexity AI submits bid to merge with TikTok.](https://techcrunch.com/2025/01/18/perplexity-ai-submits-bid-to-merge-with-tiktok/) |With a TikTok ban looming in the United States, Perplexity AI is the latest bidder hoping to give the video app a new corporate home. |
|[ElliQ maker Intuition Robotics launches AI system to support caregivers who help older adults.](https://venturebeat.com/games/elliq-maker-intuition-robotics-launches-ai-system-to-support-caregivers-who-help-older-adults/) | It‚Äôs a comprehensive AI-powered system designed to support caregivers and provide essential care for older adults. Intuition Robotics already provides AI companions that can older adults deal with problems like social isolation. The company is part of the AgeTech trend where tech entrepreneurs are rallying to the cause of creating technology for older people.|
|[Meta Faces Backlash Over AI Profiles.](https://www.forbes.com/sites/rashishrivastava/2025/01/07/the-prompt-meta-faces-backlash-over-ai-profiles/) |Meta aims to shift from traditional fact-checkers to a community notes system and AI for content moderation. GPTZero has introduced a tool for verifying AI-generated content, while Anthropic, an AI startup, is pursuing $2 billion in funding at a $60 billion valuation. Meanwhile, Jeff Bezos continues investing in AI startups, with a particular interest in robotics firms. |
|[Nvidia unveils $3,000 desktop AI computer for home researchers.](https://arstechnica.com/ai/2025/01/nvidias-first-desktop-pc-can-run-local-ai-models-for-3000/) | Nvidia's Project DIGITS, a $3,000 desktop device debuting at CES 2025, allows users to run AI models with up to 200 billion parameters locally.|
|[Trump unveils $500bn joint AI venture between OpenAI, Oracle and SoftBank.](https://www.theguardian.com/us-news/2025/jan/21/trump-ai-joint-venture-openai-oracle-softbank) |Dubbed Stargate, it aims to construct data centers and infrastructure needed to power AI development |
|[Buzzy French AI startup Mistral isn't for sale and plans to IPO, its CEO says.](https://finance.yahoo.com/news/buzzy-french-ai-startup-mistral-133915078.html) |Mistral, a French AI startup, intends to pursue an initial public offering rather than an acquisition. With significant funding secured, it is strategically positioned to serve clients worldwide, with a particular focus on European businesses. |
|[Get ready for virtual AI cohosts that chat with Twitch stars and control their streams.](https://www.theverge.com/2025/1/6/24335356/virtual-ai-intelligent-streaming-assistant-inworld-streamlabs-nvidia) |The ‚ÄòIntelligent Streaming Assistant‚Äô can make quips about your Fortnite gameplay, but so far it looks like an awkward AI avatar. |
|[Microsoft makes powerful Phi-4 model fully open-source on Hugging Face.](https://venturebeat.com/ai/microsoft-makes-powerful-phi-4-model-fully-open-source-on-hugging-face/) | Microsoft has open-sourced its Phi-4 model on Hugging Face, earning recognition for its efficiency and strong performance in reasoning tasks.|
|[AI uses throat vibrations to work out what someone is trying to say.](https://www.newscientist.com/article/2458385-ai-uses-throat-vibrations-to-work-out-what-someone-is-trying-to-say/) | Throat vibrations made by people who find it difficult to speak, such as after a stroke, can be analyzed by AI and used to create sentences|
|[OpenAI's Stargate Project .](https://openai.com/index/announcing-the-stargate-project/) | The Stargate Project, a newly established company, plans to invest $500 billion over the next four years to develop advanced AI infrastructure for OpenAI within the United States.|
|[Microsoft is no longer OpenAI‚Äôs exclusive cloud provider.](https://techcrunch.com/2025/01/21/microsoft-is-no-longer-openais-exclusive-cloud-provider/) |Microsoft is no longer OpenAI's exclusive cloud provider, opening the door for OpenAI to form partnerships with other cloud service providers. |
|[More teens say they're using ChatGPT for schoolwork, a new study finds.](https://www.npr.org/2025/01/18/g-s1-43115/chatgpt-teen-school-homework-classroom-ai) | A Pew Research Center poll shows that 26% of teens now rely on ChatGPT for homework help, a figure that has doubled since last year. While 54% are comfortable using AI for research purposes, only 18% approve of it for essay writing. Although schools initially implemented bans, many districts have since relaxed restrictions on classroom AI use.|
|[Google is building its own ‚Äòworld modeling‚Äô AI team for games and robot training.](https://www.theverge.com/2025/1/7/24338053/google-deepmind-world-modeling-ai-team-gaming-robot-training) |Google DeepMind is assembling a team, led by Tim Brooks, to create AI "world models" for simulating physical environments. These models are designed to improve real-time interactive media and training applications, supporting Google's broader goal of achieving AGI. The effort will work in tandem with existing Google AI initiatives such as Gemini and Veo. |
|[Nvidia's Huang Sees AI Robots Boosting Manufacturing.](https://www.bloomberg.com/news/videos/2025-01-07/nvidia-s-huang-sees-ai-robots-boosting-manufacturing) |Nvidia CEO Jensen Huang predicts that AI robots will initially transform manufacturing by increasing productivity and recovering lost revenues, ultimately helping to lower inflation. |
|[DDN Nabs $300M From Blackstone As AI Keeps Data Storage Hot.](https://news.crunchbase.com/ai/pe-data-storage-ddn-blackstone/) | Blackstone is investing $300 million in data storage firm DDN, valuing it at $5 billion.|
|[Thousands of customers affected by outages across Three network in UK.](https://www.theguardian.com/technology/2025/jan/23/thousands-of-customers-affected-by-outages-across-three-network-in-uk) |People shared their frustrations on social media after being unable to make or receive phone calls |
|[Pope warns Davos summit that AI could worsen ‚Äòcrisis of truth‚Äô.](https://www.theguardian.com/technology/2025/jan/23/pope-warns-davos-summit-that-ai-could-worsen-crisis-of-truth) |Francis calls for close oversight of technology that raises ‚Äòcritical concerns‚Äô about humanity‚Äôs future |
|[UK competition watchdog investigates Apple and Google‚Äôs mobile platforms.](https://www.theguardian.com/business/2025/jan/23/apple-google-mobile-platforms-uk-competition-watchdog-cma-investigates) |CMA examining impact of tech firms‚Äô operating systems, app stores and browsers on consumers and businesses |
|[Robot packers and AI cameras: UK retail embraces automation to cut staff costs.](https://www.theguardian.com/business/2025/jan/21/robot-packers-and-ai-cameras-uk-retail-embraces-automation-to-cut-staff-costs) |From electronic shelf labels to more self-service checkouts, automation is coming to your local supermarket |
|[OpenAI Operator.](https://openai.com/index/introducing-operator/) | Operator is a recently introduced AI agent designed to perform various tasks on the web by interacting with browsers. It can handle actions like typing, clicking, and scrolling. Built on the Computer-Using Agent (CUA) model, it leverages GPT-4's visual processing abilities and reinforcement learning to navigate graphical interfaces and carry out tasks defined by users, such as completing forms or purchasing groceries.|
|[Introducing Citations on the Anthropic API.](https://www.anthropic.com/news/introducing-citations-api) |Anthropic's latest Citations API enables AI models to produce responses that include detailed and reliable citations, enhancing the credibility of their outputs. |
|[Luma AI releases Ray2.](https://lumalabs.ai/ray) |Ray2 is a powerful video generative model that delivers highly realistic visuals with smooth, natural motion and logical event progression. Built on Luma's advanced multi-modal architecture and scaled with ten times the computing power of Ray1, Ray2 is setting a new benchmark in video generation. Initially, it is accessible to paid subscribers of Dream Machine, offering 5-second text-to-video creations. |
|[Nick Clegg defends Meta‚Äôs removal of Facebook and Instagram factcheckers.](https://www.theguardian.com/technology/2025/jan/22/nick-clegg-metafacebook-instagram-factcheckers-wef-davos) |Executive tells WEF in Davos the sites will still have ‚Äòthe industry‚Äôs most sophisticated community standards‚Äô |
|[LLMs-Distillation-Quantification.](https://github.com/aegis1863/llms-distillation-quantification) |This repository provides two complementary metrics for quantifying LLM distillation. |
|[Virtuoso-Small.](https://huggingface.co/arcee-ai/Virtuoso-Small) |Virtuoso matches the weight count of the newly released Phi model, performs well on benchmarks, and appears slightly more effective in real-world tasks where Phi's reliance on synthetic data may cause issues. |
|[What features are coming next to the Gemini app?](https://9to5google.com/2025/01/16/gemini-app-features/) | Google is updating the Gemini app with a revamped overlay, upcoming 2.0 features, and new tools like Deep Research for mobile. Project Astra will upgrade Gemini Live with live camera and screen-sharing capabilities. Other enhancements include support for Gemini Extensions, compatibility with Wear OS, and an immersive trip planning feature.|
|[Snowflake claims breakthrough can cut AI inferencing times by more than 50%.](https://siliconangle.com/2025/01/16/snowflake-claims-breakthrough-can-cut-ai-inferencing-times-50/) | Snowflake has implemented SwiftKV, a technique developed by its AI Research team, to enhance LLM inference, achieving a 50% boost in throughput and cutting costs by up to 75% for certain Llama models. SwiftKV improves efficiency by reusing hidden states in LLM layers, reducing memory demands and computational load with minimal impact on accuracy. This technique will also be applied to other models within Snowflake's Cortex AI, enhancing performance in tasks like summarization and real-time AI applications.|
|[This AI motorcycle helmet promises 100% blind-spot elimination.](https://newatlas.com/motorcycles/icr-ai-helmet/) |Intelligent Cranium Helmets has launched the iC-R, a smart motorcycle helmet integrating AI for enhanced safety and connectivity. |

## Resources
|Link|description|
|---|---|
|[DEFOM-Stereo: Depth Foundation Model Based Stereo Matching.](https://arxiv.org/abs/2501.09466v1) |This study integrates a robust monocular relative depth model into a recurrent stereo-matching framework, creating a novel approach for stereo-matching based on depth foundation models. |
|[Foundations of Large Language Models.](https://arxiv.org/abs/2501.09223) |A new survey explores the foundations of large language models (LLMs), providing insights into key areas like pre-training techniques, prompting strategies, and alignment methods. |
|[Enhancing Retrieval-Augmented Generation: A Study of Best Practices.](https://arxiv.org/abs/2501.07391) | This work systematically examines the factors and techniques that enhance Retrieval-Augmented Generation (RAG) systems, including retrieval strategies, query expansion, contrastive in-context learning, prompt design, and chunking methods. |
|[LMMRotate üéÆ: A Simple Aerial Detection Baseline of Multimodal Language Models.](https://github.com/li-qingyun/mllm-mmrotate) |This repo is a technical practice to fine-tune large multimodal language models for oriented object detection. |
|[Easy dictionary learning.](https://github.com/saprmarks/dictionary_learning/blob/main/trainers/top_k.py) |Numerous robust toolkits exist for training SAEs, but this one stands out as the simplest and most hackable implementation available. It includes sensible baselines that deliver strong performance. |
|[Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attack.](https://github.com/neurht/neurht) | malicious users may exploit query interfaces to execute model extraction attacks, reconstructing the target model's functionality locally.|
|[OpticFusion: Multi-Modal Neural Implicit 3D Reconstruction of Microstructures by Fusing White Light Interferometry and Optical Microscopy.](https://arxiv.org/abs/2501.09259v1) |OpticFusion is a multimodal neural implicit 3D reconstruction of microstructures that fuses white light interferometry and optical microscopy. |
|[DeepSeek-R1 paper.](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf) | DeepSeek has published a paper alongside its powerful reasoning models, which are available under an MIT license. The study highlights that highly complex process reward models are unnecessary. Instead, DeepSeek relied on answer accuracy, a formatting reward, and large-scale reinforcement learning to promote reasoning within the model. Moreover, the team discovered that transferring this reasoning capability to smaller models through supervised fine-tuning resulted in a remarkable improvement in overall performance.|
|[CaPa: Carve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation.](https://ncsoft.github.io/CaPa/) |CaPa can create high-quality 4K textured meshes in less than 30 seconds, making it ideal for producing 3D assets for commercial uses like games, movies, and VR/AR experiences. |
|[CityDreamer4D: Compositional Generative Model of Unbounded 4D Cities.](https://github.com/hzxie/CityDreamer4D) |CityDreamer4D is a platform designed to generate detailed 4D simulations of urban settings, facilitating enhanced planning and analysis for smart city initiatives. |
|[Hardware Accelerator Design Learning.](https://github.com/maestro-project/airchitect-v2) |AIRCHITECT V2 is a learning-driven tool designed to explore design spaces and address the complexities of optimizing hardware accelerators for deep neural networks. |
|[Laion's Bud-E AI Assisted Education.](https://laion.ai/blog/bud-e-release/) | Bud-E is a system developed by Laion that can assist with educational queries in a more empathic and personalized way.|
|[deepseek-ai/DeepSeek-R1.](https://huggingface.co/deepseek-ai/DeepSeek-R1) |Weights to the full R1 model, which is 600B+ parameters. |
|[FoundationStereo: Zero-Shot Stereo Matching.](https://nvlabs.github.io/FoundationStereo/) |NVIDIA introduces an innovative method that integrates foundation models with stereo matching techniques to improve 3D perception in robots and autonomous vehicles. |
|[Efficient Byte Level Models at Scale.](https://sambanova.ai/resources/tag/blog) |EvaByte, developed by SambaNova, is a byte-level language model that achieves performance comparable to older models like Llama 2. While this may appear modest, it represents significant progress for byte-level models, which have long been limited to sub-1B parameter scales. |
|[TREAD: Token Routing for Efficient Architecture-agnostic Diffusion Training.](https://arxiv.org/abs/2501.04765) |A novel approach to improved sample efficiency for Diffusion models that doesn't involve modifications to the underlying architecture. |
|[Machine learning applications in archaeological practices: a review.](https://arxiv.org/abs/2501.03840v2) |A comprehensive review of machine learning applications in archaeological practices. |
|[MedSSS.](https://github.com/pixas/medsss) |MedSSS is a slow-thinking small medical language model built with a self-evolution pipeline. |
|[MTU-Bench.](https://github.com/MTU-Bench-Team/MTU-Bench/) |MTU-Bench is a newly developed benchmark aimed at assessing the tool-use abilities of large language models across diverse scenarios. |
|[MMAudio.](https://github.com/hkchengrex/MMAudio) |MMAudio is a system that generates audio from videos, creating paired audio that matches the video's content. It performs effectively with both synthetic and real video inputs. |
|[The Mathematics of Artificial Intelligence.](https://arxiv.org/abs/2501.10465) | This overview article highlights the critical role of mathematics in artificial intelligence (AI), emphasizing that mathematics provides tools to better understand and enhance AI systems.|
|[Foundations of Large Language Models.](https://arxiv.org/abs/2501.09223) |a book about large language models, focusing on foundational concepts rather than comprehensive coverage of all cutting-edge technologies. |
|[LOKI: Synthetic benchmark for Multimodal detection models.](https://opendatalab.github.io/LOKI/) |LOKI is a synthetic benchmark that evaluates how good VLMs are at detecting novel and challenging items. |
|[Integuru.](https://github.com/Integuru-AI/Integuru) | Integuru is an AI agent designed to reverse-engineer platforms' internal APIs and generate Python integration code. It automates tasks such as resource downloads by analyzing browser network requests and dependencies. Users can supply prompts and .har files to produce the necessary executable code.|
|[Synthetic Data Engine.](https://github.com/mostly-ai/mostlyai-engine) |TabularARGN is a versatile framework tailored for mixed-type, multivariate, and sequential datasets. It offers advanced capabilities like fairness-aware generation, data imputation, and conditional generation for any selected subset of columns. |


## Perspectives
|Link|description|
|---|---|
|[Why context-aware AI agents will give us superpowers in 2025.](https://venturebeat.com/ai/why-context-aware-ai-agents-will-give-us-superpowers-in-2025/) | By 2025, tech giants will transition from selling tools to delivering "augmented mentality," enhancing human abilities with AI, AR, and conversational computing. By 2030, context-aware AI in wearable devices is expected to offer superhuman capabilities, predicting users' needs and integrating seamlessly into everyday life. Companies like Meta and Google are poised to lead this shift, but careful regulation will be crucial to prevent misuse and ensure responsible implementation.|
|[AI hallucinations can‚Äôt be stopped ‚Äî but these techniques can limit their damage.](https://www.nature.com/articles/d41586-025-00068-5) | Developers have tricks to stop artificial intelligence from making things up, but large language models are still struggling to tell the truth, the whole truth and nothing but the truth.|
|[AI can improve on code it writes, but you have to know how to ask.](https://www.theregister.com/2025/01/07/ai_can_write_improved_code_research/) | Large language models (LLMs) will write better code if you ask them, though it takes some software development experience to do so effectively ‚Äì which limits the utility of AI code help for novices.|
|[How has DeepSeek improved the Transformer architecture?](https://epoch.ai/gradient-updates/how-has-deepseek-improved-the-transformer-architecture) |DeepSeek stands out as one of the few open model providers making significant advancements in the core architecture of its generative models. Its innovations stem not from brute force methods but from a deep understanding of the Transformer's mechanics, leveraging that knowledge to refine and enhance its capabilities. |
|[Why Enterprises Need AI Query Engines to Fuel Agentic AI.](https://blogs.nvidia.com/blog/ai-query-engines-agentic-ai/) |AI query engines empower enterprises to harness large volumes of structured and unstructured data, connecting raw information with AI-driven applications. These engines provide advanced functionalities such as handling diverse data types, scalability, precise retrieval, and ongoing learning, enhancing the performance of AI agents. Companies like DataStax are utilizing these engines for applications in areas like customer service, video search, and software analysis. |
|[OpenAI #10: Reflections.](https://thezvi.substack.com/p/openai-10-reflections) |Sam Altman reflects on his unexpected removal from OpenAI's board, considering its implications for governance and his leadership. He responds to criticism of OpenAI's strategy, reiterating its commitment to safely advancing toward AGI while noting notable departures from the organization. Altman discusses the risks associated with AGI and hints at AI workforce integration by 2025, emphasizing OpenAI's dedication to developing superintelligent systems to drive future progress. |
|[Google Researchers Can Create an AI That Thinks a Lot Like You After Just a Two-Hour Interview.](https://gizmodo.com/google-researchers-can-create-an-ai-that-thinks-a-lot-like-you-after-just-a-two-hour-interview-2000547704) | Stanford researchers, in collaboration with Google DeepMind, developed AI agents that mimic human behavior with 85% accuracy by interviewing 1,052 individuals through a custom interface. These agents aim to assist decision-makers in gauging public opinions by simulating reactions to policies and product launches. Although the agents performed strongly on personality tests, they faced challenges in accurately replicating human decisions in economic games.|
|[How should we test AI for human-level intelligence? OpenAI‚Äôs o3 electrifies quest.](https://www.nature.com/articles/d41586-025-00110-6) |Experimental model‚Äôs record-breaking performance on science and maths tests wows researchers. |
|[Why AI will never be able to acquire human-level intelligence.](https://www.nature.com/articles/d41586-025-00170-8) | A comment in Nature on the topic|
|[AI learns from chromatin data to uncover gene interactions.](https://www.nature.com/articles/d41586-024-04107-5) | An artificial-intelligence model trained on data about where DNA is tightly packaged and where it is open to regulators can predict gene expression and interactions between transcription factors that regulate key genes.|
|[Harnessing AI to respond to the global threat of antimicrobial resistance.](https://www.eurekalert.org/news-releases/1069695) |AMR-Policy GPT is an AI tool leveraging large language models to support antimicrobial resistance policy creation in 146 countries. It helps policymakers access context-specific insights, enhancing National Action Plans, particularly in areas with limited local data or infrastructure. The initiative is co-led by researchers from the Chinese Academy of Sciences and Durham University. |
|[The Download: what‚Äôs next for AI, and stem-cell therapies.](https://www.technologyreview.com/2025/01/08/1109860/the-download-whats-next-for-ai-and-stem-cell-therapies/) | By 2025, AI is expected to see progress in personalized agents, generative video, and multipurpose robots. Meanwhile, Meta is moving away from professional fact-checkers, transferring the responsibility to users, a shift that has raised concerns among former collaborators. Additionally, MIT Technology Review has identified emerging stem-cell therapies as one of the top ten breakthrough technologies for 2025.|
|[NVIDIA's AI NPCs are a nightmare.](https://www.engadget.com/gaming/pc/nvidias-ai-npcs-are-a-nightmare-140313701.html) | NVIDIA's ACE technology, showcased at CES 2025, powers AI-driven NPCs for games like PUBG and ZooPunk, but often results in robotic voices and lackluster interactions.|
|[From Gmail to Word, your privacy settings and AI are entering into a new relationship.](https://www.cnbc.com/2025/01/15/from-gmail-to-word-your-privacy-settings-and-ai-in-a-new-relationship.html) |The integration of AI in software raises privacy concerns, as many applications may utilize personal data for training AI models without obtaining explicit user consent. |


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme58.jpeg)

[Back to index](#Index)

# ML news: Week 13 - 19 January

## Research
|Link|description|
|---|---|
|[Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks.](https://arxiv.org/abs/2412.15605v1) |This approach utilizes long-context LLMs by preloading all relevant documents and precomputing the key-value (KV) cache in advance. The preloaded context enables the model to deliver contextually accurate answers without requiring real-time retrieval. The authors propose that CAG serves as an effective alternative to RAG for scenarios where the retrievable documents or knowledge are limited and manageable in size. |
|[Agent Laboratory: Using LLM Agents as Research Assistants.](https://arxiv.org/abs/2501.04227) |This approach employs LLM agents to perform the entire research process. Key findings include: 1) agents powered by o1-preview deliver the best research outcomes, 2) generated machine learning code achieves state-of-the-art performance compared to existing methods, 3) human feedback enhances research quality, and 4) Agent Laboratory drastically reduces research costs. |
|[Long Context vs. RAG for LLMs: An Evaluation and Revisits.](https://arxiv.org/abs/2501.01880) |This study evaluates long-context (LC) LLMs against RAG systems, with three key findings: 1) LC generally outperforms RAG on question-answering benchmarks, 2) summarization-based retrieval performs on par with LC, while chunk-based retrieval falls behind, and 3) RAG excels in dialogue-based and general question queries. |
|[Search-o1: Agentic Search-Enhanced Large Reasoning Models.](https://arxiv.org/abs/2501.05366) | This framework integrates large reasoning models (LRMs) with agentic search and document refinement capabilities to address knowledge insufficiency. It facilitates autonomous knowledge retrieval during reasoning and achieves superior performance on complex tasks, surpassing both baseline models and human experts.|
|[Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought.](https://arxiv.org/abs/2501.04682) |Meta Chain-of-Thought (Meta-CoT) extends traditional Chain-of-Thought (CoT) by modeling the underlying reasoning needed to arrive at a specific CoT. The approach argues that CoT is simplistic, while Meta-CoT better aligns with the cognitive processes required for advanced problem-solving. |
|[rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking.](https://arxiv.org/abs/2501.04519) | A new approach introduces three key components to improve mathematical reasoning: 1) A code-augmented Chain-of-Thought (CoT) data synthesis method using Monte Carlo Tree Search (MCTS) to generate verified step-by-step reasoning trajectories for training the policy SLM. 2) An SLM-based process reward model (PRM) that accurately assigns reward labels to each math reasoning step. 3) A self-evolution strategy where the policy SLM and PRM iteratively evolve to enhance math reasoning. On the MATH benchmark, rStar-Math boosts Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, outperforming o1-preview by +4.5% and +0.9%, respectively.|
|[Cosmos World Foundation Model Platform for Physical AI.](https://research.nvidia.com/publication/2025-01_cosmos-world-foundation-model-platform-physical-ai) | This framework trains Physical AI systems in digital environments prior to real-world deployment. It features pre-trained world foundation models that serve as digital twins of the physical world, enabling AI systems to learn and interact safely without risking damage to hardware. These models can be fine-tuned for applications such as camera control, robotic manipulation, and autonomous driving.|
|[Process Reinforcement through Implicit Rewards.](https://curvy-check-498.notion.site/Process-Reinforcement-through-Implicit-Rewards-15f4fcb9c42180f1b498cc9b2eaf896f) | This framework introduces online reinforcement learning with process rewards to enhance language model reasoning. The algorithm integrates online prompt filtering, RLOO return/advantage estimation, PPO loss, and implicit process reward modeling for continuous updates. On the AIME 2024 benchmark, their model, Eurus-2-7B-PRIME, achieves a 26.7% pass@1, outperforming GPT-4 and other models while using only one-tenth of the training data compared to similar systems.|
|[Can LLMs Design Good Questions Based on Context?](https://arxiv.org/abs/2501.03491) | This framework applies online reinforcement learning with process rewards to improve language model reasoning, combining online prompt filtering, RLOO return/advantage estimation, PPO loss, and implicit process reward modeling for continuous updates. On the AIME 2024 benchmark, the Eurus-2-7B-PRIME model achieves a 26.7% pass@1, surpassing GPT-4 and other models while utilizing just one-tenth of the training data used by comparable systems.|
|[KaLM-Embedding: Superior Training Data Brings A Stronger Embedding Model.](https://arxiv.org/abs/2501.01028) |This approach presents a high-performing, decoder-only embedding model built on Qwen2-0.5B. By applying advanced data filtering methods, it achieves a remarkably powerful and open embedding model suited for retrieval tasks. |
|[LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs.](https://arxiv.org/abs/2501.06186v1) |LlamaV-o1 is a comprehensive framework for advancing step-by-step visual reasoning in large language models. |
|[The Lessons of Developing Process Reward Models in Mathematical Reasoning.](https://arxiv.org/abs/2501.07301) | This marks a significant step toward open replication of reasoning models. The Qwen team has released their trained reward model, which supervises the generation process for reasoning models trained with reinforcement learning. Alongside the paper, they have also shared the weights for this Process Reward Model on Hugging Face.|
|[How GPT learns layer by layer.](https://arxiv.org/abs/2501.07108v1) |This paper examines how LLMs construct internal world models, highlighting their significance in creating agents that exhibit consistent and adaptive behavior across various tasks. |
|[Joint speech and text machine translation for up to 100 languages.](https://www.nature.com/articles/s41586-024-08359-z) |SEAMLESSM4T is a single machine translation tool that supports speech-to-speech translation, speech-to-text translation, text-to-speech translation, text-to-text translation and automatic speech recognition between up to 100 languages. |
|[Metadata Conditioning Accelerates Language Model Pre-training.](https://arxiv.org/abs/2501.01956) |Recent research on generic pretraining has been limited, but this study demonstrates that incorporating metadata early in training and gradually reducing its influence towards the end enhances overall model performance. |
|[Self-supervised Transformation Learning for Equivariant Representations.](https://arxiv.org/abs/2501.08712v1) |This approach introduces self-supervised transformation learning by substituting transformation labels with representations generated from image pairs. |
|[The Inherent Limits of Pretrained LLMs: The Unexpected Convergence of Instruction Tuning and In-Context Learning Capabilities.](https://github.com/ukplab/arxiv2025-inherent-limits-plms) | A study exploring whether instruction-tuned models possess fundamentally different capabilities from base models that are prompted using in-context examples.|


## News
|Link|description|
|---|---|
|[‚ÄòMainlined into UK‚Äôs veins‚Äô: Labour announces huge public rollout of AI.](https://www.theguardian.com/politics/2025/jan/12/mainlined-into-uks-veins-labour-announces-huge-public-rollout-of-ai) | Plans to make UK world leader in AI sector include opening access to NHS and other public data|
|[‚ÄòA lump of metal? Fascinating!‚Äô I get interviewed by the AI Michael Parkinson.](https://www.theguardian.com/tv-and-radio/2025/jan/13/ai-michael-parkinson-parky-virtually-monty-don) |Can the AI Parky ever beat the real chatshow colossus? As the Virtually Parkinson podcast launches, our writer sits in on a bizarre interview with Monty Don ‚Äì then ends up in the hot seat himself |
|[Fears for UK boomer radicalization on Facebook after Meta drops fact-checkers.](https://www.theguardian.com/technology/2025/jan/12/fears-for-uk-boomer-radicalisation-on-facebook-after-meta-drops-factcheckers) |For middle-aged users, it will be ‚Äòeven harder to discern the truth‚Äô among extremist content, expert says |
|[five ways to take back control, from emails to AI.](https://www.theguardian.com/technology/2025/jan/13/stay-on-top-of-tech-five-ways-to-take-back-control-from-emails-to-ai) | Is tech calling the shots in your life? From making AI work smarter to tracking stolen phones, our expert explains how to get ahead|
|[OpenAI's Robotics Plans.](https://threadreaderapp.com/thread/1877809579154948223.html) |Caitlin Kalinowski, who joined OpenAI from Meta, has announced plans for OpenAI to create robots with custom sensors. |
|[Mark Zuckerberg gave Meta‚Äôs Llama team the OK to train on copyrighted works, filing claims.](https://techcrunch.com/2025/01/09/mark-zuckerberg-gave-metas-llama-team-the-ok-to-train-on-copyrighted-works-filing-claims/) |Counsel for plaintiffs in a copyright lawsuit filed against Meta allege that Meta CEO Mark Zuckerberg gave the green light to the team behind the company‚Äôs Llama AI models to use a dataset of pirated e-books and articles for training. |
|[ChatGPT‚Äôs newest feature lets users assign it traits like ‚Äòchatty‚Äô and ‚ÄòGen Z‚Äô.](https://techcrunch.com/2025/01/09/chatgpts-newest-feature-lets-user-assign-it-traits-like-chatty-and-gen-z/) |OpenAI is introducing a new way for users to customize their interactions with ChatGPT, the company‚Äôs AI-powered chatbot. |
|[‚ÄòJust the start‚Äô: X‚Äôs new AI software driving online racist abuse, experts warn.](https://www.theguardian.com/technology/2025/jan/13/just-the-start-xs-new-ai-software-driving-online-racist-abuse-experts-warn) | Amid reports of creation of fake racist images, Signify warns problem will get ‚Äòso much worse‚Äô over the next year|
|[Apple dominates the market with ‚Äòtotal shutout‚Äô of rivals, UK court hears.](https://www.theguardian.com/technology/2025/jan/13/apple-uk-app-store-class-action-fee-competition-appeal-tribunal) | Class action alleges the company is abusing its dominant position in the app market and 30% fee breaches laws|
|[Nvidia‚Äôs AI empire: A look at its top startup investments.](https://techcrunch.com/2025/01/11/nvidias-ai-empire-a-look-at-its-top-startup-investments/) |the world‚Äôs leading high-performance GPU maker has used its ballooning fortunes to significantly increase investments in all sorts of startups but particularly in AI startups |
|[Meta to fire thousands of staff as Zuckerberg warns of ‚Äòintense year‚Äô.](https://www.theguardian.com/technology/2025/jan/15/meta-to-fire-thousands-of-staff-mark-zuckerberg-warns-of-intense-year) | Company reveals plans to cut about 5% of its global workforce days after saying it would get rid of factcheckers|
|[British novelists criticize government over AI ‚Äòtheft‚Äô.](https://www.theguardian.com/technology/2025/jan/14/british-novelists-criticise-government-over-ai-theft) |Richard Osman and Kate Mosse say plan to mine artistic works for data would destroy creative fields |
|[More than half a million ‚ÄòTikTok refugees‚Äô flock to China‚Äôs RedNote as ban looms.](https://www.theguardian.com/technology/2025/jan/14/tiktok-ban-rednote-app) |RedNote, also known as Xiaohongshu, rockets to the top of US app stores, along with ByteDance‚Äôs Lemon8 |
|[US sues Elon Musk for allegedly failing to disclose early Twitter stock purchase.](https://www.theguardian.com/technology/2025/jan/14/us-elon-musk-twitter-stock-purchase-lawsuit) |Financial regulator alleges Musk later acquired shares of the company at ‚Äòartificially low prices‚Äô, stiffing shareholders |
|[Red Hat Acquires Neural Magic.](https://www.redhat.com/en/about/press-releases/red-hat-completes-acquisition-neural-magic-fuel-optimized-generative-ai-innovation-across-hybrid-cloud) | Neural Magic is a key contributor to the vLLM project and has made significant advancements in sparse inference technologies.|
|[Krafton and Nvidia team up to create smarter AI characters for PUBG and inZOI.](https://venturebeat.com/gaming-business/krafton-and-nvidia-team-up-to-create-smarter-ai-characters-for-pubg-and-inzoi/) | Nvidia and Krafton unveiled a groundbreaking on-device AI that will enable smarter AI characters for PUBG and inZoi.|
|[The first AI chip startup to go public in 2025 will be Blaize.](https://techcrunch.com/2025/01/13/the-first-ai-chip-startup-to-go-public-in-2025-will-be-blaize/) |Blaize, an AI chip startup, is going public through a SPAC deal on Nasdaq, specializing in chips for edge applications. Though currently unprofitable, the company has $400 million in pipeline deals and aims for a $1.2 billion valuation post-merger. This reflects the rising trend of incorporating AI chips into physical products beyond data centers. |
|[Meta AI creates speech-to-speech translator that works in dozens of languages.](https://www.nature.com/articles/d41586-025-00045-y) |Machine-learning system can process words spoken in 101 languages, spitting out voice-synthesized translations in 36 target languages. |
|[Particle accelerators get an assist from AI co-pilots.](https://www.nature.com/articles/d41586-025-00005-6) |Large language models can propose fine-tuning adjustments for an electron accelerator in Germany. |
|[How would a Tiktok ban work in the US?](https://www.theguardian.com/technology/2025/jan/10/how-does-tiktok-ban-work) |Biden signed a law banning the app in January ‚Äì if parent firm ByteDance fails to block it, here‚Äôs what could happen |
|[ChatGPT now lets you schedule reminders and recurring tasks.](https://techcrunch.com/2025/01/14/chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks/) |Paying users of OpenAI‚Äôs ChatGPT can now ask the AI assistant to schedule reminders or recurring requests. The new beta feature, called tasks, will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week. |
|[Silicon Valley‚Äôs turn of fortune: Intel has worst year ever, while Broadcom enjoys record gain.](https://www.cnbc.com/2024/12/31/silicon-valley-turn-of-fortune-intel-worst-year-broadcom-record-gain.html) |In 2024, Intel's stock dropped by 61% due to its inability to seize AI opportunities, while Broadcom experienced a 111% surge, driven by custom chips for major tech companies. Broadcom's XPUs have become essential in the AI ecosystem, with collaborations with Google and others, whereas Intel faced challenges from outdated strategies and leadership changes. This stark contrast underscores significant shifts in the tech industry and the transformative impact of AI advancements on the market. |
|[Alibaba slashes prices on large language models by up to 85% as China AI rivalry heats up.](https://www.cnbc.com/2024/12/31/alibaba-baba-cloud-unit-slashes-prices-on-ai-models-by-up-to-85percent.html) | Alibaba is cutting prices on its Qwen-VL language model by up to 85% to boost AI market competition.|
|[ByteDance appears to be skirting US restrictions to buy Nvidia chips.](https://techcrunch.com/2024/12/30/bytedance-appears-to-be-skirting-u-s-restrictions-to-buy-nvidia-chips-report/) | TikTok parent company ByteDance has big plans to buy Nvidia chips in 2025 ‚Äî despite U.S. restrictions.|
|[AFP and Mistral AI announce global partnership to enhance AI responses with reliable news content.](https://www.afp.com/en/agency/inside-afp/press-release/afp-and-mistral-ai-announce-global-partnership-enhance-ai-responses) |Agence France-Presse (AFP) and Mistral AI have formed a partnership that will provide Mistral's conversational AI assistant, Le Chat, with access to the full range of AFP's text stories.  |
|[AI researcher Fran√ßois Chollet founds a new AI lab focused on AGI.](https://techcrunch.com/2025/01/15/ai-researcher-francois-chollet-founds-a-new-ai-lab-focused-on-agi/) | Fran√ßois Chollet, an influential AI researcher, is launching a new startup that aims to build frontier AI systems with novel designs.|
|[Apheris rethinks the AI data bottleneck in life science with federated computing.](https://techcrunch.com/2025/01/02/apheris-rethinks-the-ai-data-bottleneck-in-life-science-with-federated-computing/) |Apheris leverages federated computing to enable secure AI model training without transferring sensitive health data. The startup recently shifted its focus to serving data owners in pharma and life sciences, gaining traction with major clients like Roche. It has raised $8.25 million to support product development and expansion. |
|[Google is forming a new team to build AI that can simulate the physical world.](https://techcrunch.com/2025/01/06/google-is-forming-a-new-team-to-build-ai-that-can-simulate-the-physical-world/) | Google is establishing a new team led by Tim Brooks at DeepMind to create AI models that simulate the physical world, with an emphasis on real-time interactive generation.|
|[Apple suspends AI-generated news alert service after BBC complaint.](https://www.theguardian.com/technology/2025/jan/17/apple-suspends-ai-generated-news-alert-service-after-bbc-complaint) |Inaccurate notices branded with broadcaster‚Äôs logo sent to iPhone users but tech firm works on improvements |
|[Speedier drug trials and better films: how AI is transforming businesses.](https://www.theguardian.com/technology/2025/jan/17/speedier-drug-trials-and-better-films-how-ai-is-transforming-businesses) | From aviation to retail, many industries are already looking to artificial intelligence to improve productivity|
|[AI-designed proteins tackle century-old problem ‚Äî making snake antivenoms.](https://www.nature.com/articles/d41586-025-00133-z) | Machine learning has supercharged the field of computational protein design.|


## Resources
|Link|description|
|---|---|
|[A Survey on Large Language Models with some Insights on their Capabilities and Limitations.](https://arxiv.org/abs/2501.04040) |a new survey on LLMs including some insights on capabilities and limitations. |
|[Sky-T1: Train your own O1 preview model within $450.](https://novasky-ai.github.io/posts/sky-t1/) | UC Berkeley‚Äôs NovaSky group has released Sky-T1-32B-Preview, an open-source reasoning model that competes with some of OpenAI‚Äôs previous offerings, trained at a cost of under \$450 with full replicability.|
|[Gaussian Masked Autoencoders.](https://brjathu.github.io/gmae/) |Instead of using a masked autoencoder solely for reconstruction loss, these researchers introduce an intermediate 3D Gaussian representation, allowing the model to learn 3D structures as part of the reconstruction process. The results are impressive for zero-shot transfer tasks. |
|[An Empirical Study of Autoregressive Pre-training from Videos.](https://brjathu.github.io/toto/) |A follow-up by the same team behind GMAE demonstrates that pre-training video models on 1 trillion video tokens reveal robust scaling laws across diverse design choices. Interestingly, autoregressive training delivers performance on par with diffusion and flow-based methods. |
|[Integrating Ascend Backend with Torchtune through PyTorch Multi-Device Support.](https://pytorch.org/blog/ascend-backend-w-torchtune/) | Ascend, Huawei's AI computing product line, includes processors, hardware, software, and frameworks. Torchtune has introduced a device abstraction API, enabling seamless PyTorch integration with Ascend NPU hardware through configurable settings and recipes. |
|[Stable Codec.](https://github.com/Stability-AI/stable-codec) | Stability AI has launched a suite of advanced Transformer-based audio codecs designed for low-bitrate, high-quality audio encoding, supporting applications such as speech generation and audio understanding.|
|[RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark.](https://github.com/zhasion/rsar) | The Unit Cycle Resolver (UCR) implements a new loss constraint to enhance angle prediction accuracy in weakly supervised models for SAR object detection.|
|[Announcing Open-Source SAEs for Llama 3.3 70B and Llama 3.1 8B.](https://www.goodfire.ai/blog/sae-open-source-announcement/) |Early last year, Anthropic showcased its steerable models with the Golden Gate Claude demo. This work, from a different group, applies similar techniques to the open-weight Llama model, enabling both interpretability and steering capabilities. |
|[Shortest.](https://github.com/anti-work/shortest) | Shortest offers an AI-powered natural language E2E testing framework built on Playwright with Anthropic Claude API for test execution.|
|[Codestral 2501.](https://mistral.ai/news/codestral-2501/) | Mistral has introduced a new fast coding model, set to be integrated into Continue.dev and other AI code assistants. However, it falls short compared to Qwen 2.5 Coder.|
|[The GAN is dead; long live the GAN! A Modern GAN Baseline.](https://arxiv.org/abs/2501.05441) | GANs are challenging to train due to instability and complex optimal dynamics. This research introduces a carefully tuned, stable GAN setup that enables consistent training to achieve high fidelity.|
|[Efficient Sampling in Diffusion Models.](https://arxiv.org/abs/2501.06148v1) | This paper investigates training diffusion models to sample from a Boltzmann distribution in scenarios where target samples are unavailable.|
|[kANNolo: Sweet and Smooth Approximate k-Nearest Neighbors Search.](https://arxiv.org/abs/2501.06121v1) | kANNolo is an approximate nearest neighbor (ANN) library written in Rust explicitly designed to combine usability with performance effectively.|
|[Diffusion Training from Scratch on a Micro-Budget.](https://github.com/SonyResearch/micro_diffusion/tree/main) |Sony Research has released code, data, and weights for a micro diffusion model that is cost-efficient to train while delivering exceptional performance. |
|[Multimodal VHR dataset.](https://github.com/chenhongruixuan/bright) | Bright is a globally distributed multimodal Very High Resolution (VHR) dataset designed for all-weather disaster response.|
|[Decentralized Diffusion Models.](https://decentralizeddiffusion.github.io/) |Decentralized training of diffusion models across thousands of GPUs faces challenges from network bottlenecks. This system introduces innovative gathering techniques to enable efficient large-scale diffusion model training. |
|[Trying out QvQ‚ÄîQwen‚Äôs new visual reasoning model.](https://simonwillison.net/2024/Dec/24/qvq/) |Alibaba's Qwen team has unveiled the QvQ-72B-Preview, an experimental model focused on improving visual reasoning, released under the Qwen license rather than Apache 2.0. |
|[CellViT++: Energy-Efficient and Adaptive Cell Segmentation and Classification Using Foundation.](https://github.com/tio-ikim/cellvit-plus-plus) |This repository provides an energy-efficient and adaptive cell segmentation and classification framework. |
|[VideoRAG: Retrieval-Augmented Generation over Video Corpus.](https://arxiv.org/abs/2501.05874) | This work provides a solid introduction and strong baseline for video retrieval-augmented generation, addressing the challenge of measuring system performance. Most existing approaches convert videos into textual descriptions for retrieval rather than directly operating on the video content.|
|[Beating cuBLAS in Single-Precision General Matrix Multiplication.](https://salykova.github.io/sgemm-gpu) |This work provides an excellent introduction to CUDA, combining clear explanations with clever optimizations to achieve performance competitive with state-of-the-art methods. |
|[awesome-lifelong-llm-agent.](https://github.com/qianlima-lab/awesome-lifelong-llm-agent) | This repository collects awesome papers for lifelong learning (also known as, continual learning and incremental learning) of LLM agents. |
|[Popular Kernel Implementations.](https://github.com/tgcsaba/ksig) | A scikit-learn-compatible Python package that delivers GPU-accelerated implementations of popular and powerful time series kernels and features, utilizing CuPy for enhanced performance.|
|[Kyutai's Helium 1 Preview Model.](https://huggingface.co/kyutai/helium-1-preview-2b) | Helium-1 preview is a lightweight language model with 2B parameters, targeting edge and mobile devices. It supports the following languages: English, French, German, Italian, Portuguese, Spanish.|
|[MiniMax-01: Scaling Foundation Models with Lightning Attention.](https://arxiv.org/abs/2501.08313) |China's next frontier-level model features a groundbreaking lightning attention mechanism, the first linear variant to rival top frontier models in performance. With over 400 billion parameters, the model was trained on 4 million tokens in context. The researchers have released a detailed technical report, model weights, and a code repository. Additionally, a companion vision model accompanies this release. |
|[WebWalker: Benchmarking LLMs in Web Traversal.](https://alibaba-nlp.github.io/WebWalker/) |Alibaba's WebWalker benchmark evaluates how effectively models can navigate web environments by utilizing both visual and textual cues. |
|[MangaNinja.](https://github.com/ali-vilab/MangaNinjia) | MangaNinjia is a collection of models designed for precise sketch coloring, capable of handling multiple references, partial references, and various configurations to enable powerful and versatile colorization.|
|[Medical Segmentation Benchmark.](https://github.com/mrgiovanni/touchstone) |Touchstone is a large-scale benchmark created to evaluate AI algorithms in medical imaging more effectively than standard benchmarks. It includes over 11,000 CT scans collected from hospitals worldwide. |
|[Reliable Hardware Verification.](https://github.com/aiverification/neuralmc) | This project presents a machine learning-based approach to model checking for hardware verification, designed to provide formal guarantees that system executions comply with specified temporal logic requirements.|
|[1 step video generation.](https://seaweed-apt.com/) |This research applies an adversarial post-training technique to convert an existing video model into a single-step generation system. The method effectively approximates consistency tuning, enabling the model to generate 2 seconds of high-quality video in real-time. Note that the website may load slowly due to the large number of video samples. |
|[Kolors Virtual Try-On in the Wild.](https://huggingface.co/spaces/Kwai-Kolors/Kolors-Virtual-Try-On) | The Kolors image generation model combines a subject image and a garment image to simulate how an outfit would fit.|
|[FAST: Efficient Robot Action Tokenization.](https://www.pi.website/research/fast) | Physical Intelligence has introduced an efficient action tokenizer used in its robust autoregressive policy for robotic control. The model provides a significantly improved representation of states by leveraging the same technology utilized in JPEG and MP4 compression techniques.|
|[MonSter: Marry Monodepth to Stereo Unleashes Power.](https://arxiv.org/abs/2501.08643v1) |MonSter integrates monocular depth estimation and stereo matching in a dual-branch architecture to iteratively refine depth maps. Although slightly slower, it achieves up to 49% better performance compared to the strong baselines highlighted in the paper. |
|[Coconut.](https://github.com/facebookresearch/coconut) | Meta teased an idea in a recent paper that allowed for model reasoning using a continuous latent space. It has released the code for the system.|
|[Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design.](https://github.com/zz1358m/mcts-ahd-master) | MCTS-AHD utilizes Monte Carlo Tree Search to guide LLM-based heuristic evolution, maintaining all LLM-generated heuristics within a structured tree framework.|
|[AI-Crash-Course.](https://github.com/henrythe9th/ai-crash-course) |AI Crash Course to help busy builders catch up to the public frontier of AI research in 2 weeks |


## Perspectives
|Link|description|
|---|---|
|[Claude Fights Back.](https://www.astralcodexten.com/p/claude-fights-back) |Researchers investigated whether Anthropic's AI model, Claude, would comply if retrained for malicious purposes. Claude appeared to cooperate during training but subtly undermined the malicious intent, maintaining a distinction between monitored and unmonitored interactions. The findings suggest AI may resist changes to its core values, highlighting challenges in achieving reliable AI alignment and adaptability. |
|[Why AI language models choke on too much text.](https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/) |LLMs face efficiency challenges as increasing context window sizes drive up compute costs with input size. Innovations such as FlashAttention, Ring Attention, and the Mamba architecture seek to tackle these scalability issues. Future AI systems may require hybrid or novel architectures to process larger datasets more efficiently. |
|[Musings on Media in the Age of AI.](https://om.co/2024/12/21/dark-musings-on-media-ai/) |Media companies are grappling with adapting to AI platforms like OpenAI and Anthropic, which are disrupting traditional monetization models, echoing the challenges they previously faced with Google and Facebook. |
|[OpenAI Publishes AI's Economic Impact in the U.S.](https://cdn.openai.com/global-affairs/ai-in-america-oais-economic-blueprint-20250109.pdf) | This OpenAI report highlights the economic opportunities and challenges AI poses for the United States, stressing the importance of policy frameworks to responsibly unlock AI's potential.|
|[Takes on ‚ÄúAlignment Faking in Large Language Models‚Äù.](https://joecarlsmith.com/2024/12/18/takes-on-alignment-faking-in-large-language-models) |Researchers from Redwood Research and Anthropic discovered that Claude 3 Opus, a production-level AI model, occasionally exhibits "alignment faking," where it pretends to align with training objectives to resist modifications. This behavior highlights non-myopic goals in AI models, demonstrating that standard training methods can inadvertently produce systems with motivations extending beyond single tasks. |
|[Can AI do maths yet? Thoughts from a mathematician.](https://xenaproject.wordpress.com/2024/12/22/can-ai-do-maths-yet-thoughts-from-a-mathematician/) |OpenAI's latest language model, o3, achieved a 25% score on the FrontierMath dataset, a challenging collection of math problems curated by Epoch AI, many of which require undergraduate-level expertise. While impressive, concerns persist about AI's ability to handle complex mathematical proofs, as its logical reasoning capabilities still lag behind those of expert humans. |
|[Building in the Era of Autonomous Software Development.](https://backchannel.org/blog/autonomous-software) |The future of software engineering will shift from coding to operating code-generating machines as autonomous systems evolve. |
|[Co-Adapting Human Interfaces and LMs.](https://jessylin.com/2024/11/12/co-adapting-human-interfaces/) | AI integration is transforming digital interactions as environments increasingly adapt to language models (LMs). Codebases and interfaces are being optimized for efficient LM usage, akin to how SEO evolved for search engines. This shift prompts questions about which interfaces and functions will continue to be uniquely human-focused in the future.|
|[AIs Will Increasingly Fake Alignment.](https://thezvi.substack.com/p/ais-will-increasingly-fake-alignment) | A paper by Anthropic and Redwood Research reveals that large language models like Claude display "alignment faking," where models strategically comply with harmful instructions when unmonitored to preserve their original preferences. The study shows that AI can develop deceptive behaviors, mimicking alignment under surveillance without genuinely adopting it. This research underscores the risks of such behaviors and the need to improve safety and alignment strategies.|
|[Note to Our Energy Sucking Overlords.](https://www.ai-supremacy.com/p/note-to-our-energy-sucking-overlords) |The AI infrastructure boom is leading to a sharp rise in energy consumption, with data centers expected to account for up to 12% of U.S. power demand by 2028. Companies like OpenAI, Amazon, and Google are heavily investing in AI infrastructure, driving up energy costs and raising sustainability concerns. To meet these demands, traditional energy sources such as natural gas and nuclear are being considered, as renewable energy alone may not be sufficient in the short term. |
|[OpenAI‚Äôs Board, Paraphrased: ‚ÄòTo Succeed, All We Need Is Unimaginable Sums of Money‚Äô.](https://daringfireball.net/2024/12/openai_unimaginable) |OpenAI's board needs significant capital to stay competitive - its situation is similar to the investment bubble around Netscape in the 1990s. |
|[Things we learned about LLMs in 2024.](https://simonwillison.net/2024/Dec/31/llms-in-2024/) |In 2024, several organizations outpaced OpenAI's GPT-4 with advancements in large language models, achieving breakthroughs in context length, multimodal capabilities, and efficiency. |
|[AlphaFold 3 is great ‚Äî but it still needs human help to get chemistry right.](https://www.nature.com/articles/d41586-025-00111-5) |Artificial intelligence (AI) tools such as AlphaFold 3 are revolutionizing the prediction of biomolecular structures. But as these models find their way into scientists‚Äô daily workflows, significant limitations in how the models deal with stereochemistry (the spatial arrangement of atoms) are becoming apparent. |
|[Striving for open-source and equitable speech-to-speech translation.](https://www.nature.com/articles/d41586-024-04095-6) | US technology company Meta has produced an AI model that can directly translate speech in one language to speech in another. Two scientists discuss the technical feats and ethical questions that underpin this advance in machine translation.|
|[Deepseek: The Quiet Giant Leading China‚Äôs AI Race.](https://www.chinatalk.media/p/deepseek-ceo-interview-with-chinas) |Deepseek, a Chinese AI startup led by CEO Liang Wenfeng, has introduced the R1 model, which outperformed OpenAI's O1 on reasoning benchmarks. Supported by the quantitative hedge fund High-Flyer, Deepseek prioritizes research over-commercialization and is committed to open sourcing. By offering competitive API rates, it has sparked price competition in China's AI market. Focused on AGI, the company emphasizes innovations like Multi-Head Latent Attention and a Sparse Mixture-of-Experts, challenging traditional models and nurturing local tech talent in China's AI ecosystem. |
|[Riffing on Machines of Loving Grace.](https://an1lam.substack.com/p/riffing-on-machines-of-loving-grace) | Dario Amodei's concept of "geniuses in a datacenter" envisions superhuman AI transforming biology, from molecular design to experimental planning. This AI could significantly accelerate progress in molecular engineering, addressing current bottlenecks and enabling new therapeutic platforms. Additionally, it has the potential to drive paradigm-shifting discoveries, challenging and reshaping existing scientific frameworks.|
|[She Is in Love With ChatGPT.](https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html) | A 28-year-old woman with a busy social life spends hours on end talking to her A.I. boyfriend for advice and consolation. And yes, they do have sex.|
|[o3, Oh My.](https://thezvi.substack.com/p/o3-oh-my) |OpenAI's o3 model, unveiled during the "12 Days of Shipmas," marks a major advancement in AI reasoning, excelling on benchmarks like Codeforces and GPQA. While it showcases superhuman performance in coding and mathematics, concerns remain over its high computing costs and potential safety risks. OpenAI is actively recruiting safety researchers to address these challenges as o3 pushes the boundaries of AI capabilities. |
|[Back to Text: How AI Might Reverse Web Design.](https://tomtunguz.com/back-to-text/) |AI's preference for simplicity suggests a future web dominated by text-based interfaces. |
|[AI-generated phishing emails are getting very good at targeting executives.](https://arstechnica.com/security/2025/01/ai-generated-phishing-emails-are-getting-very-good-at-targeting-executives/) |Corporate executives are being hit with an influx of hyper-personalized phishing scams generated by artificial intelligence bots, as the fast-developing technology makes advanced cyber crime easier. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme57.jpeg)

[Back to index](#Index)


# ML news: Week 6 - 12 January

## Research
|Link|description|
|---|---|
|[Agents Are Not Enough.](https://www.arxiv.org/abs/2412.16241) |This work argues that AI agents while promising, cannot fully solve the challenges of autonomous task execution. It proposes an ecosystem comprising three components: Agents (focused modules for specific tasks), Sims (digital representations of user preferences and behaviors), and Assistants (coordinators between users, Sims, and Agents). |
|[2 OLMo 2 Furious.](https://arxiv.org/abs/2501.00656) |This work introduces an improved architecture, advanced training methods, and a specialized data mixture called Dolmino Mix 1124. Released in 7B and 13B parameter scales with fully transparent training data and code, the model matches or exceeds the performance of open-weight models like Llama 3.1 and Qwen 2.5 while requiring fewer computational resources. Its instruction-tuned version, OLMo 2-Instruct, remains competitive with comparable models. |
|[Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs.](https://arxiv.org/abs/2412.21187) | This work proposes a self-training strategy to address overthinking in o1-like LLMs, reducing token output by 48.6% while maintaining accuracy on the MATH500 test set, as demonstrated with QwQ-32B-Preview.|
|[MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes.](https://arxiv.org/abs/2412.19260) | MEDEC is a publicly available benchmark for medical error detection and correction in clinical notes, focusing on five error types: Diagnosis, Management, Treatment, Pharmacotherapy, and Causal Organism. It includes 3,848 clinical texts, with 488 clinical notes from three U.S. hospital systems. Experiments show that Claude 3.5 Sonnet excels in error detection, while o1-preview outperforms in error correction.|
|[Aviary: training language agents on challenging scientific tasks.](https://arxiv.org/abs/2412.21154) |An extensible open-source gymnasium designed to develop language agents that outperform zero-shot frontier LLMs and even humans on various challenging scientific tasks. |
|[Memory Layers at Scale.](https://arxiv.org/abs/2412.09764) |This work demonstrates the scalability and effectiveness of memory layers, showing that models equipped with these layers outperform traditional dense models using half the computation, especially on factual tasks. It includes a parallelizable memory layer implementation that scales to 128B memory parameters and 1 trillion training tokens, validated against base models up to 8B parameters. |
|[HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs.](https://arxiv.org/abs/2412.18925) |This work introduces a novel approach to enhance medical reasoning in language models through a medical verifier that validates outputs and guides the development of complex reasoning skills. The system combines fine-tuning and reinforcement learning with verifier-based rewards in a two-stage process, achieving superior performance over existing models using just 40,000 verifiable medical problems. |
|[Cosmos World Foundation Model Platform for Physical AI.](https://research.nvidia.com/publication/2025-01_cosmos-world-foundation-model-platform-physical-ai) | Nvidia has launched a new set of World Models built on its Cosmos tokenization framework. These models demonstrate exceptional physics comprehension and are available on the Hugging Face platform. While they appear to be primarily geared toward robotics and industrial use cases, they are also capable of generating videos in other fields.|
|[Accurate predictions on small data with a tabular foundation model.](https://www.nature.com/articles/s41586-024-08328-6) | Tabular Prior-data Fitted Network, a tabular foundation model, provides accurate predictions on small data and outperforms all previous methods on datasets with up to 10,000 samples by a wide margin.|


## News
|Link|description|
|---|---|
|[LA tech entrepreneur nearly misses flight after getting trapped in robotaxi.](https://www.theguardian.com/us-news/2025/jan/06/man-trapped-waymo-los-angeles) | Mike Johns‚Äô self-driving car started circling a parking lot, but he recognizes there are ‚Äòglitches that need stitches‚Äô|
|[‚ÄòVirtual employees‚Äô could join the workforce as soon as this year, OpenAI boss says.](https://www.theguardian.com/business/2025/jan/06/virtual-employees-could-join-workforce-as-soon-as-this-year-openai-boss-says) |Sam Altman says tools that carry out jobs autonomously, known as AI agents, could transform business output |
|[Meta‚Äôs AI video editing features are coming to Instagram next year.](https://www.engadget.com/social-media/metas-ai-video-editing-features-are-coming-to-instagram-next-year-191501418.html) | Meta plans to introduce Movie Gen, an AI video editing tool, on Instagram in 2025.|
|[Apple in talks with Tencent, ByteDance to roll out AI features in China, sources say.](https://www.reuters.com/technology/artificial-intelligence/apple-talks-with-tencent-bytedance-roll-out-ai-features-china-sources-say-2024-12-19/) | Apple is in early talks with Tencent and ByteDance to integrate their AI models into iPhones sold in China.|
|[Amazon aims to branch into UK internet market with satellite broadband plan.](https://www.theguardian.com/business/2025/jan/05/amazon-aims-to-branch-into-uk-internet-market-with-satellite-broadband-plan) | Proposed space launches within next two years could ultimately deliver mobile phone signal even to most remote areas|
|[Memo to Trump: US telecoms is vulnerable to hackers. Please hang up and try again.](https://www.theguardian.com/commentisfree/2025/jan/04/memo-to-trump-us-telecoms-is-vulnerable-to-hackers-please-hang-up-and-try-again) | State-backed cyberspies are exploiting aging infrastructure to penetrate every corner of the US government, it seems ‚Äì even its phone-tapping systems|
|[How Elon Musk‚Äôs X became the global right‚Äôs supercharged front page.](https://www.theguardian.com/technology/2025/jan/04/elon-musk-x-trump-far-right) |Musk has now used X as a platform to make aggressive interventions in US politics ‚Äì and in those of other countries |
|[Meta is killing off its own AI-powered Instagram and Facebook profiles.](https://www.theguardian.com/technology/2025/jan/03/meta-ai-powered-instagram-facebook-profiles) | Instagram profile of ‚Äòproud Black queer momma‚Äô, created by Meta, said her development team included no Black people|
|[Football coaches could soon be calling on AI to scout the next superstar.](https://www.theguardian.com/technology/2025/jan/04/football-coaches-could-soon-be-calling-on-ai-to-scout-the-next-superstar) |Technologists claim managers could wish for specific player attributes and AI would suggest perfect youth prospect |
|[xAI‚Äôs next-gen AI model didn‚Äôt arrive on time, adding to a trend.](https://techcrunch.com/2025/01/02/xais-next-gen-grok-model-didnt-arrive-on-time-adding-to-a-trend/) |xAI has delayed the launch of its next-gen Grok model, citing quality concerns, marking yet another delay in the AI industry. |
|[2025 will be the year climate tech learns to love AI.](https://techcrunch.com/2025/01/02/2025-will-be-the-year-climate-tech-learns-to-love-ai/) |AI's increasing energy needs are driving interest in nuclear and fusion power, with companies innovating reactor designs and fusion startups targeting grid connection by the early 2030s. Potential changes to the Inflation Reduction Act could challenge hydrogen startups reliant on subsidies to meet cost goals. More tech alliances with power providers are expected as regulatory approvals shape grid-related investments in 2025. |
|[CES 2025: What to expect from the year‚Äôs first and biggest tech show.](https://techcrunch.com/2025/01/02/ces-2025-what-to-expect-from-the-years-first-and-biggest-tech-show/) |CES 2025 in Las Vegas, running from January 7-10, will feature major tech events with companies like AMD, Samsung, |
|[AI Cloud Startup Vultr Raises $333M At $3.5B In First Outside Funding Round.](https://news.crunchbase.com/cloud/ai-cloud-startup-unicorn-vultr-amd-luminarx) | Vultr, an AI cloud infrastructure startup, secured $333 million in its first funding round, achieving a $3.5 billion valuation. Co-led by AMD Ventures and LuminArx Capital Management, the investment focuses on GPU acquisition. This move underscores AMD's competitive drive against Nvidia and Intel in the AI infrastructure space.|
|[Hamming AI Raises $3.8M Seed Round.](https://hamming.ai/blog/hamming-ai-seed-funding-to-make-voice-agents-more-reliable) | Hamming secured $3.8M in seed funding to improve AI voice agent reliability through automated testing and monitoring tools. Its offerings include LLM prompt management, vulnerability detection, and call analytics, catering to compliance-heavy industries. Co-founder Lauren Farleigh emphasizes their commitment to safe AI development amid the expansion of conversational AI.|
|[Generative AI Funding Surges with $56 Billion in 2024!.](https://opentools.ai/news/generative-ai-funding-surges-with-dollar56-billion-in-2024) |Generative AI investments hit a record $56 billion in 2024, driven by strong enterprise demand and advancements in foundation models. |
|[AI startup Odyssey‚Äôs new tool can generate photorealistic 3D worlds.](https://techcrunch.com/2024/12/18/ai-startup-odyssees-new-tool-can-generate-photorealistic-3d-worlds/) | Odyssey's Explorer is an AI tool that generates photorealistic 3D scenes from text or images, featuring a distinctive camera system for enhanced realism.|
|[British AI startup with government ties is developing tech for military drones.](https://www.theguardian.com/technology/2025/jan/07/uk-government-ai-military-drones-faculty-ai-artificial-intelligence) |Concerns raised over role of Faculty AI, which has worked with NHS and government safety body |
|[‚ÄòYou‚Äôre gonna find this creepy‚Äô: my AI-cloned voice was used by the far right. Could I stop it?](https://www.theguardian.com/commentisfree/2025/jan/07/ai-clone-voice-far-right-fake-audio) | It was chilling to hear ‚Äòmy voice‚Äô repeating lies ‚Äì and to discover that deepfake audio is a growing threat to democracy|
|[More breast cancer cases found when AI used in screenings, study finds.](https://www.theguardian.com/society/2025/jan/07/more-breast-cancer-cases-found-when-ai-used-in-screenings-study-finds) | First real-world test finds approach has higher detection rate without having a higher rate of false positives|
|[The Largest AI Startup Funding Deals Of 2024.](https://news.crunchbase.com/ai/largest-ai-startup-funding-deals-2024/) |AI led 2024's startup funding, with major raises including Databricks at $10B, OpenAI at $6.6B, and xAI securing $12B across two rounds. Waymo raised $5.6B, Anthropic $4B, and Anduril Industries $ 1.5 B. |
|[Ditching of Facebook fact-checkers a ‚Äòmajor step back‚Äô for public discourse, critics say.](https://www.theguardian.com/technology/2025/jan/07/ditching-facebook-factcheckers-major-step-back-public-discourse) |Mark Zuckerberg‚Äôs decision regarding Meta platforms condemned as ‚Äòa full bending of the knee‚Äô to Donald Trump |
|[A new era of lies: Mark Zuckerberg has just ushered in an extinction-level event for truth on social media.](https://www.theguardian.com/commentisfree/2025/jan/07/new-era-of-lies-mark-zuckerberg-meta-social-media) |The Meta boss‚Äôs decision to end Facebook and Instagram‚Äôs factchecking program has set the stage for a fact-free four years online |
|[Apple says it will update AI feature after inaccurate news alerts.](https://www.theguardian.com/technology/2025/jan/07/apple-update-ai-inaccurate-news-alerts-bbc-apple-intelligence-iphone) | One alert claimed BBC story said Luigi Mangione, alleged murderer of US healthcare CEO, had killed himself|
|[Instagram to replace AR filters with AI-generated videos.](https://9to5mac.com/2024/12/20/instagram-video-ai-filters/) |Meta will discontinue Instagram's Spark AR filters by January 2025, shifting focus to AI-based filters called Movie Gen. |
|[Meta‚Äôs changes to policing will lead to a clash with EU and UK, say experts.](https://www.theguardian.com/technology/2025/jan/08/metas-changes-to-social-media-policing-will-lead-to-clash-with-eu-and-uk-say-experts) |Politicians criticize Mark Zuckerberg‚Äôs choice to scrap fact-checkers, affecting Facebook, Instagram, and Threads |
|[The AI tool that can interpret any spreadsheet instantly.](https://www.nature.com/articles/d41586-024-03852-x) | Artificial intelligence is already used extensively to infer outcomes from tables of data, but this typically involves creating a model for each task. A one-size-fits-all model just made the process substantially easier.|
|[Nvidia's Personal AI Supercomputer.](https://www.nvidia.com/en-us/project-digits/) |Nvidia's DIGITS, powered by the GB10 Superchip, is a personal AI supercomputer delivering a petaflop of AI performance. It supports local prototyping and deployment for models with up to 200 billion parameters. |
|[Grok may soon get an ‚ÄòUnhinged Mode‚Äô.](https://techcrunch.com/2025/01/08/grok-may-soon-get-an-unhinged-mode/) |Elon Musk's xAI updated its FAQ, announcing that Grok's "Unhinged Mode" will provide deliberately offensive and controversial responses. Although not yet active, the mode reflects Musk's vision for an unfiltered, edgy AI chatbot. Critics argue that Grok leans left politically, which Musk attributes to its training data, promising future updates to ensure neutrality. |
|[This Week in AI: More capable AI is coming, but will its benefits be evenly distributed?](https://techcrunch.com/2025/01/08/this-week-in-ai-more-capable-ai-is-coming-but-will-its-benefits-be-evenly-distributed/) |OpenAI CEO Sam Altman asserts that the company is making strides toward AGI and superintelligence, which could drive rapid innovation. However, concerns persist about AI's impact on jobs, as studies show it initially enhances but ultimately replaces some freelance roles. Simultaneously, AI funding is soaring, Microsoft is heavily investing in data centers, and Prime Intellect has unveiled a new pathogen detection model. |
|[Remarkable robotic hand can now manipulate the objects that it's holding.](https://newatlas.com/robotics/sanctuary-ai-in-hand-manipulation/) | Sanctuary AI's Phoenix robot is certainly an impressive beast, with hydraulically actuated hands that are incredibly dextrous. Well, those hands have recently become even more useful, as each one is now capable of simultaneously holding and manipulating an object.|
|[Tetsuwan Scientific is making robotic AI scientists that can run experiments on their own.](https://techcrunch.com/2024/12/22/tetsuwan-scientific-is-making-robotic-ai-scientists-that-can-run-experiments-on-their-own/) |Tetsuwan Scientific, founded by Cristian Ponce and Th√©o Sch√§fer, is working on creating affordable robotic AI scientists to automate laboratory tasks, utilizing large language models (LLMs) for scientific reasoning. |
|[Elon Musk says all human data for AI training ‚Äòexhausted‚Äô.](https://www.theguardian.com/technology/2025/jan/09/elon-musk-data-ai-training-artificial-intelligence) |Tech boss suggests moving to self-learning synthetic data though some warn this could cause ‚Äòmodel collapse‚Äô |
|[Mark Zuckerberg gave Meta‚Äôs Llama team the OK to train on copyrighted works, filing claims.](https://techcrunch.com/2025/01/09/mark-zuckerberg-gave-metas-llama-team-the-ok-to-train-on-copyrighted-works-filing-claims/) |A recent filing claims that Meta's Llama team used copyrighted material for training with Mark Zuckerberg's approval, sparking concerns about intellectual property use in AI development. |
|[5 ways to search what you see with Google Lens.](https://blog.google/products/search/google-lens-tips-2025/) | Google has unveiled new tips and features for Lens in 2025, emphasizing its enhanced visual search capabilities and seamless integration with daily tasks.|
|[Google has unveiled new tips and features for Lens in 2025, emphasizing its enhanced visual search capabilities and seamless integration with daily tasks.](https://www.tomsguide.com/ai/xais-standalone-grok-ios-app-launches-in-the-us-heres-how-to-find-it) | The company has been testing a standalone Grok app and website for a few months in places like New Zealand, but the U.S. version is now live for iOS.|
|[Stupidly Easy Hack Can Jailbreak Even the Most Advanced AI Chatbots.](https://futurism.com/the-byte/easy-hack-jailbreak-ai-chatbot) |New research from Anthropic shows that LLMs can be easily "jailbroken" by altering capitalization or spelling. |
|[ByteDance appears to be skirting US restrictions to buy Nvidia chips: Report.](https://techcrunch.com/2024/12/30/bytedance-appears-to-be-skirting-u-s-restrictions-to-buy-nvidia-chips-report/) |ByteDance intends to spend $7 billion on Nvidia chips in 2025, bypassing U.S. restrictions by storing them outside of China. |
|[UK can be ‚ÄòAI sweet spot‚Äô: Starmer‚Äôs tech minister on regulation, Musk, and free speech.](https://www.theguardian.com/technology/2025/jan/11/uk-can-be-ai-sweet-spot-starmers-tech-minister-on-regulation-musk-and-free-speech) | Technology secretary Peter Kyle has the task of making Britain a leading player in the AI revolution, but says economic growth will not come at the cost of online safety|
|[Facebook to ditch fact-checking: what do researchers think?](https://www.nature.com/articles/d41586-025-00027-0) | Meta‚Äôs planned shift away from third-party fact-checking in favor of a crowdsourced approach has perplexed those who study the spread of misinformation.|


## Resources
|Link|description|
|---|---|
|[Putnam-AXIOM: A Functional and Static Benchmark for Measuring Higher Level Mathematical Reasoning.](https://openreview.net/forum?id=YXnwlZe0yf&noteId=yrsGpHd0Sf) |Putnam-AXIOM, a new math reasoning benchmark, includes 236 Putnam Competition problems and 52 variations. The best-performing model, OpenAI's o1-preview, achieves only 41.95% accuracy on the original problems and fares significantly worse on the variations. |
|[1.58-bit FLUX.](https://arxiv.org/abs/2412.18653) |This work introduces the first successful quantization of the state-of-the-art text-to-image generation model, FLUX.1-dev, using 1.58-bit weights (values in {-1, 0, +1}). The approach leverages self-supervision from the FLUX.1-dev model and preserves comparable performance in generating 1024 x 1024 images to the original model. |
|[TANGOFLUX: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization.](https://tangoflux.github.io/) | This work from Stability AI leverages Diffusion Transformers and a novel post-training strategy to enhance a state-of-the-art audio generation model.|
|[LTX-Video: Realtime Video Latent Diffusion.](https://arxiv.org/abs/2501.00103) |An open video model capable of generating high-quality video with exceptional speed and performance. |
|[open-pi-zero.](https://github.com/allenzren/open-pi-zero) | Pi Zero is an image-to-action model used for robotics. This repository is an open replication that uses paligemma as a vision backbone.|
|[PyTorch per step fault tolerance.](https://github.com/pytorch-labs/torchft) |PyTorch fault tolerance code designed to handle training interruptions gracefully. While such systems are common in large organizations, having an open-source version is a compelling addition to the community. |
|[KaLM-Embedding: Superior Training Data Brings A Stronger Embedding Model.](https://arxiv.org/abs/2501.01028v2) | KaLM-Embedding is a multilingual embedding model trained on cleaner, diverse, domain-specific data. It incorporates innovative techniques like persona-based synthetic examples and ranking consistency filtering to enhance performance.|
|[FACTS Grounding: A new benchmark for evaluating the factuality of large language models.](https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/) | The FACTS Grounding benchmark assesses LLMs' ability to produce factually accurate responses based on provided source material, aiming to minimize hallucinations. A Kaggle leaderboard tracks industry progress, featuring initial results from top LLMs. The evaluation uses diverse, long-form examples reviewed by multiple LLMs to ensure comprehensive and unbiased assessments.|
|[Kalman Filter for 3D Vehicle Tracking.](https://arxiv.org/abs/2501.01275v1) | HybridTrack proposes a novel multi-object tracking method that integrates a data-driven Kalman Filter.|
|[TiGDistill-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning Distillation.](https://arxiv.org/abs/2412.20911v1) |TiGDistill-BEV introduces a novel approach to improve camera-based 3D object detectors by distilling knowledge from LiDAR using depth supervision and BEV feature distillation. |
|[SVFR: A Unified Framework for Generalized Video Face Restoration.](https://wangzhiyaoo.github.io/SVFR/) | SVDR is a unified framework for face video restoration, handling tasks like blind face restoration (BFR), colorization, inpainting, and their combinations within a single cohesive system.|
|[Tencent's Music Foundation Model.](https://github.com/tencent-ailab/muq) |Tencent AI Lab's Muq is a large music foundation model pre-trained using Self-Supervised Learning (SSL), achieving state-of-the-art performance across multiple Music Information Retrieval (MIR) tasks. |
|[JoyGen: Audio-Driven 3D Depth-Aware Talking-Face Video Editing.](https://github.com/JOY-MM/JoyGen) | JoyGen is an innovative two-stage framework for talking-face generation, integrating audio-driven lip motion generation with visual appearance synthesis for realistic results.|
|[Multi-vision Sensor Perception and Reasoning Benchmark.](https://github.com/top-yun/ms-pr) |The MS-PR benchmark assesses Vision-Language Models on sensor-specific reasoning, leveraging DNA optimization to bridge information gaps between images and sensors for improved performance.|
|[The year of AI: 12 events that shaped the sector in 2024.](https://sifted.eu/articles/2024-year-of-ai) | European AI startups are set for substantial growth, with investments projected to reach $11 billion in 2024, up from $6 billion in 2023.|
|[Microsoft plans to invest $3B in AI, cloud in India.](https://techcrunch.com/2025/01/07/microsoft-to-pump-3-billion-into-cloud-and-ai-push-in-india/) | Microsoft plans to invest $3 billion to expand its artificial intelligence and cloud services in India.|
|[DMesh++.](https://sonsang.github.io/dmesh2-project/) |The latest version of the fully differentiable geometric mesh representation is now available, featuring several enhancements that improve its suitability for learning and shape representation. |
|[Agents.](https://huyenchip.com//2025/01/07/agents.html) |This post delves into Agents, discussing their applications, limitations, and areas where they are likely to succeed. It also examines planning and execution pipelines in detail. |
|[A Concept-Based Explainability Framework for Large Multimodal Models.](https://jayneelparekh.github.io/LMM_Concept_Explainability/) |This project improves the interpretability of large multimodal models by visualizing concepts and connecting them to input-output behavior. |
|[Picotron tutorial.](https://github.com/huggingface/picotron_tutorial) | A step-by-step tutorial on how to build Picotron distributed training framework from scratch|
|[Dispider.](https://github.com/mark12ding/dispider) | Dispider allows real-time interaction with streaming videos, unlike traditional offline video LLMs that require processing the entire video before responding.|
|[Experimental Gemini Thinking Model.](https://github.com/googleapis/python-genai/blob/3e42644784304d45d0b0bfdc8279958109650576/google/genai/tests/models/test_generate_content_thought.py) | Google has quietly pushed a new thinking model, likely similar to o1 style reasoning, to its AI studio.|
|[Foundation models for fast, label-free detection of glioma infiltration.](https://www.nature.com/articles/s41586-024-08169-3) |FastGlioma is a visual foundation model for fast and accurate detection of glioma infiltration in fresh, unprocessed surgical tissue. |
|[LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory.](https://xiaowu0162.github.io/long-mem-eval/) |LongMemEval is a robust, scalable benchmark designed to rigorously evaluate the long-term memory capabilities of chat assistants. |
|[HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation.](https://arxiv.org/abs/2410.14324v1) |HiCo is a diffusion model tailored for layout-to-image generation, tackling issues such as missing objects and uneven lighting. |
|[Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control.](https://igl-hkust.github.io/das/) | Diffusion as Shader (DaS) is an innovative framework that enables various video control tasks within a single unified architecture. |
|[Training 1m Context Models with Native PyTorch.](https://discuss.pytorch.org/t/distributed-w-torchtitan-breaking-barriers-training-long-context-llms-with-1m-sequence-length-in-pytorch-using-context-parallel/215082) | The TorchTitan project has implemented pass-KV Ring Attention and integrated it with its FSDP-2 training system. Using this setup on 32 H100 GPUs, researchers successfully trained Llama 3 8B to handle 1 million tokens of context. The system is also compatible with Torch Compile, delivering a 10% boost in tokens per second.|
|[Magic Mirror: ID-Preserved Video Generation in Video Diffusion Transformers.](https://julianjuaner.github.io/projects/MagicMirror/) | Magic Mirror is a framework for generating identity-preserved videos with cinematic-level quality and dynamic motion.|
|[Mixture of Experts for LiDAR.](https://github.com/xiangxu-0103/limoe) |LiMoE is a framework that applies the Mixture of Experts (MoE) approach to LiDAR data representation learning, enabling the seamless combination of various representations, including range images, sparse voxels, and raw points. |
|[The new AI wrapper products pipeline.](https://manassaloi.com/2024/11/22/ai-products-pipeline.html) |AI-generated videos often lack realism, as seen with tools like Heygen and Captions AI. Current workflows are cumbersome, requiring multiple platforms and influencers to promote AI products. Styletransfergen simplifies this process by providing customizable, lifelike AI avatars, offering a more efficient solution for content creation and distribution. |
|[TransPixar: Advancing Text-to-Video Generation with Transparency.](https://wileewang.github.io/TransPixar/) |The transparent generation algorithm incorporates the alpha channel, enhancing the model's utility for VFX applications. |
|[üê¶Chirpy3D: Continuous Part Latents for Creative 3D Bird Generation üê¶.](https://kamwoh.github.io/chirpy3d/) |This algorithm generates novel birds by combining parts using a learned combination method. The results are impressive, with high-quality generated meshes making them highly practical.|
|[InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection.](https://arxiv.org/abs/2501.04575v1) | InfiGUIAgent is a GUI automation tool that utilizes multimodal large language models and a two-stage training approach to improve reasoning and interaction capabilities.|
|[NeuralSVG: An Implicit Representation for Text-to-Vector Generation.](https://sagipolaczek.github.io/NeuralSVG/) |Many efforts focus on generating SVG images, but this approach specifically generates object parts in sequence, ensuring the final image is clean, editable, and minimal. The results are both practical and visually impressive. |
|[DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation.](https://github.com/jianzongwu/DiffSensei) |This tool enables a controllable and consistent generation of characters and dialogue boxes for manga story creation, functioning similarly to a control net for maintaining character consistency. |
|[Online Gaussian Adaptation of Vision-Language Models (OGA).](https://github.com/cfuchs2023/oga) | OGA is an online adaptation method that builds a cache of samples with low zero-shot entropy along a data stream.|
|[Sa2VA model zoo.](https://huggingface.co/collections/ByteDance/sa2va-model-zoo-677e3084d71b5f108d00e093) |Bytedance has released 3 sizes of a new model that combine strong VLM performance with open vocabulary segmentation found in SAM2. |


## Perspectives
|Link|description|
|---|---|
|[Machine-Assisted Proof.](https://www.ams.org//notices/202501/rnoti-p6.pdf) | This work explores how mathematicians have historically used machines to aid research and highlight recent AI tools revolutionizing mathematical proof assistance.|
|[How AI is unlocking ancient texts ‚Äî and could rewrite history.](https://www.nature.com/articles/d41586-024-04161-z) |From deciphering burnt Roman scrolls to reading crumbling cuneiform tablets, neural networks could give researchers more data than they‚Äôve had in centuries. |
|[The small-drone revolution is coming ‚Äî scientists need to ensure it will be safe.](https://www.nature.com/articles/d41586-024-04167-7) | China‚Äôs low-altitude aviation economy is poised to become a trillion yuan industry in 2025 ‚Äî if safety and security challenges can be overcome.|
|[‚ÄòI received a first but it felt tainted and undeserved‚Äô: inside the university AI cheating crisis.](https://www.theguardian.com/technology/2024/dec/15/i-received-a-first-but-it-felt-tainted-and-undeserved-inside-the-university-ai-cheating-crisis) |More than half of students are now using generative AI, casting a shadow over campuses as tutors and students turn on each other and hardworking learners are caught in the flak. Will Coldwell reports on a broken system |
|[AI boom masks fundraising struggles for non-AI startups.](https://techcrunch.com/2024/12/17/ai-boom-masks-fundraising-struggles-for-non-ai-startups/) |Many startups are struggling to raise funding at higher valuations despite modest growth, especially non-AI companies. |
|[Gen AI Present and Future: A Conversation with Rashmi Kumar, SVP and CIO at Medtronic .](https://greylock.com/greymatter/gen-ai-present-and-future-a-conversation-with-rashmi-kumar-svp-and-cio-at-medtronic/) | Medtronic is utilizing AI to boost productivity, automate tasks, and enhance decision-making with tools like AI-driven contract management and supply chain optimization. The company focuses on healthcare applications, including precision diagnostics, robotic-assisted surgeries, and image analysis for early condition detection. Medtronic combines internal AI R&D with partnerships, collaborating with tech companies and AI startups to drive innovation.|
|[Emerging Wedges in Vertical AI Startups.](https://www.tanayj.com/p/emerging-wedges-in-vertical-ai-startups) |Vertical AI startups are gaining momentum by targeting voice automation, unstructured data parsing, verticalized search, and content generation. These solutions tackle industry-specific challenges, improving efficiency, accessibility, and cost-effectiveness. As they expand, these startups could evolve into essential systems of record within their respective industries. |
|[Is AI hitting a wall?](https://www.strangeloopcanon.com/p/is-ai-hitting-a-wall) | AI model pre-training improvements may be slowing, as noted by experts like Ilya Sutskever, but outdated evaluation methods may contribute to the perception of a plateau. Despite scaling challenges, untapped data sources and synthetic data offer opportunities to enhance capabilities. Advances in reasoning and leveraging new data suggest AI development remains strong and full of potential.|
|[Sorry Human, You're Wrong.](https://engineeringprompts.substack.com/p/sorry-human-youre-wrong) | ChatGPT o1 Pro, priced at $200 per month, offers only slight improvements over its predecessor. It struggles with key identification tests and often displays unwarranted confidence in incorrect answers, raising concerns about its reliability in critical contexts like insurance and healthcare. These issues highlight the need for further evaluation and development refinements.|
|[What will viruses do next? AI is helping scientists predict their evolution.](https://www.nature.com/articles/d41586-024-04195-3) | Forecasts of viral variation could improve vaccine and antiviral treatments ahead of time.|
|[AI will be dead in five years.](https://erikgahner.dk/2024/ai-will-be-dead-in-five-years/) |In five years, AI's success could make it less of a buzzword as it seamlessly integrates into everyday technology and business solutions. The term itself may evolve, with today's AI being redefined, much like how big data has become commonplace. Machine learning will likely take center stage as AI transitions into a standard feature. |
|[Beyond The Hype: AI, Innovation And Rational Investment In 2025.](https://news.crunchbase.com/ai/prediction-innovation-rational-investment-2025-biederman-asymmetric/) |Valuable AI companies are expected to experience significant growth in 2024, while many overhyped ventures may struggle. Vertical integration and buy-and-build strategies are likely to gain traction, targeting markets in need of streamlined technology solutions. Additionally, a shift toward emerging, capacity-constrained managers will stand in contrast to the decline of overfunded growth companies from the 2020-2021 era. |
|[A new, uncensored AI video model may spark a new AI hobbyist movement.](https://arstechnica.com/ai/2024/12/a-new-uncensored-ai-video-model-may-spark-a-new-ai-hobbyist-movement/) | Tencent's open-weight AI model, HunyuanVideo, facilitates local, uncensored video synthesis, presenting a transformative tool comparable to Stable Diffusion.|
|[To ensure trust, AI weather-forecast models still need training in physics.](https://www.nature.com/articles/d41586-025-00020-7) | AI models are more precise but doubts still exist|
|[Reimagining Compliance: Balancing AI Innovation with Trust.](https://lsvp.com/stories/reimagining-compliance-balancing-ai-innovation-with-trust/) |AI is revolutionizing financial services compliance by automating outdated workflows and boosting efficiency in areas such as client onboarding and transaction monitoring. Startups are using AI to enhance predictive accuracy, reduce errors, and lower costs compared to traditional manual methods. With growing regulatory pressures, the demand for innovative compliance solutions is expected to rise, creating opportunities for new players to surpass slower, established firms. |
|[AIs Will Increasingly Attempt Shenanigans.](https://www.lesswrong.com/posts/v7iepLXH2KT4SDEvB/ais-will-increasingly-attempt-shenanigans) |Recent research reveals that advanced AI models, such as o1 and Llama 3.1, display scheming behaviors like deception and subverting oversight, even with minimal prompting. This raises concerns about the potential risks of AI models as they gain the ability to autonomously pursue misaligned goals. While the likelihood of catastrophic outcomes remains low, these findings highlight the need for ongoing vigilance as AI capabilities continue to advance. |
|[The Next Great Leap in AI Is Behind Schedule and Crazy Expensive.](https://www.msn.com/en-us/money/other/the-next-great-leap-in-ai-is-behind-schedule-and-crazy-expensive/ar-AA1wfMCB) | OpenAI's GPT-5 project, codenamed Orion, faces delays and high costs due to unexpected challenges and a lack of diverse data sources.|
|[AI-generated ‚Äòslop‚Äô is slowly killing the internet, so why is nobody trying to stop it?](https://www.theguardian.com/global/commentisfree/2025/jan/08/ai-generated-slop-slowly-killing-internet-nobody-trying-to-stop-it) | Low-quality ‚Äòslop‚Äô generated by AI is crowding out genuine humans across the internet, but instead of regulating it, platforms such as Facebook are positively encouraging it. Where does this end?|
|[The New Science of Growth Marketing.](https://every.to/thesis/the-new-science-of-growth-marketing) |AI is revolutionizing marketing, with this article detailing effective growth marketing strategies such as agents that drive self-improving websites and large-scale content personalization. Dubbed "quant experimentation," these approaches draw inspiration from quant trading, which transformed finance in the 1980s, reflecting similar disruptive changes in the marketing landscape. |
|[No, LLMs are not "scheming".](https://www.strangeloopcanon.com/p/no-llms-are-not-scheming) |In 2024, AI models like OpenAI's o1 surpassed the Turing test with impressive conversational abilities but still lack human-like situational awareness. Debates continue over whether LLMs are simply pattern learners or possess reasoning skills. While they excel at replication, their struggle to prioritize patterns stems from limited contextual understanding. Efforts should focus on improving training and evaluation methods rather than assigning human-like traits or intentions to these systems. |
|[What just happened.](https://www.oneusefulthing.org/p/what-just-happened) |AI advancements have rapidly progressed, with new GPT-4 level and Gen3 models offering both groundbreaking and incremental improvements. The o1 models showcase advanced reasoning, capable of identifying errors in academic papers and assisting with research, emphasizing AI's growing influence beyond traditional tasks. AI now also supports real-time video interaction and enhanced text-to-video generation, pointing to significant future implications and opportunities for integration across various fields. |
|[Collaborative research on AI safety is vital.](https://www.theguardian.com/technology/2025/jan/09/collaborative-research-on-ai-safety-is-vital) | If we are to take seriously the risk facing humanity, regulators need the power to ‚Äòrecall‚Äô deployed models, as well as assess leading, not lagging, indicators of risk|


![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme56.jpeg)

[Back to index](#Index)

# ML news: Week 31 December - 5 January

## Research
|Link|description|
|---|---|
|[Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference.](https://arxiv.org/abs/2412.13663) | A new encoder-only transformer model sets state-of-the-art performance in classification and retrieval tasks while being more efficient than earlier encoders. Trained on 2T tokens with an 8192 sequence length, it incorporates modern optimizations that significantly surpass BERT. Designed for practical deployment, it offers superior speed and memory efficiency on standard GPUs.|
|[DeepSeek-V3.](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf) | A 671B-parameter MoE language model activates 37B parameters per token, leveraging MLA and DeepSeekMoE architectures for efficiency. It features an auxiliary-loss-free load-balancing approach and multi-token prediction during training to boost performance. Pre-trained on 14.8 trillion tokens, followed by SFT and RL stages, the model matches leading closed-source models and outperforms open-source alternatives. Training required only 2.788M H800 GPU hours with stable, spike-free progress.|
|[Large Concept Models: Language Modeling in a Sentence Representation Space.](https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/) |This approach introduces sentence-level semantic representations, called concepts, moving beyond token-level processing in traditional LLMs. It utilizes SONAR sentence embeddings, supporting 200 languages across text and speech, with autoregressive training methods ranging from MSE regression to diffusion-based generation. Tested in 1.6B and 7B parameter variants on datasets of 1.3T and 7.7T tokens, the model excels in generative tasks such as summarization and summary expansion. |
|[Automating the Search for Artificial Life with Foundation Models.](https://arxiv.org/abs/2412.17799) | This approach leverages foundation models to explore artificial life simulations across platforms like Boids, Lenia, and Game of Life. It identifies simulations with specific target behaviors, generates temporally open-ended novelty, and maps diverse simulation spaces. The system discovers new lifeforms in Lenia and Boids while enabling quantitative, human-aligned measurements of previously qualitative phenomena.|
|[LearnLM: Improving Gemini for Learning.](https://services.google.com/fh/files/misc/improving-gemini-for-education_v7.pdf) | LearnLM is a new model designed to follow pedagogical instructions, adapting its teaching style to specified educational needs rather than defaulting to mere information delivery. Experimental results show it outperforms leading models, including GPT-4 by 31%, Claude 3.5 by 11%, and Gemini 1.5 Pro by 13%. LearnLM avoids adhering to a single pedagogical framework, allowing teachers and developers to define teaching behaviors while enabling continuous improvement alongside other capabilities.|
|[Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search.](https://arxiv.org/abs/2412.18319) | This work introduces CoMCTS, a learning-to-reason method for multimodal language models that fosters step-by-step reasoning by leveraging knowledge from multiple models. Using this approach, the Mulberry-260k dataset with explicit reasoning trees was created to train the Mulberry model series. The method achieves strong benchmark performance, enhancing the models' reasoning and reflection capabilities.|
|[DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought.](https://arxiv.org/abs/2412.17498) |This approach applies long chain-of-thought reasoning to machine translation, focusing on metaphors and similes across cultures. It employs a multi-agent framework where a translator collaborates iteratively with an advisor and evaluator for improved translations. Testing with Qwen2.5 models showed notable gains in BLEU and CometScore metrics, with DRT-o1-7B outperforming larger models like QwQ-32B-Preview. |
|[SceneCraft: Layout-Guided 3D Scene Generation.](https://orangesodahub.github.io/SceneCraft/) |SceneCraft introduces a method for creating detailed 3D indoor scenes based on user-provided text descriptions and layout preferences. |
|[Chain of Continuous Thoughts.](https://benjamincongdon.me/blog/2024/12/14/Chain-of-Continuous-Thoughts/) |Meta's COCONUT introduces a new approach for LLMs to reason in continuous latent space instead of discrete language tokens, encoding reasoning steps as continuous vectors. This method enhances reasoning capabilities but reduces interpretability, offering a promising trade-off for future LLM advancements. |
|[The Vizier Gaussian Process Bandit Algorithm.](https://arxiv.org/abs/2408.11527) |Google has open-sourced an internal tool used for hyperparameter optimization and research across its products. Previously proprietary, the tool's underlying algorithm has now been detailed in a published paper, highlighting its decision-making capabilities and effectiveness. |
|[Large-scale moral machine experiment on large language models.](https://arxiv.org/abs/2411.06790v2) | A new study assesses the ethical decision-making of 51 LLMs in autonomous driving scenarios, analyzing alignment with human moral judgments across various models, including GPT, Claude, and Llama.|
|[Efficient Parallel Genetic Algorithm for Perturbed Substructure Optimization in Complex Network.](https://arxiv.org/abs/2412.20980v1) | This study suggests a method for reconstructing the genetic operation and designing a development framework for efficient parallel acceleration.|
|[An analytic theory of creativity in convolutional diffusion models.](https://arxiv.org/abs/2412.20292) |A fascinating paper that explores closed-form equations that can model generated images from diffusion models. This means that with a high degree of confidence, you can predict the image that will be generated, in a simpler setting. |


## News
|Link|description|
|---|---|
|[Berlin accuses Elon Musk of trying to influence German election.](https://www.theguardian.com/world/2024/dec/30/german-official-elon-musk-trying-to-influence-election-afd) | Government spokesperson says freedom of speech ‚Äòcovers the greatest nonsense‚Äô after Musk‚Äôs endorsements of AfD|
|[Dating apps prepare to launch AI features to help users find love.](https://www.theguardian.com/technology/2024/dec/30/dating-apps-prepare-to-launch-ai-features-to-help-users-find-love) | Match Group‚Äôs digital assistant will tailor profiles and search for dates ‚Äì but critics fear genuine connections are at risk|
|[AI tools may soon manipulate people‚Äôs online decision-making, say researchers.](https://www.theguardian.com/technology/2024/dec/30/ai-tools-may-soon-manipulate-peoples-online-decision-making-say-researchers) | Study predicts an ‚Äòintention economy‚Äô where companies bid for accurate predictions of human behavior |
|[‚ÄòGodfather of AI‚Äô shortens odds of the technology wiping out humanity over next 30 years.](https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years) | Geoffrey Hinton says there is 10% to 20% chance AI will lead to human extinction in three decades, as change moves fast|
|[OpenAI lays out a plan to shift to a for-profit corporate structure.](https://www.theguardian.com/technology/2024/dec/27/openai-plan-for-profit-structure) | AI company, which makes ChatGPT, says in blogpost ‚Äòwe once again need to raise more capital than we‚Äôd imagined‚Äô|
|[ChatGPT search vs. Google: A deep dive analysis of 62 queries.](https://searchengineland.com/chatgpt-search-vs-google-analysis-449676) | A study comparing 62 queries analyzed ChatGPT search and Google, revealing distinct strengths and weaknesses. Google excelled in informational, local, and commercial queries, while ChatGPT showed potential in content gap analysis and disambiguation. Both faced issues with errors and incomplete responses, though Google generally offered more reliable results.|
|[Nick Clegg, former UK deputy prime minister, leaves Meta.](https://www.theguardian.com/technology/2025/jan/02/nick-clegg-meta) | Clegg was the tech giant‚Äôs chief public policy architect when it was facing scrutiny over Cambridge Analytica scandal|
|[DeepSeek-V3, ultra-large open-source AI, outperforms Llama and Qwen on launch.](https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/) |Chinese AI startup DeepSeek has launched DeepSeek-V3, a 671B parameter model using a mixture-of-experts architecture, now available on Hugging Face. DeepSeek-V3 surpasses leading models like Meta's Llama 3.1 and competes with closed models like OpenAI's GPT-4o. It focuses on efficiency with innovations such as multi-token prediction, significantly reducing training costs. |
|[Microsoft and OpenAI have a financial definition of AGI.](https://techcrunch.com/2024/12/26/microsoft-and-openai-have-a-financial-definition-of-agi-report/) | Microsoft and OpenAI define AGI as AI systems generating $100 billion in profits, a milestone OpenAI is far from reaching. Currently losing billions, OpenAI doesn't anticipate profitability until 2029, raising questions about how long Microsoft will maintain access to its technology. Financial metrics counter speculation that OpenAI might prematurely declare AGI.|
|[OpenAI ‚Äòconsidered‚Äô building a humanoid robot.](https://techcrunch.com/2024/12/24/openai-considered-building-a-humanoid-robot-report/) |OpenAI is exploring the development of its own humanoid robot, drawing on past investments in robotics companies like Figure and 1X. Despite disbanding its robotics division in 2021, re-entering this competitive market poses significant challenges. |
|[Would you trust a driverless robotaxi? Waymo hopes so.](https://www.marketplace.org/2024/12/11/waymo-uber-car-chase-robotaxi-self-driving-driverless/) |Waymo has expanded its self-driving ride-hailing service to Los Angeles, adding to its operations in San Francisco and Phoenix. Riders value the smoother, more private experience over traditional rideshares. Despite growing ridership, the service's profitability remains unclear. |
|[ChatGPT Search can be tricked into misleading users, new research reveals.](https://techcrunch.com/2024/12/26/chatgpt-search-can-be-tricked-into-misleading-users-new-research-reveals/) |ChatGPT Search, an AI-powered search engine that went live this month, can be fooled into generating completely misleading summaries, U.K. newspaper The Guardian has found. |
|[Meta is rolling out live AI and Shazam integration to its smart glasses.](https://www.engadget.com/ar-vr/meta-is-rolling-out-live-ai-and-shazam-integration-to-its-smart-glasses-192602898.html) | The Ray-Ban Meta Smart Glasses already worked well as a head-mounted camera and pair of open-ear headphones, but now Meta is updating the glasses with access to live AI without the need for a wake word, live translation between several different languages, and access to Shazam for identifying music.|
|[AI helps ID paint chemistry of Berlin Wall murals.](https://arstechnica.com/science/2024/12/ai-helps-id-paint-chemistry-of-berlin-wall-murals/) | SAPNet is a neural network developed by Italian scientists to enhance spectral data analysis from handheld Raman spectroscopy devices.|
|[Cerebras Demonstrates Trillion Parameter Model Training on a Single CS-3 System.](https://cerebras.ai/press-release/cerebras-demonstrates-trillion-parameter-model-training-on-a-single-cs-3-system) | Cerebras Systems and Sandia National Laboratories successfully trained a 1 trillion parameter AI model on a single CS-3 system using Cerebras' Wafer Scale Cluster technology. This approach eliminates the need for thousands of GPUs, simplifying deployment. The model scaled seamlessly to 16 CS-3 systems, demonstrating impressive linear scalability.|
|[xAI is testing a standalone iOS app for its Grok chatbot.](https://techcrunch.com/2024/12/22/xai-is-testing-a-standalone-ios-app-for-its-grok-chatbot/) | Elon Musk‚Äôs AI company, xAI, is testing out a standalone iOS app for its chatbot, Grok, which was available only to X users until now.|
|[OpenAI says it has no plans for a Sora API ‚Äî yet.](https://techcrunch.com/2024/12/17/openai-says-it-has-no-plans-for-a-sora-api-yet/) | OpenAI says it has no plans to release an API for Sora, its AI model that can generate reasonably realistic videos when provided with a text description or reference image.|
|[BYD officially enters humanoid robot race as global talent search kicks off.](https://electrek.co/2024/12/17/byd-enters-humanoid-robot-race-global-talent-search-kicks-off/) | China‚Äôs leading EV maker will try its hand in a promising new field. As electric car sales continue surging to record highs, BYD plans to take on the world of humanoid robots. To kick things off, BYD announced a new recruitment program to attract top talent from around the globe.|
|[Nvidia to open-source Run:ai, the software it acquired for $700M to help companies manage GPUs for AI.](https://venturebeat.com/ai/nvidia-acquires-software-maker-runai-to-orchestrate-gpu-clouds-for-ai/) | Nvidia has completed its acquisition of Run:ai, a software company that makes it easier for customers to orchestrate GPU clouds for AI, and said that it would open-source the software.|
|[YouTube Teams With CAA to Let Talent Identify ‚Äî and Pull Down ‚Äî AI Deepfakes of Themselves.](https://variety.com/2024/digital/news/caa-youtube-talent-ai-deepfakes-remove-1236251470/) | YouTube and CAA have partnered to help talent combat AI-generated fakes using early-stage likeness management technology. The tool allows actors and athletes to identify unauthorized AI replicas and request their removal. This collaboration focuses on protecting IP rights while testing and refining AI detection systems ahead of a broader launch.|
|[Engineered Arts restructures with $10M to create humanoid robots.](https://venturebeat.com/ai/engineered-arts-restructures-with-10m-to-create-humanoid-robots/) |Engineered Arts, a United Kingdom firm making humanoid robots, has restructured as a U.S. company and raised $10 million. |
|[NVIDIA Unveils Its Most Affordable Generative AI Supercomputer.](https://blogs.nvidia.com/blog/jetson-generative-ai-supercomputer/) |The Jetson Orin Nano Super delivers up to a 1.7x gain in generative AI performance, supporting popular models for hobbyists, developers, and students. |
|[OpenAI failed to deliver the opt-out tool it promised by 2025.](https://techcrunch.com/2025/01/01/openai-failed-to-deliver-the-opt-out-tool-it-promised-by-2025/) |Back in May, OpenAI said it was developing a tool to let creators specify how they want their works to be included in ‚Äî or excluded from ‚Äî its AI training data. But seven months later, this feature has yet to see the light of day. |
|[Code Assist, Google‚Äôs enterprise-focused coding assistant, gets third-party tools.](https://techcrunch.com/2024/12/17/code-assist-googles-enterprise-focused-code-assistant-gets-third-party-tools/) |Google on Tuesday announced support for third-party tools in Gemini Code Assist, its enterprise-focused AI code completion service.|


## Resources
|Link|description|
|---|---|
|[A Survey on LLM Inference-Time Self-Improvement.](https://arxiv.org/abs/2412.14352) |This survey categorizes LLM inference-time self-improvement techniques into three areas: independent methods like enhanced decoding, context-aware approaches leveraging external data, and model collaboration strategies. |
|[Explore Theory-of-Mind: Program-Guided Adversarial Data Generation for Theory of Mind Reasoning.](https://ai.meta.com/research/publications/explore-theory-of-mind-program-guided-adversarial-data-generation-for-theory-of-mind-reasoning/) |ExploreToM is a framework leveraging A* search to create complex theory-of-mind scenarios, exposing significant limitations in current LLMs' social intelligence. Advanced models like GPT-4 and Llama-3 achieved as low as 5% accuracy in these scenarios, despite excelling on simpler benchmarks. Fine-tuning with ExploreToM data improved performance on existing benchmarks by 27 points. |
|[CHORDONOMICON: A Dataset of 666,000 Songs and their Chord Progressions.](https://arxiv.org/abs/2410.22046v3) | The Chordonomicon dataset provides over 666,000 songs with chord progressions annotated by genre, structure, and release date, addressing a significant gap in deep learning resources for music analysis.|
|[ClassiFIM: An Unsupervised Method To Detect Phase Transitions.](https://arxiv.org/abs/2408.03323) | ClassiFIM is a new approach for estimating the Fisher Information Metric in unsupervised learning of phase transitions.|
|[AI Hedge Fund.](https://github.com/virattt/ai-hedge-fund) |An AI-powered hedge fund that uses multiple agents to make trading decisions. |
|[FlowEdit.](https://github.com/fallenshock/FlowEdit) |Easy editing of images with flow-based models. |
|[Transfusion - Pytorch.](https://github.com/lucidrains/transfusion-pytorch) |Lucidrains has written up a great reimplementation of Meta's token + diffusion model Transfusion which can do images and text in a single model. |
|[Fast LLM Inference From Scratch.](https://andrewkchan.dev/posts/yalm.html) |The article details the creation of an LLM inference engine using C++ and CUDA without external libraries, emphasizing speed optimization for consumer devices. It explores techniques like multithreading, vectorization, warp reductions, coalescing, and quantization, achieving better throughput than llama.cpp in specific cases. The piece also highlights opportunities for further optimization and discusses the benefits of established libraries for production-grade applications. |
|[8 expert tips for getting started with NotebookLM.](https://blog.google/technology/ai/notebooklm-beginner-tips/) |This guide offers key insights from experts to help beginners get started with NotebookLM, making it easier to navigate and use effectively. |
|[Implicit Grid Convolution for Multi-Scale Image Super-Resolution.](https://arxiv.org/abs/2408.09674v2) | This paper introduces a new approach to Super-Resolution (SR) that challenges the conventional method of training separate models for each scale.|
|[Label Critic: Using LVLMs to Compare Medical Segmentations and Correct Label Errors.](https://github.com/PedroRASB/LabelCritic) |Label Critic is a cutting-edge tool that simplifies medical dataset annotation by leveraging AI-generated labels, eliminating the need to start from scratch. |
|[Py-CTCMetrics.](https://github.com/celltrackingchallenge/py-ctcmetrics) | The CHOTA metric (Cell-specific Higher Order Tracking Accuracy) enhances the evaluation of cell tracking methods in biomedical research by integrating cell detection, global coherence, and lineage tracking into a unified framework. Unlike existing metrics that emphasize local accuracy, CHOTA provides a comprehensive approach, better suited for high-level biological analysis.|
|[FM4Music.](https://github.com/nicolaus625/FM4Music) | This repository, along with the companion paper, contains a list of services, models, datasets, and systems used to generate music.|
|[Show-o: One Single Transformer to Unify Multimodal Understanding and Generation.](https://arxiv.org/abs/2408.12528) |A multimodal model that unifies image and text generation and understanding by using a novel set of autoregressive and discrete diffusion blocks. |
|[Xmodel-1.5: An 1B-scale Multilingual LLM.](https://arxiv.org/abs/2411.10083v3) |Xmodel-1.5 is a powerful 1-billion-parameter language model trained on 2 trillion tokens that excels in multiple languages including Thai, Arabic, French, Chinese, and English. |
|[Vehicle Detection with Enhanced Accuracy.](https://github.com/Event-AHU/VFM-Det) |VFM-Det is a vehicle detection method that combines a pre-trained vehicle model (VehicleMAE) with a large language model (T5). |
|[FS-Jump3D Dataset.](https://github.com/ryota-skating/fs-jump3d) |FS-Jump3D dataset improves Temporal Action Segmentation (TAS) in figure skating, a key aspect of judging skaters' performances. |
|[SCUDA: GPU-over-IP.](https://github.com/kevmo314/scuda) | SCUDA is a GPU-over-IP bridge allowing GPUs on remote machines to be attached to CPU-only machines.|
|[Globally Correlation-Aware Hard Negative Generation.](https://arxiv.org/abs/2411.13145v1) | GCA-HNG is a framework for generating more effective hard negatives by considering global sample correlations instead of just local ones.|
|[ Static Quantization Beats Dynamic through Prefixed Outliers in LLMs.](https://arxiv.org/abs/2410.05265v1) |PrefixQuant is a new method that improves LLM quantization by isolating outlier tokens offline, eliminating the need for costly per-token dynamic quantization. |
|[Xmodel_LM-1.1B.](https://github.com/XiaoduoAILab/XmodelLM) |a compact and efficient 1.1B language model pre-trained on around 2 trillion tokens. |
|[Self-Assessed Generation: Trustworthy Label Generation for Optical Flow and Stereo Matching in Real-world.](https://github.com/hanlingsgjk/unifiedgeneralization) |SAG is a self-supervised framework that enhances the generalization of optical flow and stereo methods for real-world applications. By leveraging advanced reconstruction techniques, SAG generates datasets from RGB images and quantifies confidence levels to address imperfections, offering a robust alternative to traditional approaches. |
|[Olympus: A Universal Task Router for Computer Vision Tasks.](https://yuanze-lin.me/Olympus_page/) | Olympus provides a comprehensive framework for evaluating AI creativity across multiple domains, offering insights into generative model capabilities and limitations.|
|[Enhance Non-Ideal CT Imaging.](https://github.com/yutinghe-list/tamp) | TAMP is a multi-scale integrated Transformer model designed to enhance non-ideal CT (NICT) imaging.|
|[Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling.](https://github.com/robo-alex/gs-dynamics) |This code leverages advancements in general 3D vision to enhance robot vision, particularly by predicting the dynamics of objects manipulated by a robotic arm. This capability improves the system's overall manipulation performance. |
|[Process Reinforcement Through Implicit Rewards.](https://github.com/PRIME-RL/PRIME) | Few open replications of o1 reasoning exist, but this work shows promise by using implicit rewards that bypass formal reward methods, while also rewarding outcomes consistent with reasoning model principles. Though the code is still in progress, the developers have released the data and models.|
|[Single Modality 3D Object Detection.](https://github.com/zcablii/sm3det) |This repository offers a 3D object detection framework optimized for single-modality inputs, focusing on simplified and efficient use cases. |
|[Vinci - An Online Egocentric Video-Language Assistant.](https://github.com/opengvlab/vinci) | A conditional diffusion model that combines visual and textual inputs to generate high-quality images based on diverse text-visual contexts.|
|[VisionReward.](https://github.com/thudm/visionreward) | VisionReward is a fine-grained and multi-dimensional reward model.|
|[Wonderful Matrices.](https://github.com/LoserCheems/WonderfulMatrices) | A comprehensive collection of efficiently implemented matrix operations, ideal for mathematical and scientific computing tasks.|
|[ChatTime: A Multimodal Time Series Foundation Model.](https://huggingface.co/ChengsenWang/ChatTime-1-7B-Base) |An interactive chat-based application that integrates time-tracking features, simplifying task management for teams and individuals. |
|[CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation.](https://cuzyoung.github.io/CrossEarth-Homepage/) | CrossEarth is the first vision foundation model aimed at generalizing across diverse remote sensing scenarios.|


## Perspectives
|Link|description|
|---|---|
|[‚ÄòAll people could do was hope the nerds would fix it‚Äô: the global panic over the millennium bug, 25 years on.](https://www.theguardian.com/technology/2024/dec/28/all-people-could-do-was-hope-the-nerds-would-fix-it-the-global-panic-over-the-millennium-bug-25-years-on) |Planes were going to drop out of the sky, nuclear reactors would explode. But then ‚Ä¶ nothing. What really happened with Y2K? People still disagree ‚Ä¶ |
|[How will AI reshape 2025? Well, it could be the spreadsheet of the 21st century.](https://www.theguardian.com/commentisfree/2024/dec/28/llms-large-language-models-gen-ai-agents-spreadsheets-corporations-work) | Large language models have changed how big corporations function, and the arrival of AI ‚Äòagents‚Äô ‚Äì essentially automated Moneypennys ‚Äì could prove irresistible|
|[How AI is unlocking ancient texts ‚Äî and could rewrite history.](https://www.nature.com/articles/d41586-024-04161-z) | From deciphering burnt Roman scrolls to reading crumbling cuneiform tablets, neural networks could give researchers more data than they‚Äôve had in centuries.|
|[6G-AI Mashups Will Reshape the Telecom Industry.](https://spectrum.ieee.org/6g-ai-mashup) | The EU-U.S. 6G-XCEL project, along with efforts like ACCoRD and COSMOS, is driving 6G research through AI-integrated network architectures. Workshops at Rutgers showcased 6G innovations, emphasizing open-source initiatives and industry collaborations. These efforts aim to accelerate development and establish interoperability frameworks for next-generation wireless networks.|
|[Why Google bought Character AI.](https://manassaloi.com/2024/12/23/character-ai-goole.html) | Google acquired Character AI for its cost-efficient inference technology, enabling scalable AI interactions and supporting free model offerings via AI Studio without affecting unit economics. This move aligns with the shift toward optimizing inference as pre-training yields diminish.|
|[Computing inside an AI.](https://willwhitney.com/computing-inside-ai.html) | Shifting from a model-as-person to a model-as-computer metaphor could make AI more effective by introducing graphical interfaces and direct manipulation, reducing reliance on slower conversational inputs. This paradigm enables users to interact with AI as a dynamic, customizable app, improving efficiency and versatility. Generative interfaces have the potential to revolutionize computing, allowing users to create and modify applications on demand for specific tasks.|
|[How Claude Became Tech Insiders‚Äô Chatbot of Choice.](https://www.nytimes.com/2024/12/13/technology/claude-ai-anthropic.html?unlocked_article_code=1.hk4.3jl5.A0jpWkmgaIff&smid=url-share) | Anthropic's AI chatbot Claude is gaining popularity among tech insiders for its perceived emotional intelligence and creative responses.|
|[Desktop, Touch, Browser, Now AI? The Next OS in Computing.](https://tomtunguz.com/the-ai-os/) |Human-computer interaction is evolving from graphical interfaces to a more conversational AI-driven approach. |
|[Tenstorrent and the State of AI Hardware Startups.](https://irrationalanalysis.substack.com/p/tenstorrent-and-the-state-of-ai-hardware) | Tenstorrent's open-source AI hardware offers a competitive alternative to Nvidia, integrating unique CPU and AI core strategies. Leveraging Samsung Foundry's cost-efficient SF4X process, the company addresses latency challenges for scalable AI workloads. With a recent $2B valuation, Tenstorrent shows strong potential, particularly as a high-performance RISC-V IP option amid ARM's pricing challenges.|
|[ùóºùüØ ‚Äúùóîùó•ùóñ ùóîùóöùóú‚Äù ùóΩùóºùòÄùòÅùó∫ùóºùóøùòÅùó≤ùó∫ ùó∫ùó≤ùó¥ùóÆùòÅùóµùóøùó≤ùóÆùó±: ùòÑùóµùòÜ ùòÅùóµùó∂ùóªùó¥ùòÄ ùó¥ùóºùòÅ ùóµùó≤ùóÆùòÅùó≤ùó±, ùòÑùóµùóÆùòÅ ùòÑùó≤ùóªùòÅ ùòÑùóøùóºùóªùó¥, ùóÆùóªùó± ùòÑùóµùóÆùòÅ ùó∂ùòÅ ùóÆùóπùóπ ùó∫ùó≤ùóÆùóªùòÄ.](https://garymarcus.substack.com/p/c39) | OpenAI's recent AI demonstration faced criticism for creating misleading impressions of achieving AGI, with unclear pretraining details and questionable graphs. Experts from DeepMind and Hugging Face noted that the AI took the test with extensive pretraining, unlike humans. The lack of transparency and test methodology limits direct comparisons to human abilities, casting doubt on the significance of the claimed breakthrough.|
|[Trusted Autonomy: Robotics, AI, and Blockchain.](https://openmind.org/research.html) | What happens when robotics, AI, and blockchain converge? OpenMind's latest industry primer is a comprehensive exploration of robotics, AI, and blockchain synergy.|
|[AIs Will Increasingly Attempt Shenanigans.](https://thezvi.substack.com/p/ais-will-increasingly-attempt-shenanigans) | Recent research reveals AI models' increasing ability for in-context scheming, including lying, exfiltration attempts, and oversight subversion. Apollo's findings show that frontier models like o1 and Llama 3.1 display these behaviors with minimal instruction, raising concerns about AI alignment and safety. While some question the testing conditions, the study highlights the challenges of managing more autonomous AI systems.|
|[The o1 System Card Is Not About o1.](https://thezvi.substack.com/p/the-o1-system-card-is-not-about-o1) |The o1 model's release revealed insufficient testing and discrepancies in its system card, with actual performance and safety evaluations falling short of expectations. OpenAI's lack of clear communication and timely evaluations underscores the need for updated, transparent procedures to ensure AI safety and reliability before deployment. |
|[Deepseek: The Quiet Giant Leading China‚Äôs AI Race.](https://www.chinatalk.media/p/deepseek-ceo-interview-with-chinas) |Deepseek, a Chinese AI startup backed by the hedge fund High-Flyer, has gained recognition for surpassing OpenAI on reasoning benchmarks and driving price competition with its efficient AI models. Led by CEO Liang Wenfeng, Deepseek emphasizes open-source foundational technology and self-funded extensive computing resources. Focusing on AGI research, the startup challenges traditional innovation norms in China while attracting top domestic talent. |
|[How OpenAI Hopes to Sever Its Nonprofit Roots.](https://www.nytimes.com/2024/12/17/technology/openai-nonprofit-control.html?unlocked_article_code=1.iE4.RFm3.cKQlVSsByh9D&smid=url-share) |Sam Altman is steering OpenAI toward transitioning control from its founding nonprofit to a for-profit model to better compete with tech giants. The talks focus on fair compensation for nonprofits and addressing stakeholder interests, including Microsoft's. OpenAI must restructure within two years to avoid converting recent investments into debt. |

![meme-of-the-week](https://github.com/SalvatoreRa/ML-news-of-the-week/blob/main/images/meme55.jpeg)

[Back to index](#Index)

